[{"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large language models have emerged abilities including chain-of-thought toanswer math word problems step by step. Solving math word problems not onlyrequires abilities to disassemble problems via chain-of-thought but also needsto calculate arithmetic expressions correctly for each step. To the best of ourknowledge, there is no work to focus on evaluating the arithmetic ability oflarge language models. In this work, we propose an arithmetic dataset MATH 401to test the latest large language models including GPT-4, ChatGPT, InstrctGPT,Galactica, and LLaMA with various arithmetic expressions and provide a detailedanalysis of the ability of large language models. MATH 401 and evaluation codesare released at url{", "output": "How well do Large Language Models perform in Arithmetic tasks?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine Unlearning has recently been emerging as a paradigm for selectivelyremoving the impact of training datapoints from a network. While existingapproaches have focused on unlearning either a small subset of the trainingdata or a single class, in this paper we take a different path and devise aframework that can unlearn all classes of an image classification network in asingle untraining round. Our proposed technique learns to modulate the innercomponents of an image classification network through memory matrices so that,after training, the same network can selectively exhibit an unlearning behaviorover any of the classes. By discovering weights which are specific to each ofthe classes, our approach also recovers a representation of the classes whichis explainable by-design. We test the proposed framework, which we name WeightFiltering network (WF-Net), on small-scale and medium-scale imageclassification datasets, with both CNN and Transformer-based backbones. Ourwork provides interesting insights in the development of explainable solutionsfor unlearning and could be easily extended to other vision tasks.", "output": "Multi-Class Explainable Unlearning for Image Classification via Weight Filtering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fashion illustration is used by designers to communicate their vision and tobring the design idea from conceptualization to realization, showing howclothes interact with the human body. In this context, computer vision can thusbe used to improve the fashion design process. Differently from previous worksthat mainly focused on the virtual try-on of garments, we propose the task ofmultimodal-conditioned fashion image editing, guiding the generation ofhuman-centric fashion images by following multimodal prompts, such as text,human body poses, and garment sketches. We tackle this problem by proposing anew architecture based on latent diffusion models, an approach that has notbeen used before in the fashion domain. Given the lack of existing datasetssuitable for the task, we also extend two existing fashion datasets, namelyDress Code and VITON-HD, with multimodal annotations collected in asemi-automatic manner. Experimental results on these new datasets demonstratethe effectiveness of our proposal, both in terms of realism and coherence withthe given multimodal inputs. Source code and collected multimodal annotationswill be publicly released at:", "output": "Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Robotic solutions for quick disaster response are essential to ensure minimalloss of life, especially when the search area is too dangerous or too vast forhuman rescuers. We model this problem as an asynchronous multi-agentactive-search task where each robot aims to efficiently seek objects ofinterest (OOIs) in an unknown environment. This formulation addresses therequirement that search missions should focus on quick recovery of OOIs ratherthan full coverage of the search region. Previous approaches fail to accuratelymodel sensing uncertainty, account for occlusions due to foliage or terrain, orconsider the requirement for heterogeneous search teams and robustness tohardware and communication failures. We present the GeneralizedUncertainty-aware Thompson Sampling (GUTS) algorithm, which addresses theseissues and is suitable for deployment on heterogeneous multi-robot systems foractive search in large unstructured environments. We show through simulationexperiments that GUTS consistently outperforms existing methods such asparallelized Thompson Sampling and exhaustive search, recovering all OOIs in80% of all runs. In contrast, existing approaches recover all OOIs in less than40% of all runs. We conduct field tests using our multi-robot system in anunstructured environment with a search area of approximately 75,000 sq. m. Oursystem demonstrates robustness to various failure modes, achieving fullrecovery of OOIs (where feasible) in every field run, and significantlyoutperforming our baseline.", "output": "GUTS: Generalized Uncertainty-Aware Thompson Sampling for Multi-Agent Active Search."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Stock market forecasting has been a challenging part for many analysts andresearchers. Trend analysis, statistical techniques, and movement indicatorshave traditionally been used to predict stock price movements, but textextraction has emerged as a promising method in recent years. The use of neuralnetworks, especially recurrent neural networks, is abundant in the literature.In most studies, the impact of different users was considered equal or ignored,whereas users can have other effects. In the current study, we will introduceTM-vector and then use this vector to train an IndRNN and ultimately model themarket users' behaviour. In the proposed model, TM-vector is simultaneouslytrained with both the extracted Twitter features and market information.Various factors have been used for the effectiveness of the proposedforecasting approach, including the characteristics of each individual user,their impact on each other, and their impact on the market, to predict marketdirection more accurately. Dow Jones 30 index has been used in current work.The accuracy obtained for predicting daily stock changes of Apple is based onvarious models, closed to over 95% and for the other stocks is significant.Our results indicate the effectiveness of TM-vector in predicting stock marketdirection.", "output": "TM-vector: A Novel Forecasting Approach for Market stock movement with a Rich Representation of Twitter and Market data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Modeling the 3D world from sensor data for simulation is a scalable way ofdeveloping testing and validation environments for robotic learning problemssuch as autonomous driving. However, manually creating or re-creatingreal-world-like environments is difficult, expensive, and not scalable. Recentgenerative model techniques have shown promising progress to address suchchallenges by learning 3D assets using only plentiful 2D images -- but stillsuffer limitations as they leverage either human-curated image datasets orrenderings from manually-created synthetic 3D environments. In this paper, weintroduce GINA-3D, a generative model that uses real-world driving data fromcamera and LiDAR sensors to create realistic 3D implicit neural assets ofdiverse vehicles and pedestrians. Compared to the existing image datasets, thereal-world driving setting poses new challenges due to occlusions,lighting-variations and long-tail distributions. GINA-3D tackles thesechallenges by decoupling representation learning and generative modeling intotwo stages with a learned tri-plane latent structure, inspired by recentadvances in generative modeling of images. To evaluate our approach, weconstruct a large-scale object-centric dataset containing over 520K images ofvehicles and pedestrians from the Waymo Open Dataset, and a new set of 80Kimages of long-tail instances such as construction equipment, garbage trucks,and cable cars. We compare our model with existing approaches and demonstratethat it achieves state-of-the-art performance in quality and diversity for bothgenerated images and geometries.", "output": "GINA-3D: Learning to Generate Implicit Neural Assets in the Wild."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Adapters present a promising solution to the catastrophic forgetting problemin continual learning. However, training independent Adapter modules for everynew task misses an opportunity for cross-task knowledge transfer. We proposeImprovise to Initialize (I2I), a continual learning algorithm that initializesAdapters for incoming tasks by distilling knowledge from previously-learnedtasks' Adapters. We evaluate I2I on CLiMB, a multimodal continual learningbenchmark, by conducting experiments on sequences of visual question answeringtasks. Adapters trained with I2I consistently achieve better task accuracy thanindependently-trained Adapters, demonstrating that our algorithm facilitatesknowledge transfer between task Adapters. I2I also results in better cross-taskknowledge transfer than the state-of-the-art AdapterFusion without incurringthe associated parametric cost.", "output": "I2I: Initializing Adapters with Improvised Knowledge."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Synthetic electronic health records (EHRs) that are both realistic andpreserve privacy can serve as an alternative to real EHRs for machine learning(ML) modeling and statistical analysis. However, generating high-fidelity andgranular electronic health record (EHR) data in its original,highly-dimensional form poses challenges for existing methods due to thecomplexities inherent in high-dimensional data. In this paper, we proposeHierarchical Autoregressive Language mOdel (HALO) for generating longitudinalhigh-dimensional EHR, which preserve the statistical properties of real EHR andcan be used to train accurate ML models without privacy concerns. Our HALOmethod, designed as a hierarchical autoregressive model, generates aprobability density function of medical codes, clinical visits, and patientrecords, allowing for the generation of realistic EHR data in its original,unaggregated form without the need for variable selection or aggregation.Additionally, our model also produces high-quality continuous variables in alongitudinal and probabilistic manner. We conducted extensive experiments anddemonstrate that HALO can generate high-fidelity EHR data with high-dimensionaldisease code probabilities (d &gt; 10,000), disease co-occurrence probabilitieswithin visits (d &gt; 1,000,000), and conditional probabilities across consecutivevisits (d &gt; 5,000,000) and achieve above 0.9 R2 correlation in comparison toreal EHR data. This performance then enables downstream ML models trained onits synthetic data to achieve comparable accuracy to models trained on realdata (0.938 AUROC with HALO data vs. 0.943 with real data). Finally, using acombination of real and synthetic data enhances the accuracy of ML modelsbeyond that achieved by using only real EHR data.", "output": "Synthesize Extremely High-dimensional Longitudinal Electronic Health Records via Hierarchical Autoregressive Language Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Charts are a powerful tool for visually conveying complex data, but theircomprehension poses a challenge due to the diverse chart types and intricatecomponents. Existing chart comprehension methods suffer from either heuristicrules or an over-reliance on OCR systems, resulting in suboptimal performance.To address these issues, we present ChartReader, a unified framework thatseamlessly integrates chart derendering and comprehension tasks. Our approachincludes a transformer-based chart component detection module and an extendedpre-trained vision-language model for chart-to-X tasks. By learning the rulesof charts automatically from annotated datasets, our approach eliminates theneed for manual rule-making, reducing effort and enhancing accuracy.~We alsointroduce a data variable replacement technique and extend the input andposition embeddings of the pre-trained model for cross-task training. Weevaluate ChartReader on Chart-to-Table, ChartQA, and Chart-to-Text tasks,demonstrating its superiority over existing methods. Our proposed framework cansignificantly reduce the manual effort involved in chart analysis, providing astep towards a universal chart understanding model. Moreover, our approachoffers opportunities for plug-and-play integration with mainstream LLMs such asT5 and TaPas, extending their capability to chart comprehension tasks. The codeis available at ", "output": "ChartReader: A Unified Framework for Chart Derendering and Comprehension without Heuristic Rules."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Artificial intelligence (AI) systems can cause harm to people. This researchexamines how individuals react to such harm through the lens of blame. Buildingupon research suggesting that people blame AI systems, we investigated howseveral factors influence people's reactive attitudes towards machines,designers, and users. The results of three studies (N = 1,153) indicatedifferences in how blame is attributed to these actors. Whether AI systems wereexplainable did not impact blame directed at them, their developers, and theirusers. Considerations about fairness and harmfulness increased blame towardsdesigners and users but had little to no effect on judgments of AI systems.Instead, what determined people's reactive attitudes towards machines waswhether people thought blaming them would be a suitable response to algorithmicharm. We discuss implications, such as how future decisions about including AIsystems in the social and moral spheres will shape laypeople's reactions toAI-caused harm.", "output": "Blaming Humans and Machines: What Shapes People's Reactions to Algorithmic Harm."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Body movements carry important information about a person's emotions ormental state and are essential in daily communication. Enhancing the ability ofmachines to understand emotions expressed through body language can improve thecommunication of assistive robots with children and elderly users, providepsychiatric professionals with quantitative diagnostic and prognosticassistance, and aid law enforcement in identifying deception. This studydevelops a high-quality human motor element dataset based on the Laban MovementAnalysis movement coding system and utilizes that to jointly learn about motorelements and emotions. Our long-term ambition is to integrate knowledge fromcomputing, psychology, and performing arts to enable automated understandingand analysis of emotion and mental state through body language. This workserves as a launchpad for further research into recognizing emotions throughanalysis of human movement.", "output": "Bodily expressed emotion understanding through integrating Laban movement analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With growing machine learning (ML) applications in healthcare, there havebeen calls for fairness in ML to understand and mitigate ethical concerns thesesystems may pose. Fairness has implications for global health in Africa, whichalready has inequitable power imbalances between the Global North and South.This paper seeks to explore fairness for global health, with Africa as a casestudy. We propose fairness attributes for consideration in the African contextand delineate where they may come into play in different ML-enabled medicalmodalities. This work serves as a basis and call for action for furtheringresearch into fairness in global health.", "output": "Globalizing Fairness Attributes in Machine Learning: A Case Study on Health in Africa."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-turn compositional image generation (M-CIG) is a challenging task thataims to iteratively manipulate a reference image given a modification text.While most of the existing methods for M-CIG are based on generativeadversarial networks (GANs), recent advances in image generation havedemonstrated the superiority of diffusion models over GANs. In this paper, wepropose a diffusion-based method for M-CIG named conditional denoisingdiffusion with image compositional matching (CDD-ICM). We leverage CLIP as thebackbone of image and text encoders, and incorporate a gated fusion mechanism,originally proposed for question answering, to compositionally fuse thereference image and the modification text at each turn of M-CIG. We introduce aconditioning scheme to generate the target image based on the fusion results.To prioritize the semantic quality of the generated target image, we learn anauxiliary image compositional match (ICM) objective, along with the conditionaldenoising diffusion (CDD) objective in a multi-task learning framework.Additionally, we also perform ICM guidance and classifier-free guidance toimprove performance. Experimental results show that CDD-ICM achievesstate-of-the-art results on two benchmark datasets for M-CIG, i.e., CoDraw andi-CLEVR.", "output": "A Diffusion-based Method for Multi-turn Compositional Image Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Student modeling, the task of inferring a student's learning characteristicsthrough their interactions with coursework, is a fundamental issue inintelligent education. Although the recent attempts from knowledge tracing andcognitive diagnosis propose several promising directions for improving theusability and effectiveness of current models, the existing public datasets arestill insufficient to meet the need for these potential solutions due to theirignorance of complete exercising contexts, fine-grained concepts, and cognitivelabels. In this paper, we present MoocRadar, a fine-grained, multi-aspectknowledge repository consisting of 2,513 exercise questions, 5,600 knowledgeconcepts, and over 12 million behavioral records. Specifically, we propose aframework to guarantee a high-quality and comprehensive annotation offine-grained concepts and cognitive labels. The statistical and experimentalresults indicate that our dataset provides the basis for the futureimprovements of existing methods. Moreover, to support the convenient usage forresearchers, we release a set of tools for data querying, model adaption, andeven the extension of our repository, which are now available at", "output": "MoocRadar: A Fine-grained and Multi-aspect Knowledge Repository for Improving Cognitive Student Modeling in MOOCs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large language models (LLMs) such as Chat-GPT can produce coherent, cohesive,relevant, and fluent answers for various natural language processing (NLP)tasks. Taking document-level machine translation (MT) as a testbed, this paperprovides an in-depth evaluation of LLMs' ability on discourse modeling. Thestudy fo-cuses on three aspects: 1) Effects of Discourse-Aware Prompts, wherewe investigate the impact of different prompts on document-level translationquality and discourse phenomena; 2) Comparison of Translation Models, where wecompare the translation performance of Chat-GPT with commercial MT systems andadvanced document-level MT methods; 3) Analysis of Discourse ModellingAbilities, where we further probe discourse knowledge encoded in LLMs andexamine the impact of training techniques on discourse modeling. By evaluatinga number of benchmarks, we surprisingly find that 1) leveraging their powerfullong-text mod-eling capabilities, ChatGPT outperforms commercial MT systems interms of human evaluation. 2) GPT-4 demonstrates a strong ability to explaindiscourse knowledge, even through it may select incorrect translationcandidates in contrastive testing. 3) ChatGPT and GPT-4 have demonstratedsuperior performance and show potential to become a new and promising paradigmfor document-level translation. This work highlights the challenges andopportunities of discourse modeling for LLMs, which we hope can inspire thefuture design and evaluation of LLMs.", "output": "Document-Level Machine Translation with Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This article presents a new NLP task called structured information inference(SIS) to address the complexities of information extraction at the device levelin materials science. We accomplished this task by finetuning GPT-3 on aexsiting perovskite solar cell FAIR dataset with 91.8 F1-score and we updatedthe dataset with all related scientific papers up to now. The produced datasetis formatted and normalized, enabling its direct utilization as input insubsequent data analysis. This feature will enable materials scientists todevelop their own models by selecting high-quality review papers within theirdomain. Furthermore, we designed experiments to predict PCE and reverse-predictparameters and obtained comparable performance with DFT, which demonstrates thepotential of large language models to judge materials and design new materialslike a materials scientist.", "output": "Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Open-domain conversational search (ODCS) aims to provide valuable, up-to-dateinformation, while maintaining natural conversations to help users refine andultimately answer information needs. However, creating an effective and robustODCS agent is challenging. In this paper, we present a fully functional ODCSsystem, Ericson, which includes state-of-the-art question answering andinformation retrieval components, as well as intent inference and dialoguemanagement models for proactive question refinement and recommendations. Oursystem was stress-tested in the Amazon Alexa Prize, by engaging in liveconversations with thousands of Alexa users, thus providing empirical basis forthe analysis of the ODCS system in real settings. Our interaction data analysisrevealed that accurate intent classification, encouraging user engagement, andcareful proactive recommendations contribute most to the users satisfaction.Our study further identifies limitations of the existing search techniques, andcan serve as a building block for the next generation of ODCS agents.", "output": "Ericson: An Interactive Open-Domain Conversational Search Agent."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite their prevalence in eHealth applications for behavior change,persuasive messages tend to have small effects on behavior. Conditions orstates (e.g., confidence, knowledge, motivation) and characteristics (e.g.,gender, age, personality) of persuadees are two promising components for moreeffective algorithms for choosing persuasive messages. However, it is not yetsufficiently clear how well considering these components allows one to predictbehavior after persuasive attempts, especially in the long run. Sincecollecting data for many algorithm components is costly and places a burden onusers, a better understanding of the impact of individual components inpractice is welcome. This can help to make an informed decision on whichcomponents to use. We thus conducted a longitudinal study in which a virtualcoach persuaded 671 daily smokers to do preparatory activities for quittingsmoking and becoming more physically active, such as envisioning one's desiredfuture self. Based on the collected data, we designed a Reinforcement Learning(RL)-approach that considers current and future states to maximize the effortpeople spend on their activities. Using this RL-approach, we found, based onleave-one-out cross-validation, that considering states helps to predict bothbehavior and future states. User characteristics and especially involvement inthe activities, on the other hand, only help to predict behavior if used incombination with states rather than alone. We see these results as supportingthe use of states and involvement in persuasion algorithms. Our dataset isavailable online.", "output": "Persuading to Prepare for Quitting Smoking with a Virtual Coach: Using States and User Characteristics to Predict Behavior."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A method is presented that allows to reduce a problem described bydifferential equations with initial and boundary conditions to the problemdescribed only by differential equations. The advantage of using the modifiedproblem for physics-informed neural networks (PINNs) methodology is that itbecomes possible to represent the loss function in the form of a single termassociated with differential equations, thus eliminating the need to tune thescaling coefficients for the terms related to boundary and initial conditions.The weighted loss functions respecting causality were modified and new weightedloss functions based on generalized functions are derived. Numericalexperiments have been carried out for a number of problems, demonstrating theaccuracy of the proposed methods.", "output": "About optimal loss function for training physics-informed neural networks under respecting causality."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pest counting, which predicts the number of pests in the early stage, is veryimportant because it enables rapid pest control, reduces damage to crops, andimproves productivity. In recent years, light traps have been increasingly usedto lure and photograph pests for pest counting. However, pest images have awide range of variability in pest appearance owing to severe occlusion, widepose variation, and even scale variation. This makes pest counting morechallenging. To address these issues, this study proposes a new pest countingmodel referred to as multiscale and deformable attention CenterNet(Mada-CenterNet) for internal low-resolution (LR) and high-resolution (HR)joint feature learning. Compared with the conventional CenterNet, the proposedMada-CenterNet adopts a multiscale heatmap generation approach in a two-stepfashion to predict LR and HR heatmaps adaptively learned to scale variations,that is, changes in the number of pests. In addition, to overcome the pose andocclusion problems, a new between-hourglass skip connection based on deformableand multiscale attention is designed to ensure internal LR and HR joint featurelearning and incorporate geometric deformation, thereby resulting in animproved pest counting accuracy. Through experiments, the proposedMada-CenterNet is verified to generate the HR heatmap more accurately andimprove pest counting accuracy owing to multiscale heatmap generation, jointinternal feature learning, and deformable and multiscale attention. Inaddition, the proposed model is confirmed to be effective in overcoming severeocclusions and variations in pose and scale. The experimental results show thatthe proposed model outperforms state-of-the-art crowd counting and objectdetection models.", "output": "Trap-Based Pest Counting: Multiscale and Deformable Attention CenterNet Integrating Internal LR and HR Joint Feature Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The transferability of adversarial examples is a key issue in the security ofdeep neural networks. The possibility of an adversarial example crafted for asource model fooling another targeted model makes the threat of adversarialattacks more realistic. Measuring transferability is a crucial problem, but theAttack Success Rate alone does not provide a sound evaluation. This paperproposes a new methodology for evaluating transferability by putting distortionin a central position. This new tool shows that transferable attacks mayperform far worse than a black box attack if the attacker randomly picks thesource model. To address this issue, we propose a new selection mechanism,called FiT, which aims at choosing the best source model with only a fewpreliminary queries to the target. Our experimental results show that FiT ishighly effective at selecting the best source model for multiple scenarios suchas single-model attacks, ensemble-model attacks and multiple attacks (Codeavailable at: ", "output": "How to choose your best allies for a transferable attack?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Convolutional neural networks (CNNs) have shown state-of-the-art performancein various applications. However, CNNs are resource-hungry due to theirrequirement of high computational complexity and memory storage. Recent effortstoward achieving computational efficiency in CNNs involve filter pruningmethods that eliminate some of the filters in CNNs based on theenquote{importance} of the filters. The majority of existing filter pruningmethods are either \"active\", which use a dataset and generate feature maps toquantify filter importance, or \"passive\", which compute filter importance usingentry-wise norm of the filters without involving data. Under a high pruningratio where large number of filters are to be pruned from the network, theentry-wise norm methods eliminate relatively smaller norm filters withoutconsidering the significance of the filters in producing the node output,resulting in degradation in the performance. To address this, we present apassive filter pruning method where the filters are pruned based on theircontribution in producing output by considering the operator norm of thefilters. The proposed pruning method generalizes better across various CNNscompared to that of the entry-wise norm-based pruning methods. In comparison tothe existing active filter pruning methods, the proposed pruning method is atleast 4.5 times faster in computing filter importance and is able to achievesimilar performance compared to that of the active filter pruning methods. Theefficacy of the proposed pruning method is evaluated on audio sceneclassification and image classification using various CNNs architecture such asVGGish, DCASE21_Net, VGG-16 and ResNet-50.", "output": "Efficient CNNs via Passive Filter Pruning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The ability to explain decisions made by machine learning models remains oneof the most significant hurdles towards widespread adoption of AI in highlysensitive areas such as medicine, cybersecurity or autonomous driving. Greatinterest exists in understanding which features of the input data prompt modeldecision making. In this contribution, we propose a novel approach to identifyrelevant features of the input data, inspired by methods from the energylandscapes field, developed in the physical sciences. By identifying conservedweights within groups of minima of the loss landscapes, we can identify thedrivers of model decision making. Analogues to this idea exist in the molecularsciences, where coordinate invariants or order parameters are employed toidentify critical features of a molecule. However, no such approach exists formachine learning loss landscapes. We will demonstrate the applicability ofenergy landscape methods to machine learning models and give examples, bothsynthetic and from the real world, for how these methods can help to makemodels more interpretable.", "output": "Physics-Inspired Interpretability Of Machine Learning Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although Reinforcement Learning (RL) has shown to be capable of producingimpressive results, its use is limited by the impact of its hyperparameters onperformance. This often makes it difficult to achieve good results in practice.Automated RL (AutoRL) addresses this difficulty, yet little is known about thedynamics of the hyperparameter landscapes that hyperparameter optimization(HPO) methods traverse in search of optimal configurations. In view of existingAutoRL approaches dynamically adjusting hyperparameter configurations, wepropose an approach to build and analyze these hyperparameter landscapes notjust for one point in time but at multiple points in time throughout training.Addressing an important open question on the legitimacy of such dynamic AutoRLapproaches, we provide thorough empirical evidence that the hyperparameterlandscapes strongly vary over time across representative algorithms from RLliterature (DQN and SAC) in different kinds of environments (Cartpole andHopper). This supports the theory that hyperparameters should be dynamicallyadjusted during training and shows the potential for more insights on AutoRLproblems that can be gained through landscape analyses.", "output": "AutoRL Hyperparameter Landscapes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Jointly harnessing complementary features of multi-modal input data in acommon latent space has been found to be beneficial long ago. However, theinfluence of each modality on the models decision remains a puzzle. This studyproposes a deep learning framework for the modality-level interpretation ofmultimodal earth observation data in an end-to-end fashion. While leveraging anexplainable machine learning method, namely Occlusion Sensitivity, the proposedframework investigates the influence of modalities under an early-fusionscenario in which the modalities are fused before the learning process. We showthat the task of wilderness mapping largely benefits from auxiliary data suchas land cover and night time light data.", "output": "Explaining Multimodal Data Fusion: Occlusion Analysis for Wilderness Mapping."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Knowledge tracing (KT) aims to assess individuals' evolving knowledge statesaccording to their learning interactions with different exercises in onlinelearning systems (OIS), which is critical in supporting decision-making forsubsequent intelligent services, such as personalized learning sourcerecommendation. Existing researchers have broadly studied KT and developed manyeffective methods. However, most of them assume that students' historicalinteractions are uniformly distributed in a continuous sequence, ignoring thefact that actual interaction sequences are organized based on a series ofquizzes with clear boundaries, where interactions within a quiz areconsecutively completed, but interactions across different quizzes are discreteand may be spaced over days. In this paper, we present the Quiz-based KnowledgeTracing (QKT) model to monitor students' knowledge states according to theirquiz-based learning interactions. Specifically, as students' interactionswithin a quiz are continuous and have the same or similar knowledge concepts,we design the adjacent gate followed by a global average pooling layer tocapture the intra-quiz short-term knowledge influence. Then, as various quizzestend to focus on different knowledge concepts, we respectively measure theinter-quiz knowledge substitution by the gated recurrent unit and theinter-quiz knowledge complementarity by the self-attentive encoder with a novelrecency-aware attention mechanism. Finally, we integrate the inter-quizlong-term knowledge substitution and complementarity across different quizzesto output students' evolving knowledge states. Extensive experimental resultson three public real-world datasets demonstrate that QKT achievesstate-of-the-art performance compared to existing methods. Further analysesconfirm that QKT is promising in designing more effective quizzes.", "output": "Quiz-based Knowledge Tracing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "English as foreign language_EFL_students' use of text generated fromartificial intelligence_AI_natural language generation_NLG_tools may improvetheir writing quality. However, it remains unclear to what extent AI-generatedtext in these students' writing might lead to higher-quality writing. Weexplored 23 Hong Kong secondary school students' attempts to write storiescomprising their own words and AI-generated text. Human experts scored thestories for dimensions of content, language and organization. We analyzed thebasic organization and structure and syntactic complexity of the stories'AI-generated text and performed multiple linear regression and clusteranalyses. The results show the number of human words and the number ofAI-generated words contribute significantly to scores. Besides, students can begrouped into competent and less competent writers who use more AI-generatedtext or less AI-generated text compared to their peers. Comparisons of clustersreveal some benefit of AI-generated text in improving the quality of bothhigh-scoring students' and low-scoring students' writing. The findings caninform pedagogical strategies to use AI-generated text for EFL students'writing and to address digital divides. This study contributes designs of NLGtools and writing activities to implement AI-generated text in schools.", "output": "Exploring AI-Generated Text in Student Writing: How Does AI Help?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent developments in deep learning have resulted in code-generation modelsthat produce source code from natural language and code-based prompts with highaccuracy. This is likely to have profound effects in the classroom, wherenovices learning to code can now use free tools to automatically suggestsolutions to programming exercises and assignments. However, little iscurrently known about how novices interact with these tools in practice. Wepresent the first study that observes students at the introductory level usingone such code auto-generating tool, Github Copilot, on a typical introductoryprogramming (CS1) assignment. Through observations and interviews we explorestudent perceptions of the benefits and pitfalls of this technology forlearning, present new observed interaction patterns, and discuss cognitive andmetacognitive difficulties faced by students. We consider design implicationsof these findings, specifically in terms of how tools like Copilot can bettersupport and scaffold the novice programming experience.", "output": "\"It's Weird That it Knows What I Want\": Usability and Interactions with Copilot for Novice Programmers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Children typically learn the meanings of nouns earlier than the meanings ofverbs. However, it is unclear whether this asymmetry is a result of complexityin the visual structure of categories in the world to which language refers,the structure of language itself, or the interplay between the two sources ofinformation. We quantitatively test these three hypotheses regarding early verblearning by employing visual and linguistic representations of words sourcedfrom large-scale pre-trained artificial neural networks. Examining thestructure of both visual and linguistic embedding spaces, we find, first, thatthe representation of verbs is generally more variable and less discriminablewithin domain than the representation of nouns. Second, we find that if onlyone learning instance per category is available, visual and linguisticrepresentations are less well aligned in the verb system than in the nounsystem. However, in parallel with the course of human language development, ifmultiple learning instances per category are available, visual and linguisticrepresentations become almost as well aligned in the verb system as in the nounsystem. Third, we compare the relative contributions of factors that maypredict learning difficulty for individual words. A regression analysis revealsthat visual variability is the strongest factor that internally drives verblearning, followed by visual-linguistic alignment and linguistic variability.Based on these results, we conclude that verb acquisition is influenced by allthree sources of complexity, but that the variability of visual structure posesthe most significant challenge for verb learning.", "output": "Quantifying the Roles of Visual, Linguistic, and Visual-Linguistic Complexity in Verb Acquisition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in large language models (LLMs) have shown impressive abilityin biomedical question-answering, but have not been adequately investigated formore specific biomedical applications. This study investigates the performanceof LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedicaltasks beyond question-answering. Because no patient data can be passed to theOpenAI API public interface, we evaluated model performance with over 10000samples as proxies for two fundamental tasks in the clinical domain -classification and reasoning. The first task is classifying whether statementsof clinical and policy recommendations in scientific literature constitutehealth advice. The second task is causal relation detection from the biomedicalliterature. We compared LLMs with simpler models, such as bag-of-words (BoW)with logistic regression, and fine-tuned BioBERT models. Despite the excitementaround viral ChatGPT, we found that fine-tuning for two fundamental NLP tasksremained the best strategy. The simple BoW model performed on par with the mostcomplex LLM prompting. Prompt engineering required significant investment.", "output": "Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Bandit learning algorithms have been an increasingly popular design choicefor recommender systems. Despite the strong interest in bandit learning fromthe community, there remains multiple bottlenecks that prevent many banditlearning approaches from productionalization. Two of the most importantbottlenecks are scaling to multi-task and A/B testing. Classic banditalgorithms, especially those leveraging contextual information, often requiresreward for uncertainty estimation, which hinders their adoptions in multi-taskrecommender systems. Moreover, different from supervised learning algorithms,bandit learning algorithms emphasize greatly on the data collection processthrough their explorative nature. Such explorative behavior induces unfairevaluation for bandit learning agents in a classic A/B test setting. In thiswork, we present a novel design of production bandit learning life-cycle forrecommender systems, along with a novel set of metrics to measure theirefficiency in user exploration. We show through large-scale productionrecommender system experiments and in-depth analysis that our bandit agentdesign improves personalization for the production recommender system and ourexperiment design fairly evaluates the performance of bandit learningalgorithms.", "output": "Optimism Based Exploration in Large-Scale Recommender Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reinforcement Learning aims at identifying and evaluating efficient controlpolicies from data. In many real-world applications, the learner is not allowedto experiment and cannot gather data in an online manner (this is the case whenexperimenting is expensive, risky or unethical). For such applications, thereward of a given policy (the target policy) must be estimated using historicaldata gathered under a different policy (the behavior policy). Most methods forthis learning task, referred to as Off-Policy Evaluation (OPE), do not comewith accuracy and certainty guarantees. We present a novel OPE method based onConformal Prediction that outputs an interval containing the true reward of thetarget policy with a prescribed level of certainty. The main challenge in OPEstems from the distribution shift due to the discrepancies between the targetand the behavior policies. We propose and empirically evaluate different waysto deal with this shift. Some of these methods yield conformalized intervalswith reduced length compared to existing approaches, while maintaining the samecertainty level.", "output": "Conformal Off-Policy Evaluation in Markov Decision Processes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The brain is not only constrained by energy needed to fuel computation, butit is also constrained by energy needed to form memories. Experiments haveshown that learning simple conditioning tasks already carries a significantmetabolic cost. Yet, learning a task like MNIST to 95% accuracy appears torequire at least 10^{8} synaptic updates. Therefore the brain has likelyevolved to be able to learn using as little energy as possible. We explored theenergy required for learning in feedforward neural networks. Based on aparsimonious energy model, we propose two plasticity restricting algorithmsthat save energy: 1) only modify synapses with large updates, and 2) restrictplasticity to subsets of synapses that form a path through the network.Combining these two methods leads to substantial energy savings while onlyincurring a small increase in learning time. In biology networks are often muchlarger than the task requires. In particular in that case, large savings can beachieved. Thus competitively restricting plasticity helps to save metabolicenergy associated to synaptic plasticity. The results might lead to a betterunderstanding of biological plasticity and a better match between artificialand biological learning. Moreover, the algorithms might also benefit hardwarebecause in electronics memory storage is energetically costly as well.", "output": "Competitive plasticity to reduce the energetic costs of learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Bayesian inference provides a methodology for parameter estimation anduncertainty quantification in machine learning and deep learning methods.Variational inference and Markov Chain Monte-Carlo (MCMC) sampling techniquesare used to implement Bayesian inference. In the past three decades, MCMCmethods have faced a number of challenges in being adapted to larger models(such as in deep learning) and big data problems. Advanced proposals thatincorporate gradients, such as a Langevin proposal distribution, provide ameans to address some of the limitations of MCMC sampling for Bayesian neuralnetworks. Furthermore, MCMC methods have typically been constrained to use bystatisticians and are still not prominent among deep learning researchers. Wepresent a tutorial for MCMC methods that covers simple Bayesian linear andlogistic models, and Bayesian neural networks. The aim of this tutorial is tobridge the gap between theory and implementation via coding, given a generalsparsity of libraries and tutorials to this end. This tutorial provides code inPython with data and instructions that enable their use and extension. Weprovide results for some benchmark problems showing the strengths andweaknesses of implementing the respective Bayesian models via MCMC. Wehighlight the challenges in sampling multi-modal posterior distributions inparticular for the case of Bayesian neural networks, and the need for furtherimprovement of convergence diagnosis.", "output": "Bayesian neural networks via MCMC: a Python-based tutorial."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a diffusion-based model for 3D-aware generative novel viewsynthesis from as few as a single input image. Our model samples from thedistribution of possible renderings consistent with the input and, even in thepresence of ambiguity, is capable of rendering diverse and plausible novelviews. To achieve this, our method makes use of existing 2D diffusion backbonesbut, crucially, incorporates geometry priors in the form of a 3D featurevolume. This latent feature field captures the distribution over possible scenerepresentations and improves our method's ability to generate view-consistentnovel renderings. In addition to generating novel views, our method has theability to autoregressively synthesize 3D-consistent sequences. We demonstratestate-of-the-art results on synthetic renderings and room-scale scenes; we alsoshow compelling results for challenging, real-world objects.", "output": "Generative Novel View Synthesis with 3D-Aware Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Equivariance w.r.t. geometric transformations in neural networks improvesdata efficiency, parameter efficiency and robustness to out-of-domainperspective shifts. When equivariance is not designed into a neural network,the network can still learn equivariant functions from the data. We quantifythis learned equivariance, by proposing an improved measure for equivariance.We find evidence for a correlation between learned translation equivariance andvalidation accuracy on ImageNet. We therefore investigate what can increase thelearned equivariance in neural networks, and find that data augmentation,reduced model capacity and inductive bias in the form of convolutions inducehigher learned equivariance in neural networks.", "output": "What Affects Learned Equivariance in Deep Image Recognition Models?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Since diffusion models (DM) and the more recent Poisson flow generativemodels (PFGM) are inspired by physical processes, it is reasonable to ask: Canphysical processes offer additional new generative models? We show that theanswer is yes. We introduce a general family, Generative Models from PhysicalProcesses (GenPhys), where we translate partial differential equations (PDEs)describing physical processes to generative models. We show that generativemodels can be constructed from s-generative PDEs (s for smooth). GenPhyssubsume the two existing generative models (DM and PFGM) and even give rise tonew families of generative models, e.g., \"Yukawa Generative Models\" inspiredfrom weak interactions. On the other hand, some physical processes by defaultdo not belong to the GenPhys family, e.g., the wave equation and theSchr\"{o}dinger equation, but could be made into the GenPhys family with somemodifications. Our goal with GenPhys is to explore and expand the design spaceof generative models.", "output": "GenPhys: From Physical Processes to Generative Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce the Segment Anything (SA) project: a new task, model, anddataset for image segmentation. Using our efficient model in a data collectionloop, we built the largest segmentation dataset to date (by far), with over 1billion masks on 11M licensed and privacy respecting images. The model isdesigned and trained to be promptable, so it can transfer zero-shot to newimage distributions and tasks. We evaluate its capabilities on numerous tasksand find that its zero-shot performance is impressive -- often competitive withor even superior to prior fully supervised results. We are releasing theSegment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and11M images at  to foster research into foundationmodels for computer vision.", "output": "Segment Anything."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Several recent efforts have been devoted to enhancing pre-trained languagemodels (PLMs) by utilizing extra heterogeneous knowledge in knowledge graphs(KGs) and achieved consistent improvements on various knowledge-driven NLPtasks. However, most of these knowledge-enhanced PLMs embed static sub-graphsof KGs (\"knowledge context\"), regardless of that the knowledge required by PLMsmay change dynamically according to specific text (\"textual context\"). In thispaper, we propose a novel framework named Coke to dynamically select contextualknowledge and embed knowledge context according to textual context for PLMs,which can avoid the effect of redundant and ambiguous knowledge in KGs thatcannot match the input text. Our experimental results show that Cokeoutperforms various baselines on typical knowledge-driven NLP tasks, indicatingthe effectiveness of utilizing dynamic knowledge context for languageunderstanding. Besides the performance improvements, the dynamically selectedknowledge in Coke can describe the semantics of text-related knowledge in amore interpretable form than the conventional PLMs. Our source code anddatasets will be available to provide more details for Coke.", "output": "CokeBERT: Contextual Knowledge Selection and Embedding towards Enhanced Pre-Trained Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent times, BERT-based models have been extremely successful in solvinga variety of natural language processing (NLP) tasks such as readingcomprehension, natural language inference, sentiment analysis, etc. AllBERT-based architectures have a self-attention block followed by a block ofintermediate layers as the basic building component. However, a strongjustification for the inclusion of these intermediate layers remains missing inthe literature. In this work we investigate the importance of intermediatelayers on the overall network performance of downstream tasks. We show thatreducing the number of intermediate layers and modifying the architecture forBERT-BASE results in minimal loss in fine-tuning accuracy for downstream taskswhile decreasing the number of parameters and training time of the model.Additionally, we use centered kernel alignment and probing linear classifiersto gain insight into our architectural modifications and justify that removalof intermediate layers has little impact on the fine-tuned accuracy.", "output": "Undivided Attention: Are Intermediate Layers Necessary for BERT?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The semiconductors industry benefits greatly from the integration of MachineLearning (ML)-based techniques in Technology Computer-Aided Design (TCAD)methods. The performance of ML models however relies heavily on the quality andquantity of training datasets. They can be particularly difficult to obtain inthe semiconductor industry due to the complexity and expense of the devicefabrication. In this paper, we propose a self-augmentation strategy forimproving ML-based device modeling using variational autoencoder-basedtechniques. These techniques require a small number of experimental data pointsand does not rely on TCAD tools. To demonstrate the effectiveness of ourapproach, we apply it to a deep neural network-based prediction task for theOhmic resistance value in Gallium Nitride devices. A 70% reduction in meanabsolute error when predicting experimental results is achieved. The inherentflexibility of our approach allows easy adaptation to various tasks, thusmaking it highly relevant to many applications of the semiconductor industry.", "output": "Improving Semiconductor Device Modeling for Electronic Design Automation by Machine Learning Techniques."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study practical data characteristics underlying federated learning, wherenon-i.i.d. data from clients have sparse features, and a certain client's localdata normally involves only a small part of the full model, called a submodel.Due to data sparsity, the classical federated averaging (FedAvg) algorithm orits variants will be severely slowed down, because when updating the globalmodel, each client's zero update of the full model excluding its submodel isinaccurately aggregated. Therefore, we propose federated submodel averaging(FedSubAvg), ensuring that the expectation of the global update of each modelparameter is equal to the average of the local updates of the clients whoinvolve it. We theoretically proved the convergence rate of FedSubAvg byderiving an upper bound under a new metric called the element-wise gradientnorm. In particular, this new metric can characterize the convergence offederated optimization over sparse data, while the conventional metric ofsquared gradient norm used in FedAvg and its variants cannot. We extensivelyevaluated FedSubAvg over both public and industrial datasets. The evaluationresults demonstrate that FedSubAvg significantly outperforms FedAvg and itsvariants.", "output": "Federated Submodel Optimization for Hot and Cold Data Features."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The capability of a mobile robot to efficiently and safely perform complexmissions is limited by its knowledge of the environment, namely the situation.Advanced reasoning, decision-making, and execution skills enable an intelligentagent to act autonomously in unknown environments. Situational Awareness (SA)is a fundamental capability of humans that has been deeply studied in variousfields, such as psychology, military, aerospace, and education. Nevertheless,it has yet to be considered in robotics, which has focused on singlecompartmentalized concepts such as sensing, spatial perception, sensor fusion,state estimation, and Simultaneous Localization and Mapping (SLAM). Hence, thepresent research aims to connect the broad multidisciplinary existing knowledgeto pave the way for a complete SA system for mobile robotics that we deemparamount for autonomy. To this aim, we define the principal components tostructure a robotic SA and their area of competence. Accordingly, this paperinvestigates each aspect of SA, surveying the state-of-the-art roboticsalgorithms that cover them, and discusses their current limitations.Remarkably, essential aspects of SA are still immature since the currentalgorithmic development restricts their performance to only specificenvironments. Nevertheless, Artificial Intelligence (AI), particularly DeepLearning (DL), has brought new methods to bridge the gap that maintains thesefields apart from the deployment to real-world scenarios. Furthermore, anopportunity has been discovered to interconnect the vastly fragmented space ofrobotic comprehension algorithms through the mechanism of Situational Graph(S-Graph), a generalization of the well-known scene graph. Therefore, wefinally shape our vision for the future of robotic Situational Awareness bydiscussing interesting recent research directions.", "output": "From SLAM to Situational Awareness: Challenges and Survey."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision Transformer (ViT) is known to be highly nonlinear like other classicalneural networks and could be easily fooled by both natural and adversarialpatch perturbations. This limitation could pose a threat to the deployment ofViT in the real industrial environment, especially in safety-criticalscenarios. In this work, we propose PatchCensor, aiming to certify the patchrobustness of ViT by applying exhaustive testing. We try to provide a provableguarantee by considering the worst patch attack scenarios. Unlike empiricaldefenses against adversarial patches that may be adaptively breached, certifiedrobust approaches can provide a certified accuracy against arbitrary attacksunder certain conditions. However, existing robustness certifications aremostly based on robust training, which often requires substantial trainingefforts and the sacrifice of model performance on normal samples. To bridge thegap, PatchCensor seeks to improve the robustness of the whole system bydetecting abnormal inputs instead of training a robust model and asking it togive reliable results for every input, which may inevitably compromiseaccuracy. Specifically, each input is tested by voting over multiple inferenceswith different mutated attention masks, where at least one inference isguaranteed to exclude the abnormal patch. This can be seen as complete-coveragetesting, which could provide a statistical guarantee on inference at the testtime. Our comprehensive evaluation demonstrates that PatchCensor is able toachieve high certified accuracy (e.g. 67.1% on ImageNet for 2%-pixeladversarial patches), significantly outperforming state-of-the-art techniqueswhile achieving similar clean accuracy (81.8% on ImageNet). Meanwhile, ourtechnique also supports flexible configurations to handle different adversarialpatch sizes (up to 25%) by simply changing the masking strategy.", "output": "PatchCensor: Patch Robustness Certification for Transformers via Exhaustive Testing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Training of convolutional neural networks is a high dimensional and anon-convex optimization problem. At present, it is inefficient in situationswhere parametric learning rates can not be confidently set. Some past workshave introduced Newton methods for training deep neural networks. Newtonmethods for convolutional neural networks involve complicated operations.Finding the Hessian matrix in second-order methods becomes very complex as wemainly use the finite differences method with the image data. Newton methodsfor convolutional neural networks deals with this by using the sub-sampledHessian Newton methods. In this paper, we have used the complete data insteadof the sub-sampled methods that only handle partial data at a time. Further, wehave used parallel processing instead of serial processing in mini-batchcomputations. The results obtained using parallel processing in this study,outperform the time taken by the previous approach.", "output": "Newton methods based convolution neural networks using parallel processing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Novel backscatter communication techniques enable battery-free sensor tags tointeroperate with unmodified standard IoT devices, extending a sensor network'scapabilities in a scalable manner. Without requiring additional dedicatedinfrastructure, the battery-free tags harvest energy from the environment,while the IoT devices provide them with the unmodulated carrier they need tocommunicate. A schedule coordinates the provision of carriers for thecommunications of battery-free devices with IoT nodes. Optimal carrierscheduling is an NP-hard problem that limits the scalability of networkdeployments. Thus, existing solutions waste energy and other valuable resourcesby scheduling the carriers suboptimally. We present DeepGANTT, a deep learningscheduler that leverages graph neural networks to efficiently providenear-optimal carrier scheduling. We train our scheduler with relatively smalloptimal schedules obtained from a constraint optimization solver, achieving aperformance within 3% of the optimal scheduler. Without the need to retrain,DeepGANTT generalizes to networks 6x larger in the number of nodes and 10xlarger in the number of tags than those used for training, breaking thescalability limitations of the optimal scheduler and reducing carrierutilization by up to 50% compared to the state-of-the-art heuristic. Ourscheduler efficiently reduces energy and spectrum utilization in backscatternetworks.", "output": "DeepGANTT: A Scalable Deep Learning Scheduler for Backscatter Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose DeepIPC, an end-to-end autonomous driving model that handles bothperception and control tasks in driving a vehicle. The model consists of twomain parts, perception and controller modules. The perception module takes anRGBD image to perform semantic segmentation and bird's eye view (BEV) semanticmapping along with providing their encoded features. Meanwhile, the controllermodule processes these features with the measurement of GNSS locations andangular speed to estimate waypoints that come with latent features. Then, twodifferent agents are used to translate waypoints and latent features into a setof navigational controls to drive the vehicle. The model is evaluated bypredicting driving records and performing automated driving under variousconditions in real environments. The experimental results show that DeepIPCachieves the best drivability and multi-task performance even with fewerparameters compared to the other models. Codes are available at", "output": "DeepIPC: Deeply Integrated Perception and Control for an Autonomous Vehicle in Real Environments."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In an unsupervised attack on variational autoencoders (VAEs), an adversaryfinds a small perturbation in an input sample that significantly changes itslatent space encoding, thereby compromising the reconstruction for a fixeddecoder. A known reason for such vulnerability is the distortions in the latentspace resulting from a mismatch between approximated latent posterior and aprior distribution. Consequently, a slight change in an input sample can moveits encoding to a low/zero density region in the latent space resulting in anunconstrained generation. This paper demonstrates that an optimal way for anadversary to attack VAEs is to exploit a directional bias of a stochasticpullback metric tensor induced by the encoder and decoder networks. Thepullback metric tensor of an encoder measures the change in infinitesimallatent volume from an input to a latent space. Thus, it can be viewed as a lensto analyse the effect of input perturbations leading to latent spacedistortions. We propose robustness evaluation scores using the eigenspectrum ofa pullback metric tensor. Moreover, we empirically show that the scorescorrelate with the robustness parameter $beta$ of the $beta-$VAE. Sinceincreasing $beta$ also degrades reconstruction quality, we demonstrate asimple alternative using textit{mixup} training to fill the empty regions inthe latent space, thus improving robustness with improved reconstruction.", "output": "Adversarial robustness of VAEs through the lens of local geometry."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks (DNNs) have demonstrated their superiority in practice.Arguably, the rapid development of DNNs is largely benefited from high-quality(open-sourced) datasets, based on which researchers and developers can easilyevaluate and improve their learning methods. Since the data collection isusually time-consuming or even expensive, how to protect their copyrights is ofgreat significance and worth further exploration. In this paper, we revisitdataset ownership verification. We find that existing verification methodsintroduced new security risks in DNNs trained on the protected dataset, due tothe targeted nature of poison-only backdoor watermarks. To alleviate thisproblem, in this work, we explore the untargeted backdoor watermarking scheme,where the abnormal model behaviors are not deterministic. Specifically, weintroduce two dispersibilities and prove their correlation, based on which wedesign the untargeted backdoor watermark under both poisoned-label andclean-label settings. We also discuss how to use the proposed untargetedbackdoor watermark for dataset ownership verification. Experiments on benchmarkdatasets verify the effectiveness of our methods and their resistance toexisting backdoor defenses. Our codes are available aturl{", "output": "Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Offline reinforcement learning (RL) methods can generally be categorized intotwo types: RL-based and Imitation-based. RL-based methods could in principleenjoy out-of-distribution generalization but suffer from erroneous off-policyevaluation. Imitation-based methods avoid off-policy evaluation but are tooconservative to surpass the dataset. In this study, we propose an alternativeapproach, inheriting the training stability of imitation-style methods whilestill allowing logical out-of-distribution generalization. We decompose theconventional reward-maximizing policy in offline RL into a guide-policy and anexecute-policy. During training, the guide-poicy and execute-policy are learnedusing only data from the dataset, in a supervised and decoupled manner. Duringevaluation, the guide-policy guides the execute-policy by telling where itshould go so that the reward can be maximized, serving as the textit{Prophet}.By doing so, our algorithm allows textit{state-compositionality} from thedataset, rather than textit{action-compositionality} conducted in priorimitation-style methods. We dumb this new approach Policy-guided Offline RL(texttt{POR}). texttt{POR} demonstrates the state-of-the-art performance onD4RL, a standard benchmark for offline RL. We also highlight the benefits oftexttt{POR} in terms of improving with supplementary suboptimal data andeasily adapting to new tasks by only changing the guide-poicy.", "output": "A Policy-Guided Imitation Approach for Offline Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While natural systems often present collective intelligence that allows themto self-organize and adapt to changes, the equivalent is missing in mostartificial systems. We explore the possibility of such a system in the contextof cooperative 2D push manipulations using mobile robots. Although conventionalworks demonstrate potential solutions for the problem in restricted settings,they have computational and learning difficulties. More importantly, thesesystems do not possess the ability to adapt when facing environmental changes.In this work, we show that by distilling a planner derived from adifferentiable soft-body physics simulator into an attention-based neuralnetwork, our multi-robot push manipulation system achieves better performancethan baselines. In addition, our system also generalizes to configurations notseen during training and is able to adapt toward task completions when externalturbulence and environmental changes are applied. Supplementary videos can befound on our project website: ", "output": "Collective Intelligence for 2D Push Manipulations with Mobile Robots."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Many problems can be viewed as forms of geospatial search aided by aerialimagery, with examples ranging from detecting poaching activity to humantrafficking. We model this class of problems in a visual active search (VAS)framework, which takes as input an image of a broad area, and aims to identifyas many examples of a target object as possible. It does this through a limitedsequence of queries, each of which verifies whether an example is present in agiven region. A crucial feature of VAS is that each such query is informativeabout the spatial distribution of target objects beyond what is capturedvisually (for example, due to spatial correlation). We propose a reinforcementlearning approach for VAS that leverages a collection of fully annotated searchtasks as training data to learn a search policy, and combines features of theinput image with a natural representation of active search state. Additionally,we propose domain adaptation techniques to improve the policy at decision timewhen training data is not fully reflective of the test-time distribution of VAStasks. Through extensive experiments on several satellite imagery datasets, weshow that the proposed approach significantly outperforms several strongbaselines. Code and data will be made public.", "output": "A Visual Active Search Framework for Geospatial Exploration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Modern machine learning pipelines are limited due to data availability,storage quotas, privacy regulations, and expensive annotation processes. Theseconstraints make it difficult or impossible to train and update large-scalemodels on such dynamic annotated sets. Continual learning directly approachesthis problem, with the ultimate goal of devising methods where a deep neuralnetwork effectively learns relevant patterns for new (unseen) classes, withoutsignificantly altering its performance on previously learned ones. In thispaper, we address the problem of continual learning for video data. Weintroduce PIVOT, a novel method that leverages extensive knowledge inpre-trained models from the image domain, thereby reducing the number oftrainable parameters and the associated forgetting. Unlike previous methods,ours is the first approach that effectively uses prompting mechanisms forcontinual learning without any in-domain pre-training. Our experiments showthat PIVOT improves state-of-the-art methods by a significant 27% on the20-task ActivityNet setup.", "output": "PIVOT: Prompting for Video Continual Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Most recent self-supervised learning methods are pre-trained on thewell-curated ImageNet-1K dataset. In this work, given the excellent scalabilityof web data, we consider self-supervised pre-training on noisy web sourcedimage-text paired data. First, we conduct a benchmark study of representativeself-supervised pre-training methods on large-scale web data in a like-for-likesetting. We compare a range of methods, including single-modal ones that usemasked training objectives and multi-modal ones that use image-textconstrastive training. We observe that existing multi-modal methods do notoutperform their single-modal counterparts on vision transfer learning tasks.We derive an information-theoretical view to explain these benchmark results,which provides insight into how to design a novel vision learner. Inspired bythis insight, we present a new visual representation pre-training method,MUlti-modal Generator~(MUG), that learns from scalable web sourced image-textdata. MUG achieves state-of-the-art transfer performance on a variety of tasksand demonstrates promising scaling properties. Pre-trained models and code willbe made public upon acceptance.", "output": "Vision Learners Meet Web Image-Text Pairs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we introduce a novel unsupervised, graph-based filter featureselection technique which exploits the power of topologically constrainednetwork representations. We model dependency structures among features using afamily of chordal graphs (the Triangulated Maximally Filtered Graph), and wemaximise the likelihood of features' relevance by studying their relativeposition inside the network. Such an approach presents three aspects that areparticularly satisfactory compared to its alternatives: (i) it is highlytunable and easily adaptable to the nature of input data; (ii) it is fullyexplainable, maintaining, at the same time, a remarkable level of simplicity;(iii) it is computationally cheaper compared to its alternatives. We test ouralgorithm on 16 benchmark datasets from different applicative domains showingthat it outperforms or matches the current state-of-the-art under heterogeneousevaluation conditions.", "output": "Topological Feature Selection: A Graph-Based Filter Feature Selection Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The political stance prediction for news articles has been widely studied tomitigate the echo chamber effect -- people fall into their thoughts andreinforce their pre-existing beliefs. The previous works for the politicalstance problem focus on (1) identifying political factors that could reflectthe political stance of a news article and (2) capturing those factorseffectively. Despite their empirical successes, they are not sufficientlyjustified in terms of how effective their identified factors are in thepolitical stance prediction. Motivated by this, in this work, we conduct a userstudy to investigate important factors in political stance prediction, andobserve that the context and tone of a news article (implicit) and externalknowledge for real-world entities appearing in the article (explicit) areimportant in determining its political stance. Based on this observation, wepropose a novel knowledge-aware approach to political stance prediction (KHAN),employing (1) hierarchical attention networks (HAN) to learn the relationshipsamong words and sentences in three different levels and (2) knowledge encoding(KE) to incorporate external knowledge for real-world entities into the processof political stance prediction. Also, to take into account the subtle andimportant difference between opposite political stances, we build twoindependent political knowledge graphs (KG) (i.e., KG-lib and KG-con) byourselves and learn to fuse the different political knowledge. Throughextensive evaluations on three real-world datasets, we demonstrate thesuperiority of DASH in terms of (1) accuracy, (2) efficiency, and (3)effectiveness.", "output": "KHAN: Knowledge-Aware Hierarchical Attention Networks for Accurate Political Stance Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Out-of-distribution detection is one of the most critical issue in thedeployment of machine learning. The data analyst must assure that data inoperation should be compliant with the training phase as well as understand ifthe environment has changed in a way that autonomous decisions would not besafe anymore. The method of the paper is based on eXplainable ArtificialIntelligence (XAI); it takes into account different metrics to identify anyresemblance between in-distribution and out of, as seen by the XAI model. Theapproach is non-parametric and distributional assumption free. The validationover complex scenarios (predictive maintenance, vehicle platooning, covertchannels in cybersecurity) corroborates both precision in detection andevaluation of training-operation conditions proximity. Results are availablevia open source and open data at the following link:", "output": "Rule-based Out-Of-Distribution Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep Neural Networks (DNNs) are being used to solve a wide range of problemsin many domains including safety-critical domains like self-driving cars andmedical imagery. DNNs suffer from vulnerability against adversarial attacks. Inthe past few years, numerous approaches have been proposed to tackle thisproblem by training networks using adversarial training. Almost all theapproaches generate adversarial examples for the entire training dataset, thusincreasing the training time drastically. We show that we can decrease thetraining time for any adversarial training algorithm by using only a subset oftraining data for adversarial training. To select the subset, we filter theadversarially-prone samples from the training data. We perform a simpleadversarial attack on all training examples to filter this subset. In thisattack, we add a small perturbation to each pixel and a few grid lines to theinput image.We perform adversarial training on the adversarially-prone subset and mix itwith vanilla training performed on the entire dataset. Our results show thatwhen our method-agnostic approach is plugged into FGSM, we achieve a speedup of3.52x on MNIST and 1.98x on the CIFAR-10 dataset with comparable robustaccuracy. We also test our approach on state-of-the-art Free adversarialtraining and achieve a speedup of 1.2x in training time with a marginal drop inrobust accuracy on the ImageNet dataset.", "output": "Do we need entire training data for adversarial training?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Diffusion models have shown superior performance in image generation andmanipulation, but the inherent stochasticity presents challenges in preservingand manipulating image content and identity. While previous approaches likeDreamBooth and Textual Inversion have proposed model or latent representationpersonalization to maintain the content, their reliance on multiple referenceimages and complex training limits their practicality. In this paper, wepresent a simple yet highly effective approach to personalization using highlypersonalized (HiPer) text embedding by decomposing the CLIP embedding space forpersonalization and content manipulation. Our method does not require modelfine-tuning or identifiers, yet still enables manipulation of background,texture, and motion with just a single image and target text. Throughexperiments on diverse target texts, we demonstrate that our approach produceshighly personalized and complex semantic image edits across a wide range oftasks. We believe that the novel understanding of the text embedding spacepresented in this work has the potential to inspire further research acrossvarious tasks.", "output": "Highly Personalized Text Embedding for Image Manipulation by Stable Diffusion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vibration signals have been increasingly utilized in various engineeringfields for analysis and monitoring purposes, including structural healthmonitoring, fault diagnosis and damage detection, where vibration signals canprovide valuable information about the condition and integrity of structures.In recent years, there has been a growing trend towards the use of vibrationsignals in the field of bioengineering. Activity-induced structural vibrations,particularly footstep-induced signals, are useful for analyzing the movement ofbiological systems such as the human body and animals. Footstep-induced signalscan provide valuable information about an individual's gait, body mass, andposture, making them an attractive tool for health monitoring, security, andhuman-computer interaction. However, the presence of various types of noise cancompromise the accuracy of footstep-induced signal analysis. In this paper, wepropose a novel 'many-to-many' LSTM model with a KLD regularizer and L1regularization, which is effective in denoising structural vibration signals,particularly for regimes with larger amplitudes. The model was trained andtested using synthetic data generated by a single degree of freedom oscillator.Our results demonstrate that the proposed approach is effective in reducingnoise in the signals, particularly for regimes with larger amplitudes. Theapproach is promising for a wide range of applications of footstep-inducedstructural vibration signals, including healthcare, security, and technology.", "output": "Structural Vibration Signal Denoising Using KLD Regularized Bi-Directional LSTM."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Causal Discovery (CD) is the process of identifying the cause-effectrelationships among the variables of a system from data. Over the years,several methods have been developed primarily based on the statisticalproperties of data to uncover the underlying causal mechanism. In this study,we present an extensive discussion on the methods designed to perform causaldiscovery from both independent and identically distributed (i.i.d.) data andtime series data. For this purpose, we first introduce the common terminologiesin causal discovery, and then provide a comprehensive discussion of thealgorithms designed to identify the causal edges in different settings. Wefurther discuss some of the benchmark datasets available for evaluating theperformance of the causal discovery methods, available tools or softwarepackages to perform causal discovery readily, and the common metrics used toevaluate these methods. We also test some common causal discovery algorithms ondifferent benchmark datasets, and compare their performances. Finally, weconclude by presenting the common challenges involved in causal discovery, andalso, discuss the applications of causal discovery in multiple areas ofinterest.", "output": "A Survey on Causal Discovery Methods for Temporal and Non-Temporal Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present emph{TabRet}, a pre-trainable Transformer-based model for tabulardata. TabRet is designed to work on a downstream task that contains columns notseen in pre-training. Unlike other methods, TabRet has an extra learning stepbefore fine-tuning called emph{retokenizing}, which calibrates featureembeddings based on the masked autoencoding loss. In experiments, wepre-trained TabRet with a large collection of public health surveys andfine-tuned it on classification tasks in healthcare, and TabRet achieved thebest AUC performance on four datasets. In addition, an ablation study showsretokenizing and random shuffle augmentation of columns during pre-trainingcontributed to performance gains.", "output": "TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Real-time perception, or streaming perception, is a crucial aspect ofautonomous driving that has yet to be thoroughly explored in existing research.To address this gap, we present DAMO-StreamNet, an optimized framework thatcombines recent advances from the YOLO series with a comprehensive analysis ofspatial and temporal perception mechanisms, delivering a cutting-edge solution.The key innovations of DAMO-StreamNet are: (1) A robust neck structureincorporating deformable convolution, enhancing the receptive field and featurealignment capabilities. (2) A dual-branch structure that integrates short-pathsemantic features and long-path temporal features, improving motion stateprediction accuracy. (3) Logits-level distillation for efficient optimization,aligning the logits of teacher and student networks in semantic space. (4) Areal-time forecasting mechanism that updates support frame features with thecurrent frame, ensuring seamless streaming perception during inference. Ourexperiments demonstrate that DAMO-StreamNet surpasses existing state-of-the-artmethods, achieving 37.8% (normal size (600, 960)) and 43.3% (large size (1200,1920)) sAP without using extra data. This work not only sets a new benchmarkfor real-time perception but also provides valuable insights for futureresearch. Additionally, DAMO-StreamNet can be applied to various autonomoussystems, such as drones and robots, paving the way for real-time perception.The code is available at ", "output": "DAMO-StreamNet: Optimizing Streaming Perception in Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent technological advancements have considerately improved healthcaresystems to provide various intelligent healthcare services and improve thequality of life. Federated learning (FL), a new branch of artificialintelligence (AI), opens opportunities to deal with privacy issues inhealthcare systems and exploit data and computing resources available atdistributed devices. Additionally, the Metaverse, through integrating emergingtechnologies, such as AI, cloud edge computing, Internet of Things (IoT),blockchain, and semantic communications, has transformed many vertical domainsin general and the healthcare sector in particular. Obviously, FL shows manybenefits and provides new opportunities for conventional and Metaversehealthcare, motivating us to provide a survey on the usage of FL for Metaversehealthcare systems. First, we present preliminaries to IoT-based healthcaresystems, FL in conventional healthcare, and Metaverse healthcare. The benefitsof FL in Metaverse healthcare are then discussed, from improved privacy andscalability, better interoperability, better data management, and extrasecurity to automation and low-latency healthcare services. Subsequently, wediscuss several applications pertaining to FL-enabled Metaverse healthcare,including medical diagnosis, patient monitoring, medical education, infectiousdisease, and drug discovery. Finally, we highlight significant challenges andpotential solutions toward the realization of FL in Metaverse healthcare.", "output": "A Survey on Federated Learning for the Healthcare Metaverse: Concepts, Applications, Challenges, and Future Directions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Audio editing is applicable for various purposes, such as adding backgroundsound effects, replacing a musical instrument, and repairing damaged audio.Recently, some diffusion-based methods achieved zero-shot audio editing byusing a diffusion and denoising process conditioned on the text description ofthe output audio. However, these methods still have some problems: 1) they havenot been trained on editing tasks and cannot ensure good editing effects; 2)they can erroneously modify audio segments that do not require editing; 3) theyneed a complete description of the output audio, which is not always availableor necessary in practical scenarios. In this work, we propose AUDIT, aninstruction-guided audio editing model based on latent diffusion models.Specifically, AUDIT has three main design features: 1) we construct triplettraining data (instruction, input audio, output audio) for different audioediting tasks and train a diffusion model using instruction and input (to beedited) audio as conditions and generating output (edited) audio; 2) it canautomatically learn to only modify segments that need to be edited by comparingthe difference between the input and output audio; 3) it only needs editinstructions instead of full target audio descriptions as text input. AUDITachieves state-of-the-art results in both objective and subjective metrics forseveral audio editing tasks (e.g., adding, dropping, replacement, inpainting,super-resolution). Demo samples are available at ", "output": "AUDIT: Audio Editing by Following Instructions with Latent Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural networks (NNs) playing the role of controllers have demonstratedimpressive empirical performances on challenging control problems. However, thepotential adoption of NN controllers in real-life applications also gives riseto a growing concern over the safety of these neural-network controlled systems(NNCSs), especially when used in safety-critical applications. In this work, wepresent POLAR-Express, an efficient and precise formal reachability analysistool for verifying the safety of NNCSs. POLAR-Express uses Taylor modelarithmetic to propagate Taylor models (TMs) across a neural networklayer-by-layer to compute an overapproximation of the neural-network function.It can be applied to analyze any feed-forward neural network with continuousactivation functions. We also present a novel approach to propagate TMs moreefficiently and precisely across ReLU activation functions. In addition,POLAR-Express provides parallel computation support for the layer-by-layerpropagation of TMs, thus significantly improving the efficiency and scalabilityover its earlier prototype POLAR. Across the comparison with six otherstate-of-the-art tools on a diverse set of benchmarks, POLAR-Express achievesthe best verification efficiency and tightness in the reachable set analysis.", "output": "POLAR-Express: Efficient and Precise Formal Reachability Analysis of Neural-Network Controlled Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper investigates the effectiveness of large language models (LLMs) inemail spam detection by comparing prominent models from three distinctfamilies: BERT-like, Sentence Transformers, and Seq2Seq. Additionally, weexamine well-established machine learning techniques for spam detection, suchas Na\"ive Bayes and LightGBM, as baseline methods. We assess the performanceof these models across four public datasets, utilizing different numbers oftraining samples (full training set and few-shot settings). Our findings revealthat, in the majority of cases, LLMs surpass the performance of the popularbaseline techniques, particularly in few-shot scenarios. This adaptabilityrenders LLMs uniquely suited to spam detection tasks, where labeled samples arelimited in number and models require frequent updates. Additionally, weintroduce Spam-T5, a Flan-T5 model that has been specifically adapted andfine-tuned for the purpose of detecting email spam. Our results demonstratethat Spam-T5 surpasses baseline models and other LLMs in the majority ofscenarios, particularly when there are a limited number of training samplesavailable. Our code is publicly available at", "output": "Spam-T5: Benchmarking Large Language Models for Few-Shot Email Spam Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "ChatGPT has become a global sensation. As ChatGPT and other Large LanguageModels (LLMs) emerge, concerns of misusing them in various ways increase, suchas disseminating fake news, plagiarism, manipulating public opinion, cheating,and fraud. Hence, distinguishing AI-generated from human-generated becomesincreasingly essential. Researchers have proposed various detectionmethodologies, ranging from basic binary classifiers to more complexdeep-learning models. Some detection techniques rely on statisticalcharacteristics or syntactic patterns, while others incorporate semantic orcontextual information to improve accuracy. The primary objective of this studyis to provide a comprehensive and contemporary assessment of the most recenttechniques in ChatGPT detection. Additionally, we evaluated other AI-generatedtext detection tools that do not specifically claim to detect ChatGPT-generatedcontent to assess their performance in detecting ChatGPT-generated content. Forour evaluation, we have curated a benchmark dataset consisting of prompts fromChatGPT and humans, including diverse questions from medical, open Q&amp;A, andfinance domains and user-generated responses from popular social networkingplatforms. The dataset serves as a reference to assess the performance ofvarious techniques in detecting ChatGPT-generated content. Our evaluationresults demonstrate that none of the existing methods can effectively detectChatGPT-generated content.", "output": "To ChatGPT, or not to ChatGPT: That is the question!."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We consider the challenging task of training models for image-to-videodeblurring, which aims to recover a sequence of sharp images corresponding to agiven blurry image input. A critical issue disturbing the training of animage-to-video model is the ambiguity of the frame ordering since both theforward and backward sequences are plausible solutions. This paper proposes aneffective self-supervised ordering scheme that allows training high-qualityimage-to-video deblurring models. Unlike previous methods that rely onorder-invariant losses, we assign an explicit order for each video sequence,thus avoiding the order-ambiguity issue. Specifically, we map each videosequence to a vector in a latent high-dimensional space so that there exists ahyperplane such that for every video sequence, the vectors extracted from itand its reversed sequence are on different sides of the hyperplane. The side ofthe vectors will be used to define the order of the corresponding sequence.Last but not least, we propose a real-image dataset for the image-to-videodeblurring problem that covers a variety of popular domains, including face,hand, and street. Extensive experimental results confirm the effectiveness ofour method. Code and data are available at", "output": "HyperCUT: Video Sequence from a Single Blurry Image using Unsupervised Ordering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce HATELEXICON, a lexicon of slurs and targets of hate speech forthe countries of Brazil, Germany, India and Kenya, to aid training andinterpretability of models. We demonstrate how our lexicon can be used tointerpret model predictions, showing that models developed to classify extremespeech rely heavily on target words when making predictions. Further, wepropose a method to aid shot selection for training in low-resource settingsvia HATELEXICON. In few-shot learning, the selection of shots is of paramountimportance to model performance. In our work, we simulate a few-shot settingfor German and Hindi, using HASOC data for training and the MultilingualHateCheck (MHC) as a benchmark. We show that selecting shots based on ourlexicon leads to models performing better on MHC than models trained on shotssampled randomly. Thus, when given only a few training examples, using ourlexicon to select shots containing more sociocultural information leads tobetter few-shot performance.", "output": "Sociocultural knowledge is needed for selection of shots in hate speech detection tasks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The AI community has embraced multi-sensory or multi-modal approaches toadvance this generation of AI models to resemble expected intelligentunderstanding. Combining language and imagery represents a familiar method forspecific tasks like image captioning or generation from descriptions. Thispaper compares these monolithic approaches to a lightweight and specializedmethod based on employing image models to label objects, then seriallysubmitting this resulting object list to a large language model (LLM). This useof multiple Application Programming Interfaces (APIs) enables better than 95%mean average precision for correct object lists, which serve as input to thelatest Open AI text generator (GPT-4). To demonstrate the API as a modularalternative, we solve the problem of a user taking a picture of ingredientsavailable in a refrigerator, then generating novel recipe cards tailored tocomplex constraints on cost, preparation time, dietary restrictions, portionsizes, and multiple meal plans. The research concludes that monolithicmultimodal models currently lack the coherent memory to maintain context andformat for this task and that until recently, the language models like GPT-2/3struggled to format similar problems without degenerating into repetitive ornon-sensical combinations of ingredients. For the first time, an AI chef orcook seems not only possible but offers some enhanced capabilities to augmenthuman recipe libraries in pragmatic ways. The work generates a 100-page recipebook featuring the thirty top ingredients using over 2000 refrigerator imagesas initializing lists.", "output": "The Multimodal And Modular Ai Chef: Complex Recipe Generation From Imagery."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine Unlearning has recently been emerging as a paradigm for selectivelyremoving the impact of training datapoints from a network. While existingapproaches have focused on unlearning either a small subset of the trainingdata or a single class, in this paper we take a different path and devise aframework that can unlearn all classes of an image classification network in asingle untraining round. Our proposed technique learns to modulate the innercomponents of an image classification network through memory matrices so that,after training, the same network can selectively exhibit an unlearning behaviorover any of the classes. By discovering weights which are specific to each ofthe classes, our approach also recovers a representation of the classes whichis explainable by-design. We test the proposed framework, which we name WeightFiltering network (WF-Net), on small-scale and medium-scale imageclassification datasets, with both CNN and Transformer-based backbones. Ourwork provides interesting insights in the development of explainable solutionsfor unlearning and could be easily extended to other vision tasks.", "output": "Multi-Class Explainable Unlearning for Image Classification via Weight Filtering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fashion illustration is used by designers to communicate their vision and tobring the design idea from conceptualization to realization, showing howclothes interact with the human body. In this context, computer vision can thusbe used to improve the fashion design process. Differently from previous worksthat mainly focused on the virtual try-on of garments, we propose the task ofmultimodal-conditioned fashion image editing, guiding the generation ofhuman-centric fashion images by following multimodal prompts, such as text,human body poses, and garment sketches. We tackle this problem by proposing anew architecture based on latent diffusion models, an approach that has notbeen used before in the fashion domain. Given the lack of existing datasetssuitable for the task, we also extend two existing fashion datasets, namelyDress Code and VITON-HD, with multimodal annotations collected in asemi-automatic manner. Experimental results on these new datasets demonstratethe effectiveness of our proposal, both in terms of realism and coherence withthe given multimodal inputs. Source code and collected multimodal annotationswill be publicly released at:", "output": "Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce a method to synthesize animator guided human motion across 3Dscenes. Given a set of sparse (3 or 4) joint locations (such as the location ofa person's hand and two feet) and a seed motion sequence in a 3D scene, ourmethod generates a plausible motion sequence starting from the seed motionwhile satisfying the constraints imposed by the provided keypoints. Wedecompose the continual motion synthesis problem into walking along paths andtransitioning in and out of the actions specified by the keypoints, whichenables long generation of motions that satisfy scene constraints withoutexplicitly incorporating scene information. Our method is trained only usingscene agnostic mocap data. As a result, our approach is deployable across 3Dscenes with various geometries. For achieving plausible continual motionsynthesis without drift, our key contribution is to generate motion in agoal-centric canonical coordinate frame where the next immediate target issituated at the origin. Our model can generate long sequences of diverseactions such as grabbing, sitting and leaning chained together in arbitraryorder, demonstrated on scenes of varying geometry: HPS, Replica, Matterport,ScanNet and scenes represented using NeRFs. Several experiments demonstratethat our method outperforms existing methods that navigate paths in 3D scenes.", "output": "Generating Continual Human Motion in Diverse 3D Scenes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Scaling up weakly-supervised datasets has shown to be highly effective in theimage-text domain and has contributed to most of the recent state-of-the-artcomputer vision and multimodal neural networks. However, existing large-scalevideo-text datasets and mining techniques suffer from several limitations, suchas the scarcity of aligned data, the lack of diversity in the data, and thedifficulty of collecting aligned data. Currently popular video-text data miningapproach via automatic speech recognition (ASR) used in HowTo100M provideslow-quality captions that often do not refer to the video content. Other miningapproaches do not provide proper language descriptions (video tags) and arebiased toward short clips (alt text). In this work, we show how recent advancesin image captioning allow us to pre-train high-quality video models without anyparallel video-text data. We pre-train several video captioning models that arebased on an OPT language model and a TimeSformer visual backbone. We fine-tunethese networks on several video captioning datasets. First, we demonstrate thatimage captioning pseudolabels work better for pre-training than the existingHowTo100M ASR captions. Second, we show that pre-training on both images andvideos produces a significantly better network (+4 CIDER on MSR-VTT) thanpre-training on a single modality. Our methods are complementary to theexisting pre-training or data mining approaches and can be used in a variety ofsettings. Given the efficacy of the pseudolabeling method, we are planning topublicly release the generated captions.", "output": "Scalable and Accurate Self-supervised Multimodal Representation Learning without Aligned Video and Text Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a complete software pipeline for revealing the hidden texts of theHerculaneum papyri using X-ray CT images. This enhanced virtual unwrappingpipeline combines machine learning with a novel geometric framework linking 3Dand 2D images. We also present EduceLab-Scrolls, a comprehensive open datasetrepresenting two decades of research effort on this problem. EduceLab-Scrollscontains a set of volumetric X-ray CT images of both small fragments andintact, rolled scrolls. The dataset also contains 2D image labels that are usedin the supervised training of an ink detection model. Labeling is enabled byaligning spectral photography of scroll fragments with X-ray CT images of thesame fragments, thus creating a machine-learnable mapping between image spacesand modalities. This alignment permits supervised learning for the detection of\"invisible\" carbon ink in X-ray CT, a task that is \"impossible\" even for humanexpert labelers. To our knowledge, this is the first aligned dataset of itskind and is the largest dataset ever released in the heritage domain. Ourmethod is capable of revealing accurate lines of text on scroll fragments withknown ground truth. Revealed text is verified using visual confirmation,quantitative image metrics, and scholarly review. EduceLab-Scrolls has alsoenabled the discovery, for the first time, of hidden texts from the Herculaneumpapyri, which we present here. We anticipate that the EduceLab-Scrolls datasetwill generate more textual discovery as research continues.", "output": "EduceLab-Scrolls: Verifiable Recovery of Text from Herculaneum Papyri using X-ray CT."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As deep learning-based computer vision algorithms continue to improve andadvance the state of the art, their robustness to real-world data continues tolag their performance on datasets. This makes it difficult to bring analgorithm from the lab to the real world. Ensemble-based uncertainty estimationapproaches such as Monte Carlo Dropout have been successfully used in manyapplications in an attempt to address this robustness issue. Unfortunately, itis not always clear if such ensemble-based approaches can be applied to a newproblem domain. This is the case with panoptic segmentation, where thestructure of the problem and architectures designed to solve it means thatunlike image classification or even semantic segmentation, the typical solutionof using a mean across samples cannot be directly applied. In this paper, wedemonstrate how ensemble-based uncertainty estimation approaches such as MonteCarlo Dropout can be used in the panoptic segmentation domain with no changesto an existing network, providing both improved performance and moreimportantly a better measure of uncertainty for predictions made by thenetwork. Results are demonstrated quantitatively and qualitatively on the COCO,KITTI-STEP and VIPER datasets.", "output": "Uncertainty estimation in Deep Learning for Panoptic segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Camera orientations (i.e., rotation and zoom) govern the content that acamera captures in a given scene, which in turn heavily influences the accuracyof live video analytics pipelines. However, existing analytics approaches leavethis crucial adaptation knob untouched, instead opting to only alter the waythat captured images from fixed orientations are encoded, streamed, andanalyzed. We present MadEye, a camera-server system that automatically andcontinually adapts orientations to maximize accuracy for the workload andresource constraints at hand. To realize this using commodity pan-tilt-zoom(PTZ) cameras, MadEye embeds (1) a search algorithm that rapidly explores themassive space of orientations to identify a fruitful subset at each time, and(2) a novel knowledge distillation strategy to efficiently (with only cameraresources) select the ones that maximize workload accuracy. Experiments ondiverse workloads show that MadEye boosts accuracy by 2.9-25.7% for the sameresource usage, or achieves the same accuracy with 2-3.7x lower resource costs.", "output": "MadEye: Boosting Live Video Analytics Accuracy with Adaptive Camera Configurations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We adopt convolutional neural networks (CNN) to predict the basic propertiesof the porous media. Two different media types are considered: one mimics thesandstone, and the other mimics the systems derived from the extracellularspace of biological tissues. The Lattice Boltzmann Method is used to obtain thelabeled data necessary for performing supervised learning. We distinguish twotasks. In the first, networks based on the analysis of the system's geometrypredict porosity and effective diffusion coefficient. In the second, networksreconstruct the system's geometry and concentration map. In the first task, wepropose two types of CNN models: the C-Net and the encoder part of the U-Net.Both networks are modified by adding a self-normalization module. The modelspredict with reasonable accuracy but only within the data type, they aretrained on. For instance, the model trained on sandstone-like samplesovershoots or undershoots for biological-like samples. In the second task, wepropose the usage of the U-Net architecture. It accurately reconstructs theconcentration fields. Moreover, the network trained on one data type works wellfor the other. For instance, the model trained on sandstone-like samples worksperfectly on biological-like samples.", "output": "Deep learning for diffusion in porous media."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fully supervised action segmentation works on frame-wise action recognitionwith dense annotations and often suffers from the over-segmentation issue.Existing works have proposed a variety of solutions such as boundary-awarenetworks, multi-stage refinement, and temporal smoothness losses. However, mostof them take advantage of frame-wise supervision, which cannot effectivelytackle the evaluation metrics with different granularities. In this paper, forthe desirable large receptive field, we first develop a novel local-globalattention mechanism with temporal pyramid dilation and temporal pyramid poolingfor efficient multi-scale attention. Then we decouple two inherent goals inaction segmentation, ie, (1) individual identification solved by frame-wisesupervision, and (2) temporal reasoning tackled by action set prediction.Afterward, an action alignment module fuses these different granularitypredictions, leading to more accurate and smoother action segmentation. Weachieve state-of-the-art accuracy, eg, 82.8% (+2.6%) on GTEA and 74.7% (+1.2%)on Breakfast, which demonstrates the effectiveness of our proposed method,accompanied by extensive ablation studies. The code will be made availablelater.", "output": "DIR-AS: Decoupling Individual Identification and Temporal Reasoning for Action Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Contrails (condensation trails) are line-shaped ice clouds caused by aircraftand are likely the largest contributor of aviation-induced climate change.Contrail avoidance is potentially an inexpensive way to significantly reducethe climate impact of aviation. An automated contrail detection system is anessential tool to develop and evaluate contrail avoidance systems. In thispaper, we present a human-labeled dataset named OpenContrails to train andevaluate contrail detection models based on GOES-16 Advanced Baseline Imager(ABI) data. We propose and evaluate a contrail detection model thatincorporates temporal context for improved detection accuracy. The humanlabeled dataset and the contrail detection outputs are publicly available onGoogle Cloud Storage at gs://goes_contrails_dataset.", "output": "OpenContrails: Benchmarking Contrail Detection on GOES-16 ABI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although Domain Adaptation in Semantic Scene Segmentation has shownimpressive improvement in recent years, the fairness concerns in the domainadaptation have yet to be well defined and addressed. In addition, fairness isone of the most critical aspects when deploying the segmentation models intohuman-related real-world applications, e.g., autonomous driving, as any unfairpredictions could influence human safety. In this paper, we propose a novelFairness Domain Adaptation (FREDOM) approach to semantic scene segmentation. Inparticular, from the proposed formulated fairness objective, a new adaptationframework will be introduced based on the fair treatment of classdistributions. Moreover, to generally model the context of structuraldependency, a new conditional structural constraint is introduced to impose theconsistency of predicted segmentation. Thanks to the proposed ConditionalStructure Network, the self-attention mechanism has sufficiently modeled thestructural information of segmentation. Through the ablation studies, theproposed method has shown the performance improvement of the segmentationmodels and promoted fairness in the model predictions. The experimental resultson the two standard benchmarks, i.e., SYNTHIA $to$ Cityscapes and GTA5 $to$Cityscapes, have shown that our method achieved State-of-the-Art (SOTA)performance.", "output": "FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, fully-transformer architectures have replaced the defactoconvolutional architecture for the 3D human pose estimation task. In this paperwe propose textbf{textit{ConvFormer}}, a novel convolutional transformer thatleverages a new textbf{textit{dynamic multi-headed convolutionalself-attention}} mechanism for monocular 3D human pose estimation. We designeda spatial and temporal convolutional transformer to comprehensively model humanjoint relations within individual frames and globally across the motionsequence. Moreover, we introduce a novel notion of textbf{textit{temporaljoints profile}} for our temporal ConvFormer that fuses complete temporalinformation immediately for a local neighborhood of joint features. We havequantitatively and qualitatively validated our method on three common benchmarkdatasets: Human3.6M, MPI-INF-3DHP, and HumanEva. Extensive experiments havebeen conducted to identify the optimal hyper-parameter set. These experimentsdemonstrated that we achieved a textbf{significant parameter reductionrelative to prior transformer models} while attaining State-of-the-Art (SOTA)or near SOTA on all three datasets. Additionally, we achieved SOTA for ProtocolIII on H36M for both GT and CPN detection inputs. Finally, we obtained SOTA onall three metrics for the MPI-INF-3DHP dataset and for all three subjects onHumanEva under Protocol II.", "output": "ConvFormer: Parameter Reduction in Transformer Models for 3D Human Pose Estimation by Leveraging Dynamic Multi-Headed Convolutional Attention."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Current methods for self-supervised LiDAR scene flow estimation work poorlyon real data. A variety of flaws in common evaluation protocols have causedleading approaches to focus on problems that do not exist in real data. Weanalyze a suite of recent works and find that despite their focus on deeplearning, the main challenges of the LiDAR scene flow problem -- removing thedominant rigid motion and robustly estimating the simple motions that remain --can be more effectively solved with classical techniques such as ICP motioncompensation and enforcing piecewise rigid assumptions. We combine these stepswith a test-time optimization method to form a state-of-the-art system thatdoes not require any training data. Because our final approach is dataless, itcan be applied on different datasets with diverse LiDAR rigs withoutretraining. Our proposed approach outperforms all existing methods on Argoverse2.0, halves the error rate on NuScenes, and even rivals the performance ofsupervised networks on Waymo and lidarKITTI.", "output": "Re-Evaluating LiDAR Scene Flow for Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Various artifacts, such as ghost colors, interlacing, and motion blur, hinderdiagnosing colorectal cancer (CRC) from videos acquired during colonoscopy. Theframes containing these artifacts are called uninformative frames and arepresent in large proportions in colonoscopy videos. To alleviate the impact ofartifacts, we propose an adversarial network based framework to convertuninformative frames to clinically relevant frames. We examine theeffectiveness of the proposed approach by evaluating the translated frames forpolyp detection using YOLOv5. Preliminary results present improved detectionperformance along with elegant qualitative outcomes. We also examine thefailure cases to determine the directions for future work.", "output": "Can Adversarial Networks Make Uninformative Colonoscopy Video Frames Clinically Informative?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper tackles spectral reflectance recovery (SRR) from RGB images. Sincecapturing ground-truth spectral reflectance and camera spectral sensitivity arechallenging and costly, most existing approaches are trained on syntheticimages and utilize the same parameters for all unseen testing images, which aresuboptimal especially when the trained models are tested on real images becausethey never exploit the internal information of the testing images. To addressthis issue, we adopt a self-supervised meta-auxiliary learning (MAXL) strategythat fine-tunes the well-trained network parameters with each testing image tocombine external with internal information. To the best of our knowledge, thisis the first work that successfully adapts the MAXL strategy to this problem.Instead of relying on naive end-to-end training, we also propose a novelarchitecture that integrates the physical relationship between the spectralreflectance and the corresponding RGB images into the network based on ourmathematical analysis. Besides, since the spectral reflectance of a scene isindependent to its illumination while the corresponding RGB images are not, werecover the spectral reflectance of a scene from its RGB images captured undermultiple illuminations to further reduce the unknown. Qualitative andquantitative evaluations demonstrate the effectiveness of our proposed networkand of the MAXL. Our code and data are available at", "output": "Learning to Recover Spectral Reflectance from RGB Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Modeling the 3D world from sensor data for simulation is a scalable way ofdeveloping testing and validation environments for robotic learning problemssuch as autonomous driving. However, manually creating or re-creatingreal-world-like environments is difficult, expensive, and not scalable. Recentgenerative model techniques have shown promising progress to address suchchallenges by learning 3D assets using only plentiful 2D images -- but stillsuffer limitations as they leverage either human-curated image datasets orrenderings from manually-created synthetic 3D environments. In this paper, weintroduce GINA-3D, a generative model that uses real-world driving data fromcamera and LiDAR sensors to create realistic 3D implicit neural assets ofdiverse vehicles and pedestrians. Compared to the existing image datasets, thereal-world driving setting poses new challenges due to occlusions,lighting-variations and long-tail distributions. GINA-3D tackles thesechallenges by decoupling representation learning and generative modeling intotwo stages with a learned tri-plane latent structure, inspired by recentadvances in generative modeling of images. To evaluate our approach, weconstruct a large-scale object-centric dataset containing over 520K images ofvehicles and pedestrians from the Waymo Open Dataset, and a new set of 80Kimages of long-tail instances such as construction equipment, garbage trucks,and cable cars. We compare our model with existing approaches and demonstratethat it achieves state-of-the-art performance in quality and diversity for bothgenerated images and geometries.", "output": "GINA-3D: Learning to Generate Implicit Neural Assets in the Wild."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Adapters present a promising solution to the catastrophic forgetting problemin continual learning. However, training independent Adapter modules for everynew task misses an opportunity for cross-task knowledge transfer. We proposeImprovise to Initialize (I2I), a continual learning algorithm that initializesAdapters for incoming tasks by distilling knowledge from previously-learnedtasks' Adapters. We evaluate I2I on CLiMB, a multimodal continual learningbenchmark, by conducting experiments on sequences of visual question answeringtasks. Adapters trained with I2I consistently achieve better task accuracy thanindependently-trained Adapters, demonstrating that our algorithm facilitatesknowledge transfer between task Adapters. I2I also results in better cross-taskknowledge transfer than the state-of-the-art AdapterFusion without incurringthe associated parametric cost.", "output": "I2I: Initializing Adapters with Improvised Knowledge."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Charts are a powerful tool for visually conveying complex data, but theircomprehension poses a challenge due to the diverse chart types and intricatecomponents. Existing chart comprehension methods suffer from either heuristicrules or an over-reliance on OCR systems, resulting in suboptimal performance.To address these issues, we present ChartReader, a unified framework thatseamlessly integrates chart derendering and comprehension tasks. Our approachincludes a transformer-based chart component detection module and an extendedpre-trained vision-language model for chart-to-X tasks. By learning the rulesof charts automatically from annotated datasets, our approach eliminates theneed for manual rule-making, reducing effort and enhancing accuracy.~We alsointroduce a data variable replacement technique and extend the input andposition embeddings of the pre-trained model for cross-task training. Weevaluate ChartReader on Chart-to-Table, ChartQA, and Chart-to-Text tasks,demonstrating its superiority over existing methods. Our proposed framework cansignificantly reduce the manual effort involved in chart analysis, providing astep towards a universal chart understanding model. Moreover, our approachoffers opportunities for plug-and-play integration with mainstream LLMs such asT5 and TaPas, extending their capability to chart comprehension tasks. The codeis available at ", "output": "ChartReader: A Unified Framework for Chart Derendering and Comprehension without Heuristic Rules."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision-based Transformer have shown huge application in the perception moduleof autonomous driving in terms of predicting accurate 3D bounding boxes, owingto their strong capability in modeling long-range dependencies between thevisual features. However Transformers, initially designed for language models,have mostly focused on the performance accuracy, and not so much on theinference-time budget. For a safety critical system like autonomous driving,real-time inference at the on-board compute is an absolute necessity. Thiskeeps our object detection algorithm under a very tight run-time budget. Inthis paper, we evaluated a variety of strategies to optimize on theinference-time of vision transformers based object detection methods keeping aclose-watch on any performance variations. Our chosen metric for thesestrategies is accuracy-runtime joint optimization. Moreover, for actualinference-time analysis we profile our strategies with float32 and float16precision with TensorRT module. This is the most common format used by theindustry for deployment of their Machine Learning networks on the edge devices.We showed that our strategies are able to improve inference-time by 63% at thecost of performance drop of mere 3% for our problem-statement defined inevaluation section. These strategies brings down Vision Transformers detectorsinference-time even less than traditional single-image based CNN detectors likeFCOS. We recommend practitioners use these techniques to deploy Transformersbased hefty multi-view networks on a budge-constrained robotic platform.", "output": "Training Strategies for Vision Transformers for Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-turn compositional image generation (M-CIG) is a challenging task thataims to iteratively manipulate a reference image given a modification text.While most of the existing methods for M-CIG are based on generativeadversarial networks (GANs), recent advances in image generation havedemonstrated the superiority of diffusion models over GANs. In this paper, wepropose a diffusion-based method for M-CIG named conditional denoisingdiffusion with image compositional matching (CDD-ICM). We leverage CLIP as thebackbone of image and text encoders, and incorporate a gated fusion mechanism,originally proposed for question answering, to compositionally fuse thereference image and the modification text at each turn of M-CIG. We introduce aconditioning scheme to generate the target image based on the fusion results.To prioritize the semantic quality of the generated target image, we learn anauxiliary image compositional match (ICM) objective, along with the conditionaldenoising diffusion (CDD) objective in a multi-task learning framework.Additionally, we also perform ICM guidance and classifier-free guidance toimprove performance. Experimental results show that CDD-ICM achievesstate-of-the-art results on two benchmark datasets for M-CIG, i.e., CoDraw andi-CLEVR.", "output": "A Diffusion-based Method for Multi-turn Compositional Image Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Rotated bounding boxes drastically reduce output ambiguity of elongatedobjects, making it superior to axis-aligned bounding boxes. Despite theeffectiveness, rotated detectors are not widely employed. Annotating rotatedbounding boxes is such a laborious process that they are not provided in manydetection datasets where axis-aligned annotations are used instead. In thispaper, we propose a framework that allows the model to predict precise rotatedboxes only requiring cheaper axis-aligned annotation of the target dataset 1.To achieve this, we leverage the fact that neural networks are capable oflearning richer representation of the target domain than what is utilized bythe task. The under-utilized representation can be exploited to address a moredetailed task. Our framework combines task knowledge of an out-of-domain sourcedataset with stronger annotation and domain knowledge of the target datasetwith weaker annotation. A novel assignment process and projection loss are usedto enable the co-training on the source and target datasets. As a result, themodel is able to solve the more detailed task in the target domain, withoutadditional computation overhead during inference. We extensively evaluate themethod on various target datasets including fresh-produce dataset, HRSC2016 andSSDD. Results show that the proposed method consistently performs on par withthe fully supervised approach.", "output": "Knowledge Combination to Learn Rotated Detection Without Rotated Annotation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Heatmaps are widely used to interpret deep neural networks, particularly forcomputer vision tasks, and the heatmap-based explainable AI (XAI) techniquesare a well-researched topic. However, most studies concentrate on enhancing thequality of the generated heatmap or discovering alternate heatmap generationtechniques, and little effort has been devoted to making heatmap-based XAIautomatic, interactive, scalable, and accessible. To address this gap, wepropose a framework that includes two modules: (1) context modelling and (2)reasoning. We proposed a template-based image captioning approach for contextmodelling to create text-based contextual information from the heatmap andinput data. The reasoning module leverages a large language model to provideexplanations in combination with specialised knowledge. Our qualitativeexperiments demonstrate the effectiveness of our framework and heatmapcaptioning approach. The code for the proposed template-based heatmapcaptioning approach will be publicly available.", "output": "Towards Self-Explainability of Deep Neural Networks with Heatmap Captioning and Large-Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In clinical scenarios, multi-specialist consultation could significantlybenefit the diagnosis, especially for intricate cases. This inspires us toexplore a \"multi-expert joint diagnosis\" mechanism to upgrade the existing\"single expert\" framework commonly seen in the current literature. To this end,we propose METransformer, a method to realize this idea with atransformer-based backbone. The key design of our method is the introduction ofmultiple learnable \"expert\" tokens into both the transformer encoder anddecoder. In the encoder, each expert token interacts with both vision tokensand other expert tokens to learn to attend different image regions for imagerepresentation. These expert tokens are encouraged to capture complementaryinformation by an orthogonal loss that minimizes their overlap. In the decoder,each attended expert token guides the cross-attention between input words andvisual tokens, thus influencing the generated report. A metrics-based expertvoting strategy is further developed to generate the final report. By themulti-experts concept, our model enjoys the merits of an ensemble-basedapproach but through a manner that is computationally more efficient andsupports more sophisticated interactions among experts. Experimental resultsdemonstrate the promising performance of our proposed model on two widely usedbenchmarks. Last but not least, the framework-level innovation makes our workready to incorporate advances on existing \"single-expert\" models to furtherimprove its performance.", "output": "METransformer: Radiology Report Generation by Transformer with Multiple Learnable Expert Tokens."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Sketch-based image retrieval, which aims to use sketches as queries toretrieve images containing the same query instance, receives increasingattention in recent years. Although dramatic progress has been made in sketchretrieval, few efforts are devoted to logo sketch retrieval which is stillhindered by the following challenges: Firstly, logo sketch retrieval is moredifficult than typical sketch retrieval problem, since a logo sketch usuallycontains much less visual contents with only irregular strokes and lines.Secondly, instance-specific sketches demonstrate dramatic appearance variances,making them less identifiable when querying the same logo instance. Thirdly,there exist several sketch retrieval benchmarking datasets nowadays, whereas aninstance-level logo sketch dataset is still publicly unavailable. To addressthe above-mentioned limitations, we make twofold contributions in this studyfor instance-level logo sketch retrieval. To begin with, we construct aninstance-level logo sketch dataset containing 2k logo instances and exceeding9k sketches. To our knowledge, this is the first publicly availableinstance-level logo sketch dataset. Next, we develop a fine-grainedtriple-branch CNN architecture based on hybrid attention mechanism termedLogoNet for accurate logo sketch retrieval. More specifically, we embed thehybrid attention mechanism into the triple-branch architecture for capturingthe key query-specific information from the limited visual cues in the logosketches. Experimental evaluations both on our assembled dataset and publicbenchmark datasets demonstrate the effectiveness of our proposed network.", "output": "LogoNet: a fine-grained network for instance-level logo sketch retrieval."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Industrial anomaly detection (IAD) is crucial for automating industrialquality inspection. The diversity of the datasets is the foundation fordeveloping comprehensive IAD algorithms. Existing IAD datasets focus on thediversity of data categories, overlooking the diversity of domains within thesame data category. In this paper, to bridge this gap, we propose theAero-engine Blade Anomaly Detection (AeBAD) dataset, consisting of twosub-datasets: the single-blade dataset and the video anomaly detection datasetof blades. Compared to existing datasets, AeBAD has the following twocharacteristics: 1.) The target samples are not aligned and at differentscales. 2.) There is a domain shift between the distribution of normal samplesin the test set and the training set, where the domain shifts are mainly causedby the changes in illumination and view. Based on this dataset, we observe thatcurrent state-of-the-art (SOTA) IAD methods exhibit limitations when the domainof normal samples in the test set undergoes a shift. To address this issue, wepropose a novel method called masked multi-scale reconstruction (MMR), whichenhances the model's capacity to deduce causality among patches in normalsamples by a masked reconstruction task. MMR achieves superior performancecompared to SOTA methods on the AeBAD dataset. Furthermore, MMR achievescompetitive performance with SOTA methods to detect the anomalies of differenttypes on the MVTec AD dataset. Code and dataset are available at", "output": "Industrial Anomaly Detection with Domain Shift: A Real-world Dataset and Masked Multi-scale Reconstruction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Domain adaptive semantic segmentation methods commonly utilize stage-wisetraining, consisting of a warm-up and a self-training stage. However, thispopular approach still faces several challenges in each stage: for warm-up, thewidely adopted adversarial training often results in limited performance gain,due to blind feature alignment; for self-training, finding proper categoricalthresholds is very tricky. To alleviate these issues, we first propose toreplace the adversarial training in the warm-up stage by a novel symmetricknowledge distillation module that only accesses the source domain data andmakes the model domain generalizable. Surprisingly, this domain generalizablewarm-up model brings substantial performance improvement, which can be furtheramplified via our proposed cross-domain mixture data augmentation technique.Then, for the self-training stage, we propose a threshold-free dynamicpseudo-label selection mechanism to ease the aforementioned threshold problemand make the model better adapted to the target domain. Extensive experimentsdemonstrate that our framework achieves remarkable and consistent improvementscompared to the prior arts on popular benchmarks. Codes and models areavailable at ", "output": "DiGA: Distil to Generalize and then Adapt for Domain Adaptive Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A novel 4K video frame interpolator based on bilateral transformer (BiFormer)is proposed in this paper, which performs three steps: global motionestimation, local motion refinement, and frame synthesis. First, in globalmotion estimation, we predict symmetric bilateral motion fields at a coarsescale. To this end, we propose BiFormer, the first transformer-based bilateralmotion estimator. Second, we refine the global motion fields efficiently usingblockwise bilateral cost volumes (BBCVs). Third, we warp the input frames usingthe refined motion fields and blend them to synthesize an intermediate frame.Extensive experiments demonstrate that the proposed BiFormer algorithm achievesexcellent interpolation performance on 4K datasets. The source codes areavailable at ", "output": "BiFormer: Learning Bilateral Motion Estimation via Bilateral Transformer for 4K Video Frame Interpolation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently developed text-to-image diffusion models make it easy to edit orcreate high-quality images. Their ease of use has raised concerns about thepotential for malicious editing or deepfake creation. Imperceptibleperturbations have been proposed as a means of protecting images from maliciousediting by preventing diffusion models from generating realistic images.However, we find that the aforementioned perturbations are not robust to JPEGcompression, which poses a major weakness because of the common usage andavailability of JPEG. We discuss the importance of robustness for additiveimperceptible perturbations and encourage alternative approaches to protectimages against editing.", "output": "JPEG Compressed Images Can Bypass Protections Against AI Editing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Regular object detection methods output rectangle bounding boxes, which areunable to accurately describe the actual object shapes. Instance segmentationmethods output pixel-level labels, which are computationally expensive forreal-time applications. Therefore, a polygon representation is needed toachieve precise shape alignment, while retaining low computation cost. Wedevelop a novel Deformable Polar Polygon Object Detection method (DPPD) todetect objects in polygon shapes. In particular, our network predicts, for eachobject, a sparse set of flexible vertices to construct the polygon, where eachvertex is represented by a pair of angle and distance in the Polar coordinatesystem. To enable training, both ground truth and predicted polygons aredensely resampled to have the same number of vertices with equal-spacedraypoints. The resampling operation is fully differentable, allowing gradientback-propagation. Sparse polygon predicton ensures high-speed runtime inferencewhile dense resampling allows the network to learn object shapes with highprecision. The polygon detection head is established on top of an anchor-freeand NMS-free network architecture. DPPD has been demonstrated successfully invarious object detection tasks for autonomous driving such as traffic-sign,crosswalk, vehicle and pedestrian objects.", "output": "DPPD: Deformable Polar Polygon Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In digital pathology, the spatial context of cells is important for cellclassification, cancer diagnosis and prognosis. To model such complex cellcontext, however, is challenging. Cells form different mixtures, lineages,clusters and holes. To model such structural patterns in a learnable fashion,we introduce several mathematical tools from spatial statistics and topologicaldata analysis. We incorporate such structural descriptors into a deepgenerative model as both conditional inputs and a differentiable loss. Thisway, we are able to generate high quality multi-class cell layouts for thefirst time. We show that the topology-rich cell layouts can be used for dataaugmentation and improve the performance of downstream tasks such as cellclassification.", "output": "Topology-Guided Multi-Class Cell Context Generation for Digital Pathology."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision foundation models exhibit impressive power, benefiting from theextremely large model capacity and broad training data. However, in practice,downstream scenarios may only support a small model due to the limitedcomputational resources or efficiency considerations. Moreover, the data usedfor pretraining foundation models are usually invisible and very different fromthe target data of downstream tasks. This brings a critical challenge for thereal-world application of foundation models: one has to transfer the knowledgeof a foundation model to the downstream task that has a quite differentarchitecture with only downstream target data. Existing transfer learning orknowledge distillation methods depend on either the same model structure orfinetuning of the foundation model. Thus, naively introducing these methods canbe either infeasible or very inefficient. To address this, we propose aTask-Driven Model Reprogramming (TDMR) framework. Specifically, we reprogramthe foundation model to project the knowledge into a proxy space, whichalleviates the adverse effect of task mismatch and domain inconsistency. Then,we reprogram the target model via progressive distillation from the proxy spaceto efficiently learn the knowledge from the reprogrammed foundation model. TDMRis compatible with different pre-trained model types (CNN, transformer or theirmix) and limited target data, and promotes the wide applications of visionfoundation models to downstream tasks in a cost-effective manner. Extensiveexperiments on different downstream classification tasks and target modelstructures demonstrate the effectiveness of our methods with both CNNs andtransformer foundation models.", "output": "Towards Efficient Task-Driven Model Reprogramming with Foundation Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The concept of image similarity is ambiguous, meaning that images that areconsidered similar in one context might not be in another. This ambiguitymotivates the creation of metrics for specific contexts. This work explores theability of the successful deep perceptual similarity (DPS) metrics to adapt toa given context. Recently, DPS metrics have emerged using the deep features ofneural networks for comparing images. These metrics have been successful ondatasets that leverage the average human perception in limited settings. Butthe question remains if they could be adapted to specific contexts ofsimilarity. No single metric can suit all definitions of similarity andprevious metrics have been rule-based which are labor intensive to rewrite fornew contexts. DPS metrics, on the other hand, use neural networks which mightbe retrained for each context. However, retraining networks takes resources andmight ruin performance on previous tasks. This work examines the adaptabilityof DPS metrics by training positive scalars for the deep features of pretrainedCNNs to correctly measure similarity for different contexts. Evaluation isperformed on contexts defined by randomly ordering six image distortions (e.g.rotation) by which should be considered more similar when applied to an image.This also gives insight into whether the features in the CNN is enough todiscern different distortions without retraining. Finally, the trained metricsare evaluated on a perceptual similarity dataset to evaluate if adapting to anordering affects their performance on established scenarios. The findings showthat DPS metrics can be adapted with high performance. While the adaptedmetrics have difficulties with the same contexts as baselines, performance isimproved in 99% of cases. Finally, it is shown that the adaption is notsignificantly detrimental to prior performance on perceptual similarity.", "output": "Deep Perceptual Similarity is Adaptable to Ambiguous Contexts."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Learning-based video compression has been extensively studied over the pastyears, but it still has limitations in adapting to various motion patterns andentropy models. In this paper, we propose multi-mode video compression (MMVC),a block wise mode ensemble deep video compression framework that selects theoptimal mode for feature domain prediction adapting to different motionpatterns. Proposed multi-modes include ConvLSTM-based feature domainprediction, optical flow conditioned feature domain prediction, and featurepropagation to address a wide range of cases from static scenes withoutapparent motions to dynamic scenes with a moving camera. We partition thefeature space into blocks for temporal prediction in spatial block-basedrepresentations. For entropy coding, we consider both dense and sparsepost-quantization residual blocks, and apply optional run-length coding tosparse residuals to improve the compression rate. In this sense, our methoduses a dual-mode entropy coding scheme guided by a binary density map, whichoffers significant rate reduction surpassing the extra cost of transmitting thebinary selection map. We validate our scheme with some of the most popularbenchmarking datasets. Compared with state-of-the-art video compression schemesand standard codecs, our method yields better or competitive results measuredwith PSNR and MS-SSIM.", "output": "MMVC: Learned Multi-Mode Video Compression with Block-based Prediction Mode Selection and Density-Adaptive Entropy Coding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a novel and effective method calibrating cross-modal features fortext-based person search. Our method is cost-effective and can easily retrievespecific persons with textual captions. Specifically, its architecture is onlya dual-encoder and a detachable cross-modal decoder. Without extra multi-levelbranches or complex interaction modules as the neck following the backbone, ourmodel makes a high-speed inference only based on the dual-encoder. Besides, ourmethod consists of two novel losses to provide fine-grained cross-modalfeatures. A Sew loss takes the quality of textual captions as guidance andaligns features between image and text modalities. A Masking Caption Modeling(MCM) loss uses a masked captions prediction task to establish detailed andgeneric relationships between textual and visual parts. We show the top resultsin three popular benchmarks, including CUHK-PEDES, ICFG-PEDES, and RSTPReID. Inparticular, our method achieves 73.81% Rank@1, 74.25% Rank@1 and 57.35% Rank@1on them, respectively. In addition, we also validate each component of ourmethod with extensive experiments. We hope our powerful and scalable paradigmwill serve as a solid baseline and help ease future research in text-basedperson search.", "output": "Calibrating Cross-modal Feature for Text-Based Person Searching."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although face recognition has made impressive progress in recent years, weignore the racial bias of the recognition system when we pursue a high level ofaccuracy. Previous work found that for different races, face recognitionnetworks focus on different facial regions, and the sensitive regions ofdarker-skinned people are much smaller. Based on this discovery, we propose anew de-bias method based on gradient attention, called Gradient AttentionBalance Network (GABN). Specifically, we use the gradient attention map (GAM)of the face recognition network to track the sensitive facial regions and makethe GAMs of different races tend to be consistent through adversarial learning.This method mitigates the bias by making the network focus on similar facialregions. In addition, we also use masks to erase the Top-N sensitive facialregions, forcing the network to allocate its attention to a larger facialregion. This method expands the sensitive region of darker-skinned people andfurther reduces the gap between GAM of darker-skinned people and GAM ofCaucasians. Extensive experiments show that GABN successfully mitigates racialbias in face recognition and learns more balanced performance for people ofdifferent races.", "output": "Gradient Attention Balance Network: Mitigating Face Recognition Racial Bias via Gradient Attention."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Most recent methods of deep image enhancement can be generally classifiedinto two types: decompose-and-enhance and illumination estimation-centric. Theformer is usually less efficient, and the latter is constrained by a strongassumption regarding image reflectance as the desired enhancement result. Toalleviate this constraint while retaining high efficiency, we propose a noveltrainable module that diversifies the conversion from the low-light image andillumination map to the enhanced image. It formulates image enhancement as acomparametric equation parameterized by a camera response function and anexposure compensation ratio. By incorporating this module in an illuminationestimation-centric DNN, our method improves the flexibility of deep imageenhancement, limits the computational burden to illumination estimation, andallows for fully unsupervised learning adaptable to the diverse demands ofdifferent tasks.", "output": "Deep Quantigraphic Image Enhancement via Comparametric Equations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pest counting, which predicts the number of pests in the early stage, is veryimportant because it enables rapid pest control, reduces damage to crops, andimproves productivity. In recent years, light traps have been increasingly usedto lure and photograph pests for pest counting. However, pest images have awide range of variability in pest appearance owing to severe occlusion, widepose variation, and even scale variation. This makes pest counting morechallenging. To address these issues, this study proposes a new pest countingmodel referred to as multiscale and deformable attention CenterNet(Mada-CenterNet) for internal low-resolution (LR) and high-resolution (HR)joint feature learning. Compared with the conventional CenterNet, the proposedMada-CenterNet adopts a multiscale heatmap generation approach in a two-stepfashion to predict LR and HR heatmaps adaptively learned to scale variations,that is, changes in the number of pests. In addition, to overcome the pose andocclusion problems, a new between-hourglass skip connection based on deformableand multiscale attention is designed to ensure internal LR and HR joint featurelearning and incorporate geometric deformation, thereby resulting in animproved pest counting accuracy. Through experiments, the proposedMada-CenterNet is verified to generate the HR heatmap more accurately andimprove pest counting accuracy owing to multiscale heatmap generation, jointinternal feature learning, and deformable and multiscale attention. Inaddition, the proposed model is confirmed to be effective in overcoming severeocclusions and variations in pose and scale. The experimental results show thatthe proposed model outperforms state-of-the-art crowd counting and objectdetection models.", "output": "Trap-Based Pest Counting: Multiscale and Deformable Attention CenterNet Integrating Internal LR and HR Joint Feature Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advancements in deep learning and computer vision have led towidespread use of deep neural networks to extract building footprints fromremote-sensing imagery. The success of such methods relies on the availabilityof large databases of high-resolution remote sensing images with high-qualityannotations. The CrowdAI Mapping Challenge Dataset is one of these datasetsthat has been used extensively in recent years to train deep neural networks.This dataset consists of $ sim $280k training images and $ sim $60k testingimages, with polygonal building annotations for all images. However, issuessuch as low-quality and incorrect annotations, extensive duplication of imagesamples, and data leakage significantly reduce the utility of deep neuralnetworks trained on the dataset. Therefore, it is an imperative pre-conditionto adopt a data validation pipeline that evaluates the quality of the datasetprior to its use. To this end, we propose a drop-in pipeline that employsperceptual hashing techniques for efficient de-duplication of the dataset andidentification of instances of data leakage between training and testingsplits. In our experiments, we demonstrate that nearly 250k($ sim $90%)images in the training split were identical. Moreover, our analysis on thevalidation split demonstrates that roughly 56k of the 60k images also appear inthe training split, resulting in a data leakage of 93%. The source code usedfor the analysis and de-duplication of the CrowdAI Mapping Challenge dataset ispublicly available at  .", "output": "Efficient Deduplication and Leakage Detection in Large Scale Image Datasets with a focus on the CrowdAI Mapping Challenge Dataset."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "People can innately recognize human facial expressions in unnatural forms,such as when depicted on the unusual faces drawn in cartoons or when applied toan animal's features. However, current machine learning algorithms strugglewith out-of-domain transfer in facial expression recognition (FER). We proposea biologically-inspired mechanism for such transfer learning, which is based onnorm-referenced encoding, where patterns are encoded in terms of differencevectors relative to a domain-specific reference vector. By incorporatingdomain-specific reference frames, we demonstrate high data efficiency intransfer learning across multiple domains. Our proposed architecture providesan explanation for how the human brain might innately recognize facialexpressions on varying head shapes (humans, monkeys, and cartoon avatars)without extensive training. Norm-referenced encoding also allows the intensityof the expression to be read out directly from neural unit activity, similar toface-selective neurons in the brain. Our model achieves a classificationaccuracy of 92.15% on the FERG dataset with extreme data efficiency. We trainour proposed mechanism with only 12 images, including a single image of eachclass (facial expression) and one image per domain (avatar). In comparison, theauthors of the FERG dataset achieved a classification accuracy of 89.02% withtheir FaceExpr model, which was trained on 43,000 images.", "output": "Multi-Domain Norm-referenced Encoding Enables Data Efficient Transfer Learning of Facial Expression Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Convolutional neural networks (CNNs) have shown state-of-the-art performancein various applications. However, CNNs are resource-hungry due to theirrequirement of high computational complexity and memory storage. Recent effortstoward achieving computational efficiency in CNNs involve filter pruningmethods that eliminate some of the filters in CNNs based on theenquote{importance} of the filters. The majority of existing filter pruningmethods are either \"active\", which use a dataset and generate feature maps toquantify filter importance, or \"passive\", which compute filter importance usingentry-wise norm of the filters without involving data. Under a high pruningratio where large number of filters are to be pruned from the network, theentry-wise norm methods eliminate relatively smaller norm filters withoutconsidering the significance of the filters in producing the node output,resulting in degradation in the performance. To address this, we present apassive filter pruning method where the filters are pruned based on theircontribution in producing output by considering the operator norm of thefilters. The proposed pruning method generalizes better across various CNNscompared to that of the entry-wise norm-based pruning methods. In comparison tothe existing active filter pruning methods, the proposed pruning method is atleast 4.5 times faster in computing filter importance and is able to achievesimilar performance compared to that of the active filter pruning methods. Theefficacy of the proposed pruning method is evaluated on audio sceneclassification and image classification using various CNNs architecture such asVGGish, DCASE21_Net, VGG-16 and ResNet-50.", "output": "Efficient CNNs via Passive Filter Pruning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Semantic image synthesis aims to generate photo realistic images given asemantic segmentation map. Despite much recent progress, training them stillrequires large datasets of images annotated with per-pixel label maps that areextremely tedious to obtain. To alleviate the high annotation cost, we proposea transfer method that leverages a model trained on a large source dataset toimprove the learning ability on small target datasets via estimated pairwiserelations between source and target classes. The class affinity matrix isintroduced as a first layer to the source model to make it compatible with thetarget label maps, and the source model is then further finetuned for thetarget domain. To estimate the class affinities we consider differentapproaches to leverage prior knowledge: semantic segmentation on the sourcedomain, textual label embeddings, and self-supervised vision features. We applyour approach to GAN-based and diffusion-based architectures for semanticsynthesis. Our experiments show that the different ways to estimate classaffinity can be effectively combined, and that our approach significantlyimproves over existing state-of-the-art transfer approaches for generativeimage models.", "output": "Few-shot Semantic Image Synthesis with Class Affinity Transfer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Continuous convolution has recently gained prominence due to its ability tohandle irregularly sampled data and model long-term dependency. Also, thepromising experimental results of using large convolutional kernels havecatalyzed the development of continuous convolution since they can constructlarge kernels very efficiently. Leveraging neural networks, more specificallymultilayer perceptrons (MLPs), is by far the most prevalent approach toimplementing continuous convolution. However, there are a few drawbacks, suchas high computational costs, complex hyperparameter tuning, and limiteddescriptive power of filters. This paper suggests an alternative approach tobuilding a continuous convolution without neural networks, resulting in morecomputationally efficient and improved performance. We present self-movingpoint representations where weight parameters freely move, and interpolationschemes are used to implement continuous functions. When applied to constructconvolutional kernels, the experimental results have shown improved performancewith drop-in replacement in the existing frameworks. Due to its lightweightstructure, we are first to demonstrate the effectiveness of continuousconvolution in a large-scale setting, e.g., ImageNet, presenting theimprovements over the prior arts. Our code is available on", "output": "SMPConv: Self-moving Point Representations for Continuous Convolution."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a new self-supervised method for predicting 3D human body posefrom a single image. The prediction network is trained from a dataset ofunlabelled images depicting people in typical poses and a set of unpaired 2Dposes. By minimising the need for annotated data, the method has the potentialfor rapid application to pose estimation of other articulated structures (e.g.animals). The self-supervision comes from an earlier idea exploitingconsistency between predicted pose under 3D rotation. Our method is asubstantial advance on state-of-the-art self-supervised methods in training amapping directly from images, without limb articulation constraints or any 3Dempirical pose prior. We compare performance with state-of-the-artself-supervised methods using benchmark datasets that provide images andground-truth 3D pose (Human3.6M, MPI-INF-3DHP). Despite the reduced requirementfor annotated data, we show that the method outperforms on Human3.6M andmatches performance on MPI-INF-3DHP. Qualitative results on a dataset of humanhands show the potential for rapidly learning to predict 3D pose forarticulated structures other than the human body.", "output": "Self-supervised 3D Human Pose Estimation from a Single Image."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Radiotherapy (RT) is a key component in the treatment of various cancers,including Acute Lymphocytic Leukemia (ALL) and Acute Myelogenous Leukemia(AML). Precise delineation of organs at risk (OARs) and target areas isessential for effective treatment planning. Intensity Modulated Radiotherapy(IMRT) techniques, such as Total Marrow Irradiation (TMI) and Total Marrow andLymph node Irradiation (TMLI), provide more precise radiation delivery comparedto Total Body Irradiation (TBI). However, these techniques requiretime-consuming manual segmentation of structures in Computerized Tomography(CT) scans by the Radiation Oncologist (RO). In this paper, we present a deeplearning-based auto-contouring method for segmenting Planning Target Volume(PTV) for TMLI treatment using the U-Net architecture. We trained and comparedtwo segmentation models with two different loss functions on a dataset of 100patients treated with TMLI at the Humanitas Research Hospital between 2011 and2021. Despite challenges in lymph node areas, the best model achieved anaverage Dice score of 0.816 for PTV segmentation. Our findings are apreliminary but significant step towards developing a segmentation model thathas the potential to save radiation oncologists a considerable amount of time.This could allow for the treatment of more patients, resulting in improvedclinical practice efficiency and more reproducible contours.", "output": "Segmentation of Planning Target Volume in CT Series for Total Marrow Irradiation Using U-Net."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing machine learning models demonstrate excellent performance in imageobject recognition after training on a large-scale dataset under fullsupervision. However, these models only learn to map an image to a predefinedclass index, without revealing the actual semantic meaning of the object in theimage. In contrast, vision-language models like CLIP are able to assignsemantic class names to unseen objects in a `zero-shot' manner, although theystill rely on a predefined set of candidate names at test time. In this paper,we reconsider the recognition problem and task a vision-language model toassign class names to images given only a large and essentially unconstrainedvocabulary of categories as prior information. We use non-parametric methods toestablish relationships between images which allow the model to automaticallynarrow down the set of possible candidate names. Specifically, we proposeiteratively clustering the data and voting on class names within them, showingthat this enables a roughly 50% improvement over the baseline on ImageNet.Furthermore, we tackle this problem both in unsupervised and partiallysupervised settings, as well as with a coarse-grained and fine-grained searchspace as the unconstrained dictionary.", "output": "What's in a Name? Beyond Class Indices for Image Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Computer-assisted automatic analysis of diabetic retinopathy (DR) is of greatimportance in reducing the risks of vision loss and even blindness. Ultra-wideoptical coherence tomography angiography (UW-OCTA) is a non-invasive and safeimaging modality in DR diagnosis system, but there is a lack of publiclyavailable benchmarks for model development and evaluation. To promote furtherresearch and scientific benchmarking for diabetic retinopathy analysis usingUW-OCTA images, we organized a challenge named \"DRAC - Diabetic RetinopathyAnalysis Challenge\" in conjunction with the 25th International Conference onMedical Image Computing and Computer Assisted Intervention (MICCAI 2022). Thechallenge consists of three tasks: segmentation of DR lesions, image qualityassessment and DR grading. The scientific community responded positively to thechallenge, with 11, 12, and 13 teams from geographically diverse institutessubmitting different solutions in these three tasks, respectively. This paperpresents a summary and analysis of the top-performing solutions and results foreach task of the challenge. The obtained results from top algorithms indicatethe importance of data augmentation, model architecture and ensemble ofnetworks in improving the performance of deep learning models. These findingshave the potential to enable new developments in diabetic retinopathy analysis.The challenge remains open for post-challenge registrations and submissions forbenchmarking future methodology developments.", "output": "DRAC: Diabetic Retinopathy Analysis Challenge with Ultra-Wide Optical Coherence Tomography Angiography Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Jointly harnessing complementary features of multi-modal input data in acommon latent space has been found to be beneficial long ago. However, theinfluence of each modality on the models decision remains a puzzle. This studyproposes a deep learning framework for the modality-level interpretation ofmultimodal earth observation data in an end-to-end fashion. While leveraging anexplainable machine learning method, namely Occlusion Sensitivity, the proposedframework investigates the influence of modalities under an early-fusionscenario in which the modalities are fused before the learning process. We showthat the task of wilderness mapping largely benefits from auxiliary data suchas land cover and night time light data.", "output": "Explaining Multimodal Data Fusion: Occlusion Analysis for Wilderness Mapping."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a novel task for generating 3D dance movements that simultaneouslyincorporate both text and music modalities. Unlike existing works that generatedance movements using a single modality such as music, our goal is to producericher dance movements guided by the instructive information provided by thetext. However, the lack of paired motion data with both music and textmodalities limits the ability to generate dance movements that integrate both.To alleviate this challenge, we propose to utilize a 3D human motion VQ-VAE toproject the motions of the two datasets into a latent space consisting ofquantized vectors, which effectively mix the motion tokens from the twodatasets with different distributions for training. Additionally, we propose across-modal transformer to integrate text instructions into motion generationarchitecture for generating 3D dance movements without degrading theperformance of music-conditioned dance generation. To better evaluate thequality of the generated motion, we introduce two novel metrics, namely MotionPrediction Distance (MPD) and Freezing Score, to measure the coherence andfreezing percentage of the generated motion. Extensive experiments show thatour approach can generate realistic and coherent dance movements conditioned onboth text and music while maintaining comparable performance with the twosingle modalities. Code will be available at:", "output": "TM2D: Bimodality Driven 3D Dance Generation via Music-Text Integration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The Structure from Motion (SfM) challenge in computer vision is the processof recovering the 3D structure of a scene from a series of projectivemeasurements that are calculated from a collection of 2D images, taken fromdifferent perspectives. SfM consists of three main steps; feature detection andmatching, camera motion estimation, and recovery of 3D structure from estimatedintrinsic and extrinsic parameters and features.A problem encountered in SfM is that scenes lacking texture or withrepetitive features can cause erroneous feature matching between frames.Semantic segmentation offers a route to validate and correct SfM models bylabelling pixels in the input images with the use of a deep convolutionalneural network. The semantic and geometric properties associated with classesin the scene can be taken advantage of to apply prior constraints to each classof object. The SfM pipeline COLMAP and semantic segmentation pipeline DeepLabwere used. This, along with planar reconstruction of the dense model, were usedto determine erroneous points that may be occluded from the calculated cameraposition, given the semantic label, and thus prior constraint of thereconstructed plane. Herein, semantic segmentation is integrated into SfM toapply priors on the 3D point cloud, given the object detection in the 2D inputimages. Additionally, the semantic labels of matched keypoints are compared andinconsistent semantically labelled points discarded. Furthermore, semanticlabels on input images are used for the removal of objects associated withmotion in the output SfM models. The proposed approach is evaluated on adata-set of 1102 images of a repetitive architecture scene. This project offersa novel method for improved validation of 3D SfM models.", "output": "Semantic Validation in Structure from Motion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce Multi-Source 3D (MS3D), a new self-training pipeline forunsupervised domain adaptation in 3D object detection. Despite the remarkableaccuracy of 3D detectors, they often overfit to specific domain biases, leadingto suboptimal performance in various sensor setups and environments. Existingmethods typically focus on adapting a single detector to the target domain,overlooking the fact that different detectors possess distinct expertise ondifferent unseen domains. MS3D leverages this by combining differentpre-trained detectors from multiple source domains and incorporating temporalinformation to produce high-quality pseudo-labels for fine-tuning. Our proposedKernel-Density Estimation (KDE) Box Fusion method fuses box proposals frommultiple domains to obtain pseudo-labels that surpass the performance of thebest source domain detectors. MS3D exhibits greater robustness to domain shiftsand produces accurate pseudo-labels over greater distances, making itwell-suited for high-to-low beam domain adaptation and vice versa. Our methodachieved state-of-the-art performance on all evaluated datasets, and wedemonstrate that the choice of pre-trained source detectors has minimal impacton the self-training result, making MS3D suitable for real-world applications.", "output": "MS3D: Leveraging Multiple Detectors for Unsupervised Domain Adaptation in 3D Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In computer vision, contrastive learning is the most advanced unsupervisedlearning framework. Yet most previous methods simply apply fixed composition ofdata augmentations to improve data efficiency, which ignores the changes intheir optimal settings over training. Thus, the pre-determined parameters ofaugmentation operations cannot always fit well with an evolving network duringthe whole training period, which degrades the quality of the learnedrepresentations. In this work, we propose AdDA, which implements a closed-loopfeedback structure to a generic contrastive learning network. AdDA works byallowing the network to adaptively adjust the augmentation compositionsaccording to the real-time feedback. This online adjustment helps maintain thedynamic optimal composition and enables the network to acquire moregeneralizable representations with minimal computational overhead. AdDAachieves competitive results under the common linear protocol on ImageNet-100classification (+1.11% on MoCo v2).", "output": "Adaptive Data Augmentation for Contrastive Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "By using the underlying theory of proper scoring rules, we design a family ofnoise-contrastive estimation (NCE) methods that are tractable for latentvariable models. Both terms in the underlying NCE loss, the one using datasamples and the one using noise samples, can be lower-bounded as in variationalBayes, therefore we call this family of losses fully variationalnoise-contrastive estimation. Variational autoencoders are a particular examplein this family and therefore can be also understood as separating real datafrom synthetic samples using an appropriate classification loss. We furtherdiscuss other instances in this family of fully variational NCE objectives andindicate differences in their empirical behavior.", "output": "Fully Variational Noise-Contrastive Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The use of deep learning methods for automatic detection of students'classroom behavior is a promising approach to analyze their class performanceand enhance teaching effectiveness. However, the lack of publicly availabledatasets on student behavior poses a challenge for researchers in this field.To address this issue, we propose a Student Classroom Behavior dataset(SCB-dataset) that reflects real-life scenarios. Our dataset includes 11,248labels and 4,003 images, with a focus on hand-raising behavior. We evaluatedthe dataset using the YOLOv7 algorithm, achieving a mean average precision(map) of up to 85.3%. We believe that our dataset can serve as a robustfoundation for future research in the field of student behavior detection andpromote further advancements in this area.Our SCB-dataset can be downloadedfrom: ", "output": "SCB-dataset: A Dataset for Detecting Student Classroom Behavior."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Face swapping aims to generate swapped images that fuse the identity ofsource faces and the attributes of target faces. Most existing works addressthis challenging task through 3D modelling or generation using generativeadversarial networks (GANs), but 3D modelling suffers from limitedreconstruction accuracy and GANs often struggle in preserving subtle yetimportant identity details of source faces (e.g., skin colors, face features)and structural attributes of target faces (e.g., face shapes, facialexpressions). This paper presents Face Transformer, a novel face swappingnetwork that can accurately preserve source identities and target attributessimultaneously in the swapped face images. We introduce a transformer networkfor the face swapping task, which learns high-quality semantic-awarecorrespondence between source and target faces and maps identity features ofsource faces to the corresponding region in target faces. The high-qualitysemantic-aware correspondence enables smooth and accurate transfer of sourceidentity information with minimal modification of target shapes andexpressions. In addition, our Face Transformer incorporates a multi-scaletransformation mechanism for preserving the rich fine facial details. Extensiveexperiments show that our Face Transformer achieves superior face swappingperformance qualitatively and quantitatively.", "output": "Face Transformer: Towards High Fidelity and Accurate Face Swapping."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Longitudinal studies, where a series of images from the same set ofindividuals are acquired at different time-points, represent a populartechnique for studying and characterizing temporal dynamics in biomedicalapplications. The classical approach for longitudinal comparison involvesnormalizing for nuisance variations, such as image orientation or contrastdifferences, via pre-processing. Statistical analysis is, in turn, conducted todetect changes of interest, either at the individual or population level. Thisclassical approach can suffer from pre-processing issues and limitations of thestatistical modeling. For example, normalizing for nuisance variation might behard in settings where there are a lot of idiosyncratic changes. In this paper,we present a simple machine learning-based approach that can alleviate theseissues. In our approach, we train a deep learning model (called PaIRNet, forPairwise Image Ranking Network) to compare pairs of longitudinal images, withor without supervision. In the self-supervised setup, for instance, the modelis trained to temporally order the images, which requires learning to recognizetime-irreversible changes. Our results from four datasets demonstrate thatPaIRNet can be very effective in localizing and quantifying meaningfullongitudinal changes while discounting nuisance variation. Our code isavailable aturl{", "output": "Learning to Compare Longitudinal Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fully supervised models often require large amounts of labeled training data,which tends to be costly and hard to acquire. In contrast, self-supervisedrepresentation learning reduces the amount of labeled data needed for achievingthe same or even higher downstream performance. The goal is to pre-train deepneural networks on a self-supervised task such that afterwards the networks areable to extract meaningful features from raw input data. These features arethen used as inputs in downstream tasks, such as image classification.Previously, autoencoders and Siamese networks such as SimSiam have beensuccessfully employed in those tasks. Yet, challenges remain, such as matchingcharacteristics of the features (e.g., level of detail) to the given task anddata set. In this paper, we present a new self-supervised method that combinesthe benefits of Siamese architectures and denoising autoencoders. We show thatour model, called SidAE (Siamese denoising autoencoder), outperforms twoself-supervised baselines across multiple data sets, settings, and scenarios.Crucially, this includes conditions in which only a small amount of labeleddata is available.", "output": "Self-Supervised Siamese Autoencoders."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Misinformation has become a pressing issue. Fake media, in both visual andtextual forms, is widespread on the web. While various deepfake detection andtext fake news detection methods have been proposed, they are only designed forsingle-modality forgery based on binary classification, let alone analyzing andreasoning subtle forgery traces across different modalities. In this paper, wehighlight a new research problem for multi-modal fake media, namely Detectingand Grounding Multi-Modal Media Manipulation (DGM^4). DGM^4 aims to not onlydetect the authenticity of multi-modal media, but also ground the manipulatedcontent (i.e., image bounding boxes and text tokens), which requires deeperreasoning of multi-modal media manipulation. To support a large-scaleinvestigation, we construct the first DGM^4 dataset, where image-text pairs aremanipulated by various approaches, with rich annotation of diversemanipulations. Moreover, we propose a novel HierArchical Multi-modalManipulation rEasoning tRansformer (HAMMER) to fully capture the fine-grainedinteraction between different modalities. HAMMER performs 1) manipulation-awarecontrastive learning between two uni-modal encoders as shallow manipulationreasoning, and 2) modality-aware cross-attention by multi-modal aggregator asdeep manipulation reasoning. Dedicated manipulation detection and groundingheads are integrated from shallow to deep levels based on the interactedmulti-modal information. Finally, we build an extensive benchmark and set uprigorous evaluation metrics for this new research problem. Comprehensiveexperiments demonstrate the superiority of our model; several valuableobservations are also revealed to facilitate future research in multi-modalmedia manipulation.", "output": "Detecting and Grounding Multi-Modal Media Manipulation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision-Language models have shown strong performance in the image-domain --even in zero-shot settings, thanks to the availability of large amount ofpretraining data (i.e., paired image-text examples). However for videos, suchpaired data is not as abundant. Thus, video-text models are usually designed byadapting pretrained image-text models to video-domain, instead of training fromscratch. All such recipes rely on augmenting visual embeddings with temporalinformation (i.e., image -&gt; video), often keeping text embeddings unchanged oreven being discarded. In this paper, we argue that such adapted video-textmodels can benefit more by augmenting text rather than visual information. Wepropose VicTR, which jointly-optimizes text and video tokens, generating'Video-conditioned Text' embeddings. Our method can further make use offreely-available semantic information, in the form of visually-groundedauxiliary text (e.g., object or scene information). We conduct experiments onmultiple benchmarks including supervised (Kinetics-400, Charades), zero-shotand few-shot (HMDB-51, UCF-101) settings, showing competitive performance onactivity recognition based on video-text models.", "output": "VicTR: Video-conditioned Text Representations for Activity Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing work on scene flow estimation focuses on autonomous driving andmobile robotics, while automated solutions are lacking for motion in nature,such as that exhibited by debris flows. We propose DEFLOW, a model for 3Dmotion estimation of debris flows, together with a newly captured dataset. Weadopt a novel multi-level sensor fusion architecture and self-supervision toincorporate the inductive biases of the scene. We further adopt a multi-frametemporal processing module to enable flow speed estimation over time. Our modelachieves state-of-the-art optical flow and depth estimation on our dataset, andfully automates the motion estimation for debris flows. The source code anddataset are available at project page.", "output": "DEFLOW: Self-supervised 3D Motion Estimation of Debris Flow."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a diffusion-based model for 3D-aware generative novel viewsynthesis from as few as a single input image. Our model samples from thedistribution of possible renderings consistent with the input and, even in thepresence of ambiguity, is capable of rendering diverse and plausible novelviews. To achieve this, our method makes use of existing 2D diffusion backbonesbut, crucially, incorporates geometry priors in the form of a 3D featurevolume. This latent feature field captures the distribution over possible scenerepresentations and improves our method's ability to generate view-consistentnovel renderings. In addition to generating novel views, our method has theability to autoregressively synthesize 3D-consistent sequences. We demonstratestate-of-the-art results on synthetic renderings and room-scale scenes; we alsoshow compelling results for challenging, real-world objects.", "output": "Generative Novel View Synthesis with 3D-Aware Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The task of image-level weakly-supervised semantic segmentation (WSSS) hasgained popularity in recent years, as it reduces the vast data annotation costfor training segmentation models. The typical approach for WSSS involvestraining an image classification network using global average pooling (GAP) onconvolutional feature maps. This enables the estimation of object locationsbased on class activation maps (CAMs), which identify the importance of imageregions. The CAMs are then used to generate pseudo-labels, in the form ofsegmentation masks, to supervise a segmentation model in the absence ofpixel-level ground truth. In case of the SEAM baseline, a previous workproposed to improve CAM learning in two ways: (1) Importance sampling, which isa substitute for GAP, and (2) the feature similarity loss, which utilizes aheuristic that object contours almost exclusively align with color edges inimages. In this work, we propose a different probabilistic interpretation ofCAMs for these techniques, rendering the likelihood more appropriate than themultinomial posterior. As a result, we propose an add-on method that can boostessentially any previous WSSS method, improving both the region similarity andcontour quality of all implemented state-of-the-art baselines. This isdemonstrated on a wide variety of baselines on the PASCAL VOC dataset.Experiments on the MS COCO dataset show that performance gains can also beachieved in a large-scale setting. Our code is available at", "output": "High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent years have witnessed significant progress in the field of neuralsurface reconstruction. While the extensive focus was put on volumetric andimplicit approaches, a number of works have shown that explicit graphicsprimitives such as point clouds can significantly reduce computationalcomplexity, without sacrificing the reconstructed surface quality. However,less emphasis has been put on modeling dynamic surfaces with point primitives.In this work, we present a dynamic point field model that combines therepresentational benefits of explicit point-based graphics with implicitdeformation networks to allow efficient modeling of non-rigid 3D surfaces.Using explicit surface primitives also allows us to easily incorporatewell-established constraints such as-isometric-as-possible regularisation.While learning this deformation model is prone to local optima when trained ina fully unsupervised manner, we propose to additionally leverage semanticinformation such as keypoint dynamics to guide the deformation learning. Wedemonstrate our model with an example application of creating an expressiveanimatable human avatar from a collection of 3D scans. Here, previous methodsmostly rely on variants of the linear blend skinning paradigm, whichfundamentally limits the expressivity of such models when dealing with complexcloth appearances such as long skirts. We show the advantages of our dynamicpoint field framework in terms of its representational power, learningefficiency, and robustness to out-of-distribution novel poses.", "output": "Dynamic Point Fields."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Equivariance w.r.t. geometric transformations in neural networks improvesdata efficiency, parameter efficiency and robustness to out-of-domainperspective shifts. When equivariance is not designed into a neural network,the network can still learn equivariant functions from the data. We quantifythis learned equivariance, by proposing an improved measure for equivariance.We find evidence for a correlation between learned translation equivariance andvalidation accuracy on ImageNet. We therefore investigate what can increase thelearned equivariance in neural networks, and find that data augmentation,reduced model capacity and inductive bias in the form of convolutions inducehigher learned equivariance in neural networks.", "output": "What Affects Learned Equivariance in Deep Image Recognition Models?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Understanding historical forest dynamics, specifically changes in forestbiomass and carbon stocks, has become critical for assessing current forestclimate benefits and projecting future benefits under various policy,regulatory, and stewardship scenarios. Carbon accounting frameworks basedexclusively on national forest inventories are limited to broad-scaleestimates, but model-based approaches that combine these inventories withremotely sensed data can yield contiguous fine-resolution maps of forestbiomass and carbon stocks across landscapes over time. Here we describe afundamental step in building a map-based stock-change framework: mappinghistorical forest biomass at fine temporal and spatial resolution (annual, 30m)across all of New York State (USA) from 1990 to 2019, using freely availabledata and open-source tools.Using Landsat imagery, US Forest Service Forest Inventory and Analysis (FIA)data, and off-the-shelf LiDAR collections we developed three modelingapproaches for mapping historical forest aboveground biomass (AGB): training onFIA plot-level AGB estimates (direct), training on LiDAR-derived AGB maps(indirect), and an ensemble averaging predictions from the direct and indirectmodels. Model prediction surfaces (maps) were tested against FIA estimates atmultiple scales. All three approaches produced viable outputs, yet tradeoffswere evident in terms of model complexity, map accuracy, saturation, andfine-scale pattern representation. The resulting map products can help identifywhere, when, and how forest carbon stocks are changing as a result of bothanthropogenic and natural drivers alike. These products can thus serve asinputs to a wide range of applications including stock-change assessments,monitoring reporting and verification frameworks, and prioritizing parcels forprotection or enrollment in improved management programs.", "output": "Mapping historical forest biomass for stock-change assessments at parcel to landscape scales."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Implicit neural representations store videos as neural networks and haveperformed well for various vision tasks such as video compression anddenoising. With frame index or positional index as input, implicitrepresentations (NeRV, E-NeRV, etc) reconstruct video from fixed andcontent-agnostic embeddings. Such embedding largely limits the regressioncapacity and internal generalization for video interpolation. In this paper, wepropose a Hybrid Neural Representation for Videos (HNeRV), where a learnableencoder generates content-adaptive embeddings, which act as the decoder input.Besides the input embedding, we introduce HNeRV blocks, which ensure modelparameters are evenly distributed across the entire network, such that higherlayers (layers near the output) can have more capacity to store high-resolutioncontent and video details. With content-adaptive embeddings and re-designedarchitecture, HNeRV outperforms implicit methods in video regression tasks forboth reconstruction quality ($+4.7$ PSNR) and convergence speed ($16times$faster), and shows better internal generalization. As a simple and efficientvideo representation, HNeRV also shows decoding advantages for speed,flexibility, and deployment, compared to traditional codecs~(H.264, H.265) andlearning-based compression methods. Finally, we explore the effectiveness ofHNeRV on downstream tasks such as video compression and video inpainting. Weprovide project page at  and Code at", "output": "HNeRV: A Hybrid Neural Representation for Videos."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose Embodied Navigation Trajectory Learner (ENTL), a method forextracting long sequence representations for embodied navigation. Our approachunifies world modeling, localization and imitation learning into a singlesequence prediction task. We train our model using vector-quantized predictionsof future states conditioned on current states and actions. ENTL's genericarchitecture enables the sharing of the the spatio-temporal sequence encoderfor multiple challenging embodied tasks. We achieve competitive performance onnavigation tasks using significantly less data than strong baselines whileperforming auxiliary tasks such as localization and future frame prediction (aproxy for world modeling). A key property of our approach is that the model ispre-trained without any explicit reward signal, which makes the resulting modelgeneralizable to multiple tasks and environments.", "output": "ENTL: Embodied Navigation Trajectory Learner."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes a method for generating images of customized objectsspecified by users. The method is based on a general framework that bypassesthe lengthy optimization required by previous approaches, which often employ aper-object optimization paradigm. Our framework adopts an encoder to capturehigh-level identifiable semantics of objects, producing an object-specificembedding with only a single feed-forward pass. The acquired object embeddingis then passed to a text-to-image synthesis model for subsequent generation. Toeffectively blend a object-aware embedding space into a well developedtext-to-image model under the same generation context, we investigate differentnetwork designs and training strategies, and propose a simple yet effectiveregularized joint training scheme with an object identity preservation loss.Additionally, we propose a caption generation scheme that become a criticalpiece in fostering object specific embedding faithfully reflected into thegeneration process, while keeping control and editing abilities. Once trained,the network is able to produce diverse content and styles, conditioned on bothtexts and objects. We demonstrate through experiments that our proposed methodis able to synthesize images with compelling output quality, appearancediversity, and object fidelity, without the need of test-time optimization.Systematic studies are also conducted to analyze our models, providing insightsfor future work.", "output": "Taming Encoder for Zero Fine-tuning Image Customization with Text-to-Image Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce the Segment Anything (SA) project: a new task, model, anddataset for image segmentation. Using our efficient model in a data collectionloop, we built the largest segmentation dataset to date (by far), with over 1billion masks on 11M licensed and privacy respecting images. The model isdesigned and trained to be promptable, so it can transfer zero-shot to newimage distributions and tasks. We evaluate its capabilities on numerous tasksand find that its zero-shot performance is impressive -- often competitive withor even superior to prior fully supervised results. We are releasing theSegment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and11M images at  to foster research into foundationmodels for computer vision.", "output": "Segment Anything."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The capability of a mobile robot to efficiently and safely perform complexmissions is limited by its knowledge of the environment, namely the situation.Advanced reasoning, decision-making, and execution skills enable an intelligentagent to act autonomously in unknown environments. Situational Awareness (SA)is a fundamental capability of humans that has been deeply studied in variousfields, such as psychology, military, aerospace, and education. Nevertheless,it has yet to be considered in robotics, which has focused on singlecompartmentalized concepts such as sensing, spatial perception, sensor fusion,state estimation, and Simultaneous Localization and Mapping (SLAM). Hence, thepresent research aims to connect the broad multidisciplinary existing knowledgeto pave the way for a complete SA system for mobile robotics that we deemparamount for autonomy. To this aim, we define the principal components tostructure a robotic SA and their area of competence. Accordingly, this paperinvestigates each aspect of SA, surveying the state-of-the-art roboticsalgorithms that cover them, and discusses their current limitations.Remarkably, essential aspects of SA are still immature since the currentalgorithmic development restricts their performance to only specificenvironments. Nevertheless, Artificial Intelligence (AI), particularly DeepLearning (DL), has brought new methods to bridge the gap that maintains thesefields apart from the deployment to real-world scenarios. Furthermore, anopportunity has been discovered to interconnect the vastly fragmented space ofrobotic comprehension algorithms through the mechanism of Situational Graph(S-Graph), a generalization of the well-known scene graph. Therefore, wefinally shape our vision for the future of robotic Situational Awareness bydiscussing interesting recent research directions.", "output": "From SLAM to Situational Awareness: Challenges and Survey."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a novel approach to translate unpaired contrast computedtomography (CT) scans to non-contrast CT scans and the other way around.Solving this task has two important applications: (i) to automatically generatecontrast CT scans for patients for whom injecting contrast substance is not anoption, and (ii) to enhance the alignment between contrast and non-contrast CTby reducing the differences induced by the contrast substance beforeregistration. Our approach is based on cycle-consistent generative adversarialconvolutional transformers, for short, CyTran. Our neural model can be trainedon unpaired images, due to the integration of a multi-level cycle-consistencyloss. Aside from the standard cycle-consistency loss applied at the imagelevel, we propose to apply additional cycle-consistency losses betweenintermediate feature representations, which enforces the model to becycle-consistent at multiple representations levels, leading to superiorresults. To deal with high-resolution images, we design a hybrid architecturebased on convolutional and multi-head attention layers. In addition, weintroduce a novel data set, Coltea-Lung-CT-100W, containing 100 3D triphasiclung CT scans (with a total of 37,290 images) collected from 100 femalepatients (there is one examination per patient). Each scan contains threephases (non-contrast, early portal venous, and late arterial), allowing us toperform experiments to compare our novel approach with state-of-the-art methodsfor image style transfer. Our empirical results show that CyTran outperformsall competing methods. Moreover, we show that CyTran can be employed as apreliminary step to improve a state-of-the-art medical image alignment method.We release our novel model and data set as open source at", "output": "CyTran: A Cycle-Consistent Transformer with Multi-Level Consistency for Non-Contrast to Contrast CT Translation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing unsupervised person re-identification methods only rely on visualclues to match pedestrians under different cameras. Since visual data isessentially susceptible to occlusion, blur, clothing changes, etc., a promisingsolution is to introduce heterogeneous data to make up for the defect of visualdata. Some works based on full-scene labeling introduce wireless positioning toassist cross-domain person re-identification, but their GPS labeling of entiremonitoring scenes is laborious. To this end, we propose to explore unsupervisedperson re-identification with both visual data and wireless positioningtrajectories under weak scene labeling, in which we only need to know thelocations of the cameras. Specifically, we propose a novel unsupervisedmultimodal training framework (UMTF), which models the complementarity ofvisual data and wireless information. Our UMTF contains a multimodal dataassociation strategy (MMDA) and a multimodal graph neural network (MMGN). MMDAexplores potential data associations in unlabeled multimodal data, while MMGNpropagates multimodal messages in the video graph based on the adjacency matrixlearned from histogram statistics of wireless data. Thanks to the robustness ofthe wireless data to visual noise and the collaboration of various modules,UMTF is capable of learning a model free of the human label on data. Extensiveexperimental results conducted on two challenging datasets, i.e., WP-ReID andDukeMTMC-VideoReID demonstrate the effectiveness of the proposed method.", "output": "Unsupervised Person Re-Identification with Wireless Positioning under Weak Scene Labeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Domain Generalization (DG) aims to generalize a model trained on multiplesource domains to an unseen target domain. The source domains always requireprecise annotations, which can be cumbersome or even infeasible to obtain inpractice due to the vast amount of data involved. Web data, however, offers anopportunity to access large amounts of unlabeled data with rich styleinformation, which can be leveraged to improve DG. From this perspective, weintroduce a novel paradigm of DG, termed as Semi-Supervised DomainGeneralization (SSDG), to explore how the labeled and unlabeled source domainscan interact, and establish two settings, including the close-set and open-setSSDG. The close-set SSDG is based on existing public DG datasets, while theopen-set SSDG, built on the newly-collected web-crawled datasets, presents anovel yet realistic challenge that pushes the limits of current technologies. Anatural approach of SSDG is to transfer knowledge from labeled data tounlabeled data via pseudo labeling, and train the model on both labeled andpseudo-labeled data for generalization. Since there are conflicting goalsbetween domain-oriented pseudo labeling and out-of-domain generalization, wedevelop a pseudo labeling phase and a generalization phase independently forSSDG. Unfortunately, due to the large domain gap, the pseudo labels provided inthe pseudo labeling phase inevitably contain noise, which has negative affecton the subsequent generalization phase. Therefore, to improve the quality ofpseudo labels and further enhance generalizability, we propose a cycliclearning framework to encourage a positive feedback between these two phases,utilizing an evolving intermediate domain that bridges the labeled andunlabeled domains in a curriculum learning manner...", "output": "Semi-Supervised Domain Generalization with Evolving Intermediate Domain."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision Transformer (ViT) is known to be highly nonlinear like other classicalneural networks and could be easily fooled by both natural and adversarialpatch perturbations. This limitation could pose a threat to the deployment ofViT in the real industrial environment, especially in safety-criticalscenarios. In this work, we propose PatchCensor, aiming to certify the patchrobustness of ViT by applying exhaustive testing. We try to provide a provableguarantee by considering the worst patch attack scenarios. Unlike empiricaldefenses against adversarial patches that may be adaptively breached, certifiedrobust approaches can provide a certified accuracy against arbitrary attacksunder certain conditions. However, existing robustness certifications aremostly based on robust training, which often requires substantial trainingefforts and the sacrifice of model performance on normal samples. To bridge thegap, PatchCensor seeks to improve the robustness of the whole system bydetecting abnormal inputs instead of training a robust model and asking it togive reliable results for every input, which may inevitably compromiseaccuracy. Specifically, each input is tested by voting over multiple inferenceswith different mutated attention masks, where at least one inference isguaranteed to exclude the abnormal patch. This can be seen as complete-coveragetesting, which could provide a statistical guarantee on inference at the testtime. Our comprehensive evaluation demonstrates that PatchCensor is able toachieve high certified accuracy (e.g. 67.1% on ImageNet for 2%-pixeladversarial patches), significantly outperforming state-of-the-art techniqueswhile achieving similar clean accuracy (81.8% on ImageNet). Meanwhile, ourtechnique also supports flexible configurations to handle different adversarialpatch sizes (up to 25%) by simply changing the masking strategy.", "output": "PatchCensor: Patch Robustness Certification for Transformers via Exhaustive Testing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transformers have demonstrated remarkable performance in natural languageprocessing and computer vision. However, existing vision Transformers struggleto learn from limited medical data and are unable to generalize on diversemedical image tasks. To tackle these challenges, we present MedFormer, adata-scalable Transformer designed for generalizable 3D medical imagesegmentation. Our approach incorporates three key elements: a desirableinductive bias, hierarchical modeling with linear-complexity attention, andmulti-scale feature fusion that integrates spatial and semantic informationglobally. MedFormer can learn across tiny- to large-scale data withoutpre-training. Comprehensive experiments demonstrate MedFormer's potential as aversatile segmentation backbone, outperforming CNNs and vision Transformers onseven public datasets covering multiple modalities (e.g., CT and MRI) andvarious medical targets (e.g., healthy organs, diseased tissues, and tumors).We provide public access to our models and evaluation pipeline, offering solidbaselines and unbiased comparisons to advance a wide range of downstreamclinical applications.", "output": "A Data-scalable Transformer for Medical Image Segmentation: Architecture, Model Efficiency, and Benchmark."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite recent advances of AI, story understanding remains an open andunder-investigated problem. We collect, preprocess, and publicly release avideo-language story dataset, Synopses of Movie Narratives (SyMoN), containing5,193 video summaries of popular movies and TV series with a total length of869 hours. SyMoN captures naturalistic storytelling videos made by humancreators and intended for a human audience. As a prototypical and naturalisticstory dataset, SyMoN features high coverage of multimodal story events andabundant mental-state descriptions. Its use of storytelling techniques causecross-domain semantic gaps that provide appropriate challenges to existingmodels. We establish benchmarks on video-text retrieval and zero-shot alignmenton movie summary videos, which showcase the importance of in-domain data andlong-term memory in story understanding. With SyMoN, we hope to lay thegroundwork for progress in multimodal story understanding.", "output": "Synopses of Movie Narratives: a Video-Language Dataset for Story Understanding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose DeepIPC, an end-to-end autonomous driving model that handles bothperception and control tasks in driving a vehicle. The model consists of twomain parts, perception and controller modules. The perception module takes anRGBD image to perform semantic segmentation and bird's eye view (BEV) semanticmapping along with providing their encoded features. Meanwhile, the controllermodule processes these features with the measurement of GNSS locations andangular speed to estimate waypoints that come with latent features. Then, twodifferent agents are used to translate waypoints and latent features into a setof navigational controls to drive the vehicle. The model is evaluated bypredicting driving records and performing automated driving under variousconditions in real environments. The experimental results show that DeepIPCachieves the best drivability and multi-task performance even with fewerparameters compared to the other models. Codes are available at", "output": "DeepIPC: Deeply Integrated Perception and Control for an Autonomous Vehicle in Real Environments."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In an unsupervised attack on variational autoencoders (VAEs), an adversaryfinds a small perturbation in an input sample that significantly changes itslatent space encoding, thereby compromising the reconstruction for a fixeddecoder. A known reason for such vulnerability is the distortions in the latentspace resulting from a mismatch between approximated latent posterior and aprior distribution. Consequently, a slight change in an input sample can moveits encoding to a low/zero density region in the latent space resulting in anunconstrained generation. This paper demonstrates that an optimal way for anadversary to attack VAEs is to exploit a directional bias of a stochasticpullback metric tensor induced by the encoder and decoder networks. Thepullback metric tensor of an encoder measures the change in infinitesimallatent volume from an input to a latent space. Thus, it can be viewed as a lensto analyse the effect of input perturbations leading to latent spacedistortions. We propose robustness evaluation scores using the eigenspectrum ofa pullback metric tensor. Moreover, we empirically show that the scorescorrelate with the robustness parameter $beta$ of the $beta-$VAE. Sinceincreasing $beta$ also degrades reconstruction quality, we demonstrate asimple alternative using textit{mixup} training to fill the empty regions inthe latent space, thus improving robustness with improved reconstruction.", "output": "Adversarial robustness of VAEs through the lens of local geometry."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Most current multi-modal summarization methods follow a cascaded manner,where an off-the-shelf object detector is first used to extract visualfeatures, then these features are fused with language representations togenerate the summary with an encoder-decoder model. The cascaded way cannotcapture the semantic alignments between images and paragraphs, which arecrucial to a precise summary. In this paper, we propose ViL-Sum to jointlymodel paragraph-level textbf{Vi}sion-textbf{L}anguage Semantic Alignment andMulti-Modal textbf{Sum}marization. The core of ViL-Sum is a joint multi-modalencoder with two well-designed tasks, image reordering and image selection. Thejoint multi-modal encoder captures the interactions between modalities, wherethe reordering task guides the model to learn paragraph-level semanticalignment and the selection task guides the model to selected summary-relatedimages in the final summary. Experimental results show that our proposedViL-Sum significantly outperforms current state-of-the-art methods. In furtheranalysis, we find that two well-designed tasks and joint multi-modal encodercan effectively guide the model to learn reasonable paragraphs-images andsummary-images relations.", "output": "Modeling Paragraph-Level Vision-Language Semantic Alignment for Multi-Modal Summarization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Event camera is an emerging bio-inspired vision sensors that report per-pixelbrightness changes asynchronously. It holds noticeable advantage of highdynamic range, high speed response, and low power budget that enable it to bestcapture local motions in uncontrolled environments. This motivates us to unlockthe potential of event cameras for human pose estimation, as the human poseestimation with event cameras is rarely explored. Due to the novel paradigmshift from conventional frame-based cameras, however, event signals in a timeinterval contain very limited information, as event cameras can only capturethe moving body parts and ignores those static body parts, resulting in someparts to be incomplete or even disappeared in the time interval. This paperproposes a novel densely connected recurrent architecture to address theproblem of incomplete information. By this recurrent architecture, we canexplicitly model not only the sequential but also non-sequential geometricconsistency across time steps to accumulate information from previous frames torecover the entire human bodies, achieving a stable and accurate human poseestimation from event data. Moreover, to better evaluate our model, we collecta large scale multimodal event-based dataset that comes with human poseannotations, which is by far the most challenging one to the best of ourknowledge. The experimental results on two public datasets and our own datasetdemonstrate the effectiveness and strength of our approach. Code can beavailable online for facilitating the future research.", "output": "A Temporal Densely Connected Recurrent Network for Event-based Human Pose Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces a dataset for training and evaluating methods for 6Dpose estimation of hand-held tools in task demonstrations captured by astandard RGB camera. Despite the significant progress of 6D pose estimationmethods, their performance is usually limited for heavily occluded objects,which is a common case in imitation learning, where the object is typicallypartially occluded by the manipulating hand. Currently, there is a lack ofdatasets that would enable the development of robust 6D pose estimation methodsfor these conditions. To overcome this problem, we collect a new dataset(Imitrob) aimed at 6D pose estimation in imitation learning and otherapplications where a human holds a tool and performs a task. The datasetcontains image sequences of nine different tools and twelve manipulation taskswith two camera viewpoints, four human subjects, and left/right hand. Eachimage is accompanied by an accurate ground truth measurement of the 6D objectpose obtained by the HTC Vive motion tracking device. The use of the dataset isdemonstrated by training and evaluating a recent 6D object pose estimationmethod (DOPE) in various setups.", "output": "Imitrob: Imitation Learning Dataset for Training and Evaluating 6D Object Pose Estimators."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks (DNNs) have demonstrated their superiority in practice.Arguably, the rapid development of DNNs is largely benefited from high-quality(open-sourced) datasets, based on which researchers and developers can easilyevaluate and improve their learning methods. Since the data collection isusually time-consuming or even expensive, how to protect their copyrights is ofgreat significance and worth further exploration. In this paper, we revisitdataset ownership verification. We find that existing verification methodsintroduced new security risks in DNNs trained on the protected dataset, due tothe targeted nature of poison-only backdoor watermarks. To alleviate thisproblem, in this work, we explore the untargeted backdoor watermarking scheme,where the abnormal model behaviors are not deterministic. Specifically, weintroduce two dispersibilities and prove their correlation, based on which wedesign the untargeted backdoor watermark under both poisoned-label andclean-label settings. We also discuss how to use the proposed untargetedbackdoor watermark for dataset ownership verification. Experiments on benchmarkdatasets verify the effectiveness of our methods and their resistance toexisting backdoor defenses. Our codes are available aturl{", "output": "Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, there has been tremendous interest in industry 4.0 infrastructureto address labor shortages in global supply chains. Deploying artificialintelligence-enabled robotic bin picking systems in real world has becomeparticularly important for reducing stress and physical demands of workerswhile increasing speed and efficiency of warehouses. To this end, artificialintelligence-enabled robotic bin picking systems may be used to automate orderpicking, but with the risk of causing expensive damage during an abnormal eventsuch as sensor failure. As such, reliability becomes a critical factor fortranslating artificial intelligence research to real world applications andproducts. In this paper, we propose a reliable object detection andsegmentation system with MultiModal Redundancy (MMRNet) for tackling objectdetection and segmentation for robotic bin picking using data from differentmodalities. This is the first system that introduces the concept of multimodalredundancy to address sensor failure issues during deployment. In particular,we realize the multimodal redundancy framework with a gate fusion module anddynamic ensemble learning. Finally, we present a new label-free multi-modalconsistency (MC) score that utilizes the output from all modalities to measurethe overall system output reliability and uncertainty. Through experiments, wedemonstrate that in an event of missing modality, our system provides a muchmore reliable performance compared to baseline models. We also demonstrate thatour MC score is a more reliability indicator for outputs during inference timecompared to the model generated confidence scores that are oftenover-confident.", "output": "MMRNet: Improving Reliability for Multimodal Object Detection and Segmentation for Bin Picking via Multimodal Redundancy."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large-scale text-to-image generation models have achieved remarkable progressin synthesizing high-quality, feature-rich images with high resolution guidedby texts. However, these models often struggle with novel concepts, eg, newstyles, object entities, etc. Although recent attempts have employedfine-tuning or prompt-tuning strategies to teach the pre-trained diffusionmodel novel concepts from a reference image set,they have the drawback ofoverfitting to the given reference images, particularly in one-shotapplications, which is harmful to generate diverse and high-quality imageswhile maintaining generation controllability.To tackle this challenge, we present a simple yet effective method calledDreamArtist, which employs a positive-negative prompt-tuning learning strategy.Specifically, DreamArtist incorporates both positive and negative embeddingsand jointly trains them. The positive embedding aggressively captures thesalient characteristics of the reference image to drive diversified generationand the negative embedding rectifies inadequacies from the positive embedding.It learns not only what is correct, but also what can be avoided or improved.We have conducted extensive experiments and evaluated the proposed method fromimage similarity and diversity, generation controllability, and style cloning.And our DreamArtist has achieved a superior generation performance overexisting methods. Besides, our additional evaluation on extended tasks,including concept compositions and prompt-guided image editing, demonstratesits effectiveness for more applications.", "output": "DreamArtist: Towards Controllable One-Shot Text-to-Image Generation via Positive-Negative Prompt-Tuning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present XKD, a novel self-supervised framework to learn meaningfulrepresentations from unlabelled video clips. XKD is trained with two pseudotasks. First, masked data reconstruction is performed to learn individualrepresentations from audio and visual streams. Next, self-supervisedcross-modal knowledge distillation is performed between the two modalitiesthrough teacher-student setups to learn complementary information. To identifythe most effective information to transfer and also to tackle the domain gapbetween audio and visual modalities which could hinder knowledge transfer, weintroduce a domain alignment and feature refinement strategy for effectivecross-modal knowledge distillation. Lastly, to develop a general-purposenetwork capable of handling both audio and visual streams, modality-agnosticvariants of our proposed framework are introduced, which use the same backbonefor both audio and visual modalities. Our proposed cross-modal knowledgedistillation improves linear evaluation top-1 accuracy of video actionclassification by 8.6% on UCF101, 8.2% on HMDB51, 13.9% on Kinetics-Sound, and15.7% on Kinetics400. Additionally, our modality-agnostic variant showspromising results in developing a general-purpose network capable of learningboth data streams for solving different downstream tasks.", "output": "XKD: Cross-modal Knowledge Distillation with Domain Alignment for Video Representation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reliable application of machine learning-based decision systems in the wildis one of the major challenges currently investigated by the field. A largeportion of established approaches aims to detect erroneous predictions by meansof assigning confidence scores. This confidence may be obtained by eitherquantifying the model's predictive uncertainty, learning explicit scoringfunctions, or assessing whether the input is in line with the trainingdistribution. Curiously, while these approaches all state to address the sameeventual goal of detecting failures of a classifier upon real-life application,they currently constitute largely separated research fields with individualevaluation protocols, which either exclude a substantial part of relevantmethods or ignore large parts of relevant failure sources. In this work, wesystematically reveal current pitfalls caused by these inconsistencies andderive requirements for a holistic and realistic evaluation of failuredetection. To demonstrate the relevance of this unified perspective, we presenta large-scale empirical study for the first time enabling benchmarkingconfidence scoring functions w.r.t all relevant methods and failure sources.The revelation of a simple softmax response baseline as the overall bestperforming method underlines the drastic shortcomings of current evaluation inthe abundance of publicized research on confidence scoring. Code and trainedmodels are at ", "output": "A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Many problems can be viewed as forms of geospatial search aided by aerialimagery, with examples ranging from detecting poaching activity to humantrafficking. We model this class of problems in a visual active search (VAS)framework, which takes as input an image of a broad area, and aims to identifyas many examples of a target object as possible. It does this through a limitedsequence of queries, each of which verifies whether an example is present in agiven region. A crucial feature of VAS is that each such query is informativeabout the spatial distribution of target objects beyond what is capturedvisually (for example, due to spatial correlation). We propose a reinforcementlearning approach for VAS that leverages a collection of fully annotated searchtasks as training data to learn a search policy, and combines features of theinput image with a natural representation of active search state. Additionally,we propose domain adaptation techniques to improve the policy at decision timewhen training data is not fully reflective of the test-time distribution of VAStasks. Through extensive experiments on several satellite imagery datasets, weshow that the proposed approach significantly outperforms several strongbaselines. Code and data will be made public.", "output": "A Visual Active Search Framework for Geospatial Exploration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Predicting the future motion of road agents is a critical task in anautonomous driving pipeline. In this work, we address the problem of generatinga set of scene-level, or joint, future trajectory predictions in multi-agentdriving scenarios. To this end, we propose FJMP, a Factorized Joint MotionPrediction framework for multi-agent interactive driving scenarios. FJMP modelsthe future scene interaction dynamics as a sparse directed interaction graph,where edges denote explicit interactions between agents. We then prune thegraph into a directed acyclic graph (DAG) and decompose the joint predictiontask into a sequence of marginal and conditional predictions according to thepartial ordering of the DAG, where joint future trajectories are decoded usinga directed acyclic graph neural network (DAGNN). We conduct experiments on theINTERACTION and Argoverse 2 datasets and demonstrate that FJMP produces moreaccurate and scene-consistent joint trajectory predictions than non-factorizedapproaches, especially on the most interactive and kinematically interestingagents. FJMP ranks 1st on the multi-agent test leaderboard of the INTERACTIONdataset.", "output": "FJMP: Factorized Joint Multi-Agent Motion Prediction over Learned Directed Acyclic Interaction Graphs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Semantic segmentation from aerial views is a crucial task for autonomousdrones, as they rely on precise and accurate segmentation to navigate safelyand efficiently. However, aerial images present unique challenges such asdiverse viewpoints, extreme scale variations, and high scene complexity. Inthis paper, we propose an end-to-end multi-class semantic segmentationdiffusion model that addresses these challenges. We introduce recursivedenoising to allow information to propagate through the denoising process, aswell as a hierarchical multi-scale approach that complements the diffusionprocess. Our method achieves competitive results on the UAVid dataset andstate-of-the-art performance on the Vaihingen Building segmentation benchmark.Being the first iteration of this method, it shows great promise for futureimprovements.", "output": "Multi-Class Segmentation from Aerial Views using Recursive Noise Diffusion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a new approach to learned optimization where we represent thecomputation of an optimizer's update step using a neural network. Theparameters of the optimizer are then learned by training on a set ofoptimization tasks with the objective to perform minimization efficiently. Ourinnovation is a new neural network architecture, Optimus, for the learnedoptimizer inspired by the classic BFGS algorithm. As in BFGS, we estimate apreconditioning matrix as a sum of rank-one updates but use a Transformer-basedneural network to predict these updates jointly with the step length anddirection. In contrast to several recent learned optimization-based approaches,our formulation allows for conditioning across the dimensions of the parameterspace of the target problem while remaining applicable to optimization tasks ofvariable dimensionality without retraining. We demonstrate the advantages ofour approach on a benchmark composed of objective functions traditionally usedfor the evaluation of optimization algorithms, as well as on the realworld-task of physics-based visual reconstruction of articulated 3d humanmotion.", "output": "Transformer-Based Learned Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Point source localisation is generally modelled as a Lasso-type problem onmeasures. However, optimisation methods in non-Hilbert spaces, such as thespace of Radon measures, are much less developed than in Hilbert spaces. Mostnumerical algorithms for point source localisation are based on the Frank-Wolfeconditional gradient method, for which ad hoc convergence theory is developed.We develop extensions of proximal-type methods to spaces of measures. Thisincludes forward-backward splitting, its inertial version, and primal-dualproximal splitting. Their convergence proofs follow standard patterns. Wedemonstrate their numerical efficacy.", "output": "Proximal methods for point source localisation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Modern machine learning pipelines are limited due to data availability,storage quotas, privacy regulations, and expensive annotation processes. Theseconstraints make it difficult or impossible to train and update large-scalemodels on such dynamic annotated sets. Continual learning directly approachesthis problem, with the ultimate goal of devising methods where a deep neuralnetwork effectively learns relevant patterns for new (unseen) classes, withoutsignificantly altering its performance on previously learned ones. In thispaper, we address the problem of continual learning for video data. Weintroduce PIVOT, a novel method that leverages extensive knowledge inpre-trained models from the image domain, thereby reducing the number oftrainable parameters and the associated forgetting. Unlike previous methods,ours is the first approach that effectively uses prompting mechanisms forcontinual learning without any in-domain pre-training. Our experiments showthat PIVOT improves state-of-the-art methods by a significant 27% on the20-task ActivityNet setup.", "output": "PIVOT: Prompting for Video Continual Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The last several years have witnessed remarkable progress invideo-and-language (VidL) understanding. However, most modern VidL approachesuse complex and specialized model architectures and sophisticated pretrainingprotocols, making the reproducibility, analysis and comparisons of theseframeworks difficult. Hence, instead of proposing yet another new VidL model,this paper conducts a thorough empirical study demystifying the most importantfactors in the VidL model design. Among the factors that we investigate are (i)the spatiotemporal architecture design, (ii) the multimodal fusion schemes,(iii) the pretraining objectives, (iv) the choice of pretraining data, (v)pretraining and finetuning protocols, and (vi) dataset and model scaling. Ourempirical study reveals that the most important design factors include:temporal modeling, video-to-text multimodal fusion, masked modeling objectives,and joint training on images and videos. Using these empirical insights, wethen develop a step-by-step recipe, dubbed VindLU, for effective VidLpretraining. Our final model trained using our recipe achieves comparable orbetter than state-of-the-art results on several VidL tasks without relying onexternal CLIP pretraining. In particular, on the text-to-video retrieval task,our approach obtains 61.2% on DiDeMo, and 55.0% on ActivityNet, outperformingcurrent SOTA by 7.8% and 6.1% respectively. Furthermore, our model also obtainsstate-of-the-art video question-answering results on ActivityNet-QA, MSRVTT-QA,MSRVTT-MC and TVQA. Our code and pretrained models are publicly available at:", "output": "VindLU: A Recipe for Effective Video-and-Language Pretraining."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite significant advances, the performance of state-of-the-art continuallearning approaches hinges on the unrealistic scenario of fully labeled data.In this paper, we tackle this challenge and propose an approach for continualsemi-supervised learning--a setting where not all the data samples are labeled.A primary issue in this scenario is the model forgetting representations ofunlabeled data and overfitting the labeled samples. We leverage the power ofnearest-neighbor classifiers to nonlinearly partition the feature space andflexibly model the underlying data distribution thanks to its non-parametricnature. This enables the model to learn a strong representation for the currenttask, and distill relevant information from previous tasks. We perform athorough experimental evaluation and show that our method outperforms all theexisting approaches by large margins, setting a solid state of the art on thecontinual semi-supervised learning paradigm. For example, on CIFAR-100 wesurpass several others even when using at least 30 times less supervision (0.8%vs. 25% of annotations). Finally, our method works well on both low and highresolution images and scales seamlessly to more complex datasets such asImageNet-100. The code is publicly available on", "output": "A soft nearest-neighbor framework for continual semi-supervised learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce the MAsked Generative VIdeo Transformer, MAGVIT, to tacklevarious video synthesis tasks with a single model. We introduce a 3D tokenizerto quantize a video into spatial-temporal visual tokens and propose anembedding method for masked video token modeling to facilitate multi-tasklearning. We conduct extensive experiments to demonstrate the quality,efficiency, and flexibility of MAGVIT. Our experiments show that (i) MAGVITperforms favorably against state-of-the-art approaches and establishes thebest-published FVD on three video generation benchmarks, including thechallenging Kinetics-600. (ii) MAGVIT outperforms existing methods in inferencetime by two orders of magnitude against diffusion models and by 60x againstautoregressive models. (iii) A single MAGVIT model supports ten diversegeneration tasks and generalizes across videos from different visual domains.The source code and trained models will be released to the public at", "output": "MAGVIT: Masked Generative Video Transformer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present RAVEn, a self-supervised multi-modal approach to jointly learnvisual and auditory speech representations. Our pre-training objective involvesencoding masked inputs, and then predicting contextualised targets generated byslowly-evolving momentum encoders. Driven by the inherent differences betweenvideo and audio, our design is asymmetric w.r.t. the two modalities' pretexttasks: Whereas the auditory stream predicts both the visual and auditorytargets, the visual one predicts only the auditory targets. We observe strongresults in low- and high-resource labelled data settings when fine-tuning thevisual and auditory encoders resulting from a single pre-training stage, inwhich the encoders are jointly trained. Notably, RAVEn surpasses allself-supervised methods on visual speech recognition (VSR) on LRS3, andcombining RAVEn with self-training using only 30 hours of labelled data evenoutperforms a recent semi-supervised method trained on 90,000 hours ofnon-public data. At the same time, we achieve state-of-the-art results in theLRS3 low-resource setting for auditory speech recognition (as well as for VSR).Our findings point to the viability of learning powerful speech representationsentirely from raw video and audio, i.e., without relying on handcraftedfeatures. Code and models are available at ", "output": "Jointly Learning Visual and Auditory Speech Representations from Raw Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The survival analysis on histological whole-slide images (WSIs) is one of themost important means to estimate patient prognosis. Although manyweakly-supervised deep learning models have been developed for gigapixel WSIs,their potential is generally restricted by classical survival analysis rulesand fully-supervised learning requirements. As a result, these models providepatients only with a completely-certain point estimation of time-to-event, andthey could only learn from the labeled WSI data currently at a small scale. Totackle these problems, we propose a novel adversarial multiple instancelearning (AdvMIL) framework. This framework is based on adversarialtime-to-event modeling, and integrates the multiple instance learning (MIL)that is much necessary for WSI representation learning. It is a plug-and-playone, so that most existing MIL-based end-to-end methods can be easily upgradedby applying this framework, gaining the improved abilities of survivaldistribution estimation and semi-supervised learning. Our extensive experimentsshow that AdvMIL not only could often bring performance improvement tomainstream WSI survival analysis methods at a relatively low computationalcost, but also enables these methods to effectively utilize unlabeled data viasemi-supervised learning. Moreover, it is observed that AdvMIL could helpimproving the robustness of models against patch occlusion and tworepresentative image noises. The proposed AdvMIL framework could promote theresearch of survival analysis in computational pathology with its noveladversarial MIL paradigm.", "output": "AdvMIL: Adversarial Multiple Instance Learning for the Survival Analysis on Whole-Slide Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision transformers (ViTs) have achieved impressive results on variouscomputer vision tasks in the last several years. In this work, we study thecapability of frozen ViTs, pretrained only on visual data, to generalize toaudio-visual data without finetuning any of its original parameters. To do so,we propose a latent audio-visual hybrid (LAVISH) adapter that adapts pretrainedViTs to audio-visual tasks by injecting a small number of trainable parametersinto every layer of a frozen ViT. To efficiently fuse visual and audio cues,our LAVISH adapter uses a small set of latent tokens, which form an attentionbottleneck, thus, eliminating the quadratic cost of standard cross-attention.Compared to the existing modality-specific audio-visual methods, our approachachieves competitive or even better performance on various audio-visual taskswhile using fewer tunable parameters and without relying on costly audiopretraining or external audio encoders. Our code is available at", "output": "Vision Transformers are Parameter-Efficient Audio-Visual Learners."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes a novel self-supervised based Cut-and-Paste GAN toperform foreground object segmentation and generate realistic composite imageswithout manual annotations. We accomplish this goal by a simple yet effectiveself-supervised approach coupled with the U-Net based discriminator. Theproposed method extends the ability of the standard discriminators to learn notonly the global data representations via classification (real/fake) but alsolearn semantic and structural information through pseudo labels created usingthe self-supervised task. The proposed method empowers the generator to createmeaningful masks by forcing it to learn informative per-pixel as well as globalimage feedback from the discriminator. Our experiments demonstrate that ourproposed method significantly outperforms the state-of-the-art methods on thestandard benchmark datasets.", "output": "SS-CPGAN: Self-Supervised Cut-and-Pasting Generative Adversarial Network for Object Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes a pre-trained neural network for handling event cameradata. Our model is a self-supervised learning framework, and uses paired eventcamera data and natural RGB images for training.Our method contains three modules connected in a sequence: i) a family ofevent data augmentations, generating meaningful event images forself-supervised training; ii) a conditional masking strategy to sampleinformative event patches from event images, encouraging our model to capturethe spatial layout of a scene and accelerating training; iii) a contrastivelearning approach, enforcing the similarity of embeddings between matchingevent images, and between paired event and RGB images. An embedding projectionloss is proposed to avoid the model collapse when enforcing the event imageembedding similarities. A probability distribution alignment loss is proposedto encourage the event image to be consistent with its paired RGB image in thefeature space.Transfer learning performance on downstream tasks shows the superiority ofour method over state-of-the-art methods. For example, we achieve top-1accuracy at 64.83% on the N-ImageNet dataset.", "output": "Event Camera Data Pre-training."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Most dense recognition approaches bring a separate decision in eachparticular pixel. These approaches deliver competitive performance in usualclosed-set setups. However, important applications in the wild typicallyrequire strong performance in presence of outliers. We show that this demandingsetup greatly benefit from mask-level predictions, even in the case ofnon-finetuned baseline models. Moreover, we propose an alternative formulationof dense recognition uncertainty that effectively reduces false positiveresponses at semantic borders. The proposed formulation produces a furtherimprovement over a very strong baseline and sets the new state of the art inoutlier-aware semantic segmentation with and without training on negative data.Our contributions also lead to performance improvement in a recent panopticsetup. In-depth experiments confirm that our approach succeeds due to implicitaggregation of pixel-level cues into mask-level predictions.", "output": "On Advantages of Mask-level Recognition for Outlier-aware Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recovering lighting in a scene from a single image is a fundamental problemin computer vision. While a mirror ball light probe can capture omnidirectionallighting, light probes are generally unavailable in everyday images. In thiswork, we study recovering lighting from accidental light probes (ALPs) --common, shiny objects like Coke cans, which often accidentally appear in dailyscenes. We propose a physically-based approach to model ALPs and estimatelighting from their appearances in single images. The main idea is to model theappearance of ALPs by photogrammetrically principled shading and to invert thisprocess via differentiable rendering to recover incidental illumination. Wedemonstrate that we can put an ALP into a scene to allow high-fidelity lightingestimation. Our model can also recover lighting for existing images that happento contain an ALP.", "output": "Accidental Light Probes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We explore three applications of Min-Max-Jump distance (MMJ distance).MMJ-based K-means revises K-means with MMJ distance. MMJ-based Silhouettecoefficient revises Silhouette coefficient with MMJ distance. We also testedthe Clustering with Neural Network and Index (CNNI) model with MMJ-basedSilhouette coefficient. In the last application, we tested using Min-Max-Jumpdistance for predicting labels of new points, after a clustering analysis ofdata. Result shows Min-Max-Jump distance achieves good performances in all thethree proposed applications.", "output": "Min-Max-Jump distance and its applications."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Most recent self-supervised learning methods are pre-trained on thewell-curated ImageNet-1K dataset. In this work, given the excellent scalabilityof web data, we consider self-supervised pre-training on noisy web sourcedimage-text paired data. First, we conduct a benchmark study of representativeself-supervised pre-training methods on large-scale web data in a like-for-likesetting. We compare a range of methods, including single-modal ones that usemasked training objectives and multi-modal ones that use image-textconstrastive training. We observe that existing multi-modal methods do notoutperform their single-modal counterparts on vision transfer learning tasks.We derive an information-theoretical view to explain these benchmark results,which provides insight into how to design a novel vision learner. Inspired bythis insight, we present a new visual representation pre-training method,MUlti-modal Generator~(MUG), that learns from scalable web sourced image-textdata. MUG achieves state-of-the-art transfer performance on a variety of tasksand demonstrates promising scaling properties. Pre-trained models and code willbe made public upon acceptance.", "output": "Vision Learners Meet Web Image-Text Pairs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The interpretation of facial emotions plays a crucial role in humancommunication, allowing people to recognize emotions such as happiness,sadness, and anger through facial expressions and vocal tones. Facial EmotionRecognition (FER) is an area of great interest in computer vision and AI, withextensive academic and commercial potential, including security, advertising,and entertainment. We present a FER framework based on Swin vision Transformers(SwinT) and squeeze and excitation block (SE), which utilizes a transformermodel with an attention mechanism to address vision tasks. Our approach uses avision transformer with SE and a sharpness-aware minimizer (SAM), astransformers typically require substantial data to be as efficient as othercompetitive models. Our challenge was to create a good FER model based on theSwinT configuration with the ability to detect facial emotions using a smallamount of data. We used a hybrid dataset to train our model and evaluated itsperformance on the AffectNet dataset, achieving an F1-score of 0.5420. Ourmodel outperformed the winner of the (ABAW) Competition, which was held inconjunction with the European Conference on Computer Vision (ECCV) 2022", "output": "Facial Expression Recognition using Squeeze and Excitation-powered Swin Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose an approach based on convex relaxations for certifiably optimalrobust multiview triangulation. To this end, we extend existing relaxationapproaches to non-robust multiview triangulation by incorporating a truncatedleast squares cost function. We propose two formulations, one based on epipolarconstraints and one based on fractional reprojection constraints. The first islower dimensional and remains tight under moderate noise and outlier levels,while the second is higher dimensional and therefore slower but remains tighteven under extreme noise and outlier levels. We demonstrate through extensiveexperiments that the proposed approaches allow us to compute provably optimalreconstructions even under significant noise and a large percentage ofoutliers.", "output": "Semidefinite Relaxations for Robust Multiview Triangulation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Joint machine learning models that allow synthesizing and classifying dataoften offer uneven performance between those tasks or are unstable to train. Inthis work, we depart from a set of empirical observations that indicate theusefulness of internal representations built by contemporary deepdiffusion-based generative models not only for generating but also predicting.We then propose to extend the vanilla diffusion model with a classifier thatallows for stable joint end-to-end training with shared parameterizationbetween those objectives. The resulting joint diffusion model outperformsrecent state-of-the-art hybrid methods in terms of both classification andgeneration quality on all evaluated benchmarks. On top of our joint trainingapproach, we present how we can directly benefit from shared generative anddiscriminative representations by introducing a method for visualcounterfactual explanations.", "output": "Learning Data Representations with Joint Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents a new convergent Plug-and-Play (PnP) algorithm. PnPmethods are efficient iterative algorithms for solving image inverse problemsformulated as the minimization of the sum of a data-fidelity term and aregularization term. PnP methods perform regularization by plugging apre-trained denoiser in a proximal algorithm, such as Proximal Gradient Descent(PGD). To ensure convergence of PnP schemes, many works study specificparametrizations of deep denoisers. However, existing results require eitherunverifiable or suboptimal hypotheses on the denoiser, or assume restrictiveconditions on the parameters of the inverse problem. Observing that theselimitations can be due to the proximal algorithm in use, we study a relaxedversion of the PGD algorithm for minimizing the sum of a convex function and aweakly convex one. When plugged with a relaxed proximal denoiser, we show thatthe proposed PnP-$alpha$PGD algorithm converges for a wider range ofregularization parameters, thus allowing more accurate image restoration.", "output": "A relaxed proximal gradient descent algorithm for convergent plug-and-play with proximal denoiser."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "3D-aware GANs offer new capabilities for creative content editing, such asview synthesis, while preserving the editing capability of their 2Dcounterparts. These methods use GAN inversion to reconstruct images or videosby optimizing a latent code, allowing for semantic editing by manipulating thecode. However, a model pre-trained on a face dataset (e.g., FFHQ) often hasdifficulty handling faces with out-of-distribution (OOD) objects, e.g., heavymake-up or occlusions. We address this issue by explicitly modeling OOD objectsin face videos. Our core idea is to represent the face in a video using twoneural radiance fields, one for the in-distribution and the other for theout-of-distribution object, and compose them together for reconstruction. Suchexplicit decomposition alleviates the inherent trade-off between reconstructionfidelity and editability. We evaluate our method's reconstruction accuracy andeditability on challenging real videos and showcase favorable results againstother baselines.", "output": "In-N-Out: Face Video Inversion and Editing with Volumetric Decomposition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The transferability of adversarial perturbations between image models hasbeen extensively studied. In this case, an attack is generated from a knownsurrogate eg, the ImageNet trained model, and transferred to change thedecision of an unknown (black-box) model trained on an image dataset. However,attacks generated from image models do not capture the dynamic nature of amoving object or a changing scene due to a lack of temporal cues within imagemodels. This leads to reduced transferability of adversarial attacks fromrepresentation-enriched emph{image} models such as Supervised VisionTransformers (ViTs), Self-supervised ViTs (eg, DINO), and Vision-languagemodels (eg, CLIP) to black-box emph{video} models. In this work, we inducedynamic cues within the image models without sacrificing their originalperformance on images. To this end, we optimize emph{temporal prompts} throughfrozen image models to capture motion dynamics. Our temporal prompts are theresult of a learnable transformation that allows optimizing for temporalgradients during an adversarial attack to fool the motion dynamics.Specifically, we introduce spatial (image) and temporal (video) cues within thesame source model through task-specific prompts. Attacking such promptsmaximizes the adversarial transferability from image-to-video andimage-to-image models using the attacks designed for image models. Our attackresults indicate that the attacker does not need specialized architectures,eg, divided space-time attention, 3D convolutions, or multi-view convolutionnetworks for different data modalities. Image models are effective surrogatesto optimize an adversarial attack to fool black-box models in a changingenvironment over time. Code is available at ", "output": "Boosting Adversarial Transferability using Dynamic Cues."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Humans have long been recorded in a variety of forms since antiquity. Forexample, sculptures and paintings were the primary media for depicting humanbeings before the invention of cameras. However, most current human-centriccomputer vision tasks like human pose estimation and human image generationfocus exclusively on natural images in the real world. Artificial humans, suchas those in sculptures, paintings, and cartoons, are commonly neglected, makingexisting models fail in these scenarios. As an abstraction of life, artincorporates humans in both natural and artificial scenes. We take advantage ofit and introduce the Human-Art dataset to bridge related tasks in natural andartificial scenarios. Specifically, Human-Art contains 50k high-quality imageswith over 123k person instances from 5 natural and 15 artificial scenarios,which are annotated with bounding boxes, keypoints, self-contact points, andtext information for humans represented in both 2D and 3D. It is, therefore,comprehensive and versatile for various downstream tasks. We also provide arich set of baseline results and detailed analyses for related tasks, includinghuman detection, 2D and 3D human pose estimation, image generation, and motiontransfer. As a challenging dataset, we hope Human-Art can provide insights forrelevant research and open up new research questions.", "output": "Human-Art: A Versatile Human-Centric Dataset Bridging Natural and Artificial Scenes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present ODISE: Open-vocabulary DIffusion-based panoptic SEgmentation,which unifies pre-trained text-image diffusion and discriminative models toperform open-vocabulary panoptic segmentation. Text-to-image diffusion modelshave the remarkable ability to generate high-quality images with diverseopen-vocabulary language descriptions. This demonstrates that their internalrepresentation space is highly correlated with open concepts in the real world.Text-image discriminative models like CLIP, on the other hand, are good atclassifying images into open-vocabulary labels. We leverage the frozen internalrepresentations of both these models to perform panoptic segmentation of anycategory in the wild. Our approach outperforms the previous state of the art bysignificant margins on both open-vocabulary panoptic and semantic segmentationtasks. In particular, with COCO training only, our method achieves 23.4 PQ and30.0 mIoU on the ADE20K dataset, with 8.3 PQ and 7.9 mIoU absolute improvementover the previous state of the art. We open-source our code and models at .", "output": "Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep Neural Networks (DNNs) are being used to solve a wide range of problemsin many domains including safety-critical domains like self-driving cars andmedical imagery. DNNs suffer from vulnerability against adversarial attacks. Inthe past few years, numerous approaches have been proposed to tackle thisproblem by training networks using adversarial training. Almost all theapproaches generate adversarial examples for the entire training dataset, thusincreasing the training time drastically. We show that we can decrease thetraining time for any adversarial training algorithm by using only a subset oftraining data for adversarial training. To select the subset, we filter theadversarially-prone samples from the training data. We perform a simpleadversarial attack on all training examples to filter this subset. In thisattack, we add a small perturbation to each pixel and a few grid lines to theinput image.We perform adversarial training on the adversarially-prone subset and mix itwith vanilla training performed on the entire dataset. Our results show thatwhen our method-agnostic approach is plugged into FGSM, we achieve a speedup of3.52x on MNIST and 1.98x on the CIFAR-10 dataset with comparable robustaccuracy. We also test our approach on state-of-the-art Free adversarialtraining and achieve a speedup of 1.2x in training time with a marginal drop inrobust accuracy on the ImageNet dataset.", "output": "Do we need entire training data for adversarial training?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Diffusion models have shown superior performance in image generation andmanipulation, but the inherent stochasticity presents challenges in preservingand manipulating image content and identity. While previous approaches likeDreamBooth and Textual Inversion have proposed model or latent representationpersonalization to maintain the content, their reliance on multiple referenceimages and complex training limits their practicality. In this paper, wepresent a simple yet highly effective approach to personalization using highlypersonalized (HiPer) text embedding by decomposing the CLIP embedding space forpersonalization and content manipulation. Our method does not require modelfine-tuning or identifiers, yet still enables manipulation of background,texture, and motion with just a single image and target text. Throughexperiments on diverse target texts, we demonstrate that our approach produceshighly personalized and complex semantic image edits across a wide range oftasks. We believe that the novel understanding of the text embedding spacepresented in this work has the potential to inspire further research acrossvarious tasks.", "output": "Highly Personalized Text Embedding for Image Manipulation by Stable Diffusion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, monitoring the world wide area with satellite images hasbeen emerged as an important issue.Site monitoring task can be divided into two independent tasks; 1) ChangeDetection and 2) Anomaly Event Detection.Unlike to change detection research is actively conducted based on thenumerous datasets(eg LEVIR-CD, WHU-CD, S2Looking, xView2 and etc...) to meetup the expectations of industries or governments, research on AI models fordetecting anomaly events is passively and rarely conducted.In this paper, we introduce a novel satellite imagery dataset(AED-RS) fordetecting anomaly events on the open public places.AED-RS Dataset contains satellite images of normal and abnormal situations of8 open public places from all over the world.Each places are labeled with different criteria based on the difference ofcharacteristics of each places.With this dataset, we introduce a baseline model for our dataset TB-FLOW,which can be trained in weakly-supervised manner and shows reasonableperformance on the AED-RS Dataset compared with the other NF(Normalizing-Flow)based anomaly detection models. Our dataset and code will be publicly open inurl{", "output": "Focus or Not: A Baseline for Anomaly Event Detection On the Open Public Places with Satellite Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Quality assessment algorithms can be used to estimate the utility of abiometric sample for the purpose of biometric recognition. \"Error versusDiscard Characteristic\" (EDC) plots, and \"partial Area Under Curve\" (pAUC)values of curves therein, are generally used by researchers to evaluate thepredictive performance of such quality assessment algorithms. An EDC curvedepends on an error type such as the \"False Non Match Rate\" (FNMR), a qualityassessment algorithm, a biometric recognition system, a set of comparisons eachcorresponding to a biometric sample pair, and a comparison score thresholdcorresponding to a starting error. To compute an EDC curve, comparisons areprogressively discarded based on the associated samples' lowest quality scores,and the error is computed for the remaining comparisons. Additionally, adiscard fraction limit or range must be selected to compute pAUC values, whichcan then be used to quantitatively rank quality assessment algorithms.This paper discusses and analyses various details for this kind of qualityassessment algorithm evaluation, including general EDC properties,interpretability improvements for pAUC values based on a hard lower error limitand a soft upper error limit, the use of relative instead of discrete rankings,stepwise vs. linear curve interpolation, and normalisation of quality scores toa [0, 100] integer range. We also analyse the stability of quantitative qualityassessment algorithm rankings based on pAUC values across varying pAUC discardfraction limits and starting errors, concluding that higher pAUC discardfraction limits should be preferred. The analyses are conducted both withsynthetic data and with real data for a face image quality assessment scenario,with a focus on general modality-independent conclusions for EDC evaluations.", "output": "Considerations on the Evaluation of Biometric Quality Assessment Algorithms."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The view inconsistency problem in score-distilling text-to-3D generation,also known as the Janus problem, arises from the intrinsic bias of 2D diffusionmodels, which leads to the unrealistic generation of 3D objects. In this work,we explore score-distilling text-to-3D generation and identify the main causesof the Janus problem. Based on these findings, we propose two approaches todebias the score-distillation frameworks for robust text-to-3D generation. Ourfirst approach, called score debiasing, involves gradually increasing thetruncation value for the score estimated by 2D diffusion models throughout theoptimization process. Our second approach, called prompt debiasing, identifiesconflicting words between user prompts and view prompts utilizing a languagemodel and adjusts the discrepancy between view prompts and object-space cameraposes. Our experimental results show that our methods improve realism bysignificantly reducing artifacts and achieve a good trade-off betweenfaithfulness to the 2D diffusion models and 3D consistency with littleoverhead.", "output": "Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automatic radiology report generation has attracted enormous researchinterest due to its practical value in reducing the workload of radiologists.However, simultaneously establishing global correspondences between the image(e.g., Chest X-ray) and its related report and local alignments between imagepatches and keywords remains challenging. To this end, we propose an Unify,Align and then Refine (UAR) approach to learn multi-level cross-modalalignments and introduce three novel modules: Latent Space Unifier (LSU),Cross-modal Representation Aligner (CRA) and Text-to-Image Refiner (TIR).Specifically, LSU unifies multimodal data into discrete tokens, making itflexible to learn common knowledge among modalities with a shared network. Themodality-agnostic CRA learns discriminative features via a set of orthonormalbasis and a dual-gate mechanism first and then globally aligns visual andtextual representations under a triplet contrastive loss. TIR booststoken-level local alignment via calibrating text-to-image attention with alearnable mask. Additionally, we design a two-stage training procedure to makeUAR gradually grasp cross-modal alignments at different levels, which imitatesradiologists' workflow: writing sentence by sentence first and then checkingword by word. Extensive experiments and analyses on IU-Xray and MIMIC-CXRbenchmark datasets demonstrate the superiority of our UAR against variedstate-of-the-art methods.", "output": "Unify, Align and Refine: Multi-Level Semantic Alignment for Radiology Report Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "To enable progress towards egocentric agents capable of understandingeveryday tasks specified in natural language, we propose a benchmark and asynthetic dataset called Egocentric Task Verification (EgoTV). EgoTV containsmulti-step tasks with multiple sub-task decompositions, state changes, objectinteractions, and sub-task ordering constraints, in addition to abstracted taskdescriptions that contain only partial details about ways to accomplish a task.We also propose a novel Neuro-Symbolic Grounding (NSG) approach to enable thecausal, temporal, and compositional reasoning of such tasks. We demonstrateNSG's capability towards task tracking and verification on our EgoTV datasetand a real-world dataset derived from CrossTask (CTV). Our contributionsinclude the release of the EgoTV and CTV datasets, and the NSG model for futureresearch on egocentric assistive agents.", "output": "EgoTV: Egocentric Task Verification from Natural Language Task Descriptions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Advancements in the generation quality of various Generative Models (GMs) hasmade it necessary to not only perform binary manipulation detection but alsolocalize the modified pixels in an image. However, prior works termed aspassive for manipulation localization exhibit poor generalization performanceover unseen GMs and attribute modifications. To combat this issue, we propose aproactive scheme for manipulation localization, termed MaLP. We encrypt thereal images by adding a learned template. If the image is manipulated by anyGM, this added protection from the template not only aids binary detection butalso helps in identifying the pixels modified by the GM. The template islearned by leveraging local and global-level features estimated by a two-brancharchitecture. We show that MaLP performs better than prior passive works. Wealso show the generalizability of MaLP by testing on 22 different GMs,providing a benchmark for future research on manipulation localization.Finally, we show that MaLP can be used as a discriminator for improving thegeneration quality of GMs. Our models/codes are available atwww.github.com/vishal3477/pro_loc.", "output": "MaLP: Manipulation Localization Using a Proactive Scheme."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Real-time perception, or streaming perception, is a crucial aspect ofautonomous driving that has yet to be thoroughly explored in existing research.To address this gap, we present DAMO-StreamNet, an optimized framework thatcombines recent advances from the YOLO series with a comprehensive analysis ofspatial and temporal perception mechanisms, delivering a cutting-edge solution.The key innovations of DAMO-StreamNet are: (1) A robust neck structureincorporating deformable convolution, enhancing the receptive field and featurealignment capabilities. (2) A dual-branch structure that integrates short-pathsemantic features and long-path temporal features, improving motion stateprediction accuracy. (3) Logits-level distillation for efficient optimization,aligning the logits of teacher and student networks in semantic space. (4) Areal-time forecasting mechanism that updates support frame features with thecurrent frame, ensuring seamless streaming perception during inference. Ourexperiments demonstrate that DAMO-StreamNet surpasses existing state-of-the-artmethods, achieving 37.8% (normal size (600, 960)) and 43.3% (large size (1200,1920)) sAP without using extra data. This work not only sets a new benchmarkfor real-time perception but also provides valuable insights for futureresearch. Additionally, DAMO-StreamNet can be applied to various autonomoussystems, such as drones and robots, paving the way for real-time perception.The code is available at ", "output": "DAMO-StreamNet: Optimizing Streaming Perception in Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "For Human Action Recognition tasks (HAR), 3D Convolutional Neural Networkshave proven to be highly effective, achieving state-of-the-art results. Thisstudy introduces a novel streaming architecture based toolflow for mapping suchmodels onto FPGAs considering the model's inherent characteristics and thefeatures of the targeted FPGA device. The HARFLOW3D toolflow takes as input a3D CNN in ONNX format and a description of the FPGA characteristics, generatinga design that minimizes the latency of the computation. The toolflow iscomprised of a number of parts, including i) a 3D CNN parser, ii) a performanceand resource model, iii) a scheduling algorithm for executing 3D models on thegenerated hardware, iv) a resource-aware optimization engine tailored for 3Dmodels, v) an automated mapping to synthesizable code for FPGAs. The ability ofthe toolflow to support a broad range of models and devices is shown through anumber of experiments on various 3D CNN and FPGA system pairs. Furthermore, thetoolflow has produced high-performing results for 3D CNN models that have notbeen mapped to FPGAs before, demonstrating the potential of FPGA-based systemsin this space. Overall, HARFLOW3D has demonstrated its ability to delivercompetitive latency compared to a range of state-of-the-art hand-tunedapproaches being able to achieve up to 5$times$ better performance compared tosome of the existing works.", "output": "HARFLOW3D: A Latency-Oriented 3D-CNN Accelerator Toolflow for HAR on FPGA Devices."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the machine learning domain, research on anomaly detection andlocalization within image data has garnered significant attention, particularlyin practical applications such as industrial defect detection. While existingapproaches predominantly rely on Convolutional Neural Networks (CNN) as theirbackbone network, we propose an innovative method based on the Transformerbackbone network. Our approach employs a two-stage incremental learningstrategy. In the first stage, we train a Masked Autoencoder (MAE) modelexclusively on normal images. Subsequently, in the second stage, we implementpixel-level data augmentation techniques to generate corrupted normal imagesand their corresponding pixel labels. This process enables the model to learnhow to repair corrupted regions and classify the state of each pixel.Ultimately, the model produces a pixel reconstruction error matrix and a pixelanomaly probability matrix, which are combined to create an anomaly scoringmatrix that effectively identifies abnormal regions. When compared to severalstate-of-the-art CNN-based techniques, our method demonstrates superiorperformance on the MVTec AD dataset, achieving an impressive 97.6% AUC.", "output": "Incremental Self-Supervised Learning Based on Transformer for Anomaly Detection and Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes a new method for anomaly detection in time-series data byincorporating the concept of difference subspace into the singular spectrumanalysis (SSA). The key idea is to monitor slight temporal variations of thedifference subspace between two signal subspaces corresponding to the past andpresent time-series data, as anomaly score. It is a natural generalization ofthe conventional SSA-based method which measures the minimum angle between thetwo signal subspaces as the degree of changes. By replacing the minimum anglewith the difference subspace, our method boosts the performance while using theSSA-based framework as it can capture the whole structural difference betweenthe two subspaces in its magnitude and direction. We demonstrate our method'seffectiveness through performance evaluations on public time-series datasets.", "output": "Time-series Anomaly Detection based on Difference Subspace between Signal Subspaces."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While current multi-frame restoration methods combine information frommultiple input images using 2D alignment techniques, recent advances in novelview synthesis are paving the way for a new paradigm relying on volumetricscene representations. In this work, we introduce the first 3D-basedmulti-frame denoising method that significantly outperforms its 2D-basedcounterparts with lower computational requirements. Our method extends themultiplane image (MPI) framework for novel view synthesis by introducing alearnable encoder-renderer pair manipulating multiplane representations infeature space. The encoder fuses information across views and operates in adepth-wise manner while the renderer fuses information across depths andoperates in a view-wise manner. The two modules are trained end-to-end andlearn to separate depths in an unsupervised way, giving rise to MultiplaneFeature (MPF) representations. Experiments on the Spaces and RealForward-Facing datasets as well as on raw burst data validate our approach forview synthesis, multi-frame denoising, and view synthesis under noisyconditions.", "output": "Efficient View Synthesis and 3D-based Multi-Frame Denoising with Multiplane Feature Representations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, deep learning has been widely used in SAR ATR and achievedexcellent performance on the MSTAR dataset. However, due to constrained imagingconditions, MSTAR has data biases such as background correlation, i.e.,background clutter properties have a spurious correlation with target classes.Deep learning can overfit clutter to reduce training errors. Therefore, thedegree of overfitting for clutter reflects the non-causality of deep learningin SAR ATR. Existing methods only qualitatively analyze this phenomenon. Inthis paper, we quantify the contributions of different regions to targetrecognition based on the Shapley value. The Shapley value of clutter measuresthe degree of overfitting. Moreover, we explain how data bias and model biascontribute to non-causality. Concisely, data bias leads to comparablesignal-to-clutter ratios and clutter textures in training and test sets. Andvarious model structures have different degrees of overfitting for thesebiases. The experimental results of various models under standard operatingconditions on the MSTAR dataset support our conclusions. Our code is availableat ", "output": "Discovering and Explaining the Non-Causality of Deep Learning in SAR ATR."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This report serves as a supplementary document for TaskPrompter, detailingits implementation on a new joint 2D-3D multi-task learning benchmark based onCityscapes-3D. TaskPrompter presents an innovative multi-task promptingframework that unifies the learning of (i) task-generic representations, (ii)task-specific representations, and (iii) cross-task interactions, as opposed toprevious approaches that separate these learning objectives into differentnetwork modules. This unified approach not only reduces the need for meticulousempirical structure design but also significantly enhances the multi-tasknetwork's representation learning capability, as the entire model capacity isdevoted to optimizing the three objectives simultaneously. TaskPrompterintroduces a new multi-task benchmark based on Cityscapes-3D dataset, whichrequires the multi-task model to concurrently generate predictions formonocular 3D vehicle detection, semantic segmentation, and monocular depthestimation. These tasks are essential for achieving a joint 2D-3D understandingof visual scenes, particularly in the development of autonomous drivingsystems. On this challenging benchmark, our multi-task model demonstratesstrong performance compared to single-task state-of-the-art methods andestablishes new state-of-the-art results on the challenging 3D detection anddepth estimation tasks.", "output": "Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We consider the challenging task of training models for image-to-videodeblurring, which aims to recover a sequence of sharp images corresponding to agiven blurry image input. A critical issue disturbing the training of animage-to-video model is the ambiguity of the frame ordering since both theforward and backward sequences are plausible solutions. This paper proposes aneffective self-supervised ordering scheme that allows training high-qualityimage-to-video deblurring models. Unlike previous methods that rely onorder-invariant losses, we assign an explicit order for each video sequence,thus avoiding the order-ambiguity issue. Specifically, we map each videosequence to a vector in a latent high-dimensional space so that there exists ahyperplane such that for every video sequence, the vectors extracted from itand its reversed sequence are on different sides of the hyperplane. The side ofthe vectors will be used to define the order of the corresponding sequence.Last but not least, we propose a real-image dataset for the image-to-videodeblurring problem that covers a variety of popular domains, including face,hand, and street. Extensive experimental results confirm the effectiveness ofour method. Code and data are available at", "output": "HyperCUT: Video Sequence from a Single Blurry Image using Unsupervised Ordering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents a novel Diffusion-Wavelet (DiWa) approach forSingle-Image Super-Resolution (SISR). It leverages the strengths of DenoisingDiffusion Probabilistic Models (DDPMs) and Discrete Wavelet Transformation(DWT). By enabling DDPMs to operate in the DWT domain, our DDPM modelseffectively hallucinate high-frequency information for super-resolved images onthe wavelet spectrum, resulting in high-quality and detailed reconstructions inimage space. Quantitatively, we outperform state-of-the-art diffusion-basedSISR methods, namely SR3 and SRDiff, regarding PSNR, SSIM, and LPIPS on bothface (8x scaling) and general (4x scaling) SR benchmarks. Meanwhile, using DWTenabled us to use fewer parameters than the compared models: 92M parametersinstead of 550M compared to SR3 and 9.3M instead of 12M compared to SRDiff.Additionally, our method outperforms other state-of-the-art generative methodson classical general SR datasets while saving inference time. Finally, our workhighlights its potential for various applications.", "output": "Waving Goodbye to Low-Res: A Diffusion-Wavelet Approach for Image Super-Resolution."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Binary Partition Hierarchies (BPH) and minimum spanning trees are fundamentaldata structures involved in hierarchical analysis such as quasi-flat zones orwatershed. However, classical BPH construction algorithms require to have thewhole data in memory, which prevent the processing of large images that cannotfit entirely in the main memory of the computer. To cope with this problem, analgebraic framework leading to a high level calculus was introduced allowing anout-of-core computation of BPHs. This calculus relies on three operations:select, join, and insert. In this article, we introduce three efficientalgorithms to perform these operations providing pseudo-code and complexityanalysis.", "output": "Join, select, and insert: efficient out-of-core algorithms for hierarchical segmentation trees."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The AI community has embraced multi-sensory or multi-modal approaches toadvance this generation of AI models to resemble expected intelligentunderstanding. Combining language and imagery represents a familiar method forspecific tasks like image captioning or generation from descriptions. Thispaper compares these monolithic approaches to a lightweight and specializedmethod based on employing image models to label objects, then seriallysubmitting this resulting object list to a large language model (LLM). This useof multiple Application Programming Interfaces (APIs) enables better than 95%mean average precision for correct object lists, which serve as input to thelatest Open AI text generator (GPT-4). To demonstrate the API as a modularalternative, we solve the problem of a user taking a picture of ingredientsavailable in a refrigerator, then generating novel recipe cards tailored tocomplex constraints on cost, preparation time, dietary restrictions, portionsizes, and multiple meal plans. The research concludes that monolithicmultimodal models currently lack the coherent memory to maintain context andformat for this task and that until recently, the language models like GPT-2/3struggled to format similar problems without degenerating into repetitive ornon-sensical combinations of ingredients. For the first time, an AI chef orcook seems not only possible but offers some enhanced capabilities to augmenthuman recipe libraries in pragmatic ways. The work generates a 100-page recipebook featuring the thirty top ingredients using over 2000 refrigerator imagesas initializing lists.", "output": "The Multimodal And Modular Ai Chef: Complex Recipe Generation From Imagery."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fake job postings have become prevalent in the online job market, posingsignificant challenges to job seekers and employers. Despite the growing needto address this problem, there is limited research that leverages deep learningtechniques for the detection of fraudulent job advertisements. This study aimsto fill the gap by employing a Bidirectional Long Short-Term Memory (Bi-LSTM)model to identify fake job advertisements. Our approach considers both numericand text features, effectively capturing the underlying patterns andrelationships within the data. The proposed model demonstrates a superiorperformance, achieving a 0.91 ROC AUC score and a 98.71% accuracy rate,indicating its potential for practical applications in the online job market.The findings of this research contribute to the development of robust,automated tools that can help combat the proliferation of fake job postings andimprove the overall integrity of the job search process. Moreover, we discusschallenges, future research directions, and ethical considerations related toour approach, aiming to inspire further exploration and development ofpractical solutions to combat online job fraud.", "output": "Detecting Fake Job Postings Using Bidirectional LSTM."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study an online joint assortment-inventory optimization problem, in whichwe assume that the choice behavior of each customer follows the MultinomialLogit (MNL) choice model, and the attraction parameters are unknown a priori.The retailer makes periodic assortment and inventory decisions to dynamicallylearn from the realized demands about the attraction parameters whilemaximizing the expected total profit over time. In this paper, we propose anovel algorithm that can effectively balance the exploration and exploitationin the online decision-making of assortment and inventory. Our algorithm buildson a new estimator for the MNL attraction parameters, a novel approach toincentivize exploration by adaptively tuning certain known and unknownparameters, and an optimization oracle to static single-cycleassortment-inventory planning problems with given parameters. We establish aregret upper bound for our algorithm and a lower bound for the online jointassortment-inventory optimization problem, suggesting that our algorithmachieves nearly optimal regret rate, provided that the static optimizationoracle is exact. Then we incorporate more practical approximate staticoptimization oracles into our algorithm, and bound from above the impact ofstatic optimization errors on the regret of our algorithm. At last, we performnumerical studies to demonstrate the effectiveness of our proposed algorithm.", "output": "Online Joint Assortment-Inventory Optimization under MNL Choices."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We perform an effective-theory analysis of forward-backward signalpropagation in wide and deep Transformers, i.e., residual neural networks withmulti-head self-attention blocks and multilayer perceptron blocks. Thisanalysis suggests particular width scalings of initialization and traininghyperparameters for these models. We then take up such suggestions, trainingVision and Language Transformers in practical setups.", "output": "Effective Theory of Transformers at Initialization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine learning (ML) has become critical for post-acquisition data analysisin (scanning) transmission electron microscopy, (S)TEM, imaging andspectroscopy. An emerging trend is the transition to real-time analysis andclosed-loop microscope operation. The effective use of ML in electronmicroscopy now requires the development of strategies for microscopy-centeredexperiment workflow design and optimization. Here, we discuss the associatedchallenges with the transition to active ML, including sequential data analysisand out-of-distribution drift effects, the requirements for the edge operation,local and cloud data storage, and theory in the loop operations. Specifically,we discuss the relative contributions of human scientists and ML agents in theideation, orchestration, and execution of experimental workflows and the needto develop universal hyper languages that can apply across multiple platforms.These considerations will collectively inform the operationalization of ML innext-generation experimentation.", "output": "Deep Learning for Automated Experimentation in Scanning Transmission Electron Microscopy."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine Unlearning has recently been emerging as a paradigm for selectivelyremoving the impact of training datapoints from a network. While existingapproaches have focused on unlearning either a small subset of the trainingdata or a single class, in this paper we take a different path and devise aframework that can unlearn all classes of an image classification network in asingle untraining round. Our proposed technique learns to modulate the innercomponents of an image classification network through memory matrices so that,after training, the same network can selectively exhibit an unlearning behaviorover any of the classes. By discovering weights which are specific to each ofthe classes, our approach also recovers a representation of the classes whichis explainable by-design. We test the proposed framework, which we name WeightFiltering network (WF-Net), on small-scale and medium-scale imageclassification datasets, with both CNN and Transformer-based backbones. Ourwork provides interesting insights in the development of explainable solutionsfor unlearning and could be easily extended to other vision tasks.", "output": "Multi-Class Explainable Unlearning for Image Classification via Weight Filtering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We use information-theoretic tools to derive a novel analysis of Multi-sourceDomain Adaptation (MDA) from the representation learning perspective.Concretely, we study joint distribution alignment for supervised MDA with fewtarget labels and unsupervised MDA with pseudo labels, where the latter isrelatively hard and less commonly studied. We further providealgorithm-dependent generalization bounds for these two settings, where thegeneralization is characterized by the mutual information between theparameters and the data. Then we propose a novel deep MDA algorithm, implicitlyaddressing the target shift through joint alignment. Finally, the mutualinformation bounds are extended to this algorithm providing a non-vacuousgradient-norm estimation. The proposed algorithm has comparable performance tothe state-of-the-art on target-shifted MDA benchmark with improved memoryefficiency.", "output": "Algorithm-Dependent Bounds for Representation Learning of Multi-Source Domain Adaptation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a complete software pipeline for revealing the hidden texts of theHerculaneum papyri using X-ray CT images. This enhanced virtual unwrappingpipeline combines machine learning with a novel geometric framework linking 3Dand 2D images. We also present EduceLab-Scrolls, a comprehensive open datasetrepresenting two decades of research effort on this problem. EduceLab-Scrollscontains a set of volumetric X-ray CT images of both small fragments andintact, rolled scrolls. The dataset also contains 2D image labels that are usedin the supervised training of an ink detection model. Labeling is enabled byaligning spectral photography of scroll fragments with X-ray CT images of thesame fragments, thus creating a machine-learnable mapping between image spacesand modalities. This alignment permits supervised learning for the detection of\"invisible\" carbon ink in X-ray CT, a task that is \"impossible\" even for humanexpert labelers. To our knowledge, this is the first aligned dataset of itskind and is the largest dataset ever released in the heritage domain. Ourmethod is capable of revealing accurate lines of text on scroll fragments withknown ground truth. Revealed text is verified using visual confirmation,quantitative image metrics, and scholarly review. EduceLab-Scrolls has alsoenabled the discovery, for the first time, of hidden texts from the Herculaneumpapyri, which we present here. We anticipate that the EduceLab-Scrolls datasetwill generate more textual discovery as research continues.", "output": "EduceLab-Scrolls: Verifiable Recovery of Text from Herculaneum Papyri using X-ray CT."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, a Stackelberg game theoretic framework is proposed for tradingenergy bidirectionally between the demand-response (DR) aggregator and theprosumers. This formulation allows for flexible energy arbitrage and additionalmonetary rewards while ensuring that the prosumers' desired daily energy demandis met. Then, a scalable (with the number of prosumers) approach is proposed tofind approximate equilibria based on online sampling and learning of theprosumers' cumulative best response. Moreover, bounds are provided on thequality of the approximate equilibrium solution. Last, real-world data from theCalifornia day-ahead energy market and the University of California at Davisbuilding energy demands are utilized to demonstrate the efficacy of theproposed framework and the online scalable solution.", "output": "Scalable Online Learning of Approximate Stackelberg Solutions in Energy Trading Games with Demand Response Aggregators."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Estimating Click-Through Rate (CTR) is a vital yet challenging task inpersonalized product search. However, existing CTR methods still struggle inthe product search settings due to the following three challenges including howto more effectively extract users' short-term interests with respect tomultiple aspects, how to extract and fuse users' long-term interest withshort-term interests, how to address the entangling characteristic of long andshort-term interests. To resolve these challenges, in this paper, we propose anew approach named Hierarchical Interests Fusing Network (HIFN), which consistsof four basic modules namely Short-term Interests Extractor (SIE), Long-termInterests Extractor (LIE), Interests Fusion Module (IFM) and InterestsDisentanglement Module (IDM). Specifically, SIE is proposed to extract user'sshort-term interests by integrating three fundamental interests encoders withinit namely query-dependent, target-dependent and causal-dependent interestencoder, respectively, followed by delivering the resultant representation tothe module LIE, where it can effectively capture user long-term interests bydevising an attention mechanism with respect to the short-term interests fromSIE module. In IFM, the achieved long and short-term interests are furtherfused in an adaptive manner, followed by concatenating it with original rawcontext features for the final prediction result. Last but not least,considering the entangling characteristic of long and short-term interests, IDMfurther devises a self-supervised framework to disentangle long and short-terminterests. Extensive offline and online evaluations on a real-world e-commerceplatform demonstrate the superiority of HIFN over state-of-the-art methods.", "output": "Hierarchically Fusing Long and Short-Term User Interests for Click-Through Rate Prediction in Product Search."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Stock market forecasting has been a challenging part for many analysts andresearchers. Trend analysis, statistical techniques, and movement indicatorshave traditionally been used to predict stock price movements, but textextraction has emerged as a promising method in recent years. The use of neuralnetworks, especially recurrent neural networks, is abundant in the literature.In most studies, the impact of different users was considered equal or ignored,whereas users can have other effects. In the current study, we will introduceTM-vector and then use this vector to train an IndRNN and ultimately model themarket users' behaviour. In the proposed model, TM-vector is simultaneouslytrained with both the extracted Twitter features and market information.Various factors have been used for the effectiveness of the proposedforecasting approach, including the characteristics of each individual user,their impact on each other, and their impact on the market, to predict marketdirection more accurately. Dow Jones 30 index has been used in current work.The accuracy obtained for predicting daily stock changes of Apple is based onvarious models, closed to over 95% and for the other stocks is significant.Our results indicate the effectiveness of TM-vector in predicting stock marketdirection.", "output": "TM-vector: A Novel Forecasting Approach for Market stock movement with a Rich Representation of Twitter and Market data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present CAMELS-ASTRID, the third suite of hydrodynamical simulations inthe Cosmology and Astrophysics with MachinE Learning (CAMELS) project, alongwith new simulation sets that extend the model parameter space based on theprevious frameworks of CAMELS-TNG and CAMELS-SIMBA, to provide broader trainingsets and testing grounds for machine-learning algorithms designed forcosmological studies. CAMELS-ASTRID employs the galaxy formation modelfollowing the ASTRID simulation and contains 2,124 hydrodynamic simulation runsthat vary 3 cosmological parameters ($Omega_m$, $sigma_8$, $Omega_b$) and 4parameters controlling stellar and AGN feedback. Compared to the existing TNGand SIMBA simulation suites in CAMELS, the fiducial model of ASTRID featuresthe mildest AGN feedback and predicts the least baryonic effect on the matterpower spectrum. The training set of ASTRID covers a broader variation in thegalaxy populations and the baryonic impact on the matter power spectrumcompared to its TNG and SIMBA counterparts, which can make machine-learningmodels trained on the ASTRID suite exhibit better extrapolation performancewhen tested on other hydrodynamic simulation sets. We also introduce extensionsimulation sets in CAMELS that widely explore 28 parameters in the TNG andSIMBA models, demonstrating the enormity of the overall galaxy formation modelparameter space and the complex non-linear interplay between cosmology andastrophysical processes. With the new simulation suites, we show that buildingrobust machine-learning models favors training and testing on the largestpossible diversity of galaxy formation models. We also demonstrate that it ispossible to train accurate neural networks to infer cosmological parametersusing the high-dimensional TNG-SB28 simulation set.", "output": "The CAMELS project: Expanding the galaxy formation model space with new ASTRID and 28-parameter TNG and SIMBA suites."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We adopt convolutional neural networks (CNN) to predict the basic propertiesof the porous media. Two different media types are considered: one mimics thesandstone, and the other mimics the systems derived from the extracellularspace of biological tissues. The Lattice Boltzmann Method is used to obtain thelabeled data necessary for performing supervised learning. We distinguish twotasks. In the first, networks based on the analysis of the system's geometrypredict porosity and effective diffusion coefficient. In the second, networksreconstruct the system's geometry and concentration map. In the first task, wepropose two types of CNN models: the C-Net and the encoder part of the U-Net.Both networks are modified by adding a self-normalization module. The modelspredict with reasonable accuracy but only within the data type, they aretrained on. For instance, the model trained on sandstone-like samplesovershoots or undershoots for biological-like samples. In the second task, wepropose the usage of the U-Net architecture. It accurately reconstructs theconcentration fields. Moreover, the network trained on one data type works wellfor the other. For instance, the model trained on sandstone-like samples worksperfectly on biological-like samples.", "output": "Deep learning for diffusion in porous media."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The SUBNET neural network architecture has been developed to identifynonlinear state-space models from input-output data. To achieve this, itcombines the rolled-out nonlinear state-space equations and a state encoderfunction, both parameterised as a neural network. The encoder function isintroduced to reconstruct the current state from past input-output data. Henceit enables the forward simulation of the rolled-out state-space model. Whilethis approach has shown to provide high-accuracy and consistent modelestimation, its convergence can be significantly improved by efficientinitialization of the training process. This paper focuses on such aninitialisation of the subspace encoder approach using the Best LinearApproximation (BLA). Using the BLA provided state-space matrices and itsassociated reconstructability map both the state-transition part of the networkand the encoder are initialized. The performance of the improved initialisationscheme is evaluated on a Wiener-Hammerstein simulation example and a benchmarkdataset. The results show that for a weakly nonlinear system, the proposedinitialisation based on the linear reconstructability map results in a fasterconvergence and a better model quality.", "output": "Initialization Approach for Nonlinear State-Space Identification via the Subspace Encoder Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper focuses on optimal unimodal transformation of the score outputs ofa univariate learning model under linear loss functions. We demonstrate thatthe optimal mapping between score values and the target region is a rectangularfunction. To produce this optimal rectangular fit for the observed samples, wepropose a sequential approach that can its estimation with each incoming newsample. Our approach has logarithmic time complexity per iteration and isoptimally efficient.", "output": "Sequential Linearithmic Time Optimal Unimodal Fitting When Minimizing Univariate Linear Losses."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper investigates in which cases continuous optimization for directedacyclic graph (DAG) structure learning can and cannot perform well and why thishappens, and suggests possible directions to make the search procedure morereliable. Reisach et al. (2021) suggested that the remarkable performance ofseveral continuous structure learning approaches is primarily driven by a highagreement between the order of increasing marginal variances and thetopological order, and demonstrated that these approaches do not perform wellafter data standardization. We analyze this phenomenon for continuousapproaches assuming equal and non-equal noise variances, and show that thestatement may not hold in either case by providing counterexamples,justifications, and possible alternative explanations. We further demonstratethat nonconvexity may be a main concern especially for the non-equal noisevariances formulation, while recent advances in continuous structure learningfail to achieve improvement in this case. Our findings suggest that futureworks should take into account the non-equal noise variances formulation tohandle more general settings and for a more comprehensive empirical evaluation.Lastly, we provide insights into other aspects of the search procedure,including thresholding and sparsity, and show that they play an important rolein the final solutions.", "output": "Structure Learning with Continuous Optimization: A Sober Look and Beyond."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, fully-transformer architectures have replaced the defactoconvolutional architecture for the 3D human pose estimation task. In this paperwe propose textbf{textit{ConvFormer}}, a novel convolutional transformer thatleverages a new textbf{textit{dynamic multi-headed convolutionalself-attention}} mechanism for monocular 3D human pose estimation. We designeda spatial and temporal convolutional transformer to comprehensively model humanjoint relations within individual frames and globally across the motionsequence. Moreover, we introduce a novel notion of textbf{textit{temporaljoints profile}} for our temporal ConvFormer that fuses complete temporalinformation immediately for a local neighborhood of joint features. We havequantitatively and qualitatively validated our method on three common benchmarkdatasets: Human3.6M, MPI-INF-3DHP, and HumanEva. Extensive experiments havebeen conducted to identify the optimal hyper-parameter set. These experimentsdemonstrated that we achieved a textbf{significant parameter reductionrelative to prior transformer models} while attaining State-of-the-Art (SOTA)or near SOTA on all three datasets. Additionally, we achieved SOTA for ProtocolIII on H36M for both GT and CPN detection inputs. Finally, we obtained SOTA onall three metrics for the MPI-INF-3DHP dataset and for all three subjects onHumanEva under Protocol II.", "output": "ConvFormer: Parameter Reduction in Transformer Models for 3D Human Pose Estimation by Leveraging Dynamic Multi-Headed Convolutional Attention."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In spite of the progress in music source separation research, the smallamount of publicly-available clean source data remains a constant limitingfactor for performance. Thus, recent advances in self-supervised learningpresent a largely-unexplored opportunity for improving separation models byleveraging unlabelled music data. In this paper, we propose a self-supervisedlearning framework for music source separation inspired by the HuBERT speechrepresentation model. We first investigate the potential impact of the originalHuBERT model by inserting an adapted version of it into the well-known DemucsV2 time-domain separation model architecture. We then propose atime-frequency-domain self-supervised model, Pac-HuBERT (for primitive auditoryclustering HuBERT), that we later use in combination with a Res-U-Net decoderfor source separation. Pac-HuBERT uses primitive auditory features of music asunsupervised clustering labels to initialize the self-supervised pretrainingprocess using the Free Music Archive (FMA) dataset. The resulting frameworkachieves better source-to-distortion ratio (SDR) performance on the MusDB18test set than the original Demucs V2 and Res-U-Net models. We furtherdemonstrate that it can boost performance with small amounts of superviseddata. Ultimately, our proposed framework is an effective solution to thechallenge of limited clean source data for music source separation.", "output": "Pac-HuBERT: Self-Supervised Music Source Separation via Primitive Auditory Clustering and Hidden-Unit BERT."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Adapters present a promising solution to the catastrophic forgetting problemin continual learning. However, training independent Adapter modules for everynew task misses an opportunity for cross-task knowledge transfer. We proposeImprovise to Initialize (I2I), a continual learning algorithm that initializesAdapters for incoming tasks by distilling knowledge from previously-learnedtasks' Adapters. We evaluate I2I on CLiMB, a multimodal continual learningbenchmark, by conducting experiments on sequences of visual question answeringtasks. Adapters trained with I2I consistently achieve better task accuracy thanindependently-trained Adapters, demonstrating that our algorithm facilitatesknowledge transfer between task Adapters. I2I also results in better cross-taskknowledge transfer than the state-of-the-art AdapterFusion without incurringthe associated parametric cost.", "output": "I2I: Initializing Adapters with Improvised Knowledge."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Synthetic electronic health records (EHRs) that are both realistic andpreserve privacy can serve as an alternative to real EHRs for machine learning(ML) modeling and statistical analysis. However, generating high-fidelity andgranular electronic health record (EHR) data in its original,highly-dimensional form poses challenges for existing methods due to thecomplexities inherent in high-dimensional data. In this paper, we proposeHierarchical Autoregressive Language mOdel (HALO) for generating longitudinalhigh-dimensional EHR, which preserve the statistical properties of real EHR andcan be used to train accurate ML models without privacy concerns. Our HALOmethod, designed as a hierarchical autoregressive model, generates aprobability density function of medical codes, clinical visits, and patientrecords, allowing for the generation of realistic EHR data in its original,unaggregated form without the need for variable selection or aggregation.Additionally, our model also produces high-quality continuous variables in alongitudinal and probabilistic manner. We conducted extensive experiments anddemonstrate that HALO can generate high-fidelity EHR data with high-dimensionaldisease code probabilities (d &gt; 10,000), disease co-occurrence probabilitieswithin visits (d &gt; 1,000,000), and conditional probabilities across consecutivevisits (d &gt; 5,000,000) and achieve above 0.9 R2 correlation in comparison toreal EHR data. This performance then enables downstream ML models trained onits synthetic data to achieve comparable accuracy to models trained on realdata (0.938 AUROC with HALO data vs. 0.943 with real data). Finally, using acombination of real and synthetic data enhances the accuracy of ML modelsbeyond that achieved by using only real EHR data.", "output": "Synthesize Extremely High-dimensional Longitudinal Electronic Health Records via Hierarchical Autoregressive Language Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The interactive exploration of large and evolving datasets is challenging asrelationships between underlying variables may not be fully understood. Theremay be hidden trends and patterns in the data that are worthy of furtherexploration and analysis. We present a system that methodically exploresmultiple combinations of variables using a searchlight technique and identifiesoutliers. An iterative k-means clustering algorithm is applied to featuresderived through a split-apply-combine paradigm used in the database literature.Outliers are identified as singleton or small clusters. This algorithm is sweptacross the dataset in a searchlight manner. The dimensions that containoutliers are combined in pairs with other dimensions using a susbset scantechnique to gain further insight into the outliers. We illustrate this systemby anaylzing open health care data released by New York State. We apply ouriterative k-means searchlight followed by subset scanning. Several anomaloustrends in the data are identified, including cost overruns at specifichospitals, and increases in diagnoses such as suicides. These constitute novelfindings in the literature, and are of potential use to regulatory agencies,policy makers and concerned citizens.", "output": "A system for exploring big data: an iterative k-means searchlight for outlier detection on open health data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With growing machine learning (ML) applications in healthcare, there havebeen calls for fairness in ML to understand and mitigate ethical concerns thesesystems may pose. Fairness has implications for global health in Africa, whichalready has inequitable power imbalances between the Global North and South.This paper seeks to explore fairness for global health, with Africa as a casestudy. We propose fairness attributes for consideration in the African contextand delineate where they may come into play in different ML-enabled medicalmodalities. This work serves as a basis and call for action for furtheringresearch into fairness in global health.", "output": "Globalizing Fairness Attributes in Machine Learning: A Case Study on Health in Africa."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Due to rapidly rising healthcare costs worldwide, there is significantinterest in controlling them. An important aspect concerns price transparency,as preliminary efforts have demonstrated that patients will shop for lowercosts, driving efficiency. This requires the data to be made available, andmodels that can predict healthcare costs for a wide range of patientdemographics and conditions. We present an approach to this problem bydeveloping a predictive model using machine-learning techniques. We analyzedde-identified patient data from New York State SPARCS (statewide planning andresearch cooperative system), consisting of 2.3 million records in 2016. Webuilt models to predict costs from patient diagnoses and demographics. Weinvestigated two model classes consisting of sparse regression and decisiontrees. We obtained the best performance by using a decision tree with depth 10.We obtained an R-square value of 0.76 which is better than the values reportedin the literature for similar problems.", "output": "Building predictive models of healthcare costs with open healthcare data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-turn compositional image generation (M-CIG) is a challenging task thataims to iteratively manipulate a reference image given a modification text.While most of the existing methods for M-CIG are based on generativeadversarial networks (GANs), recent advances in image generation havedemonstrated the superiority of diffusion models over GANs. In this paper, wepropose a diffusion-based method for M-CIG named conditional denoisingdiffusion with image compositional matching (CDD-ICM). We leverage CLIP as thebackbone of image and text encoders, and incorporate a gated fusion mechanism,originally proposed for question answering, to compositionally fuse thereference image and the modification text at each turn of M-CIG. We introduce aconditioning scheme to generate the target image based on the fusion results.To prioritize the semantic quality of the generated target image, we learn anauxiliary image compositional match (ICM) objective, along with the conditionaldenoising diffusion (CDD) objective in a multi-task learning framework.Additionally, we also perform ICM guidance and classifier-free guidance toimprove performance. Experimental results show that CDD-ICM achievesstate-of-the-art results on two benchmark datasets for M-CIG, i.e., CoDraw andi-CLEVR.", "output": "A Diffusion-based Method for Multi-turn Compositional Image Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Protein structure prediction has reached revolutionary levels of accuracy onsingle structures, yet distributional modeling paradigms are needed to capturethe conformational ensembles and flexibility that underlie biological function.Towards this goal, we develop EigenFold, a diffusion generative modelingframework for sampling a distribution of structures from a given proteinsequence. We define a diffusion process that models the structure as a systemof harmonic oscillators and which naturally induces a cascading-resolutiongenerative process along the eigenmodes of the system. On recent CAMEO targets,EigenFold achieves a median TMScore of 0.84, while providing a morecomprehensive picture of model uncertainty via the ensemble of sampledstructures relative to existing methods. We then assess EigenFold's ability tomodel and predict conformational heterogeneity for fold-switching proteins andligand-induced conformational change. Code is available at", "output": "EigenFold: Generative Protein Structure Prediction with Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Heatmaps are widely used to interpret deep neural networks, particularly forcomputer vision tasks, and the heatmap-based explainable AI (XAI) techniquesare a well-researched topic. However, most studies concentrate on enhancing thequality of the generated heatmap or discovering alternate heatmap generationtechniques, and little effort has been devoted to making heatmap-based XAIautomatic, interactive, scalable, and accessible. To address this gap, wepropose a framework that includes two modules: (1) context modelling and (2)reasoning. We proposed a template-based image captioning approach for contextmodelling to create text-based contextual information from the heatmap andinput data. The reasoning module leverages a large language model to provideexplanations in combination with specialised knowledge. Our qualitativeexperiments demonstrate the effectiveness of our framework and heatmapcaptioning approach. The code for the proposed template-based heatmapcaptioning approach will be publicly available.", "output": "Towards Self-Explainability of Deep Neural Networks with Heatmap Captioning and Large-Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With calls for increasing transparency, governments are releasing greateramounts of data in multiple domains including finance, education andhealthcare. The efficient exploratory analysis of healthcare data constitutes asignificant challenge. Key concerns in public health include the quickidentification and analysis of trends, and the detection of outliers. Thisallows policies to be rapidly adapted to changing circumstances. We present anefficient outlier detection technique, termed PIKS (Pruned iterative-k meanssearchlight), which combines an iterative k-means algorithm with a prunedsearchlight based scan. We apply this technique to identify outliers in twopublicly available healthcare datasets from the New York Statewide Planning andResearch Cooperative System, and California's Office of Statewide HealthPlanning and Development. We provide a comparison of our technique with threeother existing outlier detection techniques, consisting of auto-encoders,isolation forests and feature bagging. We identified outliers in conditionsincluding suicide rates, immunity disorders, social admissions,cardiomyopathies, and pregnancy in the third trimester. We demonstrate that thePIKS technique produces results consistent with other techniques such as theauto-encoder. However, the auto-encoder needs to be trained, which requiresseveral parameters to be tuned. In comparison, the PIKS technique has far fewerparameters to tune. This makes it advantageous for fast, \"out-of-the-box\" dataexploration. The PIKS technique is scalable and can readily ingest newdatasets. Hence, it can provide valuable, up-to-date insights to citizens,patients and policy-makers. We have made our code open source, and with theavailability of open data, other researchers can easily reproduce and extendour work. This will help promote a deeper understanding of healthcare policiesand public health issues.", "output": "PIKS: A Technique to Identify Actionable Trends for Policy-Makers Through Open Healthcare Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper we consider a new class of RBF (Radial Basis Function) neuralnetworks, in which smoothing factors are replaced with shifts. We prove undercertain conditions on the activation function that these networks are capableof approximating any continuous multivariate function on any compact subset ofthe $d$-dimensional Euclidean space. For RBF networks with finitely many fixedcentroids we describe conditions guaranteeing approximation with arbitraryprecision.", "output": "On the universal approximation property of radial basis function neural networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Semi-supervised anomaly detection~(SSAD) is a task where normal data and alimited number of anomalous data are available for training. In practicalsituations, SSAD methods suffer adapting to domain shifts, since anomalous dataare unlikely to be available for the target domain in the training phase. Tosolve this problem, we propose a domain adaptation method for SSAD where noanomalous data are available for the target domain. First, we introduce adomain-adversarial network to a variational auto-encoder-based SSAD model toobtain domain-invariant latent variables. Since the decoder cannot reconstructthe original data solely from domain-invariant latent variables, we conditionedthe decoder on the domain label. To compensate for the missing anomalous dataof the target domain, we introduce an importance sampling-based weighted lossfunction that approximates the ideal loss function. Experimental resultsindicate that the proposed method helps adapt SSAD models to the target domainwhen no anomalous data are available for the target domain.", "output": "Zero-shot domain adaptation of anomalous samples for semi-supervised anomaly detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Most entropy measures depend on the spread of the probability distributionover the sample space X, and the maximum entropy achievable scalesproportionately with the sample space cardinality |X|. For a finite |X|, thisyields robust entropy measures which satisfy many important properties, such asinvariance to bijections, while the same is not true for continuous spaces(where |X|=infinity). Furthermore, since R and R^d (d in Z+) have the samecardinality (from Cantor's correspondence argument), cardinality-dependententropy measures cannot encode the data dimensionality. In this work, wequestion the role of cardinality and distribution spread in defining entropymeasures for continuous spaces, which can undergo multiple rounds oftransformations and distortions, e.g., in neural networks. We find that theaverage value of the local intrinsic dimension of a distribution, denoted asID-Entropy, can serve as a robust entropy measure for continuous spaces, whilecapturing the data dimensionality. We find that ID-Entropy satisfies manydesirable properties and can be extended to conditional entropy, joint entropyand mutual-information variants. ID-Entropy also yields new informationbottleneck principles and also links to causality. In the context of deeplearning, for feedforward architectures, we show, theoretically andempirically, that the ID-Entropy of a hidden layer directly controls thegeneralization gap for both classifiers and auto-encoders, when the targetfunction is Lipschitz continuous. Our work primarily shows that, for continuousspaces, taking a structural rather than a statistical approach yields entropymeasures which preserve intrinsic data dimensionality, while being relevant forstudying various architectures.", "output": "Local Intrinsic Dimensional Entropy."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study the problem of regression in a generalized linear model (GLM) withmultiple signals and latent variables. This model, which we call a matrix GLM,covers many widely studied problems in statistical learning, including mixedlinear regression, max-affine regression, and mixture-of-experts. In mixedlinear regression, each observation comes from one of $L$ signal vectors(regressors), but we do not know which one; in max-affine regression, eachobservation comes from the maximum of $L$ affine functions, each defined via adifferent signal vector. The goal in all these problems is to estimate thesignals, and possibly some of the latent variables, from the observations. Wepropose a novel approximate message passing (AMP) algorithm for estimation in amatrix GLM and rigorously characterize its performance in the high-dimensionallimit. This characterization is in terms of a state evolution recursion, whichallows us to precisely compute performance measures such as the asymptoticmean-squared error. The state evolution characterization can be used to tailorthe AMP algorithm to take advantage of any structural information known aboutthe signals. Using state evolution, we derive an optimal choice of AMP`denoising' functions that minimizes the estimation error in each iteration.The theoretical results are validated by numerical simulations for mixedlinear regression, max-affine regression, and mixture-of-experts. Formax-affine regression, we propose an algorithm that combines AMP withexpectation-maximization to estimate intercepts of the model along with thesignals. The numerical results show that AMP significantly outperforms otherestimators for mixed linear regression and max-affine regression in mostparameter regimes.", "output": "Mixed Regression via Approximate Message Passing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently developed text-to-image diffusion models make it easy to edit orcreate high-quality images. Their ease of use has raised concerns about thepotential for malicious editing or deepfake creation. Imperceptibleperturbations have been proposed as a means of protecting images from maliciousediting by preventing diffusion models from generating realistic images.However, we find that the aforementioned perturbations are not robust to JPEGcompression, which poses a major weakness because of the common usage andavailability of JPEG. We discuss the importance of robustness for additiveimperceptible perturbations and encourage alternative approaches to protectimages against editing.", "output": "JPEG Compressed Images Can Bypass Protections Against AI Editing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Wind energy has been rapidly gaining popularity as a means for combatingclimate change. However, the variable nature of wind generation can underminesystem reliability and lead to wind curtailment, causing substantial economiclosses to wind power producers. Battery energy storage systems (BESS) thatserve as onsite backup sources are among the solutions to mitigate windcurtailment. However, such an auxiliary role of the BESS might severely weakenits economic viability. This paper addresses the issue by proposing joint windcurtailment reduction and energy arbitrage for the BESS. We decouple the marketparticipation of the co-located wind-battery system and develop a joint-biddingframework for the wind farm and BESS. It is challenging to optimize thejoint-bidding because of the stochasticity of energy prices and windgeneration. Therefore, we leverage deep reinforcement learning to maximize theoverall revenue from the spot market while unlocking the BESS's potential inconcurrently reducing wind curtailment and conducting energy arbitrage. Wevalidate the proposed strategy using realistic wind farm data and demonstratethat our joint-bidding strategy responds better to wind curtailment andgenerates higher revenues than the optimization-based benchmark. Oursimulations also reveal that the extra wind generation used to be curtailed canbe an effective power source to charge the BESS, resulting in additionalfinancial returns.", "output": "Optimal Energy Storage Scheduling for Wind Curtailment Reduction and Energy Arbitrage: A Deep Reinforcement Learning Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We investigate replicable learning algorithms. Ideally, we would like todesign algorithms that output the same canonical model over multiple runs, evenwhen different runs observe a different set of samples from the unknown datadistribution. In general, such a strong notion of replicability is notachievable. Thus we consider two feasible notions of replicability called listreplicability and certificate replicability. Intuitively, these notions capturethe degree of (non) replicability. We design algorithms for certain learningproblems that are optimal in list and certificate complexity. We establishmatching impossibility results.", "output": "List and Certificate Complexities in Replicable Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We address an important gap in detection of political bias in news articles.Previous works that perform supervised document classification can be biasedtowards the writing style of each news outlet, leading to overfitting andlimited generalizability. Our approach overcomes this limitation by consideringboth the sentence-level semantics and the document-level rhetorical structure,resulting in a more robust and style-agnostic approach to detecting politicalbias in news articles. We introduce a novel multi-head hierarchical attentionmodel that effectively encodes the structure of long documents through adiverse ensemble of attention heads. While journalism follows a formalizedrhetorical structure, the writing style may vary by news outlet. We demonstratethat our method overcomes this domain dependency and outperforms previousapproaches for robustness and accuracy. Further analysis demonstrates theability of our model to capture the discourse structures commonly used in thejournalism domain.", "output": "Disentangling Structure and Style: Political Bias Detection in News by Inducing Document Hierarchy."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study oblivious sketching for $k$-sparse linear regression under variousloss functions such as an $ell_p$ norm, or from a broad class of hinge-likeloss functions, which includes the logistic and ReLU losses. We show that forsparse $ell_2$ norm regression, there is a distribution over oblivioussketches with $Theta(klog(d/k)/varepsilon^2)$ rows, which is tight up to aconstant factor. This extends to $ell_p$ loss with an additional additive$O(klog(k/varepsilon)/varepsilon^2)$ term in the upper bound. Thisestablishes a surprising separation from the related sparse recovery problem,which is an important special case of sparse regression. For this problem,under the $ell_2$ norm, we observe an upper bound of $O(k log (d)/varepsilon+ klog(k/varepsilon)/varepsilon^2)$ rows, showing that sparse recovery isstrictly easier to sketch than sparse regression. For sparse regression underhinge-like loss functions including sparse logistic and sparse ReLU regression,we give the first known sketching bounds that achieve $o(d)$ rows showing that$O(mu^2 klog(mu n d/varepsilon)/varepsilon^2)$ rows suffice, where $mu$is a natural complexity parameter needed to obtain relative error bounds forthese loss functions. We again show that this dimension is tight, up to lowerorder terms and the dependence on $mu$. Finally, we show that similarsketching bounds can be achieved for LASSO regression, a popular convexrelaxation of sparse regression, where one aims to minimize$|Ax-b|_2^2+lambda|x|_1$ over $xinmathbb{R}^d$. We show that sketchingdimension $O(log(d)/(lambda varepsilon)^2)$ suffices and that the dependenceon $d$ and $lambda$ is tight.", "output": "Optimal Sketching Bounds for Sparse Linear Regression."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Backdoor attacks have been demonstrated as a security threat for machinelearning models. Traditional backdoor attacks intend to inject backdoorfunctionality into the model such that the backdoored model will performabnormally on inputs with predefined backdoor triggers and still retainstate-of-the-art performance on the clean inputs. While there are already someworks on backdoor attacks on Graph Neural Networks (GNNs), the backdoor triggerin the graph domain is mostly injected into random positions of the sample.There is no work analyzing and explaining the backdoor attack performance wheninjecting triggers into the most important or least important area in thesample, which we refer to as trigger-injecting strategies MIAS and LIAS,respectively. Our results show that, generally, LIAS performs better, and thedifferences between the LIAS and MIAS performance can be significant.Furthermore, we explain these two strategies' similar (better) attackperformance through explanation techniques, which results in a furtherunderstanding of backdoor attacks in GNNs.", "output": "Rethinking the Trigger-injecting Position in Graph Backdoor Attack."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine learning can benefit from causal discovery for interpretation andfrom causal inference for generalization. In this line of research, a fewinvariant learning algorithms for out-of-distribution (OOD) generalization havebeen proposed by using multiple training environments to find invariantrelationships. Some of them are focused on causal discovery as Invariant CausalPrediction (ICP), which finds causal parents of a variable of interest, andsome directly provide a causal optimal predictor that generalizes well in OODenvironments as Invariant Risk Minimization (IRM). This group of algorithmsworks under the assumption of multiple environments that represent differentinterventions in the causal inference context. Those environments are notnormally available when working with observational data and real-worldapplications. Here we propose a method to generate them in an efficient way. Weassess the performance of this unsupervised learning problem by implementingICP on simulated data. We also show how to apply ICP efficiently integratedwith our method for causal discovery. Finally, we proposed an improved versionof our method in combination with ICP for datasets with multiple covariateswhere ICP and other causal discovery methods normally degrade in performance.", "output": "A step towards the applicability of algorithms based on invariant causal learning on observational data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Convolutional neural networks (CNNs) have shown state-of-the-art performancein various applications. However, CNNs are resource-hungry due to theirrequirement of high computational complexity and memory storage. Recent effortstoward achieving computational efficiency in CNNs involve filter pruningmethods that eliminate some of the filters in CNNs based on theenquote{importance} of the filters. The majority of existing filter pruningmethods are either \"active\", which use a dataset and generate feature maps toquantify filter importance, or \"passive\", which compute filter importance usingentry-wise norm of the filters without involving data. Under a high pruningratio where large number of filters are to be pruned from the network, theentry-wise norm methods eliminate relatively smaller norm filters withoutconsidering the significance of the filters in producing the node output,resulting in degradation in the performance. To address this, we present apassive filter pruning method where the filters are pruned based on theircontribution in producing output by considering the operator norm of thefilters. The proposed pruning method generalizes better across various CNNscompared to that of the entry-wise norm-based pruning methods. In comparison tothe existing active filter pruning methods, the proposed pruning method is atleast 4.5 times faster in computing filter importance and is able to achievesimilar performance compared to that of the active filter pruning methods. Theefficacy of the proposed pruning method is evaluated on audio sceneclassification and image classification using various CNNs architecture such asVGGish, DCASE21_Net, VGG-16 and ResNet-50.", "output": "Efficient CNNs via Passive Filter Pruning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent years have seen growing interest in learning disentangledrepresentations, in which distinct features, such as size or shape, arerepresented by distinct neurons. Quantifying the extent to which a givenrepresentation is disentangled is not straightforward; multiple metrics havebeen proposed. In this paper, we identify two failings of existing metrics,which mean they can assign a high score to a model which is still entangled,and we propose two new metrics, which redress these problems. We then considerthe task of compositional generalization. Unlike prior works, we treat this asa classification problem, which allows us to use it to measure thedisentanglement ability of the encoder, without depending on the decoder. Weshow that performance on this task is (a) generally quite poor, (b) correlatedwith most disentanglement metrics, and (c) most strongly correlated with ournewly proposed metrics.", "output": "Correcting Flaws in Common Disentanglement Metrics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Radiotherapy (RT) is a key component in the treatment of various cancers,including Acute Lymphocytic Leukemia (ALL) and Acute Myelogenous Leukemia(AML). Precise delineation of organs at risk (OARs) and target areas isessential for effective treatment planning. Intensity Modulated Radiotherapy(IMRT) techniques, such as Total Marrow Irradiation (TMI) and Total Marrow andLymph node Irradiation (TMLI), provide more precise radiation delivery comparedto Total Body Irradiation (TBI). However, these techniques requiretime-consuming manual segmentation of structures in Computerized Tomography(CT) scans by the Radiation Oncologist (RO). In this paper, we present a deeplearning-based auto-contouring method for segmenting Planning Target Volume(PTV) for TMLI treatment using the U-Net architecture. We trained and comparedtwo segmentation models with two different loss functions on a dataset of 100patients treated with TMLI at the Humanitas Research Hospital between 2011 and2021. Despite challenges in lymph node areas, the best model achieved anaverage Dice score of 0.816 for PTV segmentation. Our findings are apreliminary but significant step towards developing a segmentation model thathas the potential to save radiation oncologists a considerable amount of time.This could allow for the treatment of more patients, resulting in improvedclinical practice efficiency and more reproducible contours.", "output": "Segmentation of Planning Target Volume in CT Series for Total Marrow Irradiation Using U-Net."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Rayleigh-B'enard convection (RBC) is a recurrent phenomenon in severalindustrial and geoscience flows and a well-studied system from a fundamentalfluid-mechanics viewpoint. However, controlling RBC, for example by modulatingthe spatial distribution of the bottom-plate heating in the canonical RBCconfiguration, remains a challenging topic for classical control-theorymethods. In the present work, we apply deep reinforcement learning (DRL) forcontrolling RBC. We show that effective RBC control can be obtained byleveraging invariant multi-agent reinforcement learning (MARL), which takesadvantage of the locality and translational invariance inherent to RBC flowsinside wide channels. The MARL framework applied to RBC allows for an increasein the number of control segments without encountering the curse ofdimensionality that would result from a naive increase in the DRL action-sizedimension. This is made possible by the MARL ability for re-using the knowledgegenerated in different parts of the RBC domain. We show in a case study thatMARL DRL is able to discover an advanced control strategy that destabilizes thespontaneous RBC double-cell pattern, changes the topology of RBC by coalescingadjacent convection cells, and actively controls the resulting coalesced cellto bring it to a new stable configuration. This modified flow configurationresults in reduced convective heat transfer, which is beneficial in severalindustrial processes. Therefore, our work both shows the potential of MARL DRLfor controlling large RBC systems, as well as demonstrates the possibility forDRL to discover strategies that move the RBC configuration between differenttopological configurations, yielding desirable heat-transfer characteristics.These results are useful for both gaining further understanding of theintrinsic properties of RBC, as well as for developing industrial applications.", "output": "Effective control of two-dimensional Rayleigh--B\\'enard convection: invariant multi-agent reinforcement learning is all you need."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The ability to explain decisions made by machine learning models remains oneof the most significant hurdles towards widespread adoption of AI in highlysensitive areas such as medicine, cybersecurity or autonomous driving. Greatinterest exists in understanding which features of the input data prompt modeldecision making. In this contribution, we propose a novel approach to identifyrelevant features of the input data, inspired by methods from the energylandscapes field, developed in the physical sciences. By identifying conservedweights within groups of minima of the loss landscapes, we can identify thedrivers of model decision making. Analogues to this idea exist in the molecularsciences, where coordinate invariants or order parameters are employed toidentify critical features of a molecule. However, no such approach exists formachine learning loss landscapes. We will demonstrate the applicability ofenergy landscape methods to machine learning models and give examples, bothsynthetic and from the real world, for how these methods can help to makemodels more interpretable.", "output": "Physics-Inspired Interpretability Of Machine Learning Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Saliency Maps (SMs) have been extensively used to interpret deep learningmodels decision by highlighting the features deemed relevant by the model. Theyare used on highly nonlinear problems, where linear feature selection (FS)methods fail at highlighting relevant explanatory variables. However, thereliability of gradient-based feature attribution methods such as SM has mostlybeen only qualitatively (visually) assessed, and quantitative benchmarks arecurrently missing, partially due to the lack of a definite ground truth onimage data. Concerned about the apophenic biases introduced by visualassessment of these methods, in this paper we propose a synthetic quantitativebenchmark for Neural Networks (NNs) interpretation methods. For this purpose,we built synthetic datasets with nonlinearly separable classes and increasingnumber of decoy (random) features, illustrating the challenge of FS inhigh-dimensional settings. We also compare these methods to conventionalapproaches such as mRMR or Random Forests. Our results show that our simplesynthetic datasets are sufficient to challenge most of the benchmarked methods.TreeShap, mRMR and LassoNet are the best performing FS methods. We also showthat, when quantifying the relevance of a few non linearly-entangled predictivefeatures diluted in a large number of irrelevant noisy variables, neuralnetwork-based FS and interpretation methods are still far from being reliable.", "output": "How good Neural Networks interpretation methods really are? A quantitative benchmark."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Computer-assisted automatic analysis of diabetic retinopathy (DR) is of greatimportance in reducing the risks of vision loss and even blindness. Ultra-wideoptical coherence tomography angiography (UW-OCTA) is a non-invasive and safeimaging modality in DR diagnosis system, but there is a lack of publiclyavailable benchmarks for model development and evaluation. To promote furtherresearch and scientific benchmarking for diabetic retinopathy analysis usingUW-OCTA images, we organized a challenge named \"DRAC - Diabetic RetinopathyAnalysis Challenge\" in conjunction with the 25th International Conference onMedical Image Computing and Computer Assisted Intervention (MICCAI 2022). Thechallenge consists of three tasks: segmentation of DR lesions, image qualityassessment and DR grading. The scientific community responded positively to thechallenge, with 11, 12, and 13 teams from geographically diverse institutessubmitting different solutions in these three tasks, respectively. This paperpresents a summary and analysis of the top-performing solutions and results foreach task of the challenge. The obtained results from top algorithms indicatethe importance of data augmentation, model architecture and ensemble ofnetworks in improving the performance of deep learning models. These findingshave the potential to enable new developments in diabetic retinopathy analysis.The challenge remains open for post-challenge registrations and submissions forbenchmarking future methodology developments.", "output": "DRAC: Diabetic Retinopathy Analysis Challenge with Ultra-Wide Optical Coherence Tomography Angiography Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although Reinforcement Learning (RL) has shown to be capable of producingimpressive results, its use is limited by the impact of its hyperparameters onperformance. This often makes it difficult to achieve good results in practice.Automated RL (AutoRL) addresses this difficulty, yet little is known about thedynamics of the hyperparameter landscapes that hyperparameter optimization(HPO) methods traverse in search of optimal configurations. In view of existingAutoRL approaches dynamically adjusting hyperparameter configurations, wepropose an approach to build and analyze these hyperparameter landscapes notjust for one point in time but at multiple points in time throughout training.Addressing an important open question on the legitimacy of such dynamic AutoRLapproaches, we provide thorough empirical evidence that the hyperparameterlandscapes strongly vary over time across representative algorithms from RLliterature (DQN and SAC) in different kinds of environments (Cartpole andHopper). This supports the theory that hyperparameters should be dynamicallyadjusted during training and shows the potential for more insights on AutoRLproblems that can be gained through landscape analyses.", "output": "AutoRL Hyperparameter Landscapes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Jointly harnessing complementary features of multi-modal input data in acommon latent space has been found to be beneficial long ago. However, theinfluence of each modality on the models decision remains a puzzle. This studyproposes a deep learning framework for the modality-level interpretation ofmultimodal earth observation data in an end-to-end fashion. While leveraging anexplainable machine learning method, namely Occlusion Sensitivity, the proposedframework investigates the influence of modalities under an early-fusionscenario in which the modalities are fused before the learning process. We showthat the task of wilderness mapping largely benefits from auxiliary data suchas land cover and night time light data.", "output": "Explaining Multimodal Data Fusion: Occlusion Analysis for Wilderness Mapping."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Minimax problems have recently attracted a lot of research interests. A fewefforts have been made to solve decentralized nonconvex strongly-concave (NCSC)minimax-structured optimization; however, all of them focus on smooth problemswith at most a constraint on the maximization variable. In this paper, we makethe first attempt on solving composite NCSC minimax problems that can haveconvex nonsmooth terms on both minimization and maximization variables. Ouralgorithm is designed based on a novel reformulation of the decentralizedminimax problem that introduces a multiplier to absorb the dual consensusconstraint. The removal of dual consensus constraint enables the mostaggressive (i.e., local maximization instead of a gradient ascent step) dualupdate that leads to the benefit of taking a larger primal stepsize and bettercomplexity results. In addition, the decoupling of the nonsmoothness andconsensus on the dual variable eases the analysis of a decentralized algorithm;thus our reformulation creates a new way for interested researchers to designnew (and possibly more efficient) decentralized methods on solving NCSC minimaxproblems. We show a global convergence result of the proposed algorithm and aniteration complexity result to produce a (near) stationary point of thereformulation. Moreover, a relation is established between the (near)stationarities of the reformulation and the original formulation. With thisrelation, we show that when the dual regularizer is smooth, our algorithm canhave lower complexity results (with reduced dependence on a condition number)than existing ones to produce a near-stationary point of the originalformulation. Numerical experiments are conducted on a distributionally robustlogistic regression to demonstrate the performance of the proposed algorithm.", "output": "Decentralized gradient descent maximization method for composite nonconvex strongly-concave minimax problems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Real-world datasets are often of high dimension and effected by the curse ofdimensionality. This hinders their comprehensibility and interpretability. Toreduce the complexity feature selection aims to identify features that arecrucial to learn from said data. While measures of relevance and pairwisesimilarities are commonly used, the curse of dimensionality is rarelyincorporated into the process of selecting features. Here we step in with anovel method that identifies the features that allow to discriminate datasubsets of different sizes. By adapting recent work on computing intrinsicdimensionalities, our method is able to select the features that candiscriminate data and thus weaken the curse of dimensionality. Our experimentsshow that our method is competitive and commonly outperforms establishedfeature selection methods. Furthermore, we propose an approximation that allowsour method to scale to datasets consisting of millions of data points. Ourfindings suggest that features that discriminate data and are connected to alow intrinsic dimensionality are meaningful for learning procedures.", "output": "Selecting Features by their Resilience to the Curse of Dimensionality."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As a newly emerged asset class, cryptocurrency is evidently more volatilecompared to the traditional equity markets. Due to its mostly unregulatednature, and often low liquidity, the price of crypto assets can sustain asignificant change within minutes that in turn might result in considerablelosses. In this paper, we employ an approach for encoding market informationinto images and making predictions of short-term realized volatility byemploying Convolutional Neural Networks. We then compare the performance of theproposed encoding and corresponding model with other benchmark models. Theexperimental results demonstrate that this representation of market data with aConvolutional Neural Network as a predictive model has the potential to bettercapture the market dynamics and a better volatility prediction.", "output": "Short-Term Volatility Prediction Using Deep CNNs Trained on Order Flow."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "By using the underlying theory of proper scoring rules, we design a family ofnoise-contrastive estimation (NCE) methods that are tractable for latentvariable models. Both terms in the underlying NCE loss, the one using datasamples and the one using noise samples, can be lower-bounded as in variationalBayes, therefore we call this family of losses fully variationalnoise-contrastive estimation. Variational autoencoders are a particular examplein this family and therefore can be also understood as separating real datafrom synthetic samples using an appropriate classification loss. We furtherdiscuss other instances in this family of fully variational NCE objectives andindicate differences in their empirical behavior.", "output": "Fully Variational Noise-Contrastive Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite remarkable successes in solving various complex decision-makingtasks, training an imitation learning (IL) algorithm with deep neural networks(DNNs) suffers from the high computation burden. In this work, we proposequantum imitation learning (QIL) with a hope to utilize quantum advantage tospeed up IL. Concretely, we develop two QIL algorithms, quantum behaviouralcloning (Q-BC) and quantum generative adversarial imitation learning (Q-GAIL).Q-BC is trained with a negative log-likelihood loss in an off-line manner thatsuits extensive expert data cases, whereas Q-GAIL works in an inversereinforcement learning scheme, which is on-line and on-policy that is suitablefor limited expert data cases. For both QIL algorithms, we adopt variationalquantum circuits (VQCs) in place of DNNs for representing policies, which aremodified with data re-uploading and scaling parameters to enhance theexpressivity. We first encode classical data into quantum states as inputs,then perform VQCs, and finally measure quantum outputs to obtain controlsignals of agents. Experiment results demonstrate that both Q-BC and Q-GAIL canachieve comparable performance compared to classical counterparts, with thepotential of quantum speed-up. To our knowledge, we are the first to proposethe concept of QIL and conduct pilot studies, which paves the way for thequantum era.", "output": "Quantum Imitation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Optimization of experimental materials synthesis and characterization throughactive learning methods has been growing over the last decade, with examplesranging from measurements of diffraction on combinatorial alloys atsynchrotrons, to searches through chemical space with automated synthesisrobots for perovskites. In virtually all cases, the target property of interestfor optimization is defined apriori with limited human feedback duringoperation. In contrast, here we present the development of a new type of humanin the loop experimental workflow, via a Bayesian optimized active recommendersystem (BOARS), to shape targets on the fly, employing human feedback. Weshowcase examples of this framework applied to pre-acquired piezoresponse forcespectroscopy of a ferroelectric thin film, and then implement this in real timeon an atomic force microscope, where the optimization proceeds to findsymmetric piezoresponse amplitude hysteresis loops. It is found that suchfeatures appear more affected by subsurface defects than the local domainstructure. This work shows the utility of human-augmented machine learningapproaches for curiosity-driven exploration of systems across experimentaldomains. The analysis reported here is summarized in Colab Notebook for thepurpose of tutorial and application to other data:", "output": "A dynamic Bayesian optimized active recommender system for curiosity-driven Human-in-the-loop automated experiments."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Random forest is a popular machine learning approach for the analysis ofhigh-dimensional data because it is flexible and provides variable importancemeasures for the selection of relevant features. However, the complexrelationships between the features are usually not considered for the selectionand thus also neglected for the characterization of the analysed samples. Herewe propose two novel approaches that focus on the mutual impact of features inrandom forests. Mutual forest impact (MFI) is a relation parameter thatevaluates the mutual association of the featurs to the outcome and, hence, goesbeyond the analysis of correlation coefficients. Mutual impurity reduction(MIR) is an importance measure that combines this relation parameter with theimportance of the individual features. MIR and MFI are implemented togetherwith testing procedures that generate p-values for the selection of related andimportant features. Applications to various simulated data sets and thecomparison to other methods for feature selection and relation analysis showthat MFI and MIR are very promising to shed light on the complex relationshipsbetween features and outcome. In addition, they are not affected by commonbiases, e.g. that features with many possible splits or high minor allelefrequencies are prefered.", "output": "Opening the random forest black box by the analysis of the mutual impact of features."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Children typically learn the meanings of nouns earlier than the meanings ofverbs. However, it is unclear whether this asymmetry is a result of complexityin the visual structure of categories in the world to which language refers,the structure of language itself, or the interplay between the two sources ofinformation. We quantitatively test these three hypotheses regarding early verblearning by employing visual and linguistic representations of words sourcedfrom large-scale pre-trained artificial neural networks. Examining thestructure of both visual and linguistic embedding spaces, we find, first, thatthe representation of verbs is generally more variable and less discriminablewithin domain than the representation of nouns. Second, we find that if onlyone learning instance per category is available, visual and linguisticrepresentations are less well aligned in the verb system than in the nounsystem. However, in parallel with the course of human language development, ifmultiple learning instances per category are available, visual and linguisticrepresentations become almost as well aligned in the verb system as in the nounsystem. Third, we compare the relative contributions of factors that maypredict learning difficulty for individual words. A regression analysis revealsthat visual variability is the strongest factor that internally drives verblearning, followed by visual-linguistic alignment and linguistic variability.Based on these results, we conclude that verb acquisition is influenced by allthree sources of complexity, but that the variability of visual structure posesthe most significant challenge for verb learning.", "output": "Quantifying the Roles of Visual, Linguistic, and Visual-Linguistic Complexity in Verb Acquisition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This work focuses on the problem of hyper-parameter tuning (HPT) for robust(i.e., adversarially trained) models, with the twofold goal of i) establishingwhich additional HPs are relevant to tune in adversarial settings, and ii)reducing the cost of HPT for robust models. We pursue the first goal via anextensive experimental study based on 3 recent models widely adopted in theprior literature on adversarial robustness. Our findings show that thecomplexity of the HPT problem, already notoriously expensive, is exacerbated inadversarial settings due to two main reasons: i) the need of tuning additionalHPs which balance standard and adversarial training; ii) the need of tuning theHPs of the standard and adversarial training phases independently. Fortunately,we also identify new opportunities to reduce the cost of HPT for robust models.Specifically, we propose to leverage cheap adversarial training methods toobtain inexpensive, yet highly correlated, estimations of the qualityachievable using state-of-the-art methods (PGD). We show that, by exploitingthis novel idea in conjunction with a recent multi-fidelity optimizer (taKG),the efficiency of the HPT process can be significantly enhanced.", "output": "Hyper-parameter Tuning for Adversarially Robust Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Longitudinal studies, where a series of images from the same set ofindividuals are acquired at different time-points, represent a populartechnique for studying and characterizing temporal dynamics in biomedicalapplications. The classical approach for longitudinal comparison involvesnormalizing for nuisance variations, such as image orientation or contrastdifferences, via pre-processing. Statistical analysis is, in turn, conducted todetect changes of interest, either at the individual or population level. Thisclassical approach can suffer from pre-processing issues and limitations of thestatistical modeling. For example, normalizing for nuisance variation might behard in settings where there are a lot of idiosyncratic changes. In this paper,we present a simple machine learning-based approach that can alleviate theseissues. In our approach, we train a deep learning model (called PaIRNet, forPairwise Image Ranking Network) to compare pairs of longitudinal images, withor without supervision. In the self-supervised setup, for instance, the modelis trained to temporally order the images, which requires learning to recognizetime-irreversible changes. Our results from four datasets demonstrate thatPaIRNet can be very effective in localizing and quantifying meaningfullongitudinal changes while discounting nuisance variation. Our code isavailable aturl{", "output": "Learning to Compare Longitudinal Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a new policy representation based on score-based diffusion models(SDMs). We apply our new policy representation in the domain ofGoal-Conditioned Imitation Learning (GCIL) to learn general-purposegoal-specified policies from large uncurated datasets without rewards. Our newgoal-conditioned policy architecture \"$textbf{BE}$havior generation with$textbf{S}$c$textbf{O}$re-based Diffusion Policies\" (BESO) leverages agenerative, score-based diffusion model as its policy. BESO decouples thelearning of the score model from the inference sampling process, and, henceallows for fast sampling strategies to generate goal-specified behavior in just3 denoising steps, compared to 30+ steps of other diffusion based policies.Furthermore, BESO is highly expressive and can effectively capturemulti-modality present in the solution space of the play data. Unlike previousmethods such as Latent Plans or C-Bet, BESO does not rely on complexhierarchical policies or additional clustering for effective goal-conditionedbehavior learning. Finally, we show how BESO can even be used to learn agoal-independent policy from play-data using classifier-free guidance. To thebest of our knowledge this is the first work that a) represents a behaviorpolicy based on such a decoupled SDM b) learns an SDM based policy in thedomain of GCIL and c) provides a way to simultaneously learn a goal-dependentand a goal-independent policy from play-data. We evaluate BESO through detailedsimulation and show that it consistently outperforms several state-of-the-artgoal-conditioned imitation learning methods on challenging benchmarks. Weadditionally provide extensive ablation studies and experiments to demonstratethe effectiveness of our method for effective goal-conditioned behaviorgeneration.", "output": "Goal-Conditioned Imitation Learning using Score-based Diffusion Policies."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Solving complex classification tasks using deep neural networks typicallyrequires large amounts of annotated data. However, corresponding class labelsare noisy when provided by error-prone annotators, e.g., crowd workers.Training standard deep neural networks leads to subpar performances in suchmulti-annotator supervised learning settings. We address this issue bypresenting a probabilistic training framework named multi-annotator deeplearning (MaDL). A ground truth and an annotator performance model are jointlytrained in an end-to-end learning approach. The ground truth model learns topredict instances' true class labels, while the annotator performance modelinfers probabilistic estimates of annotators' performances. A modular networkarchitecture enables us to make varying assumptions regarding annotators'performances, e.g., an optional class or instance dependency. Further, we learnannotator embeddings to estimate annotators' densities within a latent space asproxies of their potentially correlated annotations. Together with a weightedloss function, we improve the learning from correlated annotation patterns. Ina comprehensive evaluation, we examine three research questions aboutmulti-annotator supervised learning. Our findings indicate MaDL'sstate-of-the-art performance and robustness against many correlated, spammingannotators.", "output": "Multi-annotator Deep Learning: A Probabilistic Framework for Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fully supervised models often require large amounts of labeled training data,which tends to be costly and hard to acquire. In contrast, self-supervisedrepresentation learning reduces the amount of labeled data needed for achievingthe same or even higher downstream performance. The goal is to pre-train deepneural networks on a self-supervised task such that afterwards the networks areable to extract meaningful features from raw input data. These features arethen used as inputs in downstream tasks, such as image classification.Previously, autoencoders and Siamese networks such as SimSiam have beensuccessfully employed in those tasks. Yet, challenges remain, such as matchingcharacteristics of the features (e.g., level of detail) to the given task anddata set. In this paper, we present a new self-supervised method that combinesthe benefits of Siamese architectures and denoising autoencoders. We show thatour model, called SidAE (Siamese denoising autoencoder), outperforms twoself-supervised baselines across multiple data sets, settings, and scenarios.Crucially, this includes conditions in which only a small amount of labeleddata is available.", "output": "Self-Supervised Siamese Autoencoders."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Bandit learning algorithms have been an increasingly popular design choicefor recommender systems. Despite the strong interest in bandit learning fromthe community, there remains multiple bottlenecks that prevent many banditlearning approaches from productionalization. Two of the most importantbottlenecks are scaling to multi-task and A/B testing. Classic banditalgorithms, especially those leveraging contextual information, often requiresreward for uncertainty estimation, which hinders their adoptions in multi-taskrecommender systems. Moreover, different from supervised learning algorithms,bandit learning algorithms emphasize greatly on the data collection processthrough their explorative nature. Such explorative behavior induces unfairevaluation for bandit learning agents in a classic A/B test setting. In thiswork, we present a novel design of production bandit learning life-cycle forrecommender systems, along with a novel set of metrics to measure theirefficiency in user exploration. We show through large-scale productionrecommender system experiments and in-depth analysis that our bandit agentdesign improves personalization for the production recommender system and ourexperiment design fairly evaluates the performance of bandit learningalgorithms.", "output": "Optimism Based Exploration in Large-Scale Recommender Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reinforcement Learning aims at identifying and evaluating efficient controlpolicies from data. In many real-world applications, the learner is not allowedto experiment and cannot gather data in an online manner (this is the case whenexperimenting is expensive, risky or unethical). For such applications, thereward of a given policy (the target policy) must be estimated using historicaldata gathered under a different policy (the behavior policy). Most methods forthis learning task, referred to as Off-Policy Evaluation (OPE), do not comewith accuracy and certainty guarantees. We present a novel OPE method based onConformal Prediction that outputs an interval containing the true reward of thetarget policy with a prescribed level of certainty. The main challenge in OPEstems from the distribution shift due to the discrepancies between the targetand the behavior policies. We propose and empirically evaluate different waysto deal with this shift. Some of these methods yield conformalized intervalswith reduced length compared to existing approaches, while maintaining the samecertainty level.", "output": "Conformal Off-Policy Evaluation in Markov Decision Processes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Feature importance methods promise to provide a ranking of features accordingto importance for a given classification task. A wide range of methods existbut their rankings often disagree and they are inherently difficult to evaluatedue to a lack of ground truth beyond synthetic datasets. In this work, we putfeature importance methods to the test on real-world data in the domain ofcardiology, where we try to distinguish three specific pathologies from healthysubjects based on ECG features comparing to features used in cardiologists'decision rules as ground truth. Some methods generally performed well andothers performed poorly, while some methods did well on some but not all of theproblems considered.", "output": "ECG Feature Importance Rankings: Cardiologists vs. Algorithms."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Purpose: Robotic assistance in otologic surgery can reduce the task load ofoperating surgeons during the removal of bone around the critical structures inthe lateral skull base. However, safe deployment into the anatomicalpassageways necessitates the development of advanced sensing capabilities toactively limit the interaction forces between the surgical tools and criticalanatomy.Methods: We introduce a surgical drill equipped with a force sensor that iscapable of measuring accurate tool-tissue interaction forces to enable forcecontrol and feedback to surgeons. The design, calibration and validation of theforce-sensing surgical drill mounted on a cooperatively controlled surgicalrobot are described in this work.Results: The force measurements on the tip of the surgical drill arevalidated with raw-egg drilling experiments, where a force sensor mounted belowthe egg serves as ground truth. The average root mean square error (RMSE) forpoints and path drilling experiments are 41.7 (pm 12.2) mN and 48.3 (pm 13.7)mN respectively.Conclusions: The force-sensing prototype measures forces with sub-millinewtonresolution and the results demonstrate that the calibrated force-sensing drillgenerates accurate force measurements with minimal error compared to themeasured drill forces. The development of such sensing capabilities is crucialfor the safe use of robotic systems in a clinical context.", "output": "A force-sensing surgical drill for real-time force feedback in robotic mastoidectomy."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Bayesian inference provides a methodology for parameter estimation anduncertainty quantification in machine learning and deep learning methods.Variational inference and Markov Chain Monte-Carlo (MCMC) sampling techniquesare used to implement Bayesian inference. In the past three decades, MCMCmethods have faced a number of challenges in being adapted to larger models(such as in deep learning) and big data problems. Advanced proposals thatincorporate gradients, such as a Langevin proposal distribution, provide ameans to address some of the limitations of MCMC sampling for Bayesian neuralnetworks. Furthermore, MCMC methods have typically been constrained to use bystatisticians and are still not prominent among deep learning researchers. Wepresent a tutorial for MCMC methods that covers simple Bayesian linear andlogistic models, and Bayesian neural networks. The aim of this tutorial is tobridge the gap between theory and implementation via coding, given a generalsparsity of libraries and tutorials to this end. This tutorial provides code inPython with data and instructions that enable their use and extension. Weprovide results for some benchmark problems showing the strengths andweaknesses of implementing the respective Bayesian models via MCMC. Wehighlight the challenges in sampling multi-modal posterior distributions inparticular for the case of Bayesian neural networks, and the need for furtherimprovement of convergence diagnosis.", "output": "Bayesian neural networks via MCMC: a Python-based tutorial."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Log-concave sampling has witnessed remarkable algorithmic advances in recentyears, but the corresponding problem of proving lower bounds for this task hasremained elusive, with lower bounds previously known only in dimension one. Inthis work, we establish the following query lower bounds: (1) sampling fromstrongly log-concave and log-smooth distributions in dimension $dge 2$requires $Omega(log kappa)$ queries, which is sharp in any constantdimension, and (2) sampling from Gaussians in dimension $d$ (hence also fromgeneral log-concave and log-smooth distributions in dimension $d$) requires$widetilde Omega(min(sqrtkappa log d, d))$ queries, which is nearly sharpfor the class of Gaussians. Here $kappa$ denotes the condition number of thetarget distribution. Our proofs rely upon (1) a multiscale constructioninspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novelreduction that demonstrates that block Krylov algorithms are optimal for thisproblem, as well as connections to lower bound techniques based on Wishartmatrices developed in the matrix-vector query literature.", "output": "Query lower bounds for log-concave sampling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we present efficient quantum algorithms that are exponentiallyfaster than classical algorithms for solving the quantum optimal controlproblem. This problem involves finding the control variable that maximizes aphysical quantity at time $T$, where the system is governed by a time-dependentSchr\"odinger equation. This type of control problem also has an intricaterelation with machine learning. Our algorithms are based on a time-dependentHamiltonian simulation method and a fast gradient-estimation algorithm. We alsoprovide a comprehensive error analysis to quantify the total error from varioussteps, such as the finite-dimensional representation of the control function,the discretization of the Schr\"odinger equation, the numerical quadrature, andoptimization. Our quantum algorithms require fault-tolerant quantum computers.", "output": "Efficient Quantum Algorithms for Quantum Optimal Control."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The task of image-level weakly-supervised semantic segmentation (WSSS) hasgained popularity in recent years, as it reduces the vast data annotation costfor training segmentation models. The typical approach for WSSS involvestraining an image classification network using global average pooling (GAP) onconvolutional feature maps. This enables the estimation of object locationsbased on class activation maps (CAMs), which identify the importance of imageregions. The CAMs are then used to generate pseudo-labels, in the form ofsegmentation masks, to supervise a segmentation model in the absence ofpixel-level ground truth. In case of the SEAM baseline, a previous workproposed to improve CAM learning in two ways: (1) Importance sampling, which isa substitute for GAP, and (2) the feature similarity loss, which utilizes aheuristic that object contours almost exclusively align with color edges inimages. In this work, we propose a different probabilistic interpretation ofCAMs for these techniques, rendering the likelihood more appropriate than themultinomial posterior. As a result, we propose an add-on method that can boostessentially any previous WSSS method, improving both the region similarity andcontour quality of all implemented state-of-the-art baselines. This isdemonstrated on a wide variety of baselines on the PASCAL VOC dataset.Experiments on the MS COCO dataset show that performance gains can also beachieved in a large-scale setting. Our code is available at", "output": "High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Understanding historical forest dynamics, specifically changes in forestbiomass and carbon stocks, has become critical for assessing current forestclimate benefits and projecting future benefits under various policy,regulatory, and stewardship scenarios. Carbon accounting frameworks basedexclusively on national forest inventories are limited to broad-scaleestimates, but model-based approaches that combine these inventories withremotely sensed data can yield contiguous fine-resolution maps of forestbiomass and carbon stocks across landscapes over time. Here we describe afundamental step in building a map-based stock-change framework: mappinghistorical forest biomass at fine temporal and spatial resolution (annual, 30m)across all of New York State (USA) from 1990 to 2019, using freely availabledata and open-source tools.Using Landsat imagery, US Forest Service Forest Inventory and Analysis (FIA)data, and off-the-shelf LiDAR collections we developed three modelingapproaches for mapping historical forest aboveground biomass (AGB): training onFIA plot-level AGB estimates (direct), training on LiDAR-derived AGB maps(indirect), and an ensemble averaging predictions from the direct and indirectmodels. Model prediction surfaces (maps) were tested against FIA estimates atmultiple scales. All three approaches produced viable outputs, yet tradeoffswere evident in terms of model complexity, map accuracy, saturation, andfine-scale pattern representation. The resulting map products can help identifywhere, when, and how forest carbon stocks are changing as a result of bothanthropogenic and natural drivers alike. These products can thus serve asinputs to a wide range of applications including stock-change assessments,monitoring reporting and verification frameworks, and prioritizing parcels forprotection or enrollment in improved management programs.", "output": "Mapping historical forest biomass for stock-change assessments at parcel to landscape scales."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Since diffusion models (DM) and the more recent Poisson flow generativemodels (PFGM) are inspired by physical processes, it is reasonable to ask: Canphysical processes offer additional new generative models? We show that theanswer is yes. We introduce a general family, Generative Models from PhysicalProcesses (GenPhys), where we translate partial differential equations (PDEs)describing physical processes to generative models. We show that generativemodels can be constructed from s-generative PDEs (s for smooth). GenPhyssubsume the two existing generative models (DM and PFGM) and even give rise tonew families of generative models, e.g., \"Yukawa Generative Models\" inspiredfrom weak interactions. On the other hand, some physical processes by defaultdo not belong to the GenPhys family, e.g., the wave equation and theSchr\"{o}dinger equation, but could be made into the GenPhys family with somemodifications. Our goal with GenPhys is to explore and expand the design spaceof generative models.", "output": "GenPhys: From Physical Processes to Generative Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose two approaches to extend the notion of knowledge distillation toGaussian Process Regression (GPR) and Gaussian Process Classification (GPC);data-centric and distribution-centric. The data-centric approach resembles mostcurrent distillation techniques for machine learning, and refits a model ondeterministic predictions from the teacher, while the distribution-centricapproach, re-uses the full probabilistic posterior for the next iteration. Byanalyzing the properties of these approaches, we show that the data-centricapproach for GPR closely relates to known results for self-distillation ofkernel ridge regression and that the distribution-centric approach for GPRcorresponds to ordinary GPR with a very particular choice of hyperparameters.Furthermore, we demonstrate that the distribution-centric approach for GPCapproximately corresponds to data duplication and a particular scaling of thecovariance and that the data-centric approach for GPC requires redefining themodel from a Binomial likelihood to a continuous Bernoulli likelihood to bewell-specified. To the best of our knowledge, our proposed approaches are thefirst to formulate knowledge distillation specifically for Gaussian Processmodels.", "output": "Self-Distillation for Gaussian Process Regression and Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce the Segment Anything (SA) project: a new task, model, anddataset for image segmentation. Using our efficient model in a data collectionloop, we built the largest segmentation dataset to date (by far), with over 1billion masks on 11M licensed and privacy respecting images. The model isdesigned and trained to be promptable, so it can transfer zero-shot to newimage distributions and tasks. We evaluate its capabilities on numerous tasksand find that its zero-shot performance is impressive -- often competitive withor even superior to prior fully supervised results. We are releasing theSegment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and11M images at  to foster research into foundationmodels for computer vision.", "output": "Segment Anything."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generative Adversarial Networks (GANs) is a novel class of deep generativemodels which has recently gained significant attention. GANs learns complex andhigh-dimensional distributions implicitly over images, audio, and data.However, there exists major challenges in training of GANs, i.e., modecollapse, non-convergence and instability, due to inappropriate design ofnetwork architecture, use of objective function and selection of optimizationalgorithm. Recently, to address these challenges, several solutions for betterdesign and optimization of GANs have been investigated based on techniques ofre-engineered network architectures, new objective functions and alternativeoptimization algorithms. To the best of our knowledge, there is no existingsurvey that has particularly focused on broad and systematic developments ofthese solutions. In this study, we perform a comprehensive survey of theadvancements in GANs design and optimization solutions proposed to handle GANschallenges. We first identify key research issues within each design andoptimization technique and then propose a new taxonomy to structure solutionsby key research issues. In accordance with the taxonomy, we provide a detaileddiscussion on different GANs variants proposed within each solution and theirrelationships. Finally, based on the insights gained, we present the promisingresearch directions in this rapidly growing field.", "output": "Generative Adversarial Networks (GANs Survey): Challenges, Solutions, and Future Directions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "There is increasing interest in allocating treatments based on observedindividual characteristics: examples include targeted marketing, individualizedcredit offers, and heterogeneous pricing. Treatment personalization introducesincentives for individuals to modify their behavior to obtain a bettertreatment. Strategic behavior shifts the joint distribution of covariates andpotential outcomes. The optimal rule without strategic behavior allocatestreatments only to those with a positive Conditional Average Treatment Effect.With strategic behavior, we show that the optimal rule can involverandomization, allocating treatments with less than 100% probability even tothose who respond positively on average to the treatment. We propose asequential experiment based on Bayesian Optimization that converges to theoptimal treatment rule without parametric assumptions on individual strategicbehavior.", "output": "Treatment Allocation with Strategic Agents."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Booking control problems are sequential decision-making problems that occurin the domain of revenue management. More precisely, freight booking controlfocuses on the problem of deciding to accept or reject bookings: given alimited capacity, accept a booking request or reject it to reserve capacity forfuture bookings with potentially higher revenue. This problem can be formulatedas a finite-horizon stochastic dynamic program, where accepting a set ofrequests results in a profit at the end of the booking period that depends onthe cost of fulfilling the accepted bookings. For many freight applications,the cost of fulfilling requests is obtained by solving an operationaldecision-making problem, which often requires the solutions to mixed-integerlinear programs. Routinely solving such operational problems when deployingreinforcement learning algorithms may be too time consuming. The majority ofbooking control policies are obtained by solving problem-specific mathematicalprogramming relaxations that are often non-trivial to generalize to newproblems and, in some cases, provide quite crude approximations.In this work, we propose a two-phase approach: we first train a supervisedlearning model to predict the objective of the operational problem, and then wedeploy the model within reinforcement learning algorithms to compute controlpolicies. This approach is general: it can be used every time the objectivefunction of the end-of-horizon operational problem can be predicted, and it isparticularly suitable to those cases where such problems are computationallyhard. Furthermore, it allows one to leverage the recent advances inreinforcement learning as routinely solving the operational problem is replacedwith a single prediction. Our methodology is evaluated on two booking controlproblems in the literature, namely, distributional logistics and airline cargomanagement.", "output": "Reinforcement Learning for Freight Booking Control Problems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We formulate an efficient approximation for multi-agent batch reinforcementlearning, the approximated multi-agent fitted Q iteration (AMAFQI). We presenta detailed derivation of our approach. We propose an iterative policy searchand show that it yields a greedy policy with respect to multiple approximationsof the centralized, learned Q-function. In each iteration and policyevaluation, AMAFQI requires a number of computations that scales linearly withthe number of agents whereas the analogous number of computations increaseexponentially for the fitted Q iteration (FQI), a commonly used approaches inbatch reinforcement learning. This property of AMAFQI is fundamental for thedesign of a tractable multi-agent approach. We evaluate the performance ofAMAFQI and compare it to FQI in numerical simulations. The simulationsillustrate the significant computation time reduction when using AMAFQI insteadof FQI in multi-agent problems and corroborate the similar performance of bothapproaches.", "output": "Approximated Multi-Agent Fitted Q Iteration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The semiconductors industry benefits greatly from the integration of MachineLearning (ML)-based techniques in Technology Computer-Aided Design (TCAD)methods. The performance of ML models however relies heavily on the quality andquantity of training datasets. They can be particularly difficult to obtain inthe semiconductor industry due to the complexity and expense of the devicefabrication. In this paper, we propose a self-augmentation strategy forimproving ML-based device modeling using variational autoencoder-basedtechniques. These techniques require a small number of experimental data pointsand does not rely on TCAD tools. To demonstrate the effectiveness of ourapproach, we apply it to a deep neural network-based prediction task for theOhmic resistance value in Gallium Nitride devices. A 70% reduction in meanabsolute error when predicting experimental results is achieved. The inherentflexibility of our approach allows easy adaptation to various tasks, thusmaking it highly relevant to many applications of the semiconductor industry.", "output": "Improving Semiconductor Device Modeling for Electronic Design Automation by Machine Learning Techniques."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Progressively applying Gaussian noise transforms complex data distributionsto approximately Gaussian. Reversing this dynamic defines a generative model.When the forward noising process is given by a Stochastic Differential Equation(SDE), Song et al. (2021) demonstrate how the time inhomogeneous drift of theassociated reverse-time SDE may be estimated using score-matching. A limitationof this approach is that the forward-time SDE must be run for a sufficientlylong time for the final distribution to be approximately Gaussian. In contrast,solving the Schr\"odinger Bridge problem (SB), i.e. an entropy-regularizedoptimal transport problem on path spaces, yields diffusions which generatesamples from the data distribution in finite time. We present Diffusion SB(DSB), an original approximation of the Iterative Proportional Fitting (IPF)procedure to solve the SB problem, and provide theoretical analysis along withgenerative modeling experiments. The first DSB iteration recovers themethodology proposed by Song et al. (2021), with the flexibility of usingshorter time intervals, as subsequent DSB iterations reduce the discrepancybetween the final-time marginal of the forward (resp. backward) SDE withrespect to the prior (resp. data) distribution. Beyond generative modeling, DSBoffers a widely applicable computational optimal transport tool as thecontinuous state-space analogue of the popular Sinkhorn algorithm (Cuturi,2013).", "output": "Diffusion Schr\\\"odinger Bridge with Applications to Score-Based Generative Modeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study practical data characteristics underlying federated learning, wherenon-i.i.d. data from clients have sparse features, and a certain client's localdata normally involves only a small part of the full model, called a submodel.Due to data sparsity, the classical federated averaging (FedAvg) algorithm orits variants will be severely slowed down, because when updating the globalmodel, each client's zero update of the full model excluding its submodel isinaccurately aggregated. Therefore, we propose federated submodel averaging(FedSubAvg), ensuring that the expectation of the global update of each modelparameter is equal to the average of the local updates of the clients whoinvolve it. We theoretically proved the convergence rate of FedSubAvg byderiving an upper bound under a new metric called the element-wise gradientnorm. In particular, this new metric can characterize the convergence offederated optimization over sparse data, while the conventional metric ofsquared gradient norm used in FedAvg and its variants cannot. We extensivelyevaluated FedSubAvg over both public and industrial datasets. The evaluationresults demonstrate that FedSubAvg significantly outperforms FedAvg and itsvariants.", "output": "Federated Submodel Optimization for Hot and Cold Data Features."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a novel approach to translate unpaired contrast computedtomography (CT) scans to non-contrast CT scans and the other way around.Solving this task has two important applications: (i) to automatically generatecontrast CT scans for patients for whom injecting contrast substance is not anoption, and (ii) to enhance the alignment between contrast and non-contrast CTby reducing the differences induced by the contrast substance beforeregistration. Our approach is based on cycle-consistent generative adversarialconvolutional transformers, for short, CyTran. Our neural model can be trainedon unpaired images, due to the integration of a multi-level cycle-consistencyloss. Aside from the standard cycle-consistency loss applied at the imagelevel, we propose to apply additional cycle-consistency losses betweenintermediate feature representations, which enforces the model to becycle-consistent at multiple representations levels, leading to superiorresults. To deal with high-resolution images, we design a hybrid architecturebased on convolutional and multi-head attention layers. In addition, weintroduce a novel data set, Coltea-Lung-CT-100W, containing 100 3D triphasiclung CT scans (with a total of 37,290 images) collected from 100 femalepatients (there is one examination per patient). Each scan contains threephases (non-contrast, early portal venous, and late arterial), allowing us toperform experiments to compare our novel approach with state-of-the-art methodsfor image style transfer. Our empirical results show that CyTran outperformsall competing methods. Moreover, we show that CyTran can be employed as apreliminary step to improve a state-of-the-art medical image alignment method.We release our novel model and data set as open source at", "output": "CyTran: A Cycle-Consistent Transformer with Multi-Level Consistency for Non-Contrast to Contrast CT Translation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, many improved naive Bayes methods have been developed with enhanceddiscrimination capabilities. Among them, regularized naive Bayes (RNB) producesexcellent performance by balancing the discrimination power and generalizationcapability. Data discretization is important in naive Bayes. By groupingsimilar values into one interval, the data distribution could be betterestimated. However, existing methods including RNB often discretize the datainto too few intervals, which may result in a significant information loss. Toaddress this problem, we propose a semi-supervised adaptive discriminativediscretization framework for naive Bayes, which could better estimate the datadistribution by utilizing both labeled data and unlabeled data throughpseudo-labeling techniques. The proposed method also significantly reduces theinformation loss during discretization by utilizing an adaptive discriminativediscretization scheme, and hence greatly improves the discrimination power ofclassifiers. The proposed RNB+, i.e., regularized naive Bayes utilizing theproposed discretization framework, is systematically evaluated on a wide rangeof machine-learning datasets. It significantly and consistently outperformsstate-of-the-art NB classifiers.", "output": "A Semi-Supervised Adaptive Discriminative Discretization Method Improving Discrimination Power of Regularized Naive Bayes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Training of convolutional neural networks is a high dimensional and anon-convex optimization problem. At present, it is inefficient in situationswhere parametric learning rates can not be confidently set. Some past workshave introduced Newton methods for training deep neural networks. Newtonmethods for convolutional neural networks involve complicated operations.Finding the Hessian matrix in second-order methods becomes very complex as wemainly use the finite differences method with the image data. Newton methodsfor convolutional neural networks deals with this by using the sub-sampledHessian Newton methods. In this paper, we have used the complete data insteadof the sub-sampled methods that only handle partial data at a time. Further, wehave used parallel processing instead of serial processing in mini-batchcomputations. The results obtained using parallel processing in this study,outperform the time taken by the previous approach.", "output": "Newton methods based convolution neural networks using parallel processing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We consider the classic 1-center problem: Given a set $P$ of $n$ points in ametric space find the point in $P$ that minimizes the maximum distance to theother points of $P$. We study the complexity of this problem in $d$-dimensional$ell_p$-metrics and in edit and Ulam metrics over strings of length $d$. Ourresults for the 1-center problem may be classified based on $d$ as follows.$bullet$ Small $d$: Assuming the hitting set conjecture (HSC), we show thatwhen $d=omega(log n)$, no subquadratic algorithm can solve 1-center problemin any of the $ell_p$-metrics, or in edit or Ulam metrics.$bullet$ Large $d$: When $d=Omega(n)$, we extend our conditional lowerbound to rule out subquartic algorithms for 1-center problem in edit metric(assuming Quantified SETH). On the other hand, we give a$(1+epsilon)$-approximation for 1-center in Ulam metric with running time$tilde{O_{varepsilon}}(nd+n^2sqrt{d})$.We also strengthen some of the above lower bounds by allowing approximationsor by reducing the dimension $d$, but only against a weaker class of algorithmswhich list all requisite solutions. Moreover, we extend one of our hardnessresults to rule out subquartic algorithms for the well-studied 1-median problemin the edit metric, where given a set of $n$ strings each of length $n$, thegoal is to find a string in the set that minimizes the sum of the editdistances to the rest of the strings in the set.", "output": "On Complexity of 1-Center in Various Metrics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Novel backscatter communication techniques enable battery-free sensor tags tointeroperate with unmodified standard IoT devices, extending a sensor network'scapabilities in a scalable manner. Without requiring additional dedicatedinfrastructure, the battery-free tags harvest energy from the environment,while the IoT devices provide them with the unmodulated carrier they need tocommunicate. A schedule coordinates the provision of carriers for thecommunications of battery-free devices with IoT nodes. Optimal carrierscheduling is an NP-hard problem that limits the scalability of networkdeployments. Thus, existing solutions waste energy and other valuable resourcesby scheduling the carriers suboptimally. We present DeepGANTT, a deep learningscheduler that leverages graph neural networks to efficiently providenear-optimal carrier scheduling. We train our scheduler with relatively smalloptimal schedules obtained from a constraint optimization solver, achieving aperformance within 3% of the optimal scheduler. Without the need to retrain,DeepGANTT generalizes to networks 6x larger in the number of nodes and 10xlarger in the number of tags than those used for training, breaking thescalability limitations of the optimal scheduler and reducing carrierutilization by up to 50% compared to the state-of-the-art heuristic. Ourscheduler efficiently reduces energy and spectrum utilization in backscatternetworks.", "output": "DeepGANTT: A Scalable Deep Learning Scheduler for Backscatter Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Need for the efficient processing of neural networks has given rise to thedevelopment of hardware accelerators. The increased adoption of specializedhardware has highlighted the need for more agile design flows forhardware-software co-design and domain-specific optimizations. In this paper,we present CFU Playground: a full-stack open-source framework that enablesrapid and iterative design and evaluation of machine learning (ML) acceleratorsfor embedded ML systems. Our tool provides a completely open-source end-to-endflow for hardware-software co-design on FPGAs and future systems research. Thisfull-stack framework gives the users access to explore experimental and bespokearchitectures that are customized and co-optimized for embedded ML. Our rapid,deploy-profile-optimization feedback loop lets ML hardware and softwaredevelopers achieve significant returns out of a relatively small investment incustomization. Using CFU Playground's design and evaluation loop, we showsubstantial speedups between 55$times$ and 75$times$. The soft CPU coupledwith the accelerator opens up a new, rich design space between the twocomponents that we explore in an automated fashion using Vizier, an open-sourceblack-box optimization service.", "output": "CFU Playground: Full-Stack Open-Source Framework for Tiny Machine Learning (tinyML) Acceleration on FPGAs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generative models for graphs have been actively studied for decades, and theyhave a wide range of applications. Recently, learning-based graph generationthat reproduces real-world graphs has been attracting the attention of manyresearchers. Although several generative models that utilize modern machinelearning technologies have been proposed, conditional generation of generalgraphs has been less explored in the field. In this paper, we propose agenerative model that allows us to tune the value of a global-level structuralfeature as a condition. Our model, called GraphTune, makes it possible to tunethe value of any structural feature of generated graphs using Long Short TermMemory (LSTM) and a Conditional Variational AutoEncoder (CVAE). We performedcomparative evaluations of GraphTune and conventional models on a real graphdataset. The evaluations show that GraphTune makes it possible to more clearlytune the value of a global-level structural feature better than conventionalmodels.", "output": "GraphTune: A Learning-based Graph Generative Model with Tunable Structural Features."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite recent advances of AI, story understanding remains an open andunder-investigated problem. We collect, preprocess, and publicly release avideo-language story dataset, Synopses of Movie Narratives (SyMoN), containing5,193 video summaries of popular movies and TV series with a total length of869 hours. SyMoN captures naturalistic storytelling videos made by humancreators and intended for a human audience. As a prototypical and naturalisticstory dataset, SyMoN features high coverage of multimodal story events andabundant mental-state descriptions. Its use of storytelling techniques causecross-domain semantic gaps that provide appropriate challenges to existingmodels. We establish benchmarks on video-text retrieval and zero-shot alignmenton movie summary videos, which showcase the importance of in-domain data andlong-term memory in story understanding. With SyMoN, we hope to lay thegroundwork for progress in multimodal story understanding.", "output": "Synopses of Movie Narratives: a Video-Language Dataset for Story Understanding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While the optimal transport (OT) problem was originally formulated as alinear program, the addition of entropic regularization has proven beneficialboth computationally and statistically, for many applications. The Sinkhornfixed-point algorithm is the most popular approach to solve this regularizedproblem, and, as a result, multiple attempts have been made to reduce itsruntime using, e.g., annealing in the regularization parameter, momentum oracceleration. The premise of this work is that initialization of the Sinkhornalgorithm has received comparatively little attention, possibly due to twopreconceptions: since the regularized OT problem is convex, it may not be worthcrafting a good initialization, since any is guaranteed to work; secondly,because the outputs of the Sinkhorn algorithm are often unrolled in end-to-endpipelines, a data-dependent initialization would bias Jacobian computations. Wechallenge this conventional wisdom, and show that data-dependent initializersresult in dramatic speed-ups, with no effect on differentiability as long asimplicit differentiation is used. Our initializations rely on closed-forms forexact or approximate OT solutions that are known in the 1D, Gaussian or GMMsettings. They can be used with minimal tuning, and result in consistentspeed-ups for a wide variety of OT problems.", "output": "Rethinking Initialization of the Sinkhorn Algorithm."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Adversarial training is one of the most popular methods for training methodsrobust to adversarial attacks, however, it is not well-understood from atheoretical perspective. We prove and existence, regularity, and minimaxtheorems for adversarial surrogate risks. Our results explain some empiricalobservations on adversarial robustness from prior work and suggest newdirections in algorithm development. Furthermore, our results extend previouslyknown existence and minimax theorems for the adversarial classification risk tosurrogate risks.", "output": "Existence and Minimax Theorems for Adversarial Surrogate Risks in Binary Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Future wireless networks are expected to support diverse mobile services,including artificial intelligence (AI) services and ubiquitous datatransmissions. Federated learning (FL), as a revolutionary learning approach,enables collaborative AI model training across distributed mobile edge devices.By exploiting the superposition property of multiple-access channels,over-the-air computation allows concurrent model uploading from massive devicesover the same radio resources, and thus significantly reduces the communicationcost of FL. In this paper, we study the coexistence of over-the-air FL andtraditional information transfer (IT) in a mobile edge network. We propose acoexisting federated learning and information transfer (CFLIT) communicationframework, where the FL and IT devices share the wireless spectrum in an OFDMsystem. Under this framework, we aim to maximize the IT data rate and guaranteea given FL convergence performance by optimizing the long-term radio resourceallocation. A key challenge that limits the spectrum efficiency of thecoexisting system lies in the large overhead incurred by frequent communicationbetween the server and edge devices for FL model aggregation. To address thechallenge, we rigorously analyze the impact of the computation-to-communicationratio on the convergence of over-the-air FL in wireless fading channels. Theanalysis reveals the existence of an optimal computation-to-communication ratiothat minimizes the amount of radio resources needed for over-the-air FL toconverge to a given error tolerance. Based on the analysis, we propose alow-complexity online algorithm to jointly optimize the radio resourceallocation for both the FL devices and IT devices. Extensive numericalsimulations verify the superior performance of the proposed design for thecoexistence of FL and IT devices in wireless cellular systems.", "output": "CFLIT: Coexisting Federated Learning and Information Transfer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In an unsupervised attack on variational autoencoders (VAEs), an adversaryfinds a small perturbation in an input sample that significantly changes itslatent space encoding, thereby compromising the reconstruction for a fixeddecoder. A known reason for such vulnerability is the distortions in the latentspace resulting from a mismatch between approximated latent posterior and aprior distribution. Consequently, a slight change in an input sample can moveits encoding to a low/zero density region in the latent space resulting in anunconstrained generation. This paper demonstrates that an optimal way for anadversary to attack VAEs is to exploit a directional bias of a stochasticpullback metric tensor induced by the encoder and decoder networks. Thepullback metric tensor of an encoder measures the change in infinitesimallatent volume from an input to a latent space. Thus, it can be viewed as a lensto analyse the effect of input perturbations leading to latent spacedistortions. We propose robustness evaluation scores using the eigenspectrum ofa pullback metric tensor. Moreover, we empirically show that the scorescorrelate with the robustness parameter $beta$ of the $beta-$VAE. Sinceincreasing $beta$ also degrades reconstruction quality, we demonstrate asimple alternative using textit{mixup} training to fill the empty regions inthe latent space, thus improving robustness with improved reconstruction.", "output": "Adversarial robustness of VAEs through the lens of local geometry."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We establish disintegrated PAC-Bayesian generalisation bounds for modelstrained with gradient descent methods or continuous gradient flows. Contrary tostandard practice in the PAC-Bayesian setting, our result applies tooptimisation algorithms that are deterministic, without requiring anyde-randomisation step. Our bounds are fully computable, depending on thedensity of the initial distribution and the Hessian of the training objectiveover the trajectory. We show that our framework can be applied to a variety ofiterative optimisation algorithms, including stochastic gradient descent (SGD),momentum-based schemes, and damped Hamiltonian dynamics.", "output": "Generalisation under gradient descent via deterministic PAC-Bayes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this short note, we propose a new method for quantizing the weights of afully trained neural network. A simple deterministic pre-processing step allowsus to quantize network layers via memoryless scalar quantization whilepreserving the network performance on given training data. On one hand, thecomputational complexity of this pre-processing slightly exceeds that ofstate-of-the-art algorithms in the literature. On the other hand, our approachdoes not require any hyper-parameter tuning and, in contrast to previousmethods, allows a plain analysis. We provide rigorous theoretical guarantees inthe case of quantizing single network layers and show that the relative errordecays with the number of parameters in the network if the training databehaves well, e.g., if it is sampled from suitable random distributions. Thedeveloped method also readily allows the quantization of deep networks byconsecutive application to single layers.", "output": "A simple approach for quantizing neural networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In many classification models, data is discretized to better estimate itsdistribution. Existing discretization methods often target at maximizing thediscriminant power of discretized data, while overlooking the fact that theprimary target of data discretization in classification is to improve thegeneralization performance. As a result, the data tend to be over-split intomany small bins since the data without discretization retain the maximaldiscriminant information. Thus, we propose a Max-Dependency-Min-Divergence(MDmD) criterion that maximizes both the discriminant information andgeneralization ability of the discretized data. More specifically, theMax-Dependency criterion maximizes the statistical dependency between thediscretized data and the classification variable while the Min-Divergencecriterion explicitly minimizes the JS-divergence between the training data andthe validation data for a given discretization scheme. The proposed MDmDcriterion is technically appealing, but it is difficult to reliably estimatethe high-order joint distributions of attributes and the classificationvariable. We hence further propose a more practical solution,Max-Relevance-Min-Divergence (MRmD) discretization scheme, where each attributeis discretized separately, by simultaneously maximizing the discriminantinformation and the generalization ability of the discretized data. Theproposed MRmD is compared with the state-of-the-art discretization algorithmsunder the naive Bayes classification framework on 45 machine-learning benchmarkdatasets. It significantly outperforms all the compared methods on most of thedatasets.", "output": "A Max-relevance-min-divergence Criterion for Data Discretization with Applications on Naive Bayes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Modern robots require accurate forecasts to make optimal decisions in thereal world. For example, self-driving cars need an accurate forecast of otheragents' future actions to plan safe trajectories. Current methods rely heavilyon historical time series to accurately predict the future. However, relyingentirely on the observed history is problematic since it could be corrupted bynoise, have outliers, or not completely represent all possible outcomes. Tosolve this problem, we propose a novel framework for generating robustforecasts for robotic control. In order to model real-world factors affectingfuture forecasts, we introduce the notion of an adversary, which perturbsobserved historical time series to increase a robot's ultimate control cost.Specifically, we model this interaction as a zero-sum two-player game between arobot's forecaster and this hypothetical adversary. We show that our proposedgame may be solved to a local Nash equilibrium using gradient-basedoptimization techniques. Furthermore, we show that a forecaster trained withour method performs 30.14% better on out-of-distribution real-world lane changedata than baselines.", "output": "Robust Forecasting for Robotic Control: A Game-Theoretic Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks (DNNs) have demonstrated their superiority in practice.Arguably, the rapid development of DNNs is largely benefited from high-quality(open-sourced) datasets, based on which researchers and developers can easilyevaluate and improve their learning methods. Since the data collection isusually time-consuming or even expensive, how to protect their copyrights is ofgreat significance and worth further exploration. In this paper, we revisitdataset ownership verification. We find that existing verification methodsintroduced new security risks in DNNs trained on the protected dataset, due tothe targeted nature of poison-only backdoor watermarks. To alleviate thisproblem, in this work, we explore the untargeted backdoor watermarking scheme,where the abnormal model behaviors are not deterministic. Specifically, weintroduce two dispersibilities and prove their correlation, based on which wedesign the untargeted backdoor watermark under both poisoned-label andclean-label settings. We also discuss how to use the proposed untargetedbackdoor watermark for dataset ownership verification. Experiments on benchmarkdatasets verify the effectiveness of our methods and their resistance toexisting backdoor defenses. Our codes are available aturl{", "output": "Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Designing Luenberger observers for nonlinear systems involves the challengingtask of transforming the state to an alternate coordinate system, possibly ofhigher dimensions, where the system is asymptotically stable and linear up tooutput injection. The observer then estimates the system's state in theoriginal coordinates by inverting the transformation map. However, finding asuitable injective transformation whose inverse can be derived remains aprimary challenge for general nonlinear systems. We propose a novel approachthat uses supervised physics-informed neural networks to approximate both thetransformation and its inverse. Our method exhibits superior generalizationcapabilities to contemporary methods and demonstrates robustness to both neuralnetwork's approximation errors and system uncertainties.", "output": "Learning-based Design of Luenberger Observers for Autonomous Nonlinear Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Graph neural networks (GNNs) have shown remarkable performance on diversegraph mining tasks. Although different GNNs can be unified as the same messagepassing framework, they learn complementary knowledge from the same graph.Knowledge distillation (KD) is developed to combine the diverse knowledge frommultiple models. It transfers knowledge from high-capacity teachers to alightweight student. However, to avoid oversmoothing, GNNs are often shallow,which deviates from the setting of KD. In this context, we revisit KD byseparating its benefits from model compression and emphasizing its power oftransferring knowledge. To this end, we need to tackle two challenges: how totransfer knowledge from compact teachers to a student with the same capacity;and, how to exploit student GNN's own strength to learn knowledge. In thispaper, we propose a novel adaptive KD framework, called BGNN, whichsequentially transfers knowledge from multiple GNNs into a student GNN. We alsointroduce an adaptive temperature module and a weight boosting module. Thesemodules guide the student to the appropriate knowledge for effective learning.Extensive experiments have demonstrated the effectiveness of BGNN. Inparticular, we achieve up to 3.05% improvement for node classification and6.35% improvement for graph classification over vanilla GNNs.", "output": "Boosting Graph Neural Networks via Adaptive Knowledge Distillation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Offline reinforcement learning (RL) methods can generally be categorized intotwo types: RL-based and Imitation-based. RL-based methods could in principleenjoy out-of-distribution generalization but suffer from erroneous off-policyevaluation. Imitation-based methods avoid off-policy evaluation but are tooconservative to surpass the dataset. In this study, we propose an alternativeapproach, inheriting the training stability of imitation-style methods whilestill allowing logical out-of-distribution generalization. We decompose theconventional reward-maximizing policy in offline RL into a guide-policy and anexecute-policy. During training, the guide-poicy and execute-policy are learnedusing only data from the dataset, in a supervised and decoupled manner. Duringevaluation, the guide-policy guides the execute-policy by telling where itshould go so that the reward can be maximized, serving as the textit{Prophet}.By doing so, our algorithm allows textit{state-compositionality} from thedataset, rather than textit{action-compositionality} conducted in priorimitation-style methods. We dumb this new approach Policy-guided Offline RL(texttt{POR}). texttt{POR} demonstrates the state-of-the-art performance onD4RL, a standard benchmark for offline RL. We also highlight the benefits oftexttt{POR} in terms of improving with supplementary suboptimal data andeasily adapting to new tasks by only changing the guide-poicy.", "output": "A Policy-Guided Imitation Approach for Offline Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, there has been tremendous interest in industry 4.0 infrastructureto address labor shortages in global supply chains. Deploying artificialintelligence-enabled robotic bin picking systems in real world has becomeparticularly important for reducing stress and physical demands of workerswhile increasing speed and efficiency of warehouses. To this end, artificialintelligence-enabled robotic bin picking systems may be used to automate orderpicking, but with the risk of causing expensive damage during an abnormal eventsuch as sensor failure. As such, reliability becomes a critical factor fortranslating artificial intelligence research to real world applications andproducts. In this paper, we propose a reliable object detection andsegmentation system with MultiModal Redundancy (MMRNet) for tackling objectdetection and segmentation for robotic bin picking using data from differentmodalities. This is the first system that introduces the concept of multimodalredundancy to address sensor failure issues during deployment. In particular,we realize the multimodal redundancy framework with a gate fusion module anddynamic ensemble learning. Finally, we present a new label-free multi-modalconsistency (MC) score that utilizes the output from all modalities to measurethe overall system output reliability and uncertainty. Through experiments, wedemonstrate that in an event of missing modality, our system provides a muchmore reliable performance compared to baseline models. We also demonstrate thatour MC score is a more reliability indicator for outputs during inference timecompared to the model generated confidence scores that are oftenover-confident.", "output": "MMRNet: Improving Reliability for Multimodal Object Detection and Segmentation for Bin Picking via Multimodal Redundancy."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-armed bandit (MAB) problems are mainly studied under two extremesettings known as stochastic and adversarial. These two settings, however, donot capture realistic environments such as search engines and marketing andadvertising, in which rewards stochastically change in time. Motivated by that,we introduce and study a dynamic MAB problem with stochastic temporalstructure, where the expected reward of each arm is governed by anauto-regressive (AR) model. Due to the dynamic nature of the rewards, simple\"explore and commit\" policies fail, as all arms have to be exploredcontinuously over time. We formalize this by characterizing a per-round regretlower bound, where the regret is measured against a strong (dynamic) benchmark.We then present an algorithm whose per-round regret almost matches our regretlower bound. Our algorithm relies on two mechanisms: (i) alternating betweenrecently pulled arms and unpulled arms with potential, and (ii) restarting.These mechanisms enable the algorithm to dynamically adapt to changes anddiscard irrelevant past information at a suitable rate. In numerical studies,we further demonstrate the strength of our algorithm under non-stationarysettings.", "output": "Dynamic Bandits with an Auto-Regressive Temporal Structure."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Quantum Approximate Optimization Algorithm (QAOA) is one of the leadingcandidates for demonstrating the quantum advantage using near-term quantumcomputers. Unfortunately, high device error rates limit us from reliablyrunning QAOA circuits for problems with more than a few qubits. In QAOA, theproblem graph is translated into a quantum circuit such that every edgecorresponds to two 2-qubit CNOT operations in each layer of the circuit. AsCNOTs are extremely error-prone, the fidelity of QAOA circuits is dictated bythe number of edges in the problem graph.We observe that majority of graphs corresponding to real-world applicationsfollow the ``power-law`` distribution, where some hotspot nodes havesignificantly higher number of connections. We leverage this insight andpropose ``FrozenQubits`` that freezes the hotspot nodes or qubits andintelligently partitions the state-space of the given problem into severalsmaller sub-spaces which are then solved independently. The corresponding QAOAsub-circuits are significantly less vulnerable to gate and decoherence errorsdue to the reduced number of CNOT operations in each sub-circuit. Unlike priorcircuit-cutting approaches, FrozenQubits does not require any exponentiallycomplex post-processing step. Our evaluations with 5,300 QAOA circuits on eightdifferent quantum computers from IBM shows that FrozenQubits can improve thequality of solutions by 8.73x on average (and by up to 57x), albeit utilizing2x more quantum resources.", "output": "FrozenQubits: Boosting Fidelity of QAOA by Skipping Hotspot Nodes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A wide variety of battery models are available, and it is not always obviouswhich model `best' describes a dataset. This paper presents a Bayesian modelselection approach using Bayesian quadrature. The model evidence is adopted asthe selection metric, choosing the simplest model that describes the data, inthe spirit of Occam's razor. However, estimating this requires integralcomputations over parameter space, which is usually prohibitively expensive.Bayesian quadrature offers sample-efficient integration via model-basedinference that minimises the number of battery model evaluations. The posteriordistribution of model parameters can also be inferred as a byproduct withoutfurther computation. Here, the simplest lithium-ion battery models, equivalentcircuit models, were used to analyse the sensitivity of the selection criterionto given different datasets and model configurations. We show that popularmodel selection criteria, such as root-mean-square error and Bayesianinformation criterion, can fail to select a parsimonious model in the case of amultimodal posterior. The model evidence can spot the optimal model in suchcases, simultaneously providing the variance of the evidence inference itselfas an indication of confidence. We also show that Bayesian quadrature cancompute the evidence faster than popular Monte Carlo based solvers.", "output": "Bayesian Model Selection of Lithium-Ion Battery Models via Bayesian Quadrature."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Secure multi-party computation (MPC) enables computation directly onencrypted data and protects both data and model privacy in deep learninginference. However, existing neural network architectures, including VisionTransformers (ViTs), are not designed or optimized for MPC and incursignificant latency overhead. We observe Softmax accounts for the major latencybottleneck due to a high communication complexity, but can be selectivelyreplaced or linearized without compromising the model accuracy. Hence, in thispaper, we propose an MPC-friendly ViT, dubbed MPCViT, to enable accurate yetefficient ViT inference in MPC. Based on a systematic latency and accuracyevaluation of the Softmax attention and other attention variants, we propose aheterogeneous attention optimization space. We also develop a simple yeteffective MPC-aware neural architecture search algorithm for fast Paretooptimization. To further boost the inference efficiency, we propose MPCViT+, tojointly optimize the Softmax attention and other network components, includingGeLU, matrix multiplication, etc. With extensive experiments, we demonstratethat MPCViT achieves 1.9%, 1.3% and 4.6% higher accuracy with 6.2x, 2.9x and1.9x latency reduction compared with baseline ViT, MPCFormer and THE-X on theTiny-ImageNet dataset, respectively. MPCViT+ further achieves 1.2x latencyreduction on CIFAR-100 dataset and reaches a better Pareto front compared withMPCViT.", "output": "MPCViT: Searching for Accurate and Efficient MPC-Friendly Vision Transformer with Heterogeneous Attention."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While natural systems often present collective intelligence that allows themto self-organize and adapt to changes, the equivalent is missing in mostartificial systems. We explore the possibility of such a system in the contextof cooperative 2D push manipulations using mobile robots. Although conventionalworks demonstrate potential solutions for the problem in restricted settings,they have computational and learning difficulties. More importantly, thesesystems do not possess the ability to adapt when facing environmental changes.In this work, we show that by distilling a planner derived from adifferentiable soft-body physics simulator into an attention-based neuralnetwork, our multi-robot push manipulation system achieves better performancethan baselines. In addition, our system also generalizes to configurations notseen during training and is able to adapt toward task completions when externalturbulence and environmental changes are applied. Supplementary videos can befound on our project website: ", "output": "Collective Intelligence for 2D Push Manipulations with Mobile Robots."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The renewed interest from the scientific community in machine learning (ML)is opening many new areas of research. Here we focus on how novel trends in MLare providing opportunities to improve the field of computational fluiddynamics (CFD). In particular, we discuss synergies between ML and CFD thathave already shown benefits, and we also assess areas that are underdevelopment and may produce important benefits in the coming years. We believethat it is also important to emphasize a balanced perspective of cautiousoptimism for these emerging approaches", "output": "Emerging trends in machine learning for computational fluid dynamics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reliable application of machine learning-based decision systems in the wildis one of the major challenges currently investigated by the field. A largeportion of established approaches aims to detect erroneous predictions by meansof assigning confidence scores. This confidence may be obtained by eitherquantifying the model's predictive uncertainty, learning explicit scoringfunctions, or assessing whether the input is in line with the trainingdistribution. Curiously, while these approaches all state to address the sameeventual goal of detecting failures of a classifier upon real-life application,they currently constitute largely separated research fields with individualevaluation protocols, which either exclude a substantial part of relevantmethods or ignore large parts of relevant failure sources. In this work, wesystematically reveal current pitfalls caused by these inconsistencies andderive requirements for a holistic and realistic evaluation of failuredetection. To demonstrate the relevance of this unified perspective, we presenta large-scale empirical study for the first time enabling benchmarkingconfidence scoring functions w.r.t all relevant methods and failure sources.The revelation of a simple softmax response baseline as the overall bestperforming method underlines the drastic shortcomings of current evaluation inthe abundance of publicized research on confidence scoring. Code and trainedmodels are at ", "output": "A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In 2016-2017, TUS, the world's first experiment for testing the possibilityof registering ultra-high energy cosmic rays (UHECRs) by their fluorescentradiation in the night atmosphere of Earth was carried out. Since 2019, theRussian-Italian fluorescence telescope (FT) Mini-EUSO (\"UV Atmosphere\") hasbeen operating on the ISS. The stratospheric experiment EUSO-SPB2, which willemploy an FT for registering UHECRs, is planned for 2023. We show how a simpleconvolutional neural network can be effectively used to find track-like eventsin the variety of data obtained with such instruments.", "output": "A Neural Network Approach for Selecting Track-like Events in Fluorescence Telescope Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Variational autoencoders (VAEs) are one class of generative probabilisticlatent-variable models designed for inference based on known data. We developthree variations on VAEs by introducing a second parameterized encoder/decoderpair and, for one variation, an additional fixed encoder. The parameters of theencoders/decoders are to be learned with a neural network. The fixed encoder isobtained by probabilistic-PCA. The variations are compared to the EvidenceLower Bound (ELBO) approximation to the original VAE. One variation leads to anEvidence Upper Bound (EUBO) that can be used in conjunction with the originalELBO to interrogate the convergence of the VAE.", "output": "Three Variations on Variational Autoencoders."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite significant advances, the performance of state-of-the-art continuallearning approaches hinges on the unrealistic scenario of fully labeled data.In this paper, we tackle this challenge and propose an approach for continualsemi-supervised learning--a setting where not all the data samples are labeled.A primary issue in this scenario is the model forgetting representations ofunlabeled data and overfitting the labeled samples. We leverage the power ofnearest-neighbor classifiers to nonlinearly partition the feature space andflexibly model the underlying data distribution thanks to its non-parametricnature. This enables the model to learn a strong representation for the currenttask, and distill relevant information from previous tasks. We perform athorough experimental evaluation and show that our method outperforms all theexisting approaches by large margins, setting a solid state of the art on thecontinual semi-supervised learning paradigm. For example, on CIFAR-100 wesurpass several others even when using at least 30 times less supervision (0.8%vs. 25% of annotations). Finally, our method works well on both low and highresolution images and scales seamlessly to more complex datasets such asImageNet-100. The code is publicly available on", "output": "A soft nearest-neighbor framework for continual semi-supervised learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Polypharmacy, most often defined as the simultaneous consumption of five ormore drugs at once, is a prevalent phenomenon in the older population. Some ofthese polypharmacies, deemed inappropriate, may be associated with adversehealth outcomes such as death or hospitalization. Considering the combinatorialnature of the problem as well as the size of claims database and the cost tocompute an exact association measure for a given drug combination, it isimpossible to investigate every possible combination of drugs. Therefore, wepropose to optimize the search for potentially inappropriate polypharmacies(PIPs). To this end, we propose the OptimNeuralTS strategy, based on NeuralThompson Sampling and differential evolution, to efficiently mine claimsdatasets and build a predictive model of the association between drugcombinations and health outcomes. We benchmark our method using two datasetsgenerated by an internally developed simulator of polypharmacy data containing500 drugs and 100 000 distinct combinations. Empirically, our method can detectup to 72% of PIPs while maintaining an average precision score of 99% using 30000 time steps.", "output": "Neural Bandits for Data Mining: Searching for Dangerous Polypharmacy."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present RAVEn, a self-supervised multi-modal approach to jointly learnvisual and auditory speech representations. Our pre-training objective involvesencoding masked inputs, and then predicting contextualised targets generated byslowly-evolving momentum encoders. Driven by the inherent differences betweenvideo and audio, our design is asymmetric w.r.t. the two modalities' pretexttasks: Whereas the auditory stream predicts both the visual and auditorytargets, the visual one predicts only the auditory targets. We observe strongresults in low- and high-resource labelled data settings when fine-tuning thevisual and auditory encoders resulting from a single pre-training stage, inwhich the encoders are jointly trained. Notably, RAVEn surpasses allself-supervised methods on visual speech recognition (VSR) on LRS3, andcombining RAVEn with self-training using only 30 hours of labelled data evenoutperforms a recent semi-supervised method trained on 90,000 hours ofnon-public data. At the same time, we achieve state-of-the-art results in theLRS3 low-resource setting for auditory speech recognition (as well as for VSR).Our findings point to the viability of learning powerful speech representationsentirely from raw video and audio, i.e., without relying on handcraftedfeatures. Code and models are available at ", "output": "Jointly Learning Visual and Auditory Speech Representations from Raw Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision transformers (ViTs) have achieved impressive results on variouscomputer vision tasks in the last several years. In this work, we study thecapability of frozen ViTs, pretrained only on visual data, to generalize toaudio-visual data without finetuning any of its original parameters. To do so,we propose a latent audio-visual hybrid (LAVISH) adapter that adapts pretrainedViTs to audio-visual tasks by injecting a small number of trainable parametersinto every layer of a frozen ViT. To efficiently fuse visual and audio cues,our LAVISH adapter uses a small set of latent tokens, which form an attentionbottleneck, thus, eliminating the quadratic cost of standard cross-attention.Compared to the existing modality-specific audio-visual methods, our approachachieves competitive or even better performance on various audio-visual taskswhile using fewer tunable parameters and without relying on costly audiopretraining or external audio encoders. Our code is available at", "output": "Vision Transformers are Parameter-Efficient Audio-Visual Learners."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes a novel self-supervised based Cut-and-Paste GAN toperform foreground object segmentation and generate realistic composite imageswithout manual annotations. We accomplish this goal by a simple yet effectiveself-supervised approach coupled with the U-Net based discriminator. Theproposed method extends the ability of the standard discriminators to learn notonly the global data representations via classification (real/fake) but alsolearn semantic and structural information through pseudo labels created usingthe self-supervised task. The proposed method empowers the generator to createmeaningful masks by forcing it to learn informative per-pixel as well as globalimage feedback from the discriminator. Our experiments demonstrate that ourproposed method significantly outperforms the state-of-the-art methods on thestandard benchmark datasets.", "output": "SS-CPGAN: Self-Supervised Cut-and-Pasting Generative Adversarial Network for Object Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We consider the problem of learning multioutput function classes in batch andonline settings. In both settings, we show that a multioutput function class islearnable if and only if each single-output restriction of the function classis learnable. This provides a complete characterization of the learnability ofmultilabel classification and multioutput regression in both batch and onlinesettings. As an extension, we also consider multilabel learnability in thebandit feedback setting and show a similar characterization as in thefull-feedback setting.", "output": "A Characterization of Multioutput Learnability."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Most recent self-supervised learning methods are pre-trained on thewell-curated ImageNet-1K dataset. In this work, given the excellent scalabilityof web data, we consider self-supervised pre-training on noisy web sourcedimage-text paired data. First, we conduct a benchmark study of representativeself-supervised pre-training methods on large-scale web data in a like-for-likesetting. We compare a range of methods, including single-modal ones that usemasked training objectives and multi-modal ones that use image-textconstrastive training. We observe that existing multi-modal methods do notoutperform their single-modal counterparts on vision transfer learning tasks.We derive an information-theoretical view to explain these benchmark results,which provides insight into how to design a novel vision learner. Inspired bythis insight, we present a new visual representation pre-training method,MUlti-modal Generator~(MUG), that learns from scalable web sourced image-textdata. MUG achieves state-of-the-art transfer performance on a variety of tasksand demonstrates promising scaling properties. Pre-trained models and code willbe made public upon acceptance.", "output": "Vision Learners Meet Web Image-Text Pairs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Joint machine learning models that allow synthesizing and classifying dataoften offer uneven performance between those tasks or are unstable to train. Inthis work, we depart from a set of empirical observations that indicate theusefulness of internal representations built by contemporary deepdiffusion-based generative models not only for generating but also predicting.We then propose to extend the vanilla diffusion model with a classifier thatallows for stable joint end-to-end training with shared parameterizationbetween those objectives. The resulting joint diffusion model outperformsrecent state-of-the-art hybrid methods in terms of both classification andgeneration quality on all evaluated benchmarks. On top of our joint trainingapproach, we present how we can directly benefit from shared generative anddiscriminative representations by introducing a method for visualcounterfactual explanations.", "output": "Learning Data Representations with Joint Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents a new convergent Plug-and-Play (PnP) algorithm. PnPmethods are efficient iterative algorithms for solving image inverse problemsformulated as the minimization of the sum of a data-fidelity term and aregularization term. PnP methods perform regularization by plugging apre-trained denoiser in a proximal algorithm, such as Proximal Gradient Descent(PGD). To ensure convergence of PnP schemes, many works study specificparametrizations of deep denoisers. However, existing results require eitherunverifiable or suboptimal hypotheses on the denoiser, or assume restrictiveconditions on the parameters of the inverse problem. Observing that theselimitations can be due to the proximal algorithm in use, we study a relaxedversion of the PGD algorithm for minimizing the sum of a convex function and aweakly convex one. When plugged with a relaxed proximal denoiser, we show thatthe proposed PnP-$alpha$PGD algorithm converges for a wider range ofregularization parameters, thus allowing more accurate image restoration.", "output": "A relaxed proximal gradient descent algorithm for convergent plug-and-play with proximal denoiser."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Alzheimer's dementia (AD) affects memory, thinking, and language,deteriorating person's life. An early diagnosis is very important as it enablesthe person to receive medical help and ensure quality of life. Therefore,leveraging spontaneous speech in conjunction with machine learning methods forrecognizing AD patients has emerged into a hot topic. Most of the previousworks employ Convolutional Neural Networks (CNNs), to process the input signal.However, finding a CNN architecture is a time-consuming process and requiresdomain expertise. Moreover, the researchers introduce early and late fusionapproaches for fusing different modalities or concatenate the representationsof the different modalities during training, thus the inter-modal interactionsare not captured. To tackle these limitations, first we exploit a NeuralArchitecture Search (NAS) method to automatically find a high performing CNNarchitecture. Next, we exploit several fusion methods, including MultimodalFactorized Bilinear Pooling and Tucker Decomposition, to combine both speechand text modalities. To the best of our knowledge, there is no prior workexploiting a NAS approach and these fusion methods in the task of dementiadetection from spontaneous speech. We perform extensive experiments on theADReSS Challenge dataset and show the effectiveness of our approach overstate-of-the-art methods.", "output": "Neural Architecture Search with Multimodal Fusion Methods for Diagnosing Dementia."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we present InstructABSA, Aspect Based Sentiment Analysis(ABSA) using the instruction learning paradigm for all ABSA subtasks: AspectTerm Extraction (ATE), Aspect Term Sentiment Classification (ATSC), and JointTask modeling. Our method introduces positive, negative, and neutral examplesto each training sample, and instruction tunes the model (Tk-Instruct) for eachABSA subtask, yielding significant performance improvements. Experimentalresults on the Sem Eval 2014, 15, and 16 datasets demonstrate that InstructABSAoutperforms the previous state-of-the-art (SOTA) approaches on all three ABSAsubtasks (ATE, ATSC, and Joint Task) by a significant margin, outperforming 7xlarger models. In particular, InstructABSA surpasses the SOTA on the Rest14 ATEsubtask by 7.31% points, Rest15 ATSC subtask by and on the Lapt14 Joint Task by8.63% points. Our results also suggest a strong generalization ability to newdomains across all three subtasks", "output": "InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we introduce a novel unsupervised, graph-based filter featureselection technique which exploits the power of topologically constrainednetwork representations. We model dependency structures among features using afamily of chordal graphs (the Triangulated Maximally Filtered Graph), and wemaximise the likelihood of features' relevance by studying their relativeposition inside the network. Such an approach presents three aspects that areparticularly satisfactory compared to its alternatives: (i) it is highlytunable and easily adaptable to the nature of input data; (ii) it is fullyexplainable, maintaining, at the same time, a remarkable level of simplicity;(iii) it is computationally cheaper compared to its alternatives. We test ouralgorithm on 16 benchmark datasets from different applicative domains showingthat it outperforms or matches the current state-of-the-art under heterogeneousevaluation conditions.", "output": "Topological Feature Selection: A Graph-Based Filter Feature Selection Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The political stance prediction for news articles has been widely studied tomitigate the echo chamber effect -- people fall into their thoughts andreinforce their pre-existing beliefs. The previous works for the politicalstance problem focus on (1) identifying political factors that could reflectthe political stance of a news article and (2) capturing those factorseffectively. Despite their empirical successes, they are not sufficientlyjustified in terms of how effective their identified factors are in thepolitical stance prediction. Motivated by this, in this work, we conduct a userstudy to investigate important factors in political stance prediction, andobserve that the context and tone of a news article (implicit) and externalknowledge for real-world entities appearing in the article (explicit) areimportant in determining its political stance. Based on this observation, wepropose a novel knowledge-aware approach to political stance prediction (KHAN),employing (1) hierarchical attention networks (HAN) to learn the relationshipsamong words and sentences in three different levels and (2) knowledge encoding(KE) to incorporate external knowledge for real-world entities into the processof political stance prediction. Also, to take into account the subtle andimportant difference between opposite political stances, we build twoindependent political knowledge graphs (KG) (i.e., KG-lib and KG-con) byourselves and learn to fuse the different political knowledge. Throughextensive evaluations on three real-world datasets, we demonstrate thesuperiority of DASH in terms of (1) accuracy, (2) efficiency, and (3)effectiveness.", "output": "KHAN: Knowledge-Aware Hierarchical Attention Networks for Accurate Political Stance Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The transferability of adversarial perturbations between image models hasbeen extensively studied. In this case, an attack is generated from a knownsurrogate eg, the ImageNet trained model, and transferred to change thedecision of an unknown (black-box) model trained on an image dataset. However,attacks generated from image models do not capture the dynamic nature of amoving object or a changing scene due to a lack of temporal cues within imagemodels. This leads to reduced transferability of adversarial attacks fromrepresentation-enriched emph{image} models such as Supervised VisionTransformers (ViTs), Self-supervised ViTs (eg, DINO), and Vision-languagemodels (eg, CLIP) to black-box emph{video} models. In this work, we inducedynamic cues within the image models without sacrificing their originalperformance on images. To this end, we optimize emph{temporal prompts} throughfrozen image models to capture motion dynamics. Our temporal prompts are theresult of a learnable transformation that allows optimizing for temporalgradients during an adversarial attack to fool the motion dynamics.Specifically, we introduce spatial (image) and temporal (video) cues within thesame source model through task-specific prompts. Attacking such promptsmaximizes the adversarial transferability from image-to-video andimage-to-image models using the attacks designed for image models. Our attackresults indicate that the attacker does not need specialized architectures,eg, divided space-time attention, 3D convolutions, or multi-view convolutionnetworks for different data modalities. Image models are effective surrogatesto optimize an adversarial attack to fool black-box models in a changingenvironment over time. Code is available at ", "output": "Boosting Adversarial Transferability using Dynamic Cues."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Most of the available user information can be represented as a sequence oftimestamped events. Each event is assigned a set of categorical labels whosefuture structure is of great interest. For instance, our goal is to predict agroup of items in the next customer's purchase or tomorrow's clienttransactions. This is a multi-label classification problem for sequential data.Modern approaches focus on transformer architecture for sequential dataintroducing self-attention for the elements in a sequence. In that case, wetake into account events' time interactions but lose information on labelinter-dependencies. Motivated by this shortcoming, we propose leveraging aself-attention mechanism over labels preceding the predicted step. As ourapproach is a Label-Attention NETwork, we call it LANET. Experimental evidencesuggests that LANET outperforms the established models' performance and greatlycaptures interconnections between labels. For example, the micro-AUC of ourapproach is $0.9536$ compared to $0.7501$ for a vanilla transformer. We providean implementation of LANET to facilitate its wider usage.", "output": "Label Attention Network for sequential multi-label classification: you were looking at a wrong self-attention."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep Neural Networks (DNNs) are being used to solve a wide range of problemsin many domains including safety-critical domains like self-driving cars andmedical imagery. DNNs suffer from vulnerability against adversarial attacks. Inthe past few years, numerous approaches have been proposed to tackle thisproblem by training networks using adversarial training. Almost all theapproaches generate adversarial examples for the entire training dataset, thusincreasing the training time drastically. We show that we can decrease thetraining time for any adversarial training algorithm by using only a subset oftraining data for adversarial training. To select the subset, we filter theadversarially-prone samples from the training data. We perform a simpleadversarial attack on all training examples to filter this subset. In thisattack, we add a small perturbation to each pixel and a few grid lines to theinput image.We perform adversarial training on the adversarially-prone subset and mix itwith vanilla training performed on the entire dataset. Our results show thatwhen our method-agnostic approach is plugged into FGSM, we achieve a speedup of3.52x on MNIST and 1.98x on the CIFAR-10 dataset with comparable robustaccuracy. We also test our approach on state-of-the-art Free adversarialtraining and achieve a speedup of 1.2x in training time with a marginal drop inrobust accuracy on the ImageNet dataset.", "output": "Do we need entire training data for adversarial training?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vibration signals have been increasingly utilized in various engineeringfields for analysis and monitoring purposes, including structural healthmonitoring, fault diagnosis and damage detection, where vibration signals canprovide valuable information about the condition and integrity of structures.In recent years, there has been a growing trend towards the use of vibrationsignals in the field of bioengineering. Activity-induced structural vibrations,particularly footstep-induced signals, are useful for analyzing the movement ofbiological systems such as the human body and animals. Footstep-induced signalscan provide valuable information about an individual's gait, body mass, andposture, making them an attractive tool for health monitoring, security, andhuman-computer interaction. However, the presence of various types of noise cancompromise the accuracy of footstep-induced signal analysis. In this paper, wepropose a novel 'many-to-many' LSTM model with a KLD regularizer and L1regularization, which is effective in denoising structural vibration signals,particularly for regimes with larger amplitudes. The model was trained andtested using synthetic data generated by a single degree of freedom oscillator.Our results demonstrate that the proposed approach is effective in reducingnoise in the signals, particularly for regimes with larger amplitudes. Theapproach is promising for a wide range of applications of footstep-inducedstructural vibration signals, including healthcare, security, and technology.", "output": "Structural Vibration Signal Denoising Using KLD Regularized Bi-Directional LSTM."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent years have seen development of descriptor generation based onrepresentation learning of extremely diverse molecules, especially those thatapply natural language processing (NLP) models to SMILES, a literalrepresentation of molecular structure. However, little research has been doneon how these models understand chemical structure. To address this, weinvestigated the relationship between the learning progress of SMILES andchemical structure using a representative NLP model, the Transformer. Theresults suggest that while the Transformer learns partial structures ofmolecules quickly, it requires extended training to understand overallstructures. Consistently, the accuracy of molecular property predictions usingdescriptors generated from models at different learning steps was similar fromthe beginning to the end of training. Furthermore, we found that theTransformer requires particularly long training to learn chirality andsometimes stagnates with low translation accuracy due to misunderstanding ofenantiomers. These findings are expected to deepen understanding of NLP modelsin chemistry.", "output": "Difficulty in learning chirality for Transformer fed with SMILES."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The view inconsistency problem in score-distilling text-to-3D generation,also known as the Janus problem, arises from the intrinsic bias of 2D diffusionmodels, which leads to the unrealistic generation of 3D objects. In this work,we explore score-distilling text-to-3D generation and identify the main causesof the Janus problem. Based on these findings, we propose two approaches todebias the score-distillation frameworks for robust text-to-3D generation. Ourfirst approach, called score debiasing, involves gradually increasing thetruncation value for the score estimated by 2D diffusion models throughout theoptimization process. Our second approach, called prompt debiasing, identifiesconflicting words between user prompts and view prompts utilizing a languagemodel and adjusts the discrepancy between view prompts and object-space cameraposes. Our experimental results show that our methods improve realism bysignificantly reducing artifacts and achieve a good trade-off betweenfaithfulness to the 2D diffusion models and 3D consistency with littleoverhead.", "output": "Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In many research fields in artificial intelligence, it has been shown thatdeep neural networks are useful to estimate unknown functions on highdimensional input spaces. However, their generalization performance is not yetcompletely clarified from the theoretical point of view because they arenonidentifiable and singular learning machines. Moreover, a ReLU function isnot differentiable, to which algebraic or analytic methods in singular learningtheory cannot be applied. In this paper, we study a deep ReLU neural network inoverparametrized cases and prove that the Bayesian free energy, which is equalto the minus log marginal likelihoodor the Bayesian stochastic complexity, isbounded even if the number of layers are larger than necessary to estimate anunknown data-generating function. Since the Bayesian generalization error isequal to the increase of the free energy as a function of a sample size, ourresult also shows that the Bayesian generalization error does not increase evenif a deep ReLU neural network is designed to be sufficiently large or in anopeverparametrized state.", "output": "Bayesian Free Energy of Deep ReLU Neural Network in Overparametrized Cases."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present emph{TabRet}, a pre-trainable Transformer-based model for tabulardata. TabRet is designed to work on a downstream task that contains columns notseen in pre-training. Unlike other methods, TabRet has an extra learning stepbefore fine-tuning called emph{retokenizing}, which calibrates featureembeddings based on the masked autoencoding loss. In experiments, wepre-trained TabRet with a large collection of public health surveys andfine-tuned it on classification tasks in healthcare, and TabRet achieved thebest AUC performance on four datasets. In addition, an ablation study showsretokenizing and random shuffle augmentation of columns during pre-trainingcontributed to performance gains.", "output": "TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Hyperspectral imaging acquires data in both the spatial and frequency domainsto offer abundant physical or biological information. However, conventionalhyperspectral imaging has intrinsic limitations of bulky instruments, slow dataacquisition rate, and spatiospectral tradeoff. Here we introduce hyperspectrallearning for snapshot hyperspectral imaging in which sampled hyperspectral datain a small subarea are incorporated into a learning algorithm to recover thehypercube. Hyperspectral learning exploits the idea that a photograph is morethan merely a picture and contains detailed spectral information. A smallsampling of hyperspectral data enables spectrally informed learning to recovera hypercube from an RGB image. Hyperspectral learning is capable of recoveringfull spectroscopic resolution in the hypercube, comparable to high spectralresolutions of scientific spectrometers. Hyperspectral learning also enablesultrafast dynamic imaging, leveraging ultraslow video recording in anoff-the-shelf smartphone, given that a video comprises a time series ofmultiple RGB images. To demonstrate its versatility, an experimental model ofvascular development is used to extract hemodynamic parameters via statisticaland deep-learning approaches. Subsequently, the hemodynamics of peripheralmicrocirculation is assessed at an ultrafast temporal resolution up to amillisecond, using a conventional smartphone camera. This spectrally informedlearning method is analogous to compressed sensing; however, it further allowsfor reliable hypercube recovery and key feature extractions with a transparentlearning algorithm. This learning-powered snapshot hyperspectral imaging methodyields high spectral and temporal resolutions and eliminates the spatiospectraltradeoff, offering simple hardware requirements and potential applications ofvarious machine-learning techniques.", "output": "mHealth hyperspectral learning for instantaneous spatiospectral imaging of hemodynamics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Classical results in neural network approximation theory show how arbitrarycontinuous functions can be approximated by networks with a single hiddenlayer, under mild assumptions on the activation function. However, theclassical theory does not give a constructive means to generate the networkparameters that achieve a desired accuracy. Recent results have demonstratedthat for specialized activation functions, such as ReLUs and some classes ofanalytic functions, high accuracy can be achieved via linear combinations ofrandomly initialized activations. These recent works utilize specializedintegral representations of target functions that depend on the specificactivation functions used. This paper defines mollified integralrepresentations, which provide a means to form integral representations oftarget functions using activations for which no direct integral representationis currently known. The new construction enables approximation guarantees forrandomly initialized networks for a variety of widely used activationfunctions.", "output": "Function Approximation with Randomly Initialized Neural Networks for Approximate Model Reference Adaptive Control."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reducing the computational cost of running large scale neural networks usingsparsity has attracted great attention in the deep learning community. Whilemuch success has been achieved in reducing FLOP and parameter counts whilemaintaining acceptable task performance, achieving actual speed improvementshas typically been much more difficult, particularly on general purposeaccelerators (GPAs) such as NVIDIA GPUs using low precision number formats. Inthis work we introduce PopSparse, a library that enables fast sparse operationson Graphcore IPUs by leveraging both the unique hardware characteristics ofIPUs as well as any block structure defined in the data. We target twodifferent types of sparsity: static, where the sparsity pattern is fixed atcompile-time; and dynamic, where it can change each time the model is run. Wepresent benchmark results for matrix multiplication for both of these modes onIPU with a range of block sizes, matrix sizes and densities. Results indicatethat the PopSparse implementations are faster than dense matrix multiplicationson IPU at a range of sparsity levels with large matrix size and block size.Furthermore, static sparsity in general outperforms dynamic sparsity. Whileprevious work on GPAs has shown speedups only for very high sparsity (typically99% and above), the present work demonstrates that our static sparseimplementation outperforms equivalent dense calculations in FP16 at lowersparsity (around 90%). IPU code is available to view and run atipu.dev/sparsity-benchmarks, GPU code will be made available shortly.", "output": "PopSparse: Accelerated block sparse matrix multiplication on IPU."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "For Human Action Recognition tasks (HAR), 3D Convolutional Neural Networkshave proven to be highly effective, achieving state-of-the-art results. Thisstudy introduces a novel streaming architecture based toolflow for mapping suchmodels onto FPGAs considering the model's inherent characteristics and thefeatures of the targeted FPGA device. The HARFLOW3D toolflow takes as input a3D CNN in ONNX format and a description of the FPGA characteristics, generatinga design that minimizes the latency of the computation. The toolflow iscomprised of a number of parts, including i) a 3D CNN parser, ii) a performanceand resource model, iii) a scheduling algorithm for executing 3D models on thegenerated hardware, iv) a resource-aware optimization engine tailored for 3Dmodels, v) an automated mapping to synthesizable code for FPGAs. The ability ofthe toolflow to support a broad range of models and devices is shown through anumber of experiments on various 3D CNN and FPGA system pairs. Furthermore, thetoolflow has produced high-performing results for 3D CNN models that have notbeen mapped to FPGAs before, demonstrating the potential of FPGA-based systemsin this space. Overall, HARFLOW3D has demonstrated its ability to delivercompetitive latency compared to a range of state-of-the-art hand-tunedapproaches being able to achieve up to 5$times$ better performance compared tosome of the existing works.", "output": "HARFLOW3D: A Latency-Oriented 3D-CNN Accelerator Toolflow for HAR on FPGA Devices."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the machine learning domain, research on anomaly detection andlocalization within image data has garnered significant attention, particularlyin practical applications such as industrial defect detection. While existingapproaches predominantly rely on Convolutional Neural Networks (CNN) as theirbackbone network, we propose an innovative method based on the Transformerbackbone network. Our approach employs a two-stage incremental learningstrategy. In the first stage, we train a Masked Autoencoder (MAE) modelexclusively on normal images. Subsequently, in the second stage, we implementpixel-level data augmentation techniques to generate corrupted normal imagesand their corresponding pixel labels. This process enables the model to learnhow to repair corrupted regions and classify the state of each pixel.Ultimately, the model produces a pixel reconstruction error matrix and a pixelanomaly probability matrix, which are combined to create an anomaly scoringmatrix that effectively identifies abnormal regions. When compared to severalstate-of-the-art CNN-based techniques, our method demonstrates superiorperformance on the MVTec AD dataset, achieving an impressive 97.6% AUC.", "output": "Incremental Self-Supervised Learning Based on Transformer for Anomaly Detection and Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine Learning (ML) models are widely employed to drive many modern datasystems. While they are undeniably powerful tools, ML models often demonstrateimbalanced performance and unfair behaviors. The root of this problem oftenlies in the fact that different subpopulations commonly display divergenttrends: as a learning algorithm tries to identify trends in the data, itnaturally favors the trends of the majority groups, leading to a model thatperforms poorly and unfairly for minority populations. Our goal is to improvethe fairness and trustworthiness of ML models by applying only non-invasiveinterventions, i.e., without altering the data or the learning algorithm. Weuse a simple but key insight: the divergence of trends between differentpopulations, and, consecutively, between a learned model and minoritypopulations, is analogous to data drift, which indicates the poor conformancebetween parts of the data and the trained model. We explore two strategies(model-splitting and reweighing) to resolve this drift, aiming to improve theoverall conformance of models to the underlying data. Both our methodsintroduce novel ways to employ the recently-proposed data profiling primitiveof Conformance Constraints. Our experimental evaluation over 7 real-worlddatasets shows that both DifFair and ConFair improve the fairness of ML models.We demonstrate scenarios where DifFair has an edge, though ConFair has thegreatest practical impact and outperforms other baselines. Moreover, as amodel-agnostic technique, ConFair stays robust when used against differentmodels than the ones on which the weights have been learned, which is not thecase for other state of the art.", "output": "Non-Invasive Fairness in Learning through the Lens of Data Drift."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes a new method for anomaly detection in time-series data byincorporating the concept of difference subspace into the singular spectrumanalysis (SSA). The key idea is to monitor slight temporal variations of thedifference subspace between two signal subspaces corresponding to the past andpresent time-series data, as anomaly score. It is a natural generalization ofthe conventional SSA-based method which measures the minimum angle between thetwo signal subspaces as the degree of changes. By replacing the minimum anglewith the difference subspace, our method boosts the performance while using theSSA-based framework as it can capture the whole structural difference betweenthe two subspaces in its magnitude and direction. We demonstrate our method'seffectiveness through performance evaluations on public time-series datasets.", "output": "Time-series Anomaly Detection based on Difference Subspace between Signal Subspaces."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, deep learning has been widely used in SAR ATR and achievedexcellent performance on the MSTAR dataset. However, due to constrained imagingconditions, MSTAR has data biases such as background correlation, i.e.,background clutter properties have a spurious correlation with target classes.Deep learning can overfit clutter to reduce training errors. Therefore, thedegree of overfitting for clutter reflects the non-causality of deep learningin SAR ATR. Existing methods only qualitatively analyze this phenomenon. Inthis paper, we quantify the contributions of different regions to targetrecognition based on the Shapley value. The Shapley value of clutter measuresthe degree of overfitting. Moreover, we explain how data bias and model biascontribute to non-causality. Concisely, data bias leads to comparablesignal-to-clutter ratios and clutter textures in training and test sets. Andvarious model structures have different degrees of overfitting for thesebiases. The experimental results of various models under standard operatingconditions on the MSTAR dataset support our conclusions. Our code is availableat ", "output": "Discovering and Explaining the Non-Causality of Deep Learning in SAR ATR."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Audio editing is applicable for various purposes, such as adding backgroundsound effects, replacing a musical instrument, and repairing damaged audio.Recently, some diffusion-based methods achieved zero-shot audio editing byusing a diffusion and denoising process conditioned on the text description ofthe output audio. However, these methods still have some problems: 1) they havenot been trained on editing tasks and cannot ensure good editing effects; 2)they can erroneously modify audio segments that do not require editing; 3) theyneed a complete description of the output audio, which is not always availableor necessary in practical scenarios. In this work, we propose AUDIT, aninstruction-guided audio editing model based on latent diffusion models.Specifically, AUDIT has three main design features: 1) we construct triplettraining data (instruction, input audio, output audio) for different audioediting tasks and train a diffusion model using instruction and input (to beedited) audio as conditions and generating output (edited) audio; 2) it canautomatically learn to only modify segments that need to be edited by comparingthe difference between the input and output audio; 3) it only needs editinstructions instead of full target audio descriptions as text input. AUDITachieves state-of-the-art results in both objective and subjective metrics forseveral audio editing tasks (e.g., adding, dropping, replacement, inpainting,super-resolution). Demo samples are available at ", "output": "AUDIT: Audio Editing by Following Instructions with Latent Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This report serves as a supplementary document for TaskPrompter, detailingits implementation on a new joint 2D-3D multi-task learning benchmark based onCityscapes-3D. TaskPrompter presents an innovative multi-task promptingframework that unifies the learning of (i) task-generic representations, (ii)task-specific representations, and (iii) cross-task interactions, as opposed toprevious approaches that separate these learning objectives into differentnetwork modules. This unified approach not only reduces the need for meticulousempirical structure design but also significantly enhances the multi-tasknetwork's representation learning capability, as the entire model capacity isdevoted to optimizing the three objectives simultaneously. TaskPrompterintroduces a new multi-task benchmark based on Cityscapes-3D dataset, whichrequires the multi-task model to concurrently generate predictions formonocular 3D vehicle detection, semantic segmentation, and monocular depthestimation. These tasks are essential for achieving a joint 2D-3D understandingof visual scenes, particularly in the development of autonomous drivingsystems. On this challenging benchmark, our multi-task model demonstratesstrong performance compared to single-task state-of-the-art methods andestablishes new state-of-the-art results on the challenging 3D detection anddepth estimation tasks.", "output": "Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In goal-reaching reinforcement learning (RL), the optimal value function hasa particular geometry, called quasimetric structure. This paper introducesQuasimetric Reinforcement Learning (QRL), a new RL method that utilizesquasimetric models to learn optimal value functions. Distinct from priorapproaches, the QRL objective is specifically designed for quasimetrics, andprovides strong theoretical recovery guarantees. Empirically, we conductthorough analyses on a discretized MountainCar environment, identifyingproperties of QRL and its advantages over alternatives. On offline and onlinegoal-reaching benchmarks, QRL also demonstrates improved sample efficiency andperformance, across both state-based and image-based observations.", "output": "Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural networks (NNs) playing the role of controllers have demonstratedimpressive empirical performances on challenging control problems. However, thepotential adoption of NN controllers in real-life applications also gives riseto a growing concern over the safety of these neural-network controlled systems(NNCSs), especially when used in safety-critical applications. In this work, wepresent POLAR-Express, an efficient and precise formal reachability analysistool for verifying the safety of NNCSs. POLAR-Express uses Taylor modelarithmetic to propagate Taylor models (TMs) across a neural networklayer-by-layer to compute an overapproximation of the neural-network function.It can be applied to analyze any feed-forward neural network with continuousactivation functions. We also present a novel approach to propagate TMs moreefficiently and precisely across ReLU activation functions. In addition,POLAR-Express provides parallel computation support for the layer-by-layerpropagation of TMs, thus significantly improving the efficiency and scalabilityover its earlier prototype POLAR. Across the comparison with six otherstate-of-the-art tools on a diverse set of benchmarks, POLAR-Express achievesthe best verification efficiency and tightness in the reachable set analysis.", "output": "POLAR-Express: Efficient and Precise Formal Reachability Analysis of Neural-Network Controlled Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pain is a common reason for accessing healthcare resources and is a growingarea of research, especially in its overlap with mental health. Mental healthelectronic health records are a good data source to study this overlap.However, much information on pain is held in the free text of these records,where mentions of pain present a unique natural language processing problem dueto its ambiguous nature. This project uses data from an anonymised mentalhealth electronic health records database. The data are used to train a machinelearning based classification algorithm to classify sentences as discussingpatient pain or not. This will facilitate the extraction of relevant paininformation from large databases, and the use of such outputs for furtherstudies on pain and mental health. 1,985 documents were manuallytriple-annotated for creation of gold standard training data, which was used totrain three commonly used classification algorithms. The best performing modelachieved an F1-score of 0.98 (95% CI 0.98-0.99).", "output": "Identifying Mentions of Pain in Mental Health Records Text: A Natural Language Processing Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Structured, or tabular, data is the most common format in data science. Whiledeep learning models have proven formidable in learning from unstructured datasuch as images or speech, they are less accurate than simpler approaches whenlearning from tabular data. In contrast, modern tree-based Machine Learning(ML) models shine in extracting relevant information from structured data. Anessential requirement in data science is to reduce model inference latency incases where, for example, models are used in a closed loop with simulation toaccelerate scientific discovery. However, the hardware acceleration communityhas mostly focused on deep neural networks and largely ignored other forms ofmachine learning. Previous work has described the use of an analog contentaddressable memory (CAM) component for efficiently mapping random forests. Inthis work, we focus on an overall analog-digital architecture implementing anovel increased precision analog CAM and a programmable network on chipallowing the inference of state-of-the-art tree-based ML models, such asXGBoost and CatBoost. Results evaluated in a single chip at 16nm technologyshow 119x lower latency at 9740x higher throughput compared with astate-of-the-art GPU, with a 19W peak power consumption.", "output": "X-TIME: An in-memory engine for accelerating machine learning on tabular data with CAMs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "ChatGPT has become a global sensation. As ChatGPT and other Large LanguageModels (LLMs) emerge, concerns of misusing them in various ways increase, suchas disseminating fake news, plagiarism, manipulating public opinion, cheating,and fraud. Hence, distinguishing AI-generated from human-generated becomesincreasingly essential. Researchers have proposed various detectionmethodologies, ranging from basic binary classifiers to more complexdeep-learning models. Some detection techniques rely on statisticalcharacteristics or syntactic patterns, while others incorporate semantic orcontextual information to improve accuracy. The primary objective of this studyis to provide a comprehensive and contemporary assessment of the most recenttechniques in ChatGPT detection. Additionally, we evaluated other AI-generatedtext detection tools that do not specifically claim to detect ChatGPT-generatedcontent to assess their performance in detecting ChatGPT-generated content. Forour evaluation, we have curated a benchmark dataset consisting of prompts fromChatGPT and humans, including diverse questions from medical, open Q&amp;A, andfinance domains and user-generated responses from popular social networkingplatforms. The dataset serves as a reference to assess the performance ofvarious techniques in detecting ChatGPT-generated content. Our evaluationresults demonstrate that none of the existing methods can effectively detectChatGPT-generated content.", "output": "To ChatGPT, or not to ChatGPT: That is the question!."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce HATELEXICON, a lexicon of slurs and targets of hate speech forthe countries of Brazil, Germany, India and Kenya, to aid training andinterpretability of models. We demonstrate how our lexicon can be used tointerpret model predictions, showing that models developed to classify extremespeech rely heavily on target words when making predictions. Further, wepropose a method to aid shot selection for training in low-resource settingsvia HATELEXICON. In few-shot learning, the selection of shots is of paramountimportance to model performance. In our work, we simulate a few-shot settingfor German and Hindi, using HASOC data for training and the MultilingualHateCheck (MHC) as a benchmark. We show that selecting shots based on ourlexicon leads to models performing better on MHC than models trained on shotssampled randomly. Thus, when given only a few training examples, using ourlexicon to select shots containing more sociocultural information leads tobetter few-shot performance.", "output": "Sociocultural knowledge is needed for selection of shots in hate speech detection tasks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present dual-attention neural biasing, an architecture designed to boostWake Words (WW) recognition and improve inference time latency on speechrecognition tasks. This architecture enables a dynamic switch for its runtimecompute paths by exploiting WW spotting to select which branch of its attentionnetworks to execute for an input audio frame. With this approach, weeffectively improve WW spotting accuracy while saving runtime compute cost asdefined by floating point operations (FLOPs). Using an in-house de-identifieddataset, we demonstrate that the proposed dual-attention network can reduce thecompute cost by $90%$ for WW audio frames, with only $1%$ increase in thenumber of parameters. This architecture improves WW F1 score by $16%$ relativeand improves generic rare word error rate by $3%$ relative compared to thebaselines.", "output": "Dual-Attention Neural Transducers for Efficient Wake Word Spotting in Speech Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents a novel Diffusion-Wavelet (DiWa) approach forSingle-Image Super-Resolution (SISR). It leverages the strengths of DenoisingDiffusion Probabilistic Models (DDPMs) and Discrete Wavelet Transformation(DWT). By enabling DDPMs to operate in the DWT domain, our DDPM modelseffectively hallucinate high-frequency information for super-resolved images onthe wavelet spectrum, resulting in high-quality and detailed reconstructions inimage space. Quantitatively, we outperform state-of-the-art diffusion-basedSISR methods, namely SR3 and SRDiff, regarding PSNR, SSIM, and LPIPS on bothface (8x scaling) and general (4x scaling) SR benchmarks. Meanwhile, using DWTenabled us to use fewer parameters than the compared models: 92M parametersinstead of 550M compared to SR3 and 9.3M instead of 12M compared to SRDiff.Additionally, our method outperforms other state-of-the-art generative methodson classical general SR datasets while saving inference time. Finally, our workhighlights its potential for various applications.", "output": "Waving Goodbye to Low-Res: A Diffusion-Wavelet Approach for Image Super-Resolution."}]