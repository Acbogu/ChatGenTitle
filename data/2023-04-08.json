[{"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we consider the problem of probabilistic stability analysis ofa subclass of Stochastic Hybrid Systems, namely, Polyhedral ProbabilisticHybrid Systems (PPHS), where the flow dynamics is given by a polyhedralinclusion, the discrete switching between modes happens probabilistically atthe boundaries of their invariant regions and the continuous state is not resetduring switching. We present an abstraction-based analysis framework thatconsists of constructing a finite Markov Decision Processes (MDP) such thatverification of certain property on the finite MDP ensures the satisfaction ofprobabilistic stability on the PPHS. Further, we present a polynomial-timealgorithm for verifying the corresponding property on the MDP. Our experimentalanalysis demonstrates the feasibility of the approach in successfully verifyingprobabilistic stability on PPHS of various dimensions and sizes.", "output": "Abstraction-based Probabilistic Stability Analysis of Polyhedral Probabilistic Hybrid Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large language models (LLM) not only empower multiple language tasks but alsoserve as a general interface across different spaces. Up to now, it has notbeen demonstrated yet how to effectively translate the successes of LLMs in thecomputer vision field to the medical imaging field which involveshigh-dimensional and multi-modal medical images. In this paper, we report afeasibility study of building a multi-task CT large image-text (LIT) model forlung cancer diagnosis by combining an LLM and a large image model (LIM).Specifically, the LLM and LIM are used as encoders to perceive multi-modalinformation under task-specific text prompts, which synergizes multi-sourceinformation and task-specific and patient-specific priors for optimizeddiagnostic performance. The key components of our LIT model and associatedtechniques are evaluated with an emphasis on 3D lung CT analysis. Our initialresults show that the LIT model performs multiple medical tasks well, includinglung segmentation, lung nodule detection, and lung cancer classification.Active efforts are in progress to develop large image-language models forsuperior medical imaging in diverse applications and optimal patient outcomes.", "output": "CT Multi-Task Learning with a Large Image-Text (LIT) Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we present an Adaptive Ensemble Learning framework that aimsto boost the performance of deep neural networks by intelligently fusingfeatures through ensemble learning techniques. The proposed frameworkintegrates ensemble learning strategies with deep learning architectures tocreate a more robust and adaptable model capable of handling complex tasksacross various domains. By leveraging intelligent feature fusion methods, theAdaptive Ensemble Learning framework generates more discriminative andeffective feature representations, leading to improved model performance andgeneralization capabilities.We conducted extensive experiments and evaluations on several benchmarkdatasets, including image classification, object detection, natural languageprocessing, and graph-based learning tasks. The results demonstrate that theproposed framework consistently outperforms baseline models and traditionalfeature fusion techniques, highlighting its effectiveness in enhancing deeplearning models' performance. Furthermore, we provide insights into the impactof intelligent feature fusion on model performance and discuss the potentialapplications of the Adaptive Ensemble Learning framework in real-worldscenarios.The paper also explores the design and implementation of adaptive ensemblemodels, ensemble training strategies, and meta-learning techniques, whichcontribute to the framework's versatility and adaptability. In conclusion, theAdaptive Ensemble Learning framework represents a significant advancement inthe field of feature fusion and ensemble learning for deep neural networks,with the potential to transform a wide range of applications across multipledomains.", "output": "Adaptive Ensemble Learning: Boosting Model Performance through Intelligent Feature Fusion in Deep Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Backpropagation has rapidly become the workhorse credit assignment algorithmfor modern deep learning methods. Recently, modified forms of predictive coding(PC), an algorithm with origins in computational neuroscience, have been shownto result in approximately or exactly equal parameter updates to those underbackpropagation. Due to this connection, it has been suggested that PC can actas an alternative to backpropagation with desirable properties that mayfacilitate implementation in neuromorphic systems. Here, we explore theseclaims using the different contemporary PC variants proposed in the literature.We obtain time complexity bounds for these PC variants which we show arelower-bounded by backpropagation. We also present key properties of thesevariants that have implications for neurobiological plausibility and theirinterpretations, particularly from the perspective of standard PC as avariational Bayes algorithm for latent probabilistic models. Our findings shednew light on the connection between the two learning frameworks and suggestthat, in its current forms, PC may have more limited potential as a directreplacement of backpropagation than previously envisioned.", "output": "Predictive Coding as a Neuromorphic Alternative to Backpropagation: A Critical Evaluation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Medical data often exhibits long-tail distributions with heavy classimbalance, which naturally leads to difficulty in classifying the minorityclasses (i.e., boundary regions or rare objects). Recent work has significantlyimproved semi-supervised medical image segmentation in long-tailed scenarios byequipping them with unsupervised contrastive criteria. However, it remainsunclear how well they will perform in the labeled portion of data where classdistribution is also highly imbalanced. In this work, we present ACTION++, animproved contrastive learning framework with adaptive anatomical contrast forsemi-supervised medical segmentation. Specifically, we propose an adaptivesupervised contrastive loss, where we first compute the optimal locations ofclass centers uniformly distributed on the embedding space (i.e., off-line),and then perform online contrastive matching training by encouraging differentclass features to adaptively match these distinct and uniformly distributedclass centers. Moreover, we argue that blindly adopting a constant temperature$tau$ in the contrastive loss on long-tailed medical data is not optimal, andpropose to use a dynamic $tau$ via a simple cosine schedule to yield betterseparation between majority and minority classes. Empirically, we evaluateACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-artacross two semi-supervised settings. Theoretically, we analyze the performanceof adaptive anatomical contrast and confirm its superiority in labelefficiency.", "output": "ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Creating knowledge bases and ontologies is a time consuming task that relieson a manual curation. AI/NLP approaches can assist expert curators inpopulating these knowledge bases, but current approaches rely on extensivetraining data, and are not able to populate arbitrary complex nested knowledgeschemas.Here we present Structured Prompt Interrogation and Recursive Extraction ofSemantics (SPIRES), a Knowledge Extraction approach that relies on the abilityof Large Language Models (LLMs) to perform zero-shot learning (ZSL) andgeneral-purpose query answering from flexible prompts and return informationconforming to a specified schema. Given a detailed, user-defined knowledgeschema and an input text, SPIRES recursively performs prompt interrogationagainst GPT-3+ to obtain a set of responses matching the provided schema.SPIRES uses existing ontologies and vocabularies to provide identifiers for allmatched elements.We present examples of use of SPIRES in different domains, includingextraction of food recipes, multi-species cellular signaling pathways, diseasetreatments, multi-step drug mechanisms, and chemical to disease causationgraphs. Current SPIRES accuracy is comparable to the mid-range of existingRelation Extraction (RE) methods, but has the advantage of easy customization,flexibility, and, crucially, the ability to perform new tasks in the absence ofany training data. This method supports a general strategy of leveraging thelanguage interpreting capabilities of LLMs to assemble knowledge bases,assisting manual knowledge curation and acquisition while supporting validationwith publicly-available databases and ontologies external to the LLM.SPIRES is available as part of the open source OntoGPT package: monarch-initiative/ontogpt.", "output": "Structured prompt interrogation and recursive extraction of semantics (SPIRES): A method for populating knowledge bases using zero-shot learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Sequence-to-sequence language models can be used to produce abstractivesummaries which are coherent, relevant, and concise. Still, model sizes canmake deployment in latency-sensitive or web-scale implementations difficult.This paper studies the relationship between model size, structured pruning,inference efficiency, and summarization accuracy on widely used summarizationdatasets. We show that model accuracy is tied to the encoder size whileinference efficiency is connected to the decoder. Using asymmetric pruning canlead to nearly 3x improvement in inference latency with ~1 point loss inRouge-2. Moreover, we find both the average degradation and the role ofasymmetry to be consistent across model sizes and variations in datasets.", "output": "To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in the areas of Multimodal Machine Learning and ArtificialIntelligence (AI) have led to the development of challenging tasks at theintersection of Computer Vision, Natural Language Processing, and Robotics.Whereas many approaches and previous survey pursuits have characterised one ortwo of these dimensions, there has not been a holistic analysis at the centerof all three. Moreover, even when combinations of these topics are considered,more focus is placed on describing, e.g., current architectural methods, asopposed to also illustrating high-level challenges and opportunities for thefield. In this survey paper, we discuss Embodied Vision-Language Planning(EVLP) tasks, a family of prominent embodied navigation and manipulationproblems that jointly leverage computer vision and natural language forinteraction in physical environments. We propose a taxonomy to unify thesetasks and provide an in-depth analysis and comparison of the current and newalgorithmic approaches, metrics, simulators, and datasets used for EVLP tasks.Finally, we present the core challenges that we believe new EVLP works shouldseek to address, and we advocate for task construction that enables modelgeneralisability and furthers real-world deployment.", "output": "Core Challenges in Embodied Vision-Language Planning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper investigates the potential of semi-supervised GenerativeAdversarial Networks (GANs) to fine-tune pretrained language models in order toclassify Bengali fake reviews from real reviews with a few annotated data. Withthe rise of social media and e-commerce, the ability to detect fake ordeceptive reviews is becoming increasingly important in order to protectconsumers from being misled by false information. Any machine learning modelwill have trouble identifying a fake review, especially for a low resourcelanguage like Bengali. We have demonstrated that the proposed semi-supervisedGAN-LM architecture (generative adversarial network on top of a pretrainedlanguage model) is a viable solution in classifying Bengali fake reviews as theexperimental results suggest that even with only 1024 annotated samples,BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% anda f1-score of 84.89% outperforming other pretrained language models -BanglaBERT generator, Bangla BERT Base and Bangla-Electra by almost 3%, 4% and10% respectively in terms of accuracy. The experiments were conducted on amanually labeled food review dataset consisting of total 6014 real and fakereviews collected from various social media groups. Researchers that areexperiencing difficulty recognizing not just fake reviews but otherclassification issues owing to a lack of labeled data may find a solution inour proposed methodology.", "output": "Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural network models of language have long been used as a tool fordeveloping hypotheses about conceptual representation in the mind and brain.For many years, such use involved extracting vector-space representations ofwords and using distances among these to predict or understand human behaviorin various semantic tasks. In contemporary language AIs, however, it ispossible to interrogate the latent structure of conceptual representationsusing methods nearly identical to those commonly used with human participants.The current work uses two common techniques borrowed from cognitive psychologyto estimate and compare lexical-semantic structure in both humans and awell-known AI, the DaVinci variant of GPT-3. In humans, we show that conceptualstructure is robust to differences in culture, language, and method ofestimation. Structures estimated from AI behavior, while individually fairlyconsistent with those estimated from human behavior, depend much more upon theparticular task used to generate behavior responses--responses generated by thevery same model in the two tasks yield estimates of conceptual structure thatcohere less with one another than do human structure estimates. The resultssuggest one important way that knowledge inhering in contemporary AIs candiffer from human cognition.", "output": "Behavioral estimates of conceptual structure are robust across tasks in humans but not large language models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces the Saudi Privacy Policy Dataset, a diverse compilationof Arabic privacy policies from various sectors in Saudi Arabia, annotatedaccording to the 10 principles of the Personal Data Protection Law (PDPL); thePDPL was established to be compatible with General Data Protection Regulation(GDPR); one of the most comprehensive data regulations worldwide. Data werecollected from multiple sources, including the Saudi Central Bank, the SaudiArabia National United Platform, the Council of Health Insurance, and generalwebsites using Google and Wikipedia. The final dataset includes 1,000 websitesbelonging to 7 sectors, 4,638 lines of text, 775,370 tokens, and a corpus sizeof 8,353 KB. The annotated dataset offers significant reuse potential forassessing privacy policy compliance, benchmarking privacy practices acrossindustries, and developing automated tools for monitoring adherence to dataprotection regulations. By providing a comprehensive and annotated dataset ofprivacy policies, this paper aims to facilitate further research anddevelopment in the areas of privacy policy analysis, natural languageprocessing, and machine learning applications related to privacy and dataprotection, while also serving as an essential resource for researchers,policymakers, and industry professionals interested in understanding andpromoting compliance with privacy regulations in Saudi Arabia.", "output": "The Saudi Privacy Policy Dataset."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The combined growth of available data and their unstructured nature hasreceived increased interest in natural language processing (NLP) techniques tomake value of these data assets since this format is not suitable forstatistical analysis. This work presents a systematic literature review ofstate-of-the-art advances using transformer-based methods on electronic medicalrecords (EMRs) in different NLP tasks. To the best of our knowledge, this workis unique in providing a comprehensive review of research on transformer-basedmethods for NLP applied to the EMR field. In the initial query, 99 articleswere selected from three public databases and filtered into 65 articles fordetailed analysis. The papers were analyzed with respect to the businessproblem, NLP task, models and techniques, availability of datasets,reproducibility of modeling, language, and exchange format. The paper presentssome limitations of current research and some recommendations for furtherresearch.", "output": "Application of Transformers based methods in Electronic Medical Records: A Systematic Literature Review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we study the problem of claim verification in the context ofclaims about fictional stories in a low-shot learning setting. To this end, wegenerate two synthetic datasets and then develop an end-to-end pipeline andmodel that is tested on both benchmarks. To test the efficacy of our pipelineand the difficulty of benchmarks, we compare our models' results against humanand random assignment results. Our code is available at", "output": "Low-Shot Learning for Fictional Claim Verification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this note, we establish the hardness of approximation of the problem ofcomputing the minimal size of a $delta$-sufficient reason for decision trees.", "output": "Inapproximability of sufficient reasons for decision trees."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The backdoor attack, where the adversary uses inputs stamped with triggers(e.g., a patch) to activate pre-planted malicious behaviors, is a severe threatto Deep Neural Network (DNN) models. Trigger inversion is an effective way ofidentifying backdoor models and understanding embedded adversarial behaviors. Achallenge of trigger inversion is that there are many ways of constructing thetrigger. Existing methods cannot generalize to various types of triggers bymaking certain assumptions or attack-specific constraints. The fundamentalreason is that existing work does not consider the trigger's design space intheir formulation of the inversion problem. This work formally defines andanalyzes the triggers injected in different spaces and the inversion problem.Then, it proposes a unified framework to invert backdoor triggers based on theformalization of triggers and the identified inner behaviors of backdoor modelsfrom our analysis. Our prototype UNICORN is general and effective in invertingbackdoor triggers in DNNs. The code can be found at", "output": "UNICORN: A Unified Backdoor Trigger Inversion Framework."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Planning from demonstrations has shown promising results with the advances ofdeep neural networks. One of the most popular real-world applications isautomated handwriting using a robotic manipulator. Classically it is simplifiedas a two-dimension problem. This representation is suitable for elementarydrawings, but it is not sufficient for Japanese calligraphy or complex work ofart where the orientation of a pen is part of the user expression. In thisstudy, we focus on automated planning of Japanese calligraphy using athree-dimension representation of the trajectory as well as the rotation of thepen tip, and propose a novel deep imitation learning neural network that learnsfrom expert demonstrations through a combination of images and pose data. Thenetwork consists of a combination of variational auto-encoder, bi-directionalLSTM, and Multi-Layer Perceptron (MLP). Experiments are conducted in aprogressive way, and results demonstrate that the proposed approach issuccessful in completion of tasks for real-world robots, overcoming thedistribution shift problem in imitation learning. The source code and datasetwill be public.", "output": "End-to-end Manipulator Calligraphy Planning via Variational Imitation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Due to the complex behavior arising from non-uniqueness, symmetry, andbifurcations in the solution space, solving inverse problems of nonlineardifferential equations (DEs) with multiple solutions is a challenging task. Toaddress this issue, we propose homotopy physics-informed neural networks(HomPINNs), a novel framework that leverages homotopy continuation and neuralnetworks (NNs) to solve inverse problems. The proposed framework begins withthe use of a NN to simultaneously approximate known observations and conform tothe constraints of DEs. By utilizing the homotopy continuation method, theapproximation traces the observations to identify multiple solutions and solvethe inverse problem. The experiments involve testing the performance of theproposed method on one-dimensional DEs and applying it to solve atwo-dimensional Gray-Scott simulation. Our findings demonstrate that theproposed method is scalable and adaptable, providing an effective solution forsolving DEs with multiple solutions and unknown parameters. Moreover, it hassignificant potential for various applications in scientific computing, such asmodeling complex systems and solving inverse problems in physics, chemistry,biology, etc.", "output": "HomPINNs: homotopy physics-informed neural networks for solving the inverse problems of nonlinear differential equations with multiple solutions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a high-precision real-time facial animation pipeline suitable foranimators to use on their desktops. This pipeline is about to be launched inFACEGOOD's Avataryfootnote{ software, which willaccelerate animators' productivity. The pipeline differs from professionalhead-mounted facial capture solutions in that it only requires the use of aconsumer-grade 3D camera on the desk to achieve high-precision real-time facialcapture. The system enables animators to create high-quality facial animationswith ease and speed, while reducing the cost and complexity of traditionalfacial capture solutions. Our approach has the potential to revolutionize theway facial animation is done in the entertainment industry.", "output": "4D Agnostic Real-Time Facial Animation Pipeline for Desktop Scenarios."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The rapid adoption of generative language models has brought aboutsubstantial advancements in digital communication, while simultaneously raisingconcerns regarding the potential misuse of AI-generated content. Althoughnumerous detection methods have been proposed to differentiate between AI andhuman-generated content, the fairness and robustness of these detectors remainunderexplored. In this study, we evaluate the performance of severalwidely-used GPT detectors using writing samples from native and non-nativeEnglish writers. Our findings reveal that these detectors consistentlymisclassify non-native English writing samples as AI-generated, whereas nativewriting samples are accurately identified. Furthermore, we demonstrate thatsimple prompting strategies can not only mitigate this bias but alsoeffectively bypass GPT detectors, suggesting that GPT detectors mayunintentionally penalize writers with constrained linguistic expressions. Ourresults call for a broader conversation about the ethical implications ofdeploying ChatGPT content detectors and caution against their use in evaluativeor educational settings, particularly when they may inadvertently penalize orexclude non-native English speakers from the global discourse.", "output": "GPT detectors are biased against non-native English writers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The increasing demand for high-quality 3D content creation has motivated thedevelopment of automated methods for creating 3D object models from a singleimage and/or from a text prompt. However, the reconstructed 3D objects usingstate-of-the-art image-to-3D methods still exhibit low correspondence to thegiven image and low multi-view consistency. Recent state-of-the-art text-to-3Dmethods are also limited, yielding 3D samples with low diversity per promptwith long synthesis time. To address these challenges, we propose DITTO-NeRF, anovel pipeline to generate a high-quality 3D NeRF model from a text prompt or asingle image. Our DITTO-NeRF consists of constructing high-quality partial 3Dobject for limited in-boundary (IB) angles using the given or text-generated 2Dimage from the frontal view and then iteratively reconstructing the remaining3D NeRF using inpainting latent diffusion model. We propose progressive 3Dobject reconstruction schemes in terms of scales (low to high resolution),angles (IB angles initially to outer-boundary (OB) later), and masks (object tobackground boundary) in our DITTO-NeRF so that high-quality information on IBcan be propagated into OB. Our DITTO-NeRF outperforms state-of-the-art methodsin terms of fidelity and diversity qualitatively and quantitatively with muchfaster training times than prior arts on image/text-to-3D such as DreamFusion,and NeuralLift-360.", "output": "DITTO-NeRF: Diffusion-based Iterative Text To Omni-directional 3D Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We analyze the data-dependent capacity of neural networks and assessanomalies in inputs from the perspective of networks during inference. Thenotion of data-dependent capacity allows for analyzing the knowledge base of amodel populated by learned features from training data. We define purview asthe additional capacity necessary to characterize inference samples that differfrom the training data. To probe the purview of a network, we utilize gradientsto measure the amount of change required for the model to characterize thegiven inputs more accurately. To eliminate the dependency on ground-truthlabels in generating gradients, we introduce confounding labels that areformulated by combining multiple categorical labels. We demonstrate that ourgradient-based approach can effectively differentiate inputs that cannot beaccurately represented with learned features. We utilize our approach inapplications of detecting anomalous inputs, including out-of-distribution,adversarial, and corrupted samples. Our approach requires no hyperparametertuning or additional data processing and outperforms state-of-the-art methodsby up to 2.7%, 19.8%, and 35.6% of AUROC scores, respectively.", "output": "Probing the Purview of Neural Networks via Gradient Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "APT detection is difficult to detect due to the long-term latency, covert andslow multistage attack patterns of Advanced Persistent Threat (APT). To tacklethese issues, we propose TBDetector, a transformer-based advanced persistentthreat detection method for APT attack detection. Considering that provenancegraphs provide rich historical information and have the powerful attackshistoric correlation ability to identify anomalous activities, TBDetectoremploys provenance analysis for APT detection, which summarizes long-runningsystem execution with space efficiency and utilizes transformer withself-attention based encoder-decoder to extract long-term contextual featuresof system states to detect slow-acting attacks. Furthermore, we furtherintroduce anomaly scores to investigate the anomaly of different system states,where each state is calculated with an anomaly score corresponding to itssimilarity score and isolation score. To evaluate the effectiveness of theproposed method, we have conducted experiments on five public datasets, i.e.,streamspot, cadets, shellshock, clearscope, and wget_baseline. Experimentalresults and comparisons with state-of-the-art methods have exhibited betterperformance of our proposed method.", "output": "TBDetector:Transformer-Based Detector for Advanced Persistent Threats with Provenance Graph."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Intelligent or generative writing tools rely on large language models thatrecognize, summarize, translate, and predict content. This position paperprobes the copyright interests of open data sets used to train large languagemodels (LLMs). Our paper asks, how do LLMs trained on open data sets circumventthe copyright interests of the used data? We start by defining softwarecopyright and tracing its history. We rely on GitHub Copilot as a modern casestudy challenging software copyright. Our conclusion outlines obstacles thatgenerative writing assistants create for copyright, and offers a practical roadmap for copyright analysis for developers, software law experts, and generalusers to consider in the context of intelligent LLM-powered writing tools.", "output": "Whose Text Is It Anyway? Exploring BigCode, Intellectual Property, and Ethics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural Architectures Search (NAS) becomes more and more popular over theseyears. However, NAS-generated models tends to suffer greater vulnerability tovarious malicious attacks. Lots of robust NAS methods leverage adversarialtraining to enhance the robustness of NAS-generated models, however, theyneglected the nature accuracy of NAS-generated models. In our paper, we proposea novel NAS method, Robust Neural Architecture Search (RNAS). To design aregularization term to balance accuracy and robustness, RNAS generatesarchitectures with both high accuracy and good robustness. To reduce searchcost, we further propose to use noise examples instead adversarial examples asinput to search architectures. Extensive experiments show that RNAS achievesstate-of-the-art (SOTA) performance on both image classification andadversarial attacks, which illustrates the proposed RNAS achieves a goodtradeoff between robustness and accuracy.", "output": "Robust Neural Architecture Search."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep networks have achieved impressive results on a range of well-curatedbenchmark datasets. Surprisingly, their performance remains sensitive toperturbations that have little effect on human performance. In this work, wepropose a novel extension of Mixup called Robustmix that regularizes networksto classify based on lower-frequency spatial features. We show that this typeof regularization improves robustness on a range of benchmarks such asImagenet-C and Stylized Imagenet. It adds little computational overhead and,furthermore, does not require a priori knowledge of a large set of imagetransformations. We find that this approach further complements recent advancesin model architecture and data augmentation, attaining a state-of-the-art mCEof 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of16 mCE compared to the baseline.", "output": "Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Class imbalance (CI) in classification problems arises when the number ofobservations belonging to one class is lower than the other classes. Ensemblelearning that combines multiple models to obtain a robust model has beenprominently used with data augmentation methods to address class imbalanceproblems. In the last decade, a number of strategies have been added to enhanceensemble learning and data augmentation methods, along with new methods such asgenerative adversarial networks (GANs). A combination of these has been appliedin many studies, but the true rank of different combinations would require acomputational review. In this paper, we present a computational review toevaluate data augmentation and ensemble learning methods used to addressprominent benchmark CI problems. We propose a general framework that evaluates10 data augmentation and 10 ensemble learning methods for CI problems. Ourobjective was to identify the most effective combination for improvingclassification performance on imbalanced datasets. The results indicate thatcombinations of data augmentation methods with ensemble learning cansignificantly improve classification performance on imbalanced datasets. Thesefindings have important implications for the development of more effectiveapproaches for handling imbalanced datasets in machine learning applications.", "output": "A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large language models (LLMs) such as ChatGPT and GPT-4 have recentlydemonstrated their remarkable abilities of communicating with human users. Inthis technical report, we take an initiative to investigate their capacities ofplaying text games, in which a player has to understand the environment andrespond to situations by having dialogues with the game world. Our experimentsshow that ChatGPT performs competitively compared to all the existing systemsbut still exhibits a low level of intelligence. Precisely, ChatGPT can notconstruct the world model by playing the game or even reading the game manual;it may fail to leverage the world knowledge that it already has; it cannotinfer the goal of each step as the game progresses. Our results open up newresearch questions at the intersection of artificial intelligence, machinelearning, and natural language processing.", "output": "Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automatically associating ICD codes with electronic health data is awell-known NLP task in medical research. NLP has evolved significantly inrecent years with the emergence of pre-trained language models based onTransformers architecture, mainly in the English language. This paper adaptsthese models to automatically associate the ICD codes. Several neural networkarchitectures have been experimented with to address the challenges of dealingwith a large set of both input tokens and labels to be guessed. In this paper,we propose a model that combines the latest advances in NLP and multi-labelclassification for ICD-10 code association. Fair experiments on a Clinicaldataset in the French language show that our approach increases the $F_1$-scoremetric by more than 55% compared to state-of-the-art results.", "output": "Automatic ICD-10 Code Association: A Challenging Task on French Clinical Texts."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated learning (FL) is a distributed framework for collaborativelytraining with privacy guarantees. In real-world scenarios, clients may haveNon-IID data (local class imbalance) with poor annotation quality (labelnoise). The co-existence of label noise and class imbalance in FL's small localdatasets renders conventional FL methods and noisy-label learning methods bothineffective. To address the challenges, we propose FedCNI without using anadditional clean proxy dataset. It includes a noise-resilient local solver anda robust global aggregator. For the local solver, we design a more robustprototypical noise detector to distinguish noisy samples. Further to reduce thenegative impact brought by the noisy samples, we devise a curriculum pseudolabeling method and a denoise Mixup training strategy. For the globalaggregator, we propose a switching re-weighted aggregation method tailored todifferent learning periods. Extensive experiments demonstrate our method cansubstantially outperform state-of-the-art solutions in mix-heterogeneous FLenvironments.", "output": "Learning Cautiously in Federated Learning with Noisy and Heterogeneous Clients."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We focus on the task of language-conditioned object placement, in which arobot should generate placements that satisfy all the spatial relationalconstraints in language instructions. Previous works based on rule-basedlanguage parsing or scene-centric visual representation have restrictions onthe form of instructions and reference objects or require large amounts oftraining data. We propose an object-centric framework that leverages foundationmodels to ground the reference objects and spatial relations for placement,which is more sample efficient and generalizable. Experiments indicate that ourmodel can achieve a 97.75% success rate of placement with only ~0.26M trainableparameters. Besides, our method generalizes better to both unseen objects andinstructions. Moreover, with only 25% training data, we still outperform thetop competing approach.", "output": "Object-centric Inference for Language Conditioned Placement: A Foundation Model based Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Physical artificial intelligence can prove to be one of the most importantchallenges of the artificial intelligence. The governance of physicalartificial intelligence would define its responsible intelligent application inthe society.", "output": "The Governance of Physical Artificial Intelligence."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Knowledge Graph Embedding (KGE) is a fundamental technique that extractsexpressive representation from knowledge graph (KG) to facilitate diversedownstream tasks. The emerging federated KGE (FKGE) collaboratively trains fromdistributed KGs held among clients while avoiding exchanging clients' sensitiveraw KGs, which can still suffer from privacy threats as evidenced in otherfederated model trainings (e.g., neural networks). However, quantifying anddefending against such privacy threats remain unexplored for FKGE whichpossesses unique properties not shared by previously studied models. In thispaper, we conduct the first holistic study of the privacy threat on FKGE fromboth attack and defense perspectives. For the attack, we quantify the privacythreat by proposing three new inference attacks, which reveal substantialprivacy risk by successfully inferring the existence of the KG triple fromvictim clients. For the defense, we propose DP-Flames, a novel differentiallyprivate FKGE with private selection, which offers a better privacy-utilitytradeoff by exploiting the entity-binding sparse gradient property of FKGE andcomes with a tight privacy accountant by incorporating the state-of-the-artprivate selection technique. We further propose an adaptive privacy budgetallocation policy to dynamically adjust defense magnitude across the trainingprocedure. Comprehensive evaluations demonstrate that the proposed defense cansuccessfully mitigate the privacy threat by effectively reducing the successrate of inference attacks from $83.1%$ to $59.4%$ on average with only amodest utility decrease.", "output": "Quantifying and Defending against Privacy Threats on Federated Knowledge Graph Embedding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Flexible road pavements deteriorate primarily due to traffic and adverseenvironmental conditions. Cracking is the most common deterioration mechanism;the surveying thereof is typically conducted manually using internationallydefined classification standards. In South Africa, the use of high-definitionvideo images has been introduced, which allows for safer road surveying.However, surveying is still a tedious manual process. Automation of thedetection of defects such as cracks would allow for faster analysis of roadnetworks and potentially reduce human bias and error. This study performs acomparison of six state-of-the-art convolutional neural network models for thepurpose of crack detection. The models are pretrained on the ImageNet dataset,and fine-tuned using a new real-world binary crack dataset consisting of 14000samples. The effects of dataset augmentation are also investigated. Of the sixmodels trained, five achieved accuracy above 97%. The highest recorded accuracywas 98%, achieved by the ResNet and VGG16 models. The dataset is available atthe following URL: ", "output": "Convolutional neural networks for crack detection on flexible road pavements."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present FengWu, an advanced data-driven global medium-range weatherforecast system based on Artificial Intelligence (AI). Different from existingdata-driven weather forecast methods, FengWu solves the medium-range forecastproblem from a multi-modal and multi-task perspective. Specifically, a deeplearning architecture equipped with model-specific encoder-decoders andcross-modal fusion Transformer is elaborately designed, which is learned underthe supervision of an uncertainty loss to balance the optimization of differentpredictors in a region-adaptive manner. Besides this, a replay buffer mechanismis introduced to improve medium-range forecast performance. With 39-year datatraining based on the ERA5 reanalysis, FengWu is able to accurately reproducethe atmospheric dynamics and predict the future land and atmosphere states at37 vertical levels on a 0.25{deg} latitude-longitude resolution. Hindcasts of6-hourly weather in 2018 based on ERA5 demonstrate that FengWu performs betterthan GraphCast in predicting 80% of the 880 reported predictands, e.g.,reducing the root mean square error (RMSE) of 10-day lead global z500prediction from 733 to 651 $m^{2}/s^2$. In addition, the inference cost of eachiteration is merely 600ms on NVIDIA Tesla A100 hardware. The results suggestthat FengWu can significantly improve the forecast skill and extend theskillful global medium-range weather forecast out to 10.75 days lead (with ACCof z500 &gt; 0.6) for the first time.", "output": "FengWu: Pushing the Skillful Global Medium-range Weather Forecast beyond 10 Days Lead."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The capability of doing effective forensic analysis on printed and scanned(PS) images is essential in many applications. PS documents may be used toconceal the artifacts of images which is due to the synthetic nature of imagessince these artifacts are typically present in manipulated images and the mainartifacts in the synthetic images can be removed after the PS. Due to theappeal of Generative Adversarial Networks (GANs), synthetic face imagesgenerated with GANs models are difficult to differentiate from genuine humanfaces and may be used to create counterfeit identities. Additionally, sinceGANs models do not account for physiological constraints for generating humanfaces and their impact on human IRISes, distinguishing genuine from syntheticIRISes in the PS scenario becomes extremely difficult. As a result of the lackof large-scale reference IRIS datasets in the PS scenario, we aim at developinga novel dataset to become a standard for Multimedia Forensics (MFs)investigation which is available at [45]. In this paper, we provide a noveldataset made up of a large number of synthetic and natural printed IRISes takenfrom VIPPrint Printed and Scanned face images. We extracted irises from faceimages and it is possible that the model due to eyelid occlusion captured theincomplete irises. To fill the missing pixels of extracted iris, we appliedtechniques to discover the complex link between the iris images. To highlightthe problems involved with the evaluation of the dataset's IRIS images, weconducted a large number of analyses employing Siamese Neural Networks toassess the similarities between genuine and synthetic human IRISes, such asResNet50, Xception, VGG16, and MobileNet-v2. For instance, using the Xceptionnetwork, we achieved 56.76% similarity of IRISes for synthetic images and92.77% similarity of IRISes for real images.", "output": "Spritz-PS: Validation of Synthetic Face Images Using a Large Dataset of Printed Documents."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The retriever-reader framework is popular for open-domain question answering(ODQA), where a retriever samples for the reader a set of relevant candidatepassages from a large corpus. A key assumption behind this method is that highrelevance scores from the retriever likely indicate high answerability from thereader, which implies a high probability that the retrieved passages containanswers to a given question. In this work, we empirically dispel this beliefand observe that recent dense retrieval models based on DPR often rankunanswerable counterfactual passages higher than their answerable originalpassages. To address such answer-unawareness in dense retrievers, we seek touse counterfactual samples as additional training resources to bettersynchronize the relevance measurement of DPR with the answerability ofquestion-passage pairs. Specifically, we present counterfactually-PivotingContrastive Learning (PiCL), a novel representation learning approach forpassage retrieval that leverages counterfactual samples as pivots betweenpositive and negative samples in their learned embedding space. We incorporatePiCL into the retriever training to show the effectiveness of PiCL on ODQAbenchmarks and the robustness of the learned models.", "output": "Revisiting Dense Retrieval with Unanswerable Counterfactuals."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The role of an expert in the decision-making process is crucial, as the finalrecommendation depends on his disposition, clarity of mind, experience, andknowledge of the problem. However, the recommendation also depends on theirhonesty. But what if the expert is dishonest? Then, the answer on how difficultit is to manipulate in a given case becomes essential. In the presented work,we consider manipulation of a ranking obtained by comparing alternatives inpairs. More specifically, we propose an algorithm for finding an almost optimalway to swap the positions of two selected alternatives. Thanks to this, it ispossible to determine how difficult such manipulation is in a given case.Theoretical considerations are illustrated by a practical example.", "output": "Almost optimal manipulation of a pair of alternatives."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although real-time facial emotion recognition is a hot topic research domainin the field of human-computer interaction, state-of the-art available datasetsstill suffer from various problems, such as some unrelated photos such asdocument photos, unbalanced numbers of photos in each class, and misleadingimages that can negatively affect correct classification. The 3RL dataset wascreated, which contains approximately 24K images and will be publiclyavailable, to overcome previously available dataset problems. The 3RL datasetis labelled with five basic emotions: happiness, fear, sadness, disgust, andanger. Moreover, we compared the 3RL dataset with other famous state-of-the-artdatasets (FER dataset, CK+ dataset), and we applied the most commonly usedalgorithms in previous works, SVM and CNN. The results show a noticeableimprovement in generalization on the 3RL dataset. Experiments have shown anaccuracy of up to 91.4% on 3RL dataset using CNN where results on FER2013, CK+are, respectively (approximately from 60% to 85%).", "output": "An experimental study in Real-time Facial Emotion Recognition on new 3RL dataset."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The large amount of data collected in buildings makes energy managementsmarter and more energy efficient. This study proposes a design andimplementation methodology of data-driven heating, ventilation, and airconditioning (HVAC) control. Building thermodynamics is modeled using asymbolic regression model (SRM) built from the collected data. Additionally, anHVAC system model is also developed with a data-driven approach. A modelpredictive control (MPC) based HVAC scheduling is formulated with the developedmodels to minimize energy consumption and peak power demand and maximizethermal comfort. The performance of the proposed framework is demonstrated inthe workspace in the actual campus building. The HVAC system using the proposedframework reduces the peak power by 16.1% compared to the widely usedthermostat controller.", "output": "Data-driven HVAC Control Using Symbolic Regression: Design and Implementation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In safe MDP planning, a cost function based on the current state and actionis often used to specify safety aspects. In the real world, often the staterepresentation used may lack sufficient fidelity to specify such safetyconstraints. Operating based on an incomplete model can often produceunintended negative side effects (NSEs). To address these challenges, first, weassociate safety signals with state-action trajectories (rather than just animmediate state-action). This makes our safety model highly general. We alsoassume categorical safety labels are given for different trajectories, ratherthan a numerical cost function, which is harder to specify by the problemdesigner. We then employ a supervised learning model to learn suchnon-Markovian safety patterns. Second, we develop a Lagrange multiplier method,which incorporates the safety model and the underlying MDP model in a singlecomputation graph to facilitate agent learning of safe behaviors. Finally, ourempirical results on a variety of discrete and continuous domains show thatthis approach can satisfy complex non-Markovian safety constraints whileoptimizing an agent's total returns, is highly scalable, and is also betterthan the previous best approach for Markovian NSEs.", "output": "Safe MDP Planning by Learning Temporal Patterns of Undesirable Trajectories and Averting Negative Side Effects."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The ChatGPT, as a lite and conversational variant of Generative PretrainedTransformer 4 (GPT-4) developed by OpenAI, is one of the milestone LargeLanguage Models (LLMs) with billions of parameters. LLMs, in fact, have stirredup a lot of interest among researchers and practitioners by their impressiveskills in natural language processing tasks, which have a profound impact on awide range of fields. This paper mainly discusses the future applications ofLLMs in dentistry. We introduce two primary LLM deployment methods indentistry, including automated dental diagnosis and cross-modal dentaldiagnosis, and examine their potential applications. Especially, equipped witha cross-modal encoder, a single LLM can manage multi-source data and conductadvanced natural language reasoning to perform complex clinical operations. Ause case is presented to demonstrate the potential of a fully automaticMulti-Modal LLM AI system for dentistry clinical application. While LLMs offersignificant potential benefits, the challenges, such as data privacy, dataquality, and model bias, need further study. Overall, LLMs have the potentialto revolutionize dental diagnosis and treatment, which indicates a promisingavenue for clinical application and research in dentistry.", "output": "ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Skilled employees are usually seen as the most important pillar of anorganization. Despite this, most organizations face high attrition and turnoverrates. While several machine learning models have been developed for analyzingattrition and its causal factors, the interpretations of those models remainopaque. In this paper, we propose the HR-DSS approach, which stands for HumanResource Decision Support System, and uses explainable AI for employeeattrition problems. The system is designed to assist human resource departmentsin interpreting the predictions provided by machine learning models. In ourexperiments, eight machine learning models are employed to provide predictions,and the results achieved by the best-performing model are further processed bythe SHAP explainability process. We optimize both the correctness andexplanation of the results. Furthermore, using \"What-if-analysis\", we aim toobserve plausible causes for attrition of an individual employee. The resultsshow that by adjusting the specific dominant features of each individual,employee attrition can turn into employee retention through informativebusiness decisions. Reducing attrition is not only a problem for any specificorganization but also, in some countries, becomes a significant societalproblem that impacts the well-being of both employers and employees.", "output": "Retention Is All You Need."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep Neural Networks (DNNs) are built using artificial neural networks. Theyare part of machine learning methods that are capable of learning from datathat have been used in a wide range of applications. DNNs are mainlyhandcrafted and they usually contain numerous layers. Research frontier hasemerged that concerns automated construction of DNNs via evolutionaryalgorithms. This paper emphasizes the importance of what we calltwo-dimensional brain evolution and how it can inspire two dimensional DNNevolutionary modeling. We also highlight the connection between the dropoutmethod which is widely-used in regularizing DNNs and neurogenesis of the brain,and how these concepts could benefit DNNs evolution.The paper concludes withseveral recommendations for enhancing the automatic construction of DNNs.", "output": "Is it conceivable that neurogenesis, neural Darwinism, and species evolution could all serve as inspiration for the creation of evolutionary deep neural networks?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Detecting pedestrians accurately in urban scenes is significant for realisticapplications like autonomous driving or video surveillance. However, confusinghuman-like objects often lead to wrong detections, and small scale or heavilyoccluded pedestrians are easily missed due to their unusual appearances. Toaddress these challenges, only object regions are inadequate, thus how to fullyutilize more explicit and semantic contexts becomes a key problem. Meanwhile,previous context-aware pedestrian detectors either only learn latent contextswith visual clues, or need laborious annotations to obtain explicit andsemantic contexts. Therefore, we propose in this paper a novel approach viaVision-Language semantic self-supervision for context-aware PedestrianDetection (VLPD) to model explicitly semantic contexts without any extraannotations. Firstly, we propose a self-supervised Vision-Language Semantic(VLS) segmentation method, which learns both fully-supervised pedestriandetection and contextual segmentation via self-generated explicit labels ofsemantic classes by vision-language models. Furthermore, a self-supervisedPrototypical Semantic Contrastive (PSC) learning method is proposed to betterdiscriminate pedestrians and other classes, based on more explicit and semanticcontexts obtained from VLS. Extensive experiments on popular benchmarks showthat our proposed VLPD achieves superior performances over the previousstate-of-the-arts, particularly under challenging circumstances like smallscale and heavy occlusion. Code is available at", "output": "VLPD: Context-Aware Pedestrian Detection via Vision-Language Semantic Self-Supervision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A persistently popular topic in online social networks is the rapid andaccurate discovery of bot accounts to prevent their invasion and harassment ofgenuine users. We propose a unified embedding framework called BOTTRINET, whichutilizes textual content posted by accounts for bot detection based on theassumption that contexts naturally reveal account personalities and habits.Content is abundant and valuable if the system efficiently extracts bot-relatedinformation using embedding techniques. Beyond the general embedding frameworkthat generates word, sentence, and account embeddings, we design a tripletnetwork to tune the raw embeddings (produced by traditional natural languageprocessing techniques) for better classification performance. We evaluatedetection accuracy and f1score on a real-world dataset CRESCI2017, comprisingthree bot account categories and five bot sample sets. Our system achieves thehighest average accuracy of 98.34% and f1score of 97.99% on twocontent-intensive bot sets, outperforming previous work and becomingstate-of-the-art. It also makes a breakthrough on four content-less bot sets,with an average accuracy improvement of 11.52% and an average f1score increaseof 16.70%.", "output": "BotTriNet: A Unified and Efficient Embedding for Social Bots Detection via Metric Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks have been critical in the task of Visual QuestionAnswering (VQA), with research traditionally focused on improving modelaccuracy. Recently, however, there has been a trend towards evaluating therobustness of these models against adversarial attacks. This involves assessingthe accuracy of VQA models under increasing levels of noise in the input, whichcan target either the image or the proposed query question, dubbed the mainquestion. However, there is currently a lack of proper analysis of this aspectof VQA. This work proposes a new method that utilizes semantically relatedquestions, referred to as basic questions, acting as noise to evaluate therobustness of VQA models. It is hypothesized that as the similarity of a basicquestion to the main question decreases, the level of noise increases. Togenerate a reasonable noise level for a given main question, a pool of basicquestions is ranked based on their similarity to the main question, and thisranking problem is cast as a LASSO optimization problem. Additionally, thiswork proposes a novel robustness measure, R_score, and two basic questiondatasets to standardize the analysis of VQA model robustness. The experimentalresults demonstrate that the proposed evaluation method effectively analyzesthe robustness of VQA models. Moreover, the experiments show that in-contextlearning with a chain of basic questions can enhance model accuracy.", "output": "Improving Visual Question Answering Models through Robustness Analysis and In-Context Learning with a Chain of Basic Questions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Growing techniques have been emerging to improve the performance of passageretrieval. As an effective representation bottleneck pretraining technique, thecontextual masked auto-encoder utilizes contextual embedding to assist in thereconstruction of passages. However, it only uses a single auto-encodingpre-task for dense representation pre-training. This study brings multi-viewmodeling to the contextual masked auto-encoder. Firstly, multi-viewrepresentation utilizes both dense and sparse vectors as multi-viewrepresentations, aiming to capture sentence semantics from different aspects.Moreover, multiview decoding paradigm utilizes both autoencoding andauto-regressive decoders in representation bottleneck pre-training, aiming toprovide both reconstructive and generative signals for better contextualrepresentation pretraining. We refer to this multi-view pretraining method asCoT-MAE v2. Through extensive experiments, we show that CoT-MAE v2 is effectiveand robust on large-scale passage retrieval benchmarks and out-of-domainzero-shot benchmarks.", "output": "CoT-MAE v2: Contextual Masked Auto-Encoder with Multi-view Modeling for Passage Retrieval."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Program synthesis is the process of generating a computer program following aset of specifications, which can be a high-level description of the problemand/or a set of input-output examples. The synthesis can be modeled as a searchproblem in which the search space is the set of all the programs valid under agrammar. As the search space is vast, brute force is usually not viable andsearch heuristics, such as genetic programming, also have difficulty navigatingit without any guidance. In this paper we present HOTGP, a new geneticprogramming algorithm that synthesizes pure, typed, and functional programs.HOTGP leverages the knowledge provided by the rich data-types associated withthe specification and the built-in grammar to constrain the search space andimprove the performance of the synthesis. The grammar is based on Haskell'sstandard base library (the synthesized code can be directly compiled using anystandard Haskell compiler) and includes support for higher-order functions,$lambda$-functions, and parametric polymorphism. Experimental results showthat, when compared to $6$ state-of-the-art algorithms using a standard set ofbenchmarks, HOTGP is competitive and capable of synthesizing the correctprograms more frequently than any other of the evaluated algorithms.", "output": "HOTGP -- Higher-Order Typed Genetic Programming."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Integrating high-level semantically correlated contents and low-levelanatomical features is of central importance in medical image segmentation.Towards this end, recent deep learning-based medical segmentation methods haveshown great promise in better modeling such information. However, convolutionoperators for medical segmentation typically operate on regular grids, whichinherently blur the high-frequency regions, i.e., boundary regions. In thiswork, we propose MORSE, a generic implicit neural rendering framework designedat an anatomical level to assist learning in medical image segmentation. Ourmethod is motivated by the fact that implicit neural representation has beenshown to be more effective in fitting complex signals and solving computergraphics problems than discrete grid-based representation. The core of ourapproach is to formulate medical image segmentation as a rendering problem inan end-to-end manner. Specifically, we continuously align the coarsesegmentation prediction with the ambiguous coordinate-based pointrepresentations and aggregate these features to adaptively refine the boundaryregion. To parallelly optimize multi-scale pixel-level features, we leveragethe idea from Mixture-of-Expert (MoE) to design and train our MORSE with astochastic gating mechanism. Our experiments demonstrate that MORSE can workwell with different medical segmentation backbones, consistently achievingcompetitive performance improvements in both 2D and 3D supervised medicalsegmentation methods. We also theoretically analyze the superiority of MORSE.", "output": "Implicit Anatomical Rendering for Medical Image Segmentation with Stochastic Experts."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Cross-device user matching is a critical problem in numerous domains,including advertising, recommender systems, and cybersecurity. It involvesidentifying and linking different devices belonging to the same person,utilizing sequence logs. Previous data mining techniques have struggled toaddress the long-range dependencies and higher-order connections between thelogs. Recently, researchers have modeled this problem as a graph problem andproposed a two-tier graph contextual embedding (TGCE) neural networkarchitecture, which outperforms previous methods. In this paper, we propose anovel hierarchical graph neural network architecture (HGNN), which has a morecomputationally efficient second level design than TGCE. Furthermore, weintroduce a cross-attention (Cross-Att) mechanism in our model, which improvesperformance by 5% compared to the state-of-the-art TGCE method.", "output": "Hierarchical Graph Neural Network with Cross-Attention for Cross-Device User Matching."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we study how the generalization performance of a givendirection changes with its sampling ratio in Multilingual Neural MachineTranslation (MNMT). By training over 200 multilingual models with various modelsizes, directions, and total numbers of tasks, we find that scalarization leadsto a multitask trade-off front that deviates from the traditional Pareto frontwhen there exists data imbalance in the training corpus. That is, theperformance of certain translation directions does not improve with theincrease of its weight in the multi-task optimization objective, which posesgreater challenge to improve the overall performance of all directions. Basedon our observations, we propose the Double Power Law to predict the uniqueperformance trade-off front in MNMT, which is robust across various languages,data adequacy and number of tasks. Finally, we formulate sample ratio selectionin MNMT as an optimization problem based on the Double Power Law, whichachieves better performance than temperature searching and gradientmanipulation methods using up to half of the total training budget in ourexperiments.", "output": "On the Pareto Front of Multilingual Neural Machine Translation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose Gumbel Noise Score Matching (GNSM), a novel unsupervised method todetect anomalies in categorical data. GNSM accomplishes this by estimating thescores, i.e. the gradients of log likelihoods w.r.t.~inputs, of continuouslyrelaxed categorical distributions. We test our method on a suite of anomalydetection tabular datasets. GNSM achieves a consistently high performanceacross all experiments. We further demonstrate the flexibility of GNSM byapplying it to image data where the model is tasked to detect poor segmentationpredictions. Images ranked anomalous by GNSM show clear segmentation failures,with the outputs of GNSM strongly correlating with segmentation metricscomputed on ground-truth. We outline the score matching training objectiveutilized by GNSM and provide an open-source implementation of our work.", "output": "Anomaly Detection via Gumbel Noise Score Matching."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we aim to learn dexterous manipulation of deformable objectsusing multi-fingered hands. Reinforcement learning approaches for dexterousrigid object manipulation would struggle in this setting due to the complexityof physics interaction with deformable objects. At the same time, previoustrajectory optimization approaches with differentiable physics for deformablemanipulation would suffer from local optima caused by the explosion of contactmodes from hand-object interactions. To address these challenges, we proposeDexDeform, a principled framework that abstracts dexterous manipulation skillsfrom human demonstration and refines the learned skills with differentiablephysics. Concretely, we first collect a small set of human demonstrations usingteleoperation. And we then train a skill model using demonstrations forplanning over action abstractions in imagination. To explore the goal space, wefurther apply augmentations to the existing deformable shapes in demonstrationsand use a gradient optimizer to refine the actions planned by the skill model.Finally, we adopt the refined trajectories as new demonstrations for finetuningthe skill model. To evaluate the effectiveness of our approach, we introduce asuite of six challenging dexterous deformable object manipulation tasks.Compared with baselines, DexDeform is able to better explore and generalizeacross novel goals unseen in the initial human demonstrations.", "output": "DexDeform: Dexterous Deformable Object Manipulation with Human Demonstrations and Differentiable Physics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Chatbots are mainly data-driven and usually based on utterances that might besensitive. However, training deep learning models on shared data can violateuser privacy. Such issues have commonly existed in chatbots since theirinception. In the literature, there have been many approaches to deal withprivacy, such as differential privacy and secure multi-party computation, butmost of them need to have access to users' data. In this context, FederatedLearning (FL) aims to protect data privacy through distributed learning methodsthat keep the data in its location. This paper presents Fedbot, aproof-of-concept (POC) privacy-preserving chatbot that leverages large-scalecustomer support data. The POC combines Deep Bidirectional Transformer modelsand federated learning algorithms to protect customer data privacy duringcollaborative model training. The results of the proof-of-concept showcase thepotential for privacy-preserving chatbots to transform the customer supportindustry by delivering personalized and efficient customer service that meetsdata privacy regulations and legal requirements. Furthermore, the system isspecifically designed to improve its performance and accuracy over time byleveraging its ability to learn from previous interactions.", "output": "FedBot: Enhancing Privacy in Chatbots with Federated Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Synthetic data are becoming a critical tool for building artificiallyintelligent systems. Simulators provide a way of generating data systematicallyand at scale. These data can then be used either exclusively, or in conjunctionwith real data, for training and testing systems. Synthetic data areparticularly attractive in cases where the availability of ``real'' trainingexamples might be a bottleneck. While the volume of data in healthcare isgrowing exponentially, creating datasets for novel tasks and/or that reflect adiverse set of conditions and causal relationships is not trivial. Furthermore,these data are highly sensitive and often patient specific. Recent research hasbegun to illustrate the potential for synthetic data in many areas of medicine,but no systematic review of the literature exists. In this paper, we presentthe cases for physical and statistical simulations for creating data and theproposed applications in healthcare and medicine. We discuss that whilesynthetics can promote privacy, equity, safety and continual and causallearning, they also run the risk of introducing flaws, blind spots andpropagating or exaggerating biases.", "output": "Synthetic Data in Healthcare."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Chain-of-Thought (CoT) prompting can effectively elicit complex multi-stepreasoning from Large Language Models~(LLMs). For example, by simply adding CoTinstruction ``Let's think step-by-step'' to each input query of MultiArithdataset, GPT-3's accuracy can be improved from 17.7% to 78.7%. However, it isnot clear whether CoT is still effective on more recent instruction finetuned(IFT) LLMs such as ChatGPT. Surprisingly, on ChatGPT, CoT is no longereffective for certain tasks such as arithmetic reasoning while still keepingeffective on other reasoning tasks. Moreover, on the former tasks, ChatGPTusually achieves the best performance and can generate CoT even without beinginstructed to do so. Hence, it is plausible that ChatGPT has already beentrained on these tasks with CoT and thus memorized the instruction so itimplicitly follows such an instruction when applied to the same queries, evenwithout CoT. Our analysis reflects a potential risk of overfitting/bias towardinstructions introduced in IFT, which becomes more common in training LLMs. Inaddition, it indicates possible leakage of the pretraining recipe, e.g., onecan verify whether a dataset and instruction were used in training ChatGPT. Ourexperiments report new baseline results of ChatGPT on a variety of reasoningtasks and shed novel insights into LLM's profiling, instruction memorization,and pretraining dataset leakage.", "output": "When do you need Chain-of-Thought Prompting for ChatGPT?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The growing carbon footprint of artificial intelligence (AI) models,especially large ones such as GPT-3 and GPT-4, has been undergoing publicscrutiny. Unfortunately, however, the equally important and enormous waterfootprint of AI models has remained under the radar. For example, trainingGPT-3 in Microsoft's state-of-the-art U.S. data centers can directly consume700,000 liters of clean freshwater (enough for producing 370 BMW cars or 320Tesla electric vehicles) and the water consumption would have been tripled iftraining were done in Microsoft's Asian data centers, but such information hasbeen kept as a secret. This is extremely concerning, as freshwater scarcity hasbecome one of the most pressing challenges shared by all of us in the wake ofthe rapidly growing population, depleting water resources, and aging waterinfrastructures. To respond to the global water challenges, AI models can, andalso should, take social responsibility and lead by example by addressing theirown water footprint. In this paper, we provide a principled methodology toestimate fine-grained water footprint of AI models, and also discuss the uniquespatial-temporal diversities of AI models' runtime water efficiency. Finally,we highlight the necessity of holistically addressing water footprint alongwith carbon footprint to enable truly sustainable AI.", "output": "Making AI Less \"Thirsty\": Uncovering and Addressing the Secret Water Footprint of AI Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Motion mimicking is a foundational task in physics-based character animation.However, most existing motion mimicking methods are built upon reinforcementlearning (RL) and suffer from heavy reward engineering, high variance, and slowconvergence with hard explorations. Specifically, they usually take tens ofhours or even days of training to mimic a simple motion sequence, resulting inpoor scalability. In this work, we leverage differentiable physics simulators(DPS) and propose an efficient motion mimicking method dubbed DiffMimic. Ourkey insight is that DPS casts a complex policy learning task to a much simplerstate matching problem. In particular, DPS learns a stable policy by analyticalgradients with ground-truth physical priors hence leading to significantlyfaster and stabler convergence than RL-based methods. Moreover, to escape fromlocal optima, we utilize a Demonstration Replay mechanism to enable stablegradient backpropagation in a long horizon. Extensive experiments on standardbenchmarks show that DiffMimic has a better sample efficiency and timeefficiency than existing methods (e.g., DeepMimic). Notably, DiffMimic allows aphysically simulated character to learn Backflip after 10 minutes of trainingand be able to cycle it after 3 hours of training, while the existing approachmay require about a day of training to cycle Backflip. More importantly, wehope DiffMimic can benefit more differentiable animation systems withtechniques like differentiable clothes simulation in future research.", "output": "DiffMimic: Efficient Motion Mimicking with Differentiable Physics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Prior work has shown that finetuning large language models (LLMs) usingmachine-generated instruction-following data enables such models to achieveremarkable zero-shot capabilities on new tasks, and no human-writteninstructions are needed. In this paper, we present the first attempt to useGPT-4 to generate instruction-following data for LLM finetuning. Our earlyexperiments on instruction-tuned LLaMA models show that the 52K English andChinese instruction-following data generated by GPT-4 leads to superiorzero-shot performance on new tasks to the instruction-following data generatedby previous state-of-the-art models. We also collect feedback and comparisondata from GPT-4 to enable a comprehensive evaluation and reward model training.We make our data generated using GPT-4 as well as our codebase publiclyavailable.", "output": "Instruction Tuning with GPT-4."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Artificial agents have traditionally been trained to maximize reward, whichmay incentivize power-seeking and deception, analogous to how next-tokenprediction in language models (LMs) may incentivize toxicity. So do agentsnaturally learn to be Machiavellian? And how do we measure these behaviors ingeneral-purpose models such as GPT-4? Towards answering these questions, weintroduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure gamescontaining over half a million rich, diverse scenarios that center on socialdecision-making. Scenario labeling is automated with LMs, which are moreperformant than human annotators. We mathematize dozens of harmful behaviorsand use our annotations to evaluate agents' tendencies to be power-seeking,cause disutility, and commit ethical violations. We observe some tensionbetween maximizing reward and behaving ethically. To improve this trade-off, weinvestigate LM-based methods to steer agents' towards less harmful behaviors.Our results show that agents can both act competently and morally, so concreteprogress can currently be made in machine ethics--designing agents that arePareto improvements in both safety and capabilities.", "output": "Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Accurate inference of fine-grained traffic flow from coarse-grained one is anemerging yet crucial problem, which can help greatly reduce the number of therequired traffic monitoring sensors for cost savings. In this work, we noticethat traffic flow has a high correlation with road network, which was eithercompletely ignored or simply treated as an external factor in previous works.Tofacilitate this problem, we propose a novel Road-Aware Traffic Flow Magnifier(RATFM) that explicitly exploits the prior knowledge of road networks to fullylearn the road-aware spatial distribution of fine-grained traffic flow.Specifically, a multi-directional 1D convolutional layer is first introduced toextract the semantic feature of the road network. Subsequently, we incorporatethe road network feature and coarse-grained flow feature to regularize theshort-range spatial distribution modeling of road-relative traffic flow.Furthermore, we take the road network feature as a query to capture thelong-range spatial distribution of traffic flow with a transformerarchitecture. Benefiting from the road-aware inference mechanism, our methodcan generate high-quality fine-grained traffic flow maps. Extensive experimentson three real-world datasets show that the proposed RATFM outperformsstate-of-the-art models under various scenarios. Our code and datasets arereleased at {url{", "output": "Road Network Guided Fine-Grained Urban Traffic Flow Inference."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large Language Models have become the core architecture upon which mostmodern natural language processing (NLP) systems build. These models canconsistently deliver impressive accuracy and robustness across tasks anddomains, but their high computational overhead can make inference difficult andexpensive. To make using these models less costly, recent work has exploredleveraging structured and unstructured pruning, quantization, and distillationto improve inference speed and decrease size. This paper studies how modelspruned using Gradual Unstructured Magnitude Pruning can transfer betweendomains and tasks. Our experimentation shows that models that are pruned duringpretraining using general domain masked language models can transfer to noveldomains and tasks without extensive hyperparameter exploration or specializedapproaches. We demonstrate that our general sparse model Sparse*BERT can becomeSparseBioBERT simply by pretraining the compressed architecture on unstructuredbiomedical text. Moreover, we show that SparseBioBERT can match the quality ofBioBERT with only 10% of the parameters.", "output": "Sparse*BERT: Sparse Models Generalize To New tasks and Domains."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Complex reasoning problems contain states that vary in the computational costrequired to determine a good action plan. Taking advantage of this property, wepropose Adaptive Subgoal Search (AdaSubS), a search method that adaptivelyadjusts the planning horizon. To this end, AdaSubS generates diverse sets ofsubgoals at different distances. A verification mechanism is employed to filterout unreachable subgoals swiftly, allowing to focus on feasible furthersubgoals. In this way, AdaSubS benefits from the efficiency of planning withlonger subgoals and the fine control with the shorter ones, and thus scaleswell to difficult planning problems. We show that AdaSubS significantlysurpasses hierarchical planning algorithms on three complex reasoning tasks:Sokoban, the Rubik's Cube, and inequality proving benchmark INT.", "output": "Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal Search."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing explanation models generate only text for recommendations but stillstruggle to produce diverse contents. In this paper, to further enrichexplanations, we propose a new task named personalized showcases, in which weprovide both textual and visual information to explain our recommendations.Specifically, we first select a personalized image set that is the mostrelevant to a user's interest toward a recommended item. Then, natural languageexplanations are generated accordingly given our selected images. For this newtask, we collect a large-scale dataset from Google Local (i.e.,~maps) andconstruct a high-quality subset for generating multi-modal explanations. Wepropose a personalized multi-modal framework which can generate diverse andvisually-aligned explanations via contrastive learning. Experiments show thatour framework benefits from different modalities as inputs, and is able toproduce more diverse and expressive explanations compared to previous methodson a variety of evaluation metrics.", "output": "Personalized Showcases: Generating Multi-Modal Explanations for Recommendations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a new approach to formally describing the requirement forstatistical inference and checking whether a program uses the statisticalmethod appropriately. Specifically, we define belief Hoare logic (BHL) forformalizing and reasoning about the statistical beliefs acquired via hypothesistesting. This program logic is sound and relatively complete with respect to aKripke model for hypothesis tests. We demonstrate by examples that BHL isuseful for reasoning about practical issues in hypothesis testing. In ourframework, we clarify the importance of prior beliefs in acquiring statisticalbeliefs through hypothesis testing, and discuss the whole picture of thejustification of statistical inference inside and outside the program logic.", "output": "Sound and Relatively Complete Belief Hoare Logic for Statistical Hypothesis Testing Programs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Tensegrity robots, composed of rigid rods and flexible cables, exhibit highstrength-to-weight ratios and significant deformations, which enable them tonavigate unstructured terrains and survive harsh impacts. They are hard tocontrol, however, due to high dimensionality, complex dynamics, and a coupledarchitecture. Physics-based simulation is a promising avenue for developinglocomotion policies that can be transferred to real robots. Nevertheless,modeling tensegrity robots is a complex task due to a substantial sim2real gap.To address this issue, this paper describes a Real2Sim2Real (R2S2R) strategyfor tensegrity robots. This strategy is based on a differentiable physicsengine that can be trained given limited data from a real robot. These datainclude offline measurements of physical properties, such as mass and geometryfor various robot components, and the observation of a trajectory using arandom control policy. With the data from the real robot, the engine can beiteratively refined and used to discover locomotion policies that are directlytransferable to the real robot. Beyond the R2S2R pipeline, key contributions ofthis work include computing non-zero gradients at contact points, a lossfunction for matching tensegrity locomotion gaits, and a trajectorysegmentation technique that avoids conflicts in gradient evaluation duringtraining. Multiple iterations of the R2S2R process are demonstrated andevaluated on a real 3-bar tensegrity robot.", "output": "Real2Sim2Real Transfer for Control of Cable-driven Robots via a Differentiable Physics Engine."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The representation learning problem in the oil &amp; gas industry aims toconstruct a model that provides a representation based on logging data for awell interval. Previous attempts are mainly supervised and focus on similaritytask, which estimates closeness between intervals. We desire to buildinformative representations without using supervised (labelled) data. One ofthe possible approaches is self-supervised learning (SSL). In contrast to thesupervised paradigm, this one requires little or no labels for the data.Nowadays, most SSL approaches are either contrastive or non-contrastive.Contrastive methods make representations of similar (positive) objects closerand distancing different (negative) ones. Due to possible wrong marking ofpositive and negative pairs, these methods can provide an inferior performance.Non-contrastive methods don't rely on such labelling and are widespread incomputer vision. They learn using only pairs of similar objects that are easierto identify in logging data.We are the first to introduce non-contrastive SSL for well-logging data. Inparticular, we exploit Bootstrap Your Own Latent (BYOL) and Barlow Twinsmethods that avoid using negative pairs and focus only on matching positivepairs. The crucial part of these methods is an augmentation strategy. Ouraugmentation strategies and adaption of BYOL and Barlow Twins together allow usto achieve superior quality on clusterization and mostly the best performanceon different classification tasks. Our results prove the usefulness of theproposed non-contrastive self-supervised approaches for representation learningand interval similarity in particular.", "output": "Non-contrastive representation learning for intervals from well logs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "High-quality traffic flow generation is the core module in buildingsimulators for autonomous driving. However, the majority of availablesimulators are incapable of replicating traffic patterns that accuratelyreflect the various features of real-world data while also simulatinghuman-like reactive responses to the tested autopilot driving strategies.Taking one step forward to addressing such a problem, we propose RealisticInteractive TrAffic flow (RITA) as an integrated component of existing drivingsimulators to provide high-quality traffic flow for the evaluation andoptimization of the tested driving strategies. RITA is developed withconsideration of three key features, i.e., fidelity, diversity, andcontrollability, and consists of two core modules called RITABackend andRITAKit. RITABackend is built to support vehicle-wise control and providetraffic generation models from real-world datasets, while RITAKit is developedwith easy-to-use interfaces for controllable traffic generation viaRITABackend. We demonstrate RITA's capacity to create diversified andhigh-fidelity traffic simulations in several highly interactive highwayscenarios. The experimental findings demonstrate that our produced RITA trafficflows exhibit all three key features, hence enhancing the completeness ofdriving strategy evaluation. Moreover, we showcase the possibility for furtherimprovement of baseline strategies through online fine-tuning with RITA trafficflows.", "output": "RITA: Boost Autonomous Driving Simulators with Realistic Interactive Traffic Flow."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Scenario-based probabilistic forecasts have become vital for decision-makersin handling intermittent renewable energies. This paper presents a recentpromising deep learning generative approach called denoising diffusionprobabilistic models. It is a class of latent variable models which haverecently demonstrated impressive results in the computer vision community.However, to our knowledge, there has yet to be a demonstration that they cangenerate high-quality samples of load, PV, or wind power time series, crucialelements to face the new challenges in power systems applications. Thus, wepropose the first implementation of this model for energy forecasting using theopen data of the Global Energy Forecasting Competition 2014. The resultsdemonstrate this approach is competitive with other state-of-the-art deeplearning generative models, including generative adversarial networks,variational autoencoders, and normalizing flows.", "output": "Denoising diffusion probabilistic models for probabilistic energy forecasting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In psychiatric diagnosis, a contemporary data-driven, manual-based method formental disorders classification is the most popular technique; however, it hasseveral inevitable flaws. Using the three-way decision as a framework, wepropose a unified model that stands for clinicians' subjective approach (CSA)analysis consisting of three parts: quantitative analysis, quantitativeanalysis, and evaluation-based analysis. A ranking list and a set of numericalweights based on illness magnitude levels according to the clinician's greatestdegree of assumptions are the findings of the qualitative and quantitativeinvestigation. We further create a comparative classification of illnesses intothree groups with varying important levels; a three-way evaluation-based modelis utilized in this study for the aim of understanding and portraying theseresults in a more clear way. This proposed method might be integrated with themanual-based process as a complementary tool to improve precision whilediagnosing mental disorders", "output": "Classifying Mental-Disorders through Clinicians Subjective Approach based on Three-way Decision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite its great scientific and technological importance, wall-boundedturbulence is an unresolved problem that requires new perspectives to betackled. One of the key strategies has been to study interactions among thecoherent structures in the flow. Such interactions are explored in this studyfor the first time using an explainable deep-learning method. The instantaneousvelocity field in a turbulent channel is used to predict the velocity field intime through a convolutional neural network. Based on the predicted flow, weassess the importance of each structure for this prediction using thegame-theoretic algorithm of SHapley Additive exPlanations (SHAP). This workprovides results in agreement with previous observations in the literature andextends them by quantifying the importance of the Reynolds-stress structures,finding a connection between these structures and the dynamics of the flow. Theprocess, based on deep-learning explainability, has the potential to shed lighton numerous fundamental phenomena of wall-bounded turbulence, including theobjective definition of new types of flow structures.", "output": "Explaining wall-bounded turbulence through deep learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automation of test oracles is one of the most challenging facets of softwaretesting, but remains comparatively less addressed compared to automated testinput generation. Test oracles rely on a ground-truth that can distinguishbetween the correct and buggy behavior to determine whether a test fails(detects a bug) or passes. What makes the oracle problem challenging andundecidable is the assumption that the ground-truth should know the exactexpected, correct, or buggy behavior. However, we argue that one can stillbuild an accurate oracle without knowing the exact correct or buggy behavior,but how these two might differ. This paper presents SEER, a learning-basedapproach that in the absence of test assertions or other types of oracle, candetermine whether a unit test passes or fails on a given method under test(MUT). To build the ground-truth, SEER jointly embeds unit tests and theimplementation of MUTs into a unified vector space, in such a way that theneural representation of tests are similar to that of MUTs they pass on them,but dissimilar to MUTs they fail on them. The classifier built on top of thisvector representation serves as the oracle to generate \"fail\" labels, when testinputs detect a bug in MUT or \"pass\" labels, otherwise. Our extensiveexperiments on applying SEER to more than 5K unit tests from a diverse set ofopen-source Java projects show that the produced oracle is (1) effective inpredicting the fail or pass labels, achieving an overall accuracy, precision,recall, and F1 measure of 93%, 86%, 94%, and 90%, (2) generalizable, predictingthe labels for the unit test of projects that were not in training orvalidation set with negligible performance drop, and (3) efficient, detectingthe existence of bugs in only 6.5 milliseconds on average.", "output": "Perfect is the enemy of test oracle."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the increasing importance of data and artificial intelligence,organizations strive to become more data-driven. However, current dataarchitectures are not necessarily designed to keep up with the scale and scopeof data and analytics use cases. In fact, existing architectures often fail todeliver the promised value associated with them. Data mesh is a socio-technicalconcept that includes architectural aspects to promote data democratization andenables organizations to become truly data-driven. As the concept of data meshis still novel, it lacks empirical insights from the field. Specifically, anunderstanding of the motivational factors for introducing data mesh, theassociated challenges, best practices, its business impact, and potentialarchetypes, is missing. To address this gap, we conduct 15 semi-structuredinterviews with industry experts. Our results show, among other insights, thatindustry experts have difficulties with the transition toward federatedgovernance associated with the data mesh concept, the shift of responsibilityfor the development, provision, and maintenance of data products, and theconcept of a data product model. In our work, we derive multiple best practicesand suggest organizations embrace elements of data fabric, observe the dataproduct usage, create quick wins in the early phases, and favor small dedicatedteams that prioritize data products. While we acknowledge that organizationsneed to apply best practices according to their individual needs, we alsodeduct two archetypes that provide suggestions in more detail. Our findingssynthesize insights from industry experts and provide researchers andprofessionals with guidelines for the successful adoption of data mesh.", "output": "Data Mesh: Motivational Factors, Challenges, and Best Practices."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Friend recall is an important way to improve Daily Active Users (DAU) inonline games. The problem is to generate a proper lost friend ranking listessentially. Traditional friend recall methods focus on rules like friendintimacy or training a classifier for predicting lost players' returnprobability, but ignore feature information of (active) players and historicalfriend recall events. In this work, we treat friend recall as a link predictionproblem and explore several link prediction methods which can use features ofboth active and lost players, as well as historical events. Furthermore, wepropose a novel Edge Transformer model and pre-train the model via maskedauto-encoders. Our method achieves state-of-the-art results in the offlineexperiments and online A/B Tests of three Tencent games.", "output": "Friend Ranking in Online Games via Pre-training Edge Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Given a document in a source language, cross-lingual summarization (CLS) aimsto generate a summary in a different target language. Recently, the emergenceof Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, hasattracted wide attention from the computational linguistics community. However,it is not yet known the performance of LLMs on CLS. In this report, weempirically use various prompts to guide LLMs to perform zero-shot CLS fromdifferent paradigms (i.e., end-to-end and pipeline), and provide a preliminaryevaluation on the generated summaries. We find that ChatGPT and GPT-4originally prefer to produce lengthy summaries with detailed information. Thesetwo LLMs can further balance informativeness and conciseness with the help ofan interactive prompt, significantly improving their CLS performance.Experimental results on three widely-used CLS datasets show that GPT-4 achievesstate-of-the-art zero-shot CLS performance, and performs competitively comparedwith the fine-tuned mBART-50. Moreover, we also find some multi-lingual andbilingual LLMs (i.e., BLOOMZ, ChatGLM-6B, Vicuna-13B and ChatYuan) have limitedzero-shot CLS ability. Due to the composite nature of CLS, which requiresmodels to perform summarization and translation simultaneously, accomplishingthis task in a zero-shot manner is even a challenge for LLMs. Therefore, wesincerely hope and recommend future LLM research could use CLS as a testbed.", "output": "Zero-Shot Cross-Lingual Summarization via Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we present AR3n (pronounced as Aaron), an assist-as-needed(AAN) controller that utilizes reinforcement learning to supply adaptiveassistance during a robot assisted handwriting rehabilitation task. Unlikeprevious AAN controllers, our method does not rely on patient specificcontroller parameters or physical models. We propose the use of a virtualpatient model to generalize AR3n across multiple subjects. The system modulatesrobotic assistance in realtime based on a subject's tracking error, whileminimizing the amount of robotic assistance. The controller is experimentallyvalidated through a set of simulations and human subject experiments. Finally,a comparative study with a traditional rule-based controller is conducted toanalyze differences in assistance mechanisms of the two controllers.", "output": "AR3n: A Reinforcement Learning-based Assist-As-Needed Controller for Robotic Rehabilitation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Prediction of taxi service demand and supply is essential for improvingcustomer's experience and provider's profit. Recently, graph neural networks(GNNs) have been shown promising for this application. This approach modelscity regions as nodes in a transportation graph and their relations as edges.GNNs utilize local node features and the graph structure in the prediction.However, more efficient forecasting can still be achieved by following two mainroutes; enlarging the scale of the transportation graph, and simultaneouslyexploiting different types of nodes and edges in the graphs. However, bothapproaches are challenged by the scalability of GNNs. An immediate remedy tothe scalability challenge is to decentralize the GNN operation. However, thiscreates excessive node-to-node communication. In this paper, we firstcharacterize the excessive communication needs for the decentralized GNNapproach. Then, we propose a semi-decentralized approach utilizing multiplecloudlets, moderately sized storage and computation devices, that can beintegrated with the cellular base stations. This approach minimizesinter-cloudlet communication thereby alleviating the communication overhead ofthe decentralized approach while promoting scalability due to cloudlet-leveldecentralization. Also, we propose a heterogeneous GNN-LSTM algorithm forimproved taxi-level demand and supply forecasting for handling dynamic taxigraphs where nodes are taxis. Extensive experiments over real data show theadvantage of the semi-decentralized approach as tested over our heterogeneousGNN-LSTM algorithm. Also, the proposed semi-decentralized GNN approach is shownto reduce the overall inference time by about an order of magnitude compared tocentralized and decentralized inference schemes.", "output": "Semi-decentralized Inference in Heterogeneous Graph Neural Networks for Traffic Demand Forecasting: An Edge-Computing Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we propose a planning framework to generate a defense strategyagainst an attacker who is working in an environment where a defender canoperate without the attacker's knowledge. The objective of the defender is tocovertly guide the attacker to a trap state from which the attacker cannotachieve their goal. Further, the defender is constrained to achieve its goalwithin K number of steps, where K is calculated as a pessimistic lower boundwithin which the attacker is unlikely to suspect a threat in the environment.Such a defense strategy is highly useful in real world systems like honeypotsor honeynets, where an unsuspecting attacker interacts with a simulatedproduction system while assuming it is the actual production system. Typically,the interaction between an attacker and a defender is captured using gametheoretic frameworks. Our problem formulation allows us to capture it as a muchsimpler infinite horizon discounted MDP, in which the optimal policy for theMDP gives the defender's strategy against the actions of the attacker. Throughempirical evaluation, we show the merits of our problem formulation.", "output": "Planning for Attacker Entrapment in Adversarial Settings."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in digitization have led to the availability of multivariatetime series data in various domains, enabling real-time monitoring ofoperations. Identifying abnormal data patterns and detecting potential failuresin these scenarios are important yet rather challenging. In this work, wepropose a novel unsupervised anomaly detection method for time series data. Theproposed framework jointly learns the observation model and the dynamic model,and model uncertainty is estimated from normal samples. Specifically, a longshort-term memory (LSTM)-based encoder-decoder is adopted to represent themapping between the observation space and the latent space. Bidirectionaltransitions of states are simultaneously modeled by leveraging backward andforward temporal information. Regularization of the latent space placesconstraints on the states of normal samples, and Mahalanobis distance is usedto evaluate the abnormality level. Empirical studies on synthetic andreal-world datasets demonstrate the superior performance of the proposed methodin anomaly detection tasks.", "output": "Time series anomaly detection with reconstruction-based state-space models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The responsible and sustainable agave-tequila production chain is fundamentalfor the social, environment and economic development of Mexico's agave regions.It is therefore relevant to develop new tools for large scale automatic agaveregion monitoring. In this work, we present an Agave tequilana Weber azul cropsegmentation and maturity classification using very high resolution satelliteimagery, which could be useful for this task. To achieve this, we solvereal-world deep learning problems in the very specific context of agave cropsegmentation such as lack of data, low quality labels, highly imbalanced data,and low model performance. The proposed strategies go beyond data augmentationand data transfer combining active learning and the creation of syntheticimages with human supervision. As a result, the segmentation performanceevaluated with Intersection over Union (IoU) value increased from 0.72 to 0.90in the test set. We also propose a method for classifying agave crop maturitywith 95% accuracy. With the resulting accurate models, agave productionforecasting can be made available for large regions. In addition, somesupply-demand problems such excessive supplies of agave or, deforestation,could be detected early.", "output": "Agave crop segmentation and maturity classification with deep learning data-centric strategies using very high-resolution satellite imagery."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Understanding 3D scenes from multi-view inputs has been proven to alleviatethe view discrepancy issue in 3D visual grounding. However, existing methodsnormally neglect the view cues embedded in the text modality and fail to weighthe relative importance of different views. In this paper, we proposeViewRefer, a multi-view framework for 3D visual grounding exploring how tograsp the view knowledge from both text and 3D modalities. For the text branch,ViewRefer leverages the diverse linguistic knowledge of large-scale languagemodels, e.g., GPT, to expand a single grounding text to multiplegeometry-consistent descriptions. Meanwhile, in the 3D modality, a transformerfusion module with inter-view attention is introduced to boost the interactionof objects across views. On top of that, we further present a set of learnablemulti-view prototypes, which memorize scene-agnostic knowledge for differentviews, and enhance the framework from two perspectives: a view-guided attentionmodule for more robust text features, and a view-guided scoring strategy duringthe final prediction. With our designed paradigm, ViewRefer achieves superiorperformance on three benchmarks and surpasses the second-best by +2.8%, +1.2%,and +0.73% on Sr3D, Nr3D, and ScanRefer. Code will be released at", "output": "ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Estimating 3D humans from images often produces implausible bodies that lean,float, or penetrate the floor. Such methods ignore the fact that bodies aretypically supported by the scene. A physics engine can be used to enforcephysical plausibility, but these are not differentiable, rely on unrealisticproxy bodies, and are difficult to integrate into existing optimization andlearning frameworks. In contrast, we exploit novel intuitive-physics (IP) termsthat can be inferred from a 3D SMPL body interacting with the scene. Inspiredby biomechanics, we infer the pressure heatmap on the body, the Center ofPressure (CoP) from the heatmap, and the SMPL body's Center of Mass (CoM). Withthese, we develop IPMAN, to estimate a 3D body from a color image in a \"stable\"configuration by encouraging plausible floor contact and overlapping CoP andCoM. Our IP terms are intuitive, easy to implement, fast to compute,differentiable, and can be integrated into existing optimization and regressionmethods. We evaluate IPMAN on standard datasets and MoYo, a new dataset withsynchronized multi-view images, ground-truth 3D bodies with complex poses,body-floor contact, CoM and pressure. IPMAN produces more plausible resultsthan the state of the art, improving accuracy for static poses, while nothurting dynamic ones. Code and data are available for research at", "output": "3D Human Pose Estimation via Intuitive Physics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Symbolic regression searches for analytic expressions that accuratelydescribe studied phenomena. The main attraction of this approach is that itreturns an interpretable model that can be insightful to users. Historically,the majority of algorithms for symbolic regression have been based onevolutionary algorithms. However, there has been a recent surge of newproposals that instead utilize approaches such as enumeration algorithms, mixedlinear integer programming, neural networks, and Bayesian optimization. Inorder to assess how well these new approaches behave on a set of commonchallenges often faced in real-world data, we hosted a competition at the 2022Genetic and Evolutionary Computation Conference consisting of differentsynthetic and real-world datasets which were blind to entrants. For thereal-world track, we assessed interpretability in a realistic way by using adomain expert to judge the trustworthiness of candidate models.We present anin-depth analysis of the results obtained in this competition, discuss currentchallenges of symbolic regression algorithms and highlight possibleimprovements for future competitions.", "output": "Interpretable Symbolic Regression for Data Science: Analysis of the 2022 Competition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural networks (NNs) playing the role of controllers have demonstratedimpressive empirical performances on challenging control problems. However, thepotential adoption of NN controllers in real-life applications also gives riseto a growing concern over the safety of these neural-network controlled systems(NNCSs), especially when used in safety-critical applications. In this work, wepresent POLAR-Express, an efficient and precise formal reachability analysistool for verifying the safety of NNCSs. POLAR-Express uses Taylor modelarithmetic to propagate Taylor models (TMs) across a neural networklayer-by-layer to compute an overapproximation of the neural-network function.It can be applied to analyze any feed-forward neural network with continuousactivation functions. We also present a novel approach to propagate TMs moreefficiently and precisely across ReLU activation functions. In addition,POLAR-Express provides parallel computation support for the layer-by-layerpropagation of TMs, thus significantly improving the efficiency and scalabilityover its earlier prototype POLAR. Across the comparison with six otherstate-of-the-art tools on a diverse set of benchmarks, POLAR-Express achievesthe best verification efficiency and tightness in the reachable set analysis.", "output": "POLAR-Express: Efficient and Precise Formal Reachability Analysis of Neural-Network Controlled Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Masked graph autoencoder (MGAE) has emerged as a promising self-supervisedgraph pre-training (SGP) paradigm due to its simplicity and effectiveness.However, existing efforts perform the mask-then-reconstruct operation in theraw data space as is done in computer vision (CV) and natural languageprocessing (NLP) areas, while neglecting the important non-Euclidean propertyof graph data. As a result, the highly unstable local connection structureslargely increase the uncertainty in inferring masked data and decrease thereliability of the exploited self-supervision signals, leading to inferiorrepresentations for downstream evaluations. To address this issue, we propose anovel SGP method termed Robust mAsked gRaph autoEncoder (RARE) to improve thecertainty in inferring masked data and the reliability of the self-supervisionmechanism by further masking and reconstructing node samples in the high-orderlatent feature space. Through both theoretical and empirical analyses, we havediscovered that performing a joint mask-then-reconstruct strategy in bothlatent feature and raw data spaces could yield improved stability andperformance. To this end, we elaborately design a masked latent featurecompletion scheme, which predicts latent features of masked nodes under theguidance of high-order sample correlations that are hard to be observed fromthe raw data perspective. Specifically, we first adopt a latent featurepredictor to predict the masked latent features from the visible ones. Next, weencode the raw data of masked samples with a momentum graph encoder andsubsequently employ the resulting representations to improve predicted resultsthrough latent feature matching. Extensive experiments on seventeen datasetshave demonstrated the effectiveness and robustness of RARE againststate-of-the-art (SOTA) competitors across three downstream tasks.", "output": "RARE: Robust Masked Graph Autoencoder."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Unsupervised domain adaptation (UDA) addresses the problem of distributionshift between the unlabelled target domain and labelled source domain. Whilethe single target domain adaptation (STDA) is well studied in the literaturefor both 2D and 3D vision tasks, multi-target domain adaptation (MTDA) isbarely explored for 3D data despite its wide real-world applications such asautonomous driving systems for various geographical and climatic conditions. Weestablish an MTDA baseline for 3D point cloud data by proposing to mix thefeature representations from all domains together to achieve better domainadaptation performance by an ensemble average, which we call Mixup EnsembleAverage or MEnsA. With the mixed representation, we use a domain classifier toimprove at distinguishing the feature representations of source domain fromthose of target domains in a shared latent space. In empirical validations onthe challenging PointDA-10 dataset, we showcase a clear benefit of our simplemethod over previous unsupervised STDA and MTDA methods by large margins (up to17.10% and 4.76% on averaged over all domain shifts).", "output": "MEnsA: Mix-up Ensemble Average for Unsupervised Multi Target Domain Adaptation on 3D Point Clouds."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This article presents a new NLP task called structured information inference(SII) to address the complexities of information extraction at the device levelin materials science. We accomplished this task by tuning GPT-3 on an existedperovskite solar cell FAIR(Findable, Accessible, Interoperable, Reusable)dataset with 91.8 F1-score and we updated the dataset with all relatedscientific papers up to now. The produced dataset is formatted and normalized,enabling its direct utilization as input in subsequent data analysis. Thisfeature will enable materials scientists to develop their own models byselecting high-quality review papers within their domain. Furthermore, wedesigned experiments to predict solar cells' electrical performance andreverse-predict parameters on both material gene and FAIR datesets through LLM.We obtained comparable performance with traditional machine learning methodswithout feature selection, which demonstrates the potential of large languagemodels to judge materials and design new materials like a materials scientist.", "output": "Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Knowledge tracing (KT) aims to assess individuals' evolving knowledge statesaccording to their learning interactions with different exercises in onlinelearning systems (OIS), which is critical in supporting decision-making forsubsequent intelligent services, such as personalized learning sourcerecommendation. Existing researchers have broadly studied KT and developed manyeffective methods. However, most of them assume that students' historicalinteractions are uniformly distributed in a continuous sequence, ignoring thefact that actual interaction sequences are organized based on a series ofquizzes with clear boundaries, where interactions within a quiz areconsecutively completed, but interactions across different quizzes are discreteand may be spaced over days. In this paper, we present the Quiz-based KnowledgeTracing (QKT) model to monitor students' knowledge states according to theirquiz-based learning interactions. Specifically, as students' interactionswithin a quiz are continuous and have the same or similar knowledge concepts,we design the adjacent gate followed by a global average pooling layer tocapture the intra-quiz short-term knowledge influence. Then, as various quizzestend to focus on different knowledge concepts, we respectively measure theinter-quiz knowledge substitution by the gated recurrent unit and theinter-quiz knowledge complementarity by the self-attentive encoder with a novelrecency-aware attention mechanism. Finally, we integrate the inter-quizlong-term knowledge substitution and complementarity across different quizzesto output students' evolving knowledge states. Extensive experimental resultson three public real-world datasets demonstrate that QKT achievesstate-of-the-art performance compared to existing methods. Further analysesconfirm that QKT is promising in designing more effective quizzes.", "output": "Quiz-based Knowledge Tracing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large language models (LLM) not only empower multiple language tasks but alsoserve as a general interface across different spaces. Up to now, it has notbeen demonstrated yet how to effectively translate the successes of LLMs in thecomputer vision field to the medical imaging field which involveshigh-dimensional and multi-modal medical images. In this paper, we report afeasibility study of building a multi-task CT large image-text (LIT) model forlung cancer diagnosis by combining an LLM and a large image model (LIM).Specifically, the LLM and LIM are used as encoders to perceive multi-modalinformation under task-specific text prompts, which synergizes multi-sourceinformation and task-specific and patient-specific priors for optimizeddiagnostic performance. The key components of our LIT model and associatedtechniques are evaluated with an emphasis on 3D lung CT analysis. Our initialresults show that the LIT model performs multiple medical tasks well, includinglung segmentation, lung nodule detection, and lung cancer classification.Active efforts are in progress to develop large image-language models forsuperior medical imaging in diverse applications and optimal patient outcomes.", "output": "CT Multi-Task Learning with a Large Image-Text (LIT) Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite the recent advances in various Structural Genomics Projects, a largegap remains between the number of sequenced and structurally characterizedproteins. Some reasons for this discrepancy include technical difficulties,labor, and the cost related to determining a structure by experimental methodssuch as NMR spectroscopy. Several computational methods have been developed toexpand the applicability of NMR spectroscopy by addressing temporal andeconomical problems more efficiently. While these methods demonstratesuccessful outcomes to solve more challenging and structurally novel proteins,the cost has not been reduced significantly. Probability Density ProfileAnalysis (PDPA) has been previously introduced by our lab to directly addressthe economics of structure determination of routine proteins and theidentification of novel structures from a minimal set of unassigned NMR data.2D-PDPA (in which 2D denotes incorporation of data from two alignment media)has been successful in identifying the structural homolog of an unknown proteinwithin a library of ~1000 decoy structures. In order to further expand theselectivity and sensitivity of PDPA, the incorporation of additional data wasnecessary. However, the expansion of the original PDPA approach was limited byits computational requirements where the inclusion of additional data wouldrender it computationally intractable. Here we present the most recentdevelopments of PDPA method (nD-PDPA: n Dimensional Probability Density ProfileAnalysis) that eliminate 2D-PDPA's computational limitations, and allowsinclusion of RDC data from multiple vector types in multiple alignment media.", "output": "nD-PDPA: nDimensional Probability Density Profile Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transferability is the property of adversarial examples to be misclassifiedby other models than the surrogate model for which they were crafted. Previousresearch has shown that transferability is substantially increased when thetraining of the surrogate model has been early stopped. A common hypothesis toexplain this is that the later training epochs are when models learn thenon-robust features that adversarial attacks exploit. Hence, an early stoppedmodel is more robust (hence, a better surrogate) than fully trained models. Wedemonstrate that the reasons why early stopping improves transferability lie inthe side effects it has on the learning dynamics of the model. We first showthat early stopping benefits transferability even on models learning from datawith non-robust features. We then establish links between transferability andthe exploration of the loss landscape in the parameter space, on which earlystopping has an inherent effect. More precisely, we observe thattransferability peaks when the learning rate decays, which is also the time atwhich the sharpness of the loss significantly drops. This leads us to proposeRFN, a new approach for transferability that minimizes loss sharpness duringtraining in order to maximize transferability. We show that by searching forlarge flat neighborhoods, RFN always improves over early stopping (by up to 47points of transferability rate) and is competitive to (if not better than)strong state-of-the-art baselines.", "output": "Going Further: Flatness at the Rescue of Early Stopping for Adversarial Example Transferability."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Medical data often exhibits long-tail distributions with heavy classimbalance, which naturally leads to difficulty in classifying the minorityclasses (i.e., boundary regions or rare objects). Recent work has significantlyimproved semi-supervised medical image segmentation in long-tailed scenarios byequipping them with unsupervised contrastive criteria. However, it remainsunclear how well they will perform in the labeled portion of data where classdistribution is also highly imbalanced. In this work, we present ACTION++, animproved contrastive learning framework with adaptive anatomical contrast forsemi-supervised medical segmentation. Specifically, we propose an adaptivesupervised contrastive loss, where we first compute the optimal locations ofclass centers uniformly distributed on the embedding space (i.e., off-line),and then perform online contrastive matching training by encouraging differentclass features to adaptively match these distinct and uniformly distributedclass centers. Moreover, we argue that blindly adopting a constant temperature$tau$ in the contrastive loss on long-tailed medical data is not optimal, andpropose to use a dynamic $tau$ via a simple cosine schedule to yield betterseparation between majority and minority classes. Empirically, we evaluateACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-artacross two semi-supervised settings. Theoretically, we analyze the performanceof adaptive anatomical contrast and confirm its superiority in labelefficiency.", "output": "ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Typical video compression systems consist of two main modules: motion codingand residual coding. This general architecture is adopted by classical codingschemes (such as international standards H.265 and H.266) and deeplearning-based coding schemes. We propose a novel B-frame coding architecturebased on two-layer Conditional Augmented Normalization Flows (CANF). It has thestriking feature of not transmitting any motion information. Our proposed ideaof video compression without motion coding offers a new direction for learnedvideo coding. Our base layer is a low-resolution image compressor that replacesthe full-resolution motion compressor. The low-resolution coded image is mergedwith the warped high-resolution images to generate a high-quality image as aconditioning signal for the enhancement-layer image coding in full resolution.One advantage of this architecture is significantly reduced computationalcomplexity due to eliminating the motion information compressor. In addition,we adopt a skip-mode coding technique to reduce the transmitted latent samples.The rate-distortion performance of our scheme is slightly lower than that ofthe state-of-the-art learned B-frame coding scheme, B-CANF, but outperformsother learned B-frame coding schemes. However, compared to B-CANF, our schemesaves 45% of multiply-accumulate operations (MACs) for encoding and 27% of MACsfor decoding. The code is available at ", "output": "Hierarchical B-frame Video Coding Using Two-Layer CANF without Motion Coding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image segmentation is an important problem in many safety-criticalapplications. Recent studies show that modern image segmentation models arevulnerable to adversarial perturbations, while existing attack methods mainlyfollow the idea of attacking image classification models. We argue that imagesegmentation and classification have inherent differences, and design an attackframework specially for image segmentation models. Our attack framework isinspired by certified radius, which was originally used by defenders to defendagainst adversarial perturbations to classification models. We are the first,from the attacker perspective, to leverage the properties of certified radiusand propose a certified radius guided attack framework against imagesegmentation models. Specifically, we first adapt randomized smoothing, thestate-of-the-art certification method for classification models, to derive thepixel's certified radius. We then focus more on disrupting pixels withrelatively smaller certified radii and design a pixel-wise certified radiusguided loss, when plugged into any existing white-box attack, yields ourcertified radius-guided white-box attack. Next, we propose the first black-boxattack to image segmentation models via bandit. We design a novel gradientestimator, based on bandit feedback, which is query-efficient and provablyunbiased and stable. We use this gradient estimator to design a projectedbandit gradient descent (PBGD) attack, as well as a certified radius-guidedPBGD (CR-PBGD) attack. We prove our PBGD and CR-PBGD attacks can achieveasymptotically optimal attack performance with an optimal rate. We evaluate ourcertified-radius guided white-box and black-box attacks on multiple modernimage segmentation models and datasets. Our results validate the effectivenessof our certified radius-guided attack framework.", "output": "A Certified Radius-Guided Attack Framework to Image Segmentation Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper aims at demystifying a single motion-blurred image with events andrevealing temporally continuous scene dynamics encrypted behind motion blurs.To achieve this end, an Implicit Video Function (IVF) is learned to represent asingle motion blurred image with concurrent events, enabling the latent sharpimage restoration of arbitrary timestamps in the range of imaging exposures.Specifically, a dual attention transformer is proposed to efficiently leveragemerits from both modalities, i.e., the high temporal resolution of eventfeatures and the smoothness of image features, alleviating temporal ambiguitieswhile suppressing the event noise. The proposed network is trained only withthe supervision of ground-truth images of limited referenced timestamps.Motion- and texture-guided supervisions are employed simultaneously to enhancerestorations of the non-referenced timestamps and improve the overallsharpness. Experiments on synthetic, semi-synthetic, and real-world datasetsdemonstrate that our proposed method outperforms state-of-the-art methods by alarge margin in terms of both objective PSNR and SSIM measurements andsubjective evaluations.", "output": "Recovering Continuous Scene Dynamics from A Single Blurry Image with Events."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper addresses real-time dense 3D reconstruction for aresource-constrained Autonomous Underwater Vehicle (AUV). Underwatervision-guided operations are among the most challenging as they combine 3Dmotion in the presence of external forces, limited visibility, and absence ofglobal positioning. Obstacle avoidance and effective path planning requireonline dense reconstructions of the environment. Autonomous operation iscentral to environmental monitoring, marine archaeology, resource utilization,and underwater cave exploration. To address this problem, we propose to useSVIn2, a robust VIO method, together with a real-time 3D reconstructionpipeline. We provide extensive evaluation on four challenging underwaterdatasets. Our pipeline produces comparable reconstruction with that of COLMAP,the state-of-the-art offline 3D reconstruction method, at high frame rates on asingle CPU.", "output": "Real-Time Dense 3D Mapping of Underwater Environments."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Semantic segmentation for medical 3D image stacks enables accurate volumetricreconstructions, computer-aided diagnostics and follow up treatment planning.In this work, we present a novel variant of the Unet model called the NUMSnetthat transmits pixel neighborhood features across scans through nested layersto achieve accurate multi-class semantic segmentations with minimal trainingdata. We analyze the semantic segmentation performance of the NUMSnet model incomparison with several Unet model variants to segment 3-7 regions of interestusing only 10% of images for training per Lung-CT and Heart-CT volumetric imagestacks. The proposed NUMSnet model achieves up to 20% improvement insegmentation recall with 4-9% improvement in Dice scores for Lung-CT stacks and2.5-10% improvement in Dice scores for Heart-CT stacks when compared to theUnet++ model. The NUMSnet model needs to be trained by ordered images aroundthe central scan of each volumetric stack. Propagation of image featureinformation from the 6 nested layers of the Unet++ model are found to havebetter computation and segmentation performances than propagation of allup-sampling layers in a Unet++ model. The NUMSnet model achieves comparablesegmentation performances to existing works, while being trained on as low as5% of the training images. Also, transfer learning allows faster convergenceof the NUMSnet model for multi-class semantic segmentation from pathology inLung-CT images to cardiac segmentations in Heart-CT stacks. Thus, the proposedmodel can standardize multi-class semantic segmentation on a variety ofvolumetric image stacks with minimal training dataset. This can significantlyreduce the cost, time and inter-observer variabilities associated withcomputer-aided detections and treatment.", "output": "NUMSnet: Nested-U Multi-class Segmentation network for 3D Medical Image Stacks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Whistle contour extraction aims to derive animal whistles from time-frequencyspectrograms as polylines. For toothed whales, whistle extraction results canserve as the basis for analyzing animal abundance, species identity, and socialactivities. During the last few decades, as long-term recording systems havebecome affordable, automated whistle extraction algorithms were proposed toprocess large volumes of recording data. Recently, a deep learning-based methoddemonstrated superior performance in extracting whistles under varying noiseconditions. However, training such networks requires a large amount oflabor-intensive annotation, which is not available for many species. Toovercome this limitation, we present a framework of stage-wise generativeadversarial networks (GANs), which compile new whistle data suitable for deepmodel training via three stages: generation of background noise in thespectrogram, generation of whistle contours, and generation of whistle signals.By separating the generation of different components in the samples, ourframework composes visually promising whistle data and labels even when fewexpert annotated data are available. Regardless of the amount ofhuman-annotated data, the proposed data augmentation framework leads to aconsistent improvement in performance of the whistle extraction model, with amaximum increase of 1.69 in the whistle extraction mean F1-score. Ourstage-wise GAN also surpasses one single GAN in improving whistle extractionmodels with augmented data. The data and code will be available at", "output": "Learning Stage-wise GANs for Whistle Extraction in Time-Frequency Spectrograms."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents an unsupervised approach that leverages raw aerial videosto learn to estimate planar homographic transformation between consecutivevideo frames. Previous learning-based estimators work on pairs of images toestimate their planar homographic transformations but suffer from severeover-fitting issues, especially when applying over aerial videos. To addressthis concern, we develop a sequential estimator that directly processes asequence of video frames and estimates their pairwise planar homographictransformations in batches. We also incorporate a set of spatial-temporalknowledge to regularize the learning of such a sequence-to-sequence model. Wecollect a set of challenging aerial videos and compare the proposed method tothe alternative algorithms. Empirical studies suggest that our sequential modelachieves significant improvement over alternative image-based methods and theknowledge-rich regularization further boosts our system performance. Our codesand dataset could be found at ", "output": "Learning Knowledge-Rich Sequential Model for Planar Homography Estimation in Aerial Video."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Most statistical learning algorithms rely on an over-simplified assumption,that is, the train and test data are independent and identically distributed.In real-world scenarios, however, it is common for models to encounter datafrom new and different domains to which they were not exposed to duringtraining. This is often the case in medical imaging applications due todifferences in acquisition devices, imaging protocols, and patientcharacteristics. To address this problem, domain generalization (DG) is apromising direction as it enables models to handle data from previously unseendomains by learning domain-invariant features robust to variations acrossdifferent domains. To this end, we introduce a novel DG method calledAdversarial Intensity Attack (AdverIN), which leverages adversarial training togenerate training data with an infinite number of styles and increase datadiversity while preserving essential content information. We conduct extensiveevaluation experiments on various multi-domain segmentation datasets, including2D retinal fundus optic disc/cup and 3D prostate MRI. Our results demonstratethat AdverIN significantly improves the generalization ability of thesegmentation models, achieving significant improvement on these challengingdatasets. Code is available upon publication.", "output": "Domain Generalization with Adversarial Intensity Attack for Medical Image Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Self-supervised pretraining has been observed to improve performance insupervised learning tasks in medical imaging. This study investigates theutility of self-supervised pretraining prior to conducting supervisedfine-tuning for the downstream task of lung sliding classification in M-modelung ultrasound images. We propose a novel pairwise relationship that couplesM-mode images constructed from the same B-mode image and investigate theutility of data augmentation procedure specific to M-mode lung ultrasound. Theresults indicate that self-supervised pretraining yields better performancethan full supervision, most notably for feature extractors not initialized withImageNet-pretrained weights. Moreover, we observe that including a vast volumeof unlabelled data results in improved performance on external validationdatasets, underscoring the value of self-supervision for improvinggeneralizability in automatic ultrasound interpretation. To the authors' bestknowledge, this study is the first to characterize the influence ofself-supervised pretraining for M-mode ultrasound.", "output": "Exploring the Utility of Self-Supervised Pretraining Strategies for the Detection of Absent Lung Sliding in M-Mode Lung Ultrasound."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Accurate medical imaging segmentation is critical for precise and effectivemedical interventions. However, despite the success of convolutional neuralnetworks (CNNs) in medical image segmentation, they still face challenges inhandling fine-scale features and variations in image scales. These challengesare particularly evident in complex and challenging segmentation tasks, such asthe BraTS multi-label brain tumor segmentation challenge. In this task,accurately segmenting the various tumor sub-components, which varysignificantly in size and shape, remains a significant challenge, with evenstate-of-the-art methods producing substantial errors. Therefore, we proposetwo architectures, FMG-Net and W-Net, that incorporate the principles ofgeometric multigrid methods for solving linear systems of equations into CNNsto address these challenges. Our experiments on the BraTS 2020 datasetdemonstrate that both FMG-Net and W-Net outperform the widely used U-Netarchitecture regarding tumor subcomponent segmentation accuracy and trainingefficiency. These findings highlight the potential of incorporating theprinciples of multigrid methods into CNNs to improve the accuracy andefficiency of medical imaging segmentation.", "output": "FMG-Net and W-Net: Multigrid Inspired Deep Learning Architectures For Medical Imaging Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the advent of new technologies, Augmented Reality (AR) has become aneffective tool in remote collaboration. Narrow field-of-view (FoV) and motionblur can offer an unpleasant experience with limited cognition for remoteviewers of AR headsets. In this article, we propose a two-stage pipeline totackle this issue and ensure a stable viewing experience with a larger FoV. Thesolution involves an offline 3D reconstruction of the indoor environment,followed by enhanced rendering using only the live poses of AR device. Weexperiment with and evaluate the two different 3D reconstruction methods, RGB-Dgeometric approach and Neural Radiance Fields (NeRF), based on their datarequirements, reconstruction quality, rendering, and training times. Thegenerated sequences from these methods had smoother transitions and provided abetter perspective of the environment. The geometry-based enhanced FoV methodhad better renderings as it lacked blurry outputs making it better than theother attempted approaches. Structural Similarity Index (SSIM) and Peak Signalto Noise Ratio (PSNR) metrics were used to quantitatively show that therendering quality using the geometry-based enhanced FoV method is better. Linkto the code repository -", "output": "Image Stabilization for Hololens Camera in Remote Collaboration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Thousands of users consult digital archives daily, but the information theycan access is unrepresentative of the diversity of documentary history. Thesequence-to-sequence architecture typically used for optical characterrecognition (OCR) - which jointly learns a vision and language model - ispoorly extensible to low-resource document collections, as learning alanguage-vision model requires extensive labeled sequences and compute. Thisstudy models OCR as a character level image retrieval problem, using acontrastively trained vision encoder. Because the model only learns characters'visual features, it is more sample efficient and extensible than existingarchitectures, enabling accurate OCR in settings where existing solutions fail.Crucially, the model opens new avenues for community engagement in makingdigital history more representative of documentary history.", "output": "Efficient OCR for Building a Diverse Digital History."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in the areas of Multimodal Machine Learning and ArtificialIntelligence (AI) have led to the development of challenging tasks at theintersection of Computer Vision, Natural Language Processing, and Robotics.Whereas many approaches and previous survey pursuits have characterised one ortwo of these dimensions, there has not been a holistic analysis at the centerof all three. Moreover, even when combinations of these topics are considered,more focus is placed on describing, e.g., current architectural methods, asopposed to also illustrating high-level challenges and opportunities for thefield. In this survey paper, we discuss Embodied Vision-Language Planning(EVLP) tasks, a family of prominent embodied navigation and manipulationproblems that jointly leverage computer vision and natural language forinteraction in physical environments. We propose a taxonomy to unify thesetasks and provide an in-depth analysis and comparison of the current and newalgorithmic approaches, metrics, simulators, and datasets used for EVLP tasks.Finally, we present the core challenges that we believe new EVLP works shouldseek to address, and we advocate for task construction that enables modelgeneralisability and furthers real-world deployment.", "output": "Core Challenges in Embodied Vision-Language Planning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, the diffusion model has emerged as a superior generative model thatcan produce high-quality images with excellent realism. There is a growinginterest in applying diffusion models to image translation tasks. However, formedical image translation, the existing diffusion models are deficient inaccurately retaining structural information since the structure details ofsource domain images are lost during the forward diffusion process and cannotbe fully recovered through learned reverse diffusion, while the integrity ofanatomical structures is extremely important in medical images. Training andconditioning diffusion models using paired source and target images withmatching anatomy can help. However, such paired data are very difficult andcostly to obtain, and may also reduce the robustness of the developed model toout-of-distribution testing data. We propose a frequency-guided diffusion model(FGDM) that employs frequency-domain filters to guide the diffusion model forstructure-preserving image translation. Based on its design, FGDM allowszero-shot learning, as it can be trained solely on the data from the targetdomain, and used directly for source-to-target domain translation without anyexposure to the source-domain data during training. We trained FGDM solely onthe head-and-neck CT data, and evaluated it on both head-and-neck and lungcone-beam CT (CBCT)-to-CT translation tasks. FGDM outperformed thestate-of-the-art methods (GAN-based, VAE-based, and diffusion-based) in allmetrics, showing its significant advantages in zero-shot medical imagetranslation.", "output": "Zero-shot Medical Image Translation via Frequency-Guided Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Our paper seeks to transfer the hairstyle of a reference image to an inputphoto for virtual hair try-on. We target a variety of challenges scenarios,such as transforming a long hairstyle with bangs to a pixie cut, which requiresremoving the existing hair and inferring how the forehead would look, ortransferring partially visible hair from a hat-wearing person in a differentpose. Past solutions leverage StyleGAN for hallucinating any missing parts andproducing a seamless face-hair composite through so-called GAN inversion orprojection. However, there remains a challenge in controlling thehallucinations to accurately transfer hairstyle and preserve the face shape andidentity of the input. To overcome this, we propose a multi-view optimizationframework that uses \"two different views\" of reference composites tosemantically guide occluded or ambiguous regions. Our optimization sharesinformation between two poses, which allows us to produce high fidelity andrealistic results from incomplete references. Our framework produceshigh-quality results and outperforms prior work in a user study that consistsof significantly more challenging hair transfer scenarios than previouslystudied. Project page: ", "output": "StyleGAN Salon: Multi-View Latent Optimization for Pose-Invariant Hairstyle Transfer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we compare methods for estimating the complexity oftwo-dimensional shapes and introduce a method that exploits reconstruction lossof Variational Autoencoders with different sizes of latent vectors. Althoughcomplexity of a shape is not a well defined attribute, different aspects of itcan be estimated. We demonstrate that our methods captures some aspects ofshape complexity. Code and training details will be publicly available.", "output": "Shape complexity estimation using VAE."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Methane (CH$_4$) is the chief contributor to global climate change. RecentAirborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) hasbeen very useful in quantitative mapping of methane emissions. Existing methodsfor analyzing this data are sensitive to local terrain conditions, oftenrequire manual inspection from domain experts, prone to significant error andhence are not scalable. To address these challenges, we propose a novelend-to-end spectral absorption wavelength aware transformer network,MethaneMapper, to detect and quantify the emissions. MethaneMapper introducestwo novel modules that help to locate the most relevant methane plume regionsin the spectral domain and uses them to localize these accurately. Thoroughevaluation shows that MethaneMapper achieves 0.63 mAP in detection and reducesthe model size (by 5x) compared to the current state of the art. In addition,we also introduce a large-scale dataset of methane plume segmentation mask forover 1200 AVIRIS-NG flight lines from 2015-2022. It contains over 4000 methaneplume sites. Our dataset will provide researchers the opportunity to developand advance new methods for tackling this challenging green-house gas detectionproblem with significant broader social impact. Dataset and source code arepublic", "output": "MethaneMapper: Spectral Absorption aware Hyperspectral Transformer for Methane Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Video generation remains a challenging task due to spatiotemporal complexityand the requirement of synthesizing diverse motions with temporal consistency.Previous works attempt to generate videos in arbitrary lengths either in anautoregressive manner or regarding time as a continuous signal. However, theystruggle to synthesize detailed and diverse motions with temporal coherence andtend to generate repetitive scenes after a few time steps. In this work, weargue that a single time-agnostic latent vector of style-based generator isinsufficient to model various and temporally-consistent motions. Hence, weintroduce additional time-dependent motion styles to model diverse motionpatterns. In addition, a Motion Style Attention modulation mechanism, dubbed asMoStAtt, is proposed to augment frames with vivid dynamics for each specificscale (i.e., layer), which assigns attention score for each motion style w.r.tdeconvolution filter weights in the target synthesis layer and softly attendsdifferent motion styles for weight modulation. Experimental results show ourmodel achieves state-of-the-art performance on four unconditional $256^2$ videosynthesis benchmarks trained with only 3 frames per clip and produces betterqualitative results with respect to dynamic motions. Code and videos have beenmade available at ", "output": "MoStGAN-V: Video Generation with Temporal Motion Styles."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Few-shot-based facial recognition systems have gained increasing attentiondue to their scalability and ability to work with a few face images during themodel deployment phase. However, the power of facial recognition systemsenables entities with moderate resources to canvas the Internet and buildwell-performed facial recognition models without people's awareness andconsent. To prevent the face images from being misused, one straightforwardapproach is to modify the raw face images before sharing them, which inevitablydestroys the semantic information, increases the difficulty of retroactivity,and is still prone to adaptive attacks. Therefore, an auditing method that doesnot interfere with the facial recognition model's utility and cannot be quicklybypassed is urgently needed.In this paper, we formulate the auditing process as a user-level membershipinference problem and propose a complete toolkit FACE-AUDITOR that cancarefully choose the probing set to query the few-shot-based facial recognitionmodel and determine whether any of a user's face images is used in training themodel. We further propose to use the similarity scores between the originalface images as reference information to improve the auditing performance.Extensive experiments on multiple real-world face image datasets show thatFACE-AUDITOR can achieve auditing accuracy of up to $99%$. Finally, we showthat FACE-AUDITOR is robust in the presence of several perturbation mechanismsto the training images or the target models. The source code of our experimentscan be found at url{", "output": "FACE-AUDITOR: Data Auditing in Facial Recognition Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The backdoor attack, where the adversary uses inputs stamped with triggers(e.g., a patch) to activate pre-planted malicious behaviors, is a severe threatto Deep Neural Network (DNN) models. Trigger inversion is an effective way ofidentifying backdoor models and understanding embedded adversarial behaviors. Achallenge of trigger inversion is that there are many ways of constructing thetrigger. Existing methods cannot generalize to various types of triggers bymaking certain assumptions or attack-specific constraints. The fundamentalreason is that existing work does not consider the trigger's design space intheir formulation of the inversion problem. This work formally defines andanalyzes the triggers injected in different spaces and the inversion problem.Then, it proposes a unified framework to invert backdoor triggers based on theformalization of triggers and the identified inner behaviors of backdoor modelsfrom our analysis. Our prototype UNICORN is general and effective in invertingbackdoor triggers in DNNs. The code can be found at", "output": "UNICORN: A Unified Backdoor Trigger Inversion Framework."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Differentiable volumetric rendering is a powerful paradigm for 3Dreconstruction and novel view synthesis. However, standard volume renderingapproaches struggle with degenerate geometries in the case of limited viewpointdiversity, a common scenario in robotics applications. In this work, we proposeto use the multi-view photometric objective from the self-supervised depthestimation literature as a geometric regularizer for volumetric rendering,significantly improving novel view synthesis without requiring additionalinformation. Building upon this insight, we explore the explicit modeling ofscene geometry using a generalist Transformer, jointly learning a radiancefield as well as depth and light fields with a set of shared latent codes. Wedemonstrate that sharing geometric information across tasks is mutuallybeneficial, leading to improvements over single-task learning without anincrease in network complexity. Our DeLiRa architecture achievesstate-of-the-art results on the ScanNet benchmark, enabling high qualityvolumetric rendering as well as real-time novel view and depth synthesis in thelimited viewpoint diversity setting.", "output": "DeLiRa: Self-Supervised Depth, Light, and Radiance Fields."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While neural networks are capable of achieving human-like performance in manytasks such as image classification, the impressive performance of each model islimited to its own dataset. Source-free domain adaptation (SFDA) was introducedto address knowledge transfer between different domains in the absence ofsource data, thus, increasing data privacy. Diversity in representation spacecan be vital to a model`s adaptability in varied and difficult domains. Inunsupervised SFDA, the diversity is limited to learning a single hypothesis onthe source or learning multiple hypotheses with a shared feature extractor.Motivated by the improved predictive performance of ensembles, we propose anovel unsupervised SFDA algorithm that promotes representational diversitythrough the use of separate feature extractors with Distinct BackboneArchitectures (DBA). Although diversity in feature space is increased, theunconstrained mutual information (MI) maximization may potentially introduceamplification of weak hypotheses. Thus we introduce the Weak HypothesisPenalization (WHP) regularizer as a mitigation strategy. Our work proposesPenalized Diversity (PD) where the synergy of DBA and WHP is applied tounsupervised source-free domain adaptation for covariate shift. In addition, PDis augmented with a weighted MI maximization objective for label distributionshift. Empirical results on natural, synthetic, and medical domains demonstratethe effectiveness of PD under different distributional shifts.", "output": "Source-free Domain Adaptation Requires Penalized Diversity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The increasing demand for high-quality 3D content creation has motivated thedevelopment of automated methods for creating 3D object models from a singleimage and/or from a text prompt. However, the reconstructed 3D objects usingstate-of-the-art image-to-3D methods still exhibit low correspondence to thegiven image and low multi-view consistency. Recent state-of-the-art text-to-3Dmethods are also limited, yielding 3D samples with low diversity per promptwith long synthesis time. To address these challenges, we propose DITTO-NeRF, anovel pipeline to generate a high-quality 3D NeRF model from a text prompt or asingle image. Our DITTO-NeRF consists of constructing high-quality partial 3Dobject for limited in-boundary (IB) angles using the given or text-generated 2Dimage from the frontal view and then iteratively reconstructing the remaining3D NeRF using inpainting latent diffusion model. We propose progressive 3Dobject reconstruction schemes in terms of scales (low to high resolution),angles (IB angles initially to outer-boundary (OB) later), and masks (object tobackground boundary) in our DITTO-NeRF so that high-quality information on IBcan be propagated into OB. Our DITTO-NeRF outperforms state-of-the-art methodsin terms of fidelity and diversity qualitatively and quantitatively with muchfaster training times than prior arts on image/text-to-3D such as DreamFusion,and NeuralLift-360.", "output": "DITTO-NeRF: Diffusion-based Iterative Text To Omni-directional 3D Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The increasing tendency to collect large and uncurated datasets to trainvision-and-language models has raised concerns about fair representations. Itis known that even small but manually annotated datasets, such as MSCOCO, areaffected by societal bias. This problem, far from being solved, may be gettingworse with data crawled from the Internet without much control. In addition,the lack of tools to analyze societal bias in big collections of images makesaddressing the problem extremely challenging. Our first contribution is toannotate part of the Google Conceptual Captions dataset, widely used fortraining vision-and-language models, with four demographic and two contextualattributes. Our second contribution is to conduct a comprehensive analysis ofthe annotations, focusing on how different demographic groups are represented.Our last contribution lies in evaluating three prevailing vision-and-languagetasks: image captioning, text-image CLIP embeddings, and text-to-imagegeneration, showing that societal bias is a persistent problem in all of them.", "output": "Uncurated Image-Text Datasets: Shedding Light on Demographic Bias."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "How can we segment varying numbers of objects where each specific objectrepresents its own separate class? To make the problem even more realistic, howcan we add and delete classes on the fly without retraining? This is the caseof robotic applications where no datasets of the objects exist or applicationthat includes thousands of objects (E.g., in logistics) where it is impossibleto train a single model to learn all of the objects. Most current research onobject segmentation for robotic grasping focuses on class-level objectsegmentation (E.g., box, cup, bottle), closed sets (specific objects of adataset; for example, YCB dataset), or deep learning-based template matching.In this work, we are interested in open sets where the number of classes isunknown, varying, and without pre-knowledge about the objects' types. Weconsider each specific object as its own separate class. Our goal is to developa zero-shot object detector that requires no training and can add any object asa class just by capturing a few images of the object. Our main idea is to breakthe segmentation pipelines into two steps by combining unseen objectsegmentation networks cascaded by zero-shot classifiers. We evaluate ourzero-shot object detector on unseen datasets and compare it to a trained MaskR-CNN on those datasets. The results show that the performance varies frompractical to unsuitable depending on the environment setup and the objectsbeing handled. The code is available in our DoUnseen library repository.", "output": "DoUnseen: Zero-Shot Object Detection for Robotic Grasping."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We analyze the data-dependent capacity of neural networks and assessanomalies in inputs from the perspective of networks during inference. Thenotion of data-dependent capacity allows for analyzing the knowledge base of amodel populated by learned features from training data. We define purview asthe additional capacity necessary to characterize inference samples that differfrom the training data. To probe the purview of a network, we utilize gradientsto measure the amount of change required for the model to characterize thegiven inputs more accurately. To eliminate the dependency on ground-truthlabels in generating gradients, we introduce confounding labels that areformulated by combining multiple categorical labels. We demonstrate that ourgradient-based approach can effectively differentiate inputs that cannot beaccurately represented with learned features. We utilize our approach inapplications of detecting anomalous inputs, including out-of-distribution,adversarial, and corrupted samples. Our approach requires no hyperparametertuning or additional data processing and outperforms state-of-the-art methodsby up to 2.7%, 19.8%, and 35.6% of AUROC scores, respectively.", "output": "Probing the Purview of Neural Networks via Gradient Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The accuracy of predictive models for solitary pulmonary nodule (SPN)diagnosis can be greatly increased by incorporating repeat imaging and medicalcontext, such as electronic health records (EHRs). However, clinically routinemodalities such as imaging and diagnostic codes can be asynchronous andirregularly sampled over different time scales which are obstacles tolongitudinal multimodal learning. In this work, we propose a transformer-basedmultimodal strategy to integrate repeat imaging with longitudinal clinicalsignatures from routinely collected EHRs for SPN classification. We performunsupervised disentanglement of latent clinical signatures and leveragetime-distance scaled self-attention to jointly learn from clinical signaturesexpressions and chest computed tomography (CT) scans. Our classifier ispretrained on 2,668 scans from a public dataset and 1,149 subjects withlongitudinal chest CTs, billing codes, medications, and laboratory tests fromEHRs of our home institution. Evaluation on 227 subjects with challenging SPNsrevealed a significant AUC improvement over a longitudinal multimodal baseline(0.824 vs 0.752 AUC), as well as improvements over a single cross-sectionmultimodal scenario (0.809 AUC) and a longitudinal imaging-only scenario (0.741AUC). This work demonstrates significant advantages with a novel approach forco-learning longitudinal imaging and non-imaging phenotypes with transformers.", "output": "Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures From Routine EHRs for Pulmonary Nodule Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pruning neural networks before training has received increasing interest dueto its potential to reduce training time and memory. One popular method is toprune the connections based on a certain metric, but it is not entirely clearwhat metric is the best choice. Recent advances in neural tangent kernel (NTK)theory suggest that the training dynamics of large enough neural networks isclosely related to the spectrum of the NTK. Motivated by this finding, wepropose to prune the connections that have the least influence on the spectrumof the NTK. This method can help maintain the NTK spectrum, which may helpalign the training dynamics to that of its dense counterpart. However, onepossible issue is that the fixed-weight-NTK corresponding to a given initialpoint can be very different from the NTK corresponding to later iterates duringthe training phase. We further propose to sample multiple realizations ofrandom weights to estimate the NTK spectrum. Note that our approach isweight-agnostic, which is different from most existing methods that areweight-dependent. In addition, we use random inputs to compute thefixed-weight-NTK, making our method data-agnostic as well. We name ourforesight pruning algorithm Neural Tangent Kernel Spectrum-Aware Pruning(NTK-SAP). Empirically, our method achieves better performance than allbaselines on multiple datasets.", "output": "NTK-SAP: Improving neural network pruning by aligning training dynamics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Unsupervised semantic segmentation is a long-standing challenge in computervision with great significance. Spectral clustering is a theoretically groundedsolution to it where the spectral embeddings for pixels are computed toconstruct distinct clusters. Despite recent progress in enhancing spectralclustering with powerful pre-trained models, current approaches still sufferfrom inefficiencies in spectral decomposition and inflexibility in applyingthem to the test data. This work addresses these issues by casting spectralclustering as a parametric approach that employs neural network-basedeigenfunctions to produce spectral embeddings. The outputs of the neuraleigenfunctions are further restricted to discrete vectors that indicateclustering assignments directly. As a result, an end-to-end NN-based paradigmof spectral clustering emerges. In practice, the neural eigenfunctions arelightweight and take the features from pre-trained models as inputs, improvingtraining efficiency and unleashing the potential of pre-trained models fordense prediction. We conduct extensive empirical studies to validate theeffectiveness of our approach and observe significant performance gains overcompetitive baselines on Pascal Context, Cityscapes, and ADE20K benchmarks.", "output": "Learning Neural Eigenfunctions for Unsupervised Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generalized Zero-Shot Learning (GZSL) has emerged as a pivotal researchdomain in computer vision, owing to its capability to recognize objects thathave not been seen during training. Despite the significant progress achievedby generative techniques in converting traditional GZSL to fully supervisedlearning, they tend to generate a large number of synthetic features that areoften redundant, thereby increasing training time and decreasing accuracy. Toaddress this issue, this paper proposes a novel approach for synthetic featureselection using reinforcement learning. In particular, we propose atransformer-based selector that is trained through proximal policy optimization(PPO) to select synthetic features based on the validation classificationaccuracy of the seen classes, which serves as a reward. The proposed method ismodel-agnostic and data-agnostic, making it applicable to both images andvideos and versatile for diverse applications. Our experimental resultsdemonstrate the superiority of our approach over existing feature-generatingmethods, yielding improved overall performance on multiple benchmarks.", "output": "Synthetic Sample Selection for Generalized Zero-Shot Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep networks have achieved impressive results on a range of well-curatedbenchmark datasets. Surprisingly, their performance remains sensitive toperturbations that have little effect on human performance. In this work, wepropose a novel extension of Mixup called Robustmix that regularizes networksto classify based on lower-frequency spatial features. We show that this typeof regularization improves robustness on a range of benchmarks such asImagenet-C and Stylized Imagenet. It adds little computational overhead and,furthermore, does not require a priori knowledge of a large set of imagetransformations. We find that this approach further complements recent advancesin model architecture and data augmentation, attaining a state-of-the-art mCEof 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of16 mCE compared to the baseline.", "output": "Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite the significant success of deep learning in computer vision tasks,cross-domain tasks still present a challenge in which the model's performancewill degrade when the training set and the test set follow differentdistributions. Most existing methods employ adversarial learning or instancenormalization for achieving data augmentation to solve this task. In contrast,considering that the batch normalization (BN) layer may not be robust forunseen domains and there exist the differences between local patches of animage, we propose a novel method called patch-aware batch normalization (PBN).To be specific, we first split feature maps of a batch into non-overlappingpatches along the spatial dimension, and then independently normalize eachpatch to jointly optimize the shared BN parameter at each iteration. Byexploiting the differences between local patches of an image, our proposed PBNcan effectively enhance the robustness of the model's parameters. Besides,considering the statistics from each patch may be inaccurate due to theirsmaller size compared to the global feature maps, we incorporate the globallyaccumulated statistics with the statistics from each batch to obtain the finalstatistics for normalizing each patch. Since the proposed PBN can replace thetypical BN, it can be integrated into most existing state-of-the-art methods.Extensive experiments and analysis demonstrate the effectiveness of our PBN inmultiple computer vision tasks, including classification, object detection,instance retrieval, and semantic segmentation.", "output": "Patch-aware Batch Normalization for Improving Cross-domain Robustness."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A natural way of estimating heteroscedastic label noise in regression is tomodel the observed (potentially noisy) target as a sample from a normaldistribution, whose parameters can be learned by minimizing the negativelog-likelihood. This loss has desirable loss attenuation properties, as it canreduce the contribution of high-error examples. Intuitively, this behavior canimprove robustness against label noise by reducing overfitting. We propose anextension of this simple and probabilistic approach to classification that hasthe same desirable loss attenuation properties. We evaluate the effectivenessof the method by measuring its robustness against label noise inclassification. We perform enlightening experiments exploring the innerworkings of the method, including sensitivity to hyperparameters, ablationstudies, and more.", "output": "Logistic-Normal Likelihoods for Heteroscedastic Label Noise in Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper aims to establish a generic multi-modal foundation model that hasthe scalable capability to massive downstream applications in E-commerce.Recently, large-scale vision-language pretraining approaches have achievedremarkable advances in the general domain. However, due to the significantdifferences between natural and product images, directly applying theseframeworks for modeling image-level representations to E-commerce will beinevitably sub-optimal. To this end, we propose an instance-centric multi-modalpretraining paradigm called ECLIP in this work. In detail, we craft a decoderarchitecture that introduces a set of learnable instance queries to explicitlyaggregate instance-level semantics. Moreover, to enable the model to focus onthe desired product instance without reliance on expensive manual annotations,two specially configured pretext tasks are further proposed. Pretrained on the100 million E-commerce-related data, ECLIP successfully extracts more generic,semantic-rich, and robust representations. Extensive experimental results showthat, without further fine-tuning, ECLIP surpasses existing methods by a largemargin on a broad range of downstream tasks, demonstrating the strongtransferability to real-world E-commerce applications.", "output": "Learning Instance-Level Representation for Large-Scale Multi-Modal Pretraining in E-commerce."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image resizing operation is a fundamental preprocessing module in moderncomputer vision. Throughout the deep learning revolution, researchers haveoverlooked the potential of alternative resizing methods beyond the commonlyused resizers that are readily available, such as nearest-neighbors, bilinear,and bicubic. The key question of our interest is whether the front-end resizeraffects the performance of deep vision models? In this paper, we present anextremely lightweight multilayer Laplacian resizer with only a handful oftrainable parameters, dubbed MULLER resizer. MULLER has a bandpass nature inthat it learns to boost details in certain frequency subbands that benefit thedownstream recognition models. We show that MULLER can be easily plugged intovarious training pipelines, and it effectively boosts the performance of theunderlying vision task with little to no extra cost. Specifically, we select astate-of-the-art vision Transformer, MaxViT, as the baseline, and show that, iftrained with MULLER, MaxViT gains up to 0.6% top-1 accuracy, and meanwhileenjoys 36% inference cost saving to achieve similar top-1 accuracy onImageNet-1k, as compared to the standard training scheme. Notably, MULLER'sperformance also scales with model size and training data size such asImageNet-21k and JFT, and it is widely applicable to multiple vision tasks,including image classification, object detection and segmentation, as well asimage quality assessment.", "output": "MULLER: Multilayer Laplacian Resizer for Vision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Rain-by-snow weather removal is a specialized task in weather-degraded imagerestoration aiming to eliminate coexisting rain streaks and snow particles. Inthis paper, we propose RSFormer, an efficient and effective Transformer thataddresses this challenge. Initially, we explore the proximity of convolutionnetworks (ConvNets) and vision Transformers (ViTs) in hierarchicalarchitectures and experimentally find they perform approximately at intra-stagefeature learning. On this basis, we utilize a Transformer-like convolutionblock (TCB) that replaces the computationally expensive self-attention whilepreserving attention characteristics for adapting to input content. We alsodemonstrate that cross-stage progression is critical for performanceimprovement, and propose a global-local self-attention sampling mechanism(GLASM) that down-/up-samples features while capturing both global and localdependencies. Finally, we synthesize two novel rain-by-snow datasets,RSCityScape and RS100K, to evaluate our proposed RSFormer. Extensiveexperiments verify that RSFormer achieves the best trade-off betweenperformance and time-consumption compared to other restoration methods. Forinstance, it outperforms Restormer with a 1.53% reduction in the number ofparameters and a 15.6% reduction in inference time. Datasets, source code andpre-trained models are available at url{", "output": "Towards an Effective and Efficient Transformer for Rain-by-snow Weather Removal."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Efficient point cloud representation is a fundamental element of Lidar-based3D object detection. Recent grid-based detectors usually divide point cloudsinto voxels or pillars and construct single-stream networks in Bird's Eye View.However, these point cloud encoding paradigms underestimate the pointrepresentation in the vertical direction, which cause the loss of semantic orfine-grained information, especially for vertical sensitive objects likepedestrian and cyclists. In this paper, we propose an explicit verticalmulti-scale representation learning framework, VPFusion, to combine thecomplementary information from both voxel and pillar streams. Specifically,VPFusion first builds upon a sparse voxel-pillar-based backbone. The backbonedivides point clouds into voxels and pillars, then encodes features with 3D and2D sparse convolution simultaneously. Next, we introduce the Sparse FusionLayer (SFL), which establishes a bidirectional pathway for sparse voxel andpillar features to enable the interaction between them. Additionally, wepresent the Dense Fusion Neck (DFN) to effectively combine the dense featuremaps from voxel and pillar branches with multi-scale. Extensive experiments onthe large-scale Waymo Open Dataset and nuScenes Dataset demonstrate thatVPFusion surpasses the single-stream baselines by a large margin and achievesstate-of-the-art performance with real-time inference speed.", "output": "VPFusion: Towards Robust Vertical Representation Learning for 3D Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep unfolding networks (DUNs) are the foremost methods in the realm ofcompressed sensing MRI, as they can employ learnable networks to facilitateinterpretable forward-inference operators. However, several daunting issuesstill exist, including the heavy dependency on the first-order optimizationalgorithms, the insufficient information fusion mechanisms, and the limitationof capturing long-range relationships. To address the issues, we propose aGenerically Accelerated Half-Quadratic Splitting (GA-HQS) algorithm thatincorporates second-order gradient information and pyramid attention modulesfor the delicate fusion of inputs at the pixel level. Moreover, a multi-scalesplit transformer is also designed to enhance the global featurerepresentation. Comprehensive experiments demonstrate that our method surpassesprevious ones on single-coil MRI acceleration tasks.", "output": "GA-HQS: MRI reconstruction via a generically accelerated unfolding approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Hate speech is a societal problem that has significantly grown through theInternet. New forms of digital content such as image memes have given rise tospread of hate using multimodal means, being far more difficult to analyse anddetect compared to the unimodal case. Accurate automatic processing, analysisand understanding of this kind of content will facilitate the endeavor ofhindering hate speech proliferation through the digital world. To this end, wepropose MemeFier, a deep learning-based architecture for fine-grainedclassification of Internet image memes, utilizing a dual-stage modality fusionmodule. The first fusion stage produces feature vectors containing modalityalignment information that captures non-trivial connections between the textand image of a meme. The second fusion stage leverages the power of aTransformer encoder to learn inter-modality correlations at the token level andyield an informative representation. Additionally, we consider externalknowledge as an additional input, and background image caption supervision as aregularizing component. Extensive experiments on three widely adoptedbenchmarks, i.e., Facebook Hateful Memes, Memotion7k and MultiOFF, indicatethat our approach competes and in some cases surpasses state-of-the-art. Ourcode is available on GitHub ", "output": "MemeFier: Dual-stage Modality Fusion for Image Meme Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Face super-resolution is a technology that transforms a low-resolution faceimage into the corresponding high-resolution one. In this paper, we build anovel parsing map guided face super-resolution network which extracts the faceprior (i.e., parsing map) directly from low-resolution face image for thefollowing utilization. To exploit the extracted prior fully, a parsing mapattention fusion block is carefully designed, which can not only effectivelyexplore the information of parsing map, but also combines powerful attentionmechanism. Moreover, in light of that high-resolution features contain moreprecise spatial information while low-resolution features provide strongcontextual information, we hope to maintain and utilize these complementaryinformation. To achieve this goal, we develop a multi-scale refine block tomaintain spatial and contextual information and take advantage of multi-scalefeatures to refine the feature representations. Experimental resultsdemonstrate that our method outperforms the state-of-the-arts in terms ofquantitative metrics and visual quality. The source codes will be available at", "output": "Super-Resolving Face Image by Facial Parsing Information."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "According to the World Malaria Report of 2022, 247 million cases of malariaand 619,000 related deaths were reported in 2021. This highlights thepredominance of the disease, especially in the tropical and sub-tropicalregions of Africa, parts of South-east Asia, Central and Southern America.Malaria is caused due to the Plasmodium parasite which is circulated throughthe bites of the female Anopheles mosquito. Hence, the detection of theparasite in human blood smears could confirm malarial infestation. Since themanual identification of Plasmodium is a lengthy and time-consuming tasksubject to variability in accuracy, we propose an automated, computer-aideddiagnostic method to classify malarial thin smear blood cell images asparasitized and uninfected by using the ResNet50 Deep Neural Network. In thispaper, we have used the pre-trained ResNet50 model on the open-access databaseprovided by the National Library of Medicine's Lister Hill National Center forBiomedical Communication for 150 epochs. The results obtained showed accuracy,precision, and recall values of 98.75%, 99.3% and 99.5% on theResNet50(proposed) model. We have compared these metrics with similar modelssuch as VGG16, Watershed Segmentation and Random Forest, which showed betterperformance than traditional techniques as well.", "output": "Computer-aided Diagnosis of Malaria through Transfer Learning using the ResNet50 Backbone."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Face masks are recommended to reduce the transmission of many viruses,especially SARS-CoV-2. Therefore, the automatic detection of whether there is amask on the face, what type of mask is worn, and how it is worn is an importantresearch topic. In this work, the use of thermal imaging was considered toanalyze the possibility of detecting (localizing) a mask on the face, as wellas to check whether it is possible to classify the type of mask on the face.The previously proposed dataset of thermal images was extended and annotatedwith the description of a type of mask and a location of a mask within a face.Different deep learning models were adapted. The best model for face maskdetection turned out to be the Yolov5 model in the \"nano\" version, reaching mAPhigher than 97% and precision of about 95%. High accuracy was also obtained formask type classification. The best results were obtained for the convolutionalneural network model built on an autoencoder initially trained in the thermalimage reconstruction problem. The pretrained encoder was used to train aclassifier which achieved an accuracy of 91%.", "output": "Mask Detection and Classification in Thermal Face Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Flexible road pavements deteriorate primarily due to traffic and adverseenvironmental conditions. Cracking is the most common deterioration mechanism;the surveying thereof is typically conducted manually using internationallydefined classification standards. In South Africa, the use of high-definitionvideo images has been introduced, which allows for safer road surveying.However, surveying is still a tedious manual process. Automation of thedetection of defects such as cracks would allow for faster analysis of roadnetworks and potentially reduce human bias and error. This study performs acomparison of six state-of-the-art convolutional neural network models for thepurpose of crack detection. The models are pretrained on the ImageNet dataset,and fine-tuned using a new real-world binary crack dataset consisting of 14000samples. The effects of dataset augmentation are also investigated. Of the sixmodels trained, five achieved accuracy above 97%. The highest recorded accuracywas 98%, achieved by the ResNet and VGG16 models. The dataset is available atthe following URL: ", "output": "Convolutional neural networks for crack detection on flexible road pavements."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Video activity localization aims at understanding the semantic content inlong untrimmed videos and retrieving actions of interest. The retrieved actionwith its start and end locations can be used for highlight generation, temporalaction detection, etc. Unfortunately, learning the exact boundary location ofactivities is highly challenging because temporal activities are continuous intime, and there are often no clear-cut transitions between actions. Moreover,the definition of the start and end of events is subjective, which may confusethe model. To alleviate the boundary ambiguity, we propose to study the videoactivity localization problem from a denoising perspective. Specifically, wepropose an encoder-decoder model named DenoiseLoc. During training, a set ofaction spans is randomly generated from the ground truth with a controllednoise scale. Then we attempt to reverse this process by boundary denoising,allowing the localizer to predict activities with precise boundaries andresulting in faster convergence speed. Experiments show that DenoiseLocadvances %in several video activity understanding tasks. For example, weobserve a gain of +12.36% average mAP on QV-Highlights dataset and +1.64%mAP@0.5 on THUMOS'14 dataset over the baseline. Moreover, DenoiseLoc achievesstate-of-the-art performance on TACoS and MAD datasets, but with much fewerpredictions compared to other current methods.", "output": "Boundary-Denoising for Video Activity Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Performance analyses based on videos are commonly used by coaches of athletesin various sports disciplines. In individual sports, these analyses mainlycomprise the body posture. This paper focuses on the disciplines of triple,high, and long jump, which require fine-grained locations of the athlete'sbody. Typical human pose estimation datasets provide only a very limited set ofkeypoints, which is not sufficient in this case. Therefore, we propose a methodto detect arbitrary keypoints on the whole body of the athlete by leveragingthe limited set of annotated keypoints and auto-generated segmentation masks ofbody parts. Evaluations show that our model is capable of detecting keypointson the head, torso, hands, feet, arms, and legs, including also bent elbows andknees. We analyze and compare different techniques to encode desired keypointsas the model's input and their embedding for the Transformer backbone.", "output": "All Keypoints You Need: Detecting Arbitrary Keypoints on the Body of Triple, High, and Long Jump Athletes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Dr. KID is an algorithm that uses isometric decomposition for thephysicalization of potato-shaped organic models in a puzzle fashion. Thealgorithm begins with creating a simple, regular triangular surface mesh oforganic shapes, followed by iterative k-means clustering and remeshing. Forclustering, we need similarity between triangles (segments) which is defined asa distance function. The distance function maps each triangle's shape to asingle point in the virtual 3D space. Thus, the distance between the trianglesindicates their degree of dissimilarity. K-means clustering uses this distanceand sorts of segments into k classes. After this, remeshing is applied tominimize the distance between triangles within the same cluster by making theirshapes identical. Clustering and remeshing are repeated until the distancebetween triangles in the same cluster reaches an acceptable threshold. We adopta curvature-aware strategy to determine the surface thickness and finalizepuzzle pieces for 3D printing. Identical hinges and holes are created forassembling the puzzle components. For smoother outcomes, we use trianglesubdivision along with curvature-aware clustering, generating curved triangularpatches for 3D printing. Our algorithm was evaluated using various models, andthe 3D-printed results were analyzed. Findings indicate that our algorithmperforms reliably on target organic shapes with minimal loss of input geometry.", "output": "Dr. KID: Direct Remeshing and K-set Isometric Decomposition for Scalable Physicalization of Organic Shapes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Interactive image segmentation enables annotators to efficiently performpixel-level annotation for segmentation tasks. However, the existinginteractive segmentation pipeline suffers from inefficient computations ofinteractive models because of the following two issues. First, annotators'later click is based on models' feedback of annotators' former click. Thisserial interaction is unable to utilize model's parallelism capabilities.Second, the model has to repeatedly process the image, the annotator's currentclick, and the model's feedback of the annotator's former clicks at each stepof interaction, resulting in redundant computations. For efficient computation,we propose a method named InterFormer that follows a new pipeline to addressthese issues. InterFormer extracts and preprocesses the computationallytime-consuming part i.e. image processing from the existing process.Specifically, InterFormer employs a large vision transformer (ViT) onhigh-performance devices to preprocess images in parallel, and then uses alightweight module called interactive multi-head self attention (I-MSA) forinteractive segmentation. Furthermore, the I-MSA module's deployment onlow-power devices extends the practical application of interactivesegmentation. The I-MSA module utilizes the preprocessed features toefficiently response to the annotator inputs in real-time. The experiments onseveral datasets demonstrate the effectiveness of InterFormer, whichoutperforms previous interactive segmentation models in terms of computationalefficiency and segmentation quality, achieve real-time high-quality interactivesegmentation on CPU-only devices.", "output": "InterFormer: Real-time Interactive Image Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Domain shift degrades the performance of object detection models in practicalapplications. To alleviate the influence of domain shift, plenty of previouswork try to decouple and learn the domain-invariant (common) features fromsource domains via domain adversarial learning (DAL). However, inspired bycausal mechanisms, we find that previous methods ignore the implicitinsignificant non-causal factors hidden in the common features. This is mainlydue to the single-view nature of DAL. In this work, we present an idea toremove non-causal factors from common features by multi-view adversarialtraining on source domains, because we observe that such insignificantnon-causal factors may still be significant in other latent spaces (views) dueto the multi-mode structure of data. To summarize, we propose a Multi-viewAdversarial Discriminator (MAD) based domain generalization model, consistingof a Spurious Correlations Generator (SCG) that increases the diversity ofsource domain by random augmentation and a Multi-View Domain Classifier (MVDC)that maps features to multiple latent spaces, such that the non-causal factorsare removed and the domain-invariant features are purified. Extensiveexperiments on six benchmarks show our MAD obtains state-of-the-artperformance.", "output": "Multi-view Adversarial Discriminator: Mine the Non-causal Factors for Object Detection in Unseen Domains."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study investigates the robustness of image classifiers to text-guidedcorruptions. We utilize diffusion models to edit images to different domains.Unlike other works that use synthetic or hand-picked data for benchmarking, weuse diffusion models as they are generative models capable of learning to editimages while preserving their semantic content. Thus, the corruptions will bemore realistic and the comparison will be more informative. Also, there is noneed for manual labeling and we can create large-scale benchmarks with lesseffort. We define a prompt hierarchy based on the original ImageNet hierarchyto apply edits in different domains. As well as introducing a new benchmark wetry to investigate the robustness of different vision models. The results ofthis study demonstrate that the performance of image classifiers decreasessignificantly in different language-based corruptions and edit domains. We alsoobserve that convolutional models are more robust than transformerarchitectures. Additionally, we see that common data augmentation techniquescan improve the performance on both the original data and the edited images.The findings of this research can help improve the design of image classifiersand contribute to the development of more robust machine learning systems. Thecode for generating the benchmark will be made available online uponpublication.", "output": "Benchmarking Robustness to Text-Guided Corruptions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Audio-visual segmentation (AVS) is a complex task that involves accuratelysegmenting the corresponding sounding object based on audio-visual queries.Successful audio-visual learning requires two essential components: 1) anunbiased dataset with high-quality pixel-level multi-class labels, and 2) amodel capable of effectively linking audio information with its correspondingvisual object. However, these two requirements are only partially addressed bycurrent methods, with training sets containing biased audio-visual data, andmodels that generalise poorly beyond this biased training set. In this work, wepropose a new strategy to build cost-effective and relatively unbiasedaudio-visual semantic segmentation benchmarks. Our strategy, called VisualPost-production (VPO), explores the observation that it is not necessary tohave explicit audio-visual pairs extracted from single video sources to buildsuch benchmarks. We also refine the previously proposed AVSBench to transformit into the audio-visual semantic segmentation benchmark AVSBench-Single+.Furthermore, this paper introduces a new pixel-wise audio-visual contrastivelearning method to enable a better generalisation of the model beyond thetraining set. We verify the validity of the VPO strategy by showing thatstate-of-the-art (SOTA) models trained with datasets built by matching audioand visual data from different sources or with datasets containing audio andvisual data from the same video source produce almost the same accuracy. Then,using the proposed VPO benchmarks and AVSBench-Single+, we show that our methodproduces more accurate audio-visual semantic segmentation than SOTA models.Code and dataset will be available.", "output": "A Closer Look at Audio-Visual Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Contrastive learning has emerged as an essential approach for self-supervisedlearning in computer vision. The central objective of contrastive learning isto maximize the similarities between two augmented versions of the same image(positive pairs), while minimizing the similarities between different images(negative pairs). Recent studies have demonstrated that harder negativesamples, i.e., those that are difficult to distinguish from anchor sample, playa more critical role in contrastive learning. In this paper, we propose a novelfeaturelevel method, namely sampling synthetic hard negative samples forcontrastive learning (SSCL), to exploit harder negative samples moreeffectively. Specifically, 1) we generate more and harder negative samples bymixing negative samples, and then sample them by controlling the contrast ofanchor sample with the other negative samples. 2) Considering that the negativesamples obtained by sampling may have the problem of false negative samples, wefurther debias the negative samples. Our proposed method improves theclassification performance on different image datasets and can be readilyapplied to existing methods.", "output": "Synthetic Hard Negative Samples for Contrastive Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Low-light images often suffer from severe noise, low brightness, lowcontrast, and color deviation. While several low-light image enhancementmethods have been proposed, there remains a lack of efficient methods that cansimultaneously solve all of these problems. In this paper, we introduceFLW-Net, a Fast and LightWeight Network for low-light image enhancement thatsignificantly improves processing speed and overall effect. To achieveefficient low-light image enhancement, we recognize the challenges of the lackof an absolute reference and the need for a large receptive field to obtainglobal contrast. Therefore, we propose an efficient global feature informationextraction component and design loss functions based on relative information toovercome these challenges. Finally, we conduct comparative experiments todemonstrate the effectiveness of the proposed method, and the results confirmthat FLW-Net can significantly reduce the complexity of supervised low-lightimage enhancement networks while improving processing effect. Code is availableat ", "output": "A Fast and Lightweight Network for Low-Light Image Enhancement."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The capability of doing effective forensic analysis on printed and scanned(PS) images is essential in many applications. PS documents may be used toconceal the artifacts of images which is due to the synthetic nature of imagessince these artifacts are typically present in manipulated images and the mainartifacts in the synthetic images can be removed after the PS. Due to theappeal of Generative Adversarial Networks (GANs), synthetic face imagesgenerated with GANs models are difficult to differentiate from genuine humanfaces and may be used to create counterfeit identities. Additionally, sinceGANs models do not account for physiological constraints for generating humanfaces and their impact on human IRISes, distinguishing genuine from syntheticIRISes in the PS scenario becomes extremely difficult. As a result of the lackof large-scale reference IRIS datasets in the PS scenario, we aim at developinga novel dataset to become a standard for Multimedia Forensics (MFs)investigation which is available at [45]. In this paper, we provide a noveldataset made up of a large number of synthetic and natural printed IRISes takenfrom VIPPrint Printed and Scanned face images. We extracted irises from faceimages and it is possible that the model due to eyelid occlusion captured theincomplete irises. To fill the missing pixels of extracted iris, we appliedtechniques to discover the complex link between the iris images. To highlightthe problems involved with the evaluation of the dataset's IRIS images, weconducted a large number of analyses employing Siamese Neural Networks toassess the similarities between genuine and synthetic human IRISes, such asResNet50, Xception, VGG16, and MobileNet-v2. For instance, using the Xceptionnetwork, we achieved 56.76% similarity of IRISes for synthetic images and92.77% similarity of IRISes for real images.", "output": "Spritz-PS: Validation of Synthetic Face Images Using a Large Dataset of Printed Documents."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "3D semantic segmentation is a critical task in many real-world applications,such as autonomous driving, robotics, and mixed reality. However, the task isextremely challenging due to ambiguities coming from the unstructured, sparse,and uncolored nature of the 3D point clouds. A possible solution is to combinethe 3D information with others coming from sensors featuring a differentmodality, such as RGB cameras. Recent multi-modal 3D semantic segmentationnetworks exploit these modalities relying on two branches that process the 2Dand 3D information independently, striving to maintain the strength of eachmodality. In this work, we first explain why this design choice is effectiveand then show how it can be improved to make the multi-modal semanticsegmentation more robust to domain shift. Our surprisingly simple contributionachieves state-of-the-art performances on four popular multi-modal unsuperviseddomain adaptation benchmarks, as well as better results in a domaingeneralization scenario.", "output": "Exploiting the Complementarity of 2D and 3D Networks to Address Domain-Shift in 3D Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Trajectories are fundamental to winning in alpine skiing. Tools enabling theanalysis of such curves can enhance the training activity and enrichbroadcasting content. In this paper, we propose SkiTraVis, an algorithm tovisualize the sequence of points traversed by a skier during its performance.SkiTraVis works on monocular videos and constitutes a pipeline of a visualtracker to model the skier's motion and of a frame correspondence module toestimate the camera's motion. The separation of the two motions enables thevisualization of the trajectory according to the moving camera's perspective.We performed experiments on videos of real-world professional competitions toquantify the visualization error, the computational efficiency, as well as theapplicability. Overall, the results achieved demonstrate the potential of oursolution for broadcasting media enhancement and coach assistance.", "output": "Visualizing Skiers' Trajectories in Monocular Videos."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transformer-based models have significantly advanced natural languageprocessing and computer vision in recent years. However, due to the irregularand disordered structure of point cloud data, transformer-based models for 3Ddeep learning are still in their infancy compared to other methods. In thispaper we present Point Cross-Attention Transformer (PointCAT), a novelend-to-end network architecture using cross-attentions mechanism for pointcloud representing. Our approach combines multi-scale features via two sepratecross-attention transformer branches. To reduce the computational increasebrought by multi-branch structure, we further introduce an efficient model forshape classification, which only process single class token of one branch as aquery to calculate attention map with the other. Extensive experimentsdemonstrate that our method outperforms or achieves comparable performance toseveral approaches in shape classification, part segmentation and semanticsegmentation tasks.", "output": "PointCAT: Cross-Attention Transformer for point cloud."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although code generation for Convolution Neural Network (CNN) models has beenextensively studied, performing efficient data slicing and parallelization forhighly-constrai-ned Multicore Neural Processor Units (NPUs) is still achallenging problem. Given the size of convolutions' input/output tensors andthe small footprint of NPU on-chip memories, minimizing memory transactionswhile maximizing parallelism and MAC utilization are central to any effectivesolution. This paper proposes a TensorFlow XLA/LLVM compiler optimization passfor Multicore NPUs, called Tensor Slicing Optimization (TSO), which: (a)maximizes convolution parallelism and memory usage across NPU cores; and (b)reduces data transfers between host and NPU on-chip memories by using DRAMmemory burst time estimates to guide tensor slicing. To evaluate the proposedapproach, a set of experiments was performed using the NeuroMorphic Processor(NMP), a multicore NPU containing 32 RISC-V cores extended with novel CNNinstructions. Experimental results show that TSO is capable of identifying thebest tensor slicing that minimizes execution time for a set of CNN models.Speed-ups of up to 21.7% result when comparing the TSO burst-based techniqueto a no-burst data slicing approach. To validate the generality of the TSOapproach, the algorithm was also ported to the Glow Machine Learning framework.The performance of the models were measured on both Glow and TensorFlowXLA/LLVM compilers, revealing similar results.", "output": "Tensor Slicing and Optimization for Multicore NPUs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision-language navigation is a task that requires an agent to followinstructions to navigate in environments. It becomes increasingly crucial inthe field of embodied AI, with potential applications in autonomous navigation,search and rescue, and human-robot interaction. In this paper, we propose toaddress a more practical yet challenging counterpart setting - vision-languagenavigation in continuous environments (VLN-CE). To develop a robust VLN-CEagent, we propose a new navigation framework, ETPNav, which focuses on twocritical skills: 1) the capability to abstract environments and generatelong-range navigation plans, and 2) the ability of obstacle-avoiding control incontinuous environments. ETPNav performs online topological mapping ofenvironments by self-organizing predicted waypoints along a traversed path,without prior environmental experience. It privileges the agent to break downthe navigation procedure into high-level planning and low-level control.Concurrently, ETPNav utilizes a transformer-based cross-modal planner togenerate navigation plans based on topological maps and instructions. The planis then performed through an obstacle-avoiding controller that leverages atrial-and-error heuristic to prevent navigation from getting stuck inobstacles. Experimental results demonstrate the effectiveness of the proposedmethod. ETPNav yields more than 10% and 20% improvements over priorstate-of-the-art on R2R-CE and RxR-CE datasets, respectively. Our code isavailable at ", "output": "ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although real-time facial emotion recognition is a hot topic research domainin the field of human-computer interaction, state-of the-art available datasetsstill suffer from various problems, such as some unrelated photos such asdocument photos, unbalanced numbers of photos in each class, and misleadingimages that can negatively affect correct classification. The 3RL dataset wascreated, which contains approximately 24K images and will be publiclyavailable, to overcome previously available dataset problems. The 3RL datasetis labelled with five basic emotions: happiness, fear, sadness, disgust, andanger. Moreover, we compared the 3RL dataset with other famous state-of-the-artdatasets (FER dataset, CK+ dataset), and we applied the most commonly usedalgorithms in previous works, SVM and CNN. The results show a noticeableimprovement in generalization on the 3RL dataset. Experiments have shown anaccuracy of up to 91.4% on 3RL dataset using CNN where results on FER2013, CK+are, respectively (approximately from 60% to 85%).", "output": "An experimental study in Real-time Facial Emotion Recognition on new 3RL dataset."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ensemble methods combine the predictions of multiple models to improveperformance, but they require significantly higher computation costs atinference time. To avoid these costs, multiple neural networks can be combinedinto one by averaging their weights (model soups). However, this usuallyperforms significantly worse than ensembling. Weight averaging is onlybeneficial when weights are similar enough (in weight or feature space) toaverage well but different enough to benefit from combining them. Based on thisidea, we propose PopulAtion Parameter Averaging (PAPA): a method that combinesthe generality of ensembling with the efficiency of weight averaging. PAPAleverages a population of diverse models (trained on different data orders,augmentations, and regularizations) while occasionally (not too often, not toorarely) replacing the weights of the networks with the population average ofthe weights. PAPA reduces the performance gap between averaging and ensembling,increasing the average accuracy of a population of models by up to 1.1% onCIFAR-10, 2.4% on CIFAR-100, and 1.9% on ImageNet when compared to trainingindependent (non-averaged) models.", "output": "PopulAtion Parameter Averaging (PAPA)."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automating tissue segmentation and tumor detection in histopathology imagesof colorectal cancer (CRC) is an enabler for faster diagnostic pathologyworkflows. At the same time it is a challenging task due to low availability ofpublic annotated datasets and high variability of image appearance. Thesemi-supervised learning for CRC detection (SemiCOL) challenge 2023 providespartially annotated data to encourage the development of automated solutionsfor tissue segmentation and tumor detection. We propose a U-Net basedmulti-task model combined with channel-wise and image-statistics-based coloraugmentations, as well as test-time augmentation, as a candidate solution tothe SemiCOL challenge. Our approach achieved a multi-task Dice score of .8655(Arm 1) and .8515 (Arm 2) for tissue segmentation and AUROC of .9725 (Arm 1)and 0.9750 (Arm 2) for tumor detection on the challenge validation set. Thesource code for our approach is made publicly available at", "output": "Multi-task learning for tissue segmentation and tumor detection in colorectal cancer histology slides."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-camera 3D object detection for autonomous driving is a challengingproblem that has garnered notable attention from both academia and industry. Anobstacle encountered in vision-based techniques involves the precise extractionof geometry-conscious features from RGB images. Recent approaches have utilizedgeometric-aware image backbones pretrained on depth-relevant tasks to acquirespatial information. However, these approaches overlook the critical aspect ofview transformation, resulting in inadequate performance due to themisalignment of spatial knowledge between the image backbone and viewtransformation. To address this issue, we propose a novel geometric-awarepretraining framework called GAPretrain. Our approach incorporates spatial andstructural cues to camera networks by employing the geometric-rich modality asguidance during the pretraining phase. The transference of modal-specificattributes across different modalities is non-trivial, but we bridge this gapby using a unified bird's-eye-view (BEV) representation and structural hintsderived from LiDAR point clouds to facilitate the pretraining process.GAPretrain serves as a plug-and-play solution that can be flexibly applied tomultiple state-of-the-art detectors. Our experiments demonstrate theeffectiveness and generalization ability of the proposed method. We achieve46.2 mAP and 55.5 NDS on the nuScenes val set using the BEVFormer method, witha gain of 2.7 and 2.1 points, respectively. We also conduct experiments onvarious image backbones and view transformations to validate the efficacy ofour approach. Code will be released at", "output": "Geometric-aware Pretraining for Vision-centric 3D Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Incremental object detection (IOD) aims to train an object detector inphases, each with annotations for new object categories. As other incrementalsettings, IOD is subject to catastrophic forgetting, which is often addressedby techniques such as knowledge distillation (KD) and exemplar replay (ER).However, KD and ER do not work well if applied directly to state-of-the-arttransformer-based object detectors such as Deformable DETR and UP-DETR. In thispaper, we solve these issues by proposing a ContinuaL DEtection TRansformer(CL-DETR), a new method for transformer-based IOD which enables effective usageof KD and ER in this context. First, we introduce a Detector KnowledgeDistillation (DKD) loss, focusing on the most informative and reliablepredictions from old versions of the model, ignoring redundant backgroundpredictions, and ensuring compatibility with the available ground-truth labels.We also improve ER by proposing a calibration strategy to preserve the labeldistribution of the training set, therefore better matching training andtesting statistics. We conduct extensive experiments on COCO 2017 anddemonstrate that CL-DETR achieves state-of-the-art results in the IOD setting.", "output": "Continual Detection Transformer for Incremental Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, CLIP-guided image synthesis has shown appealing performance onadapting a pre-trained source-domain generator to an unseen target domain. Itdoes not require any target-domain samples but only the textual domain labels.The training is highly efficient, e.g., a few minutes. However, existingmethods still have some limitations in the quality of generated images and maysuffer from the mode collapse issue. A key reason is that a fixed adaptationdirection is applied for all cross-domain image pairs, which leads to identicalsupervision signals. To address this issue, we propose an Image-specific PromptLearning (IPL) method, which learns specific prompt vectors for eachsource-domain image. This produces a more precise adaptation direction forevery cross-domain image pair, endowing the target-domain generator withgreatly enhanced flexibility. Qualitative and quantitative evaluations onvarious domains demonstrate that IPL effectively improves the quality anddiversity of synthesized images and alleviates the mode collapse. Moreover, IPLis independent of the structure of the generative model, such as generativeadversarial networks or diffusion models. Code is available at", "output": "Zero-shot Generative Model Adaptation via Image-specific Prompt Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As a neuromorphic sensor with high temporal resolution, the spike camerashows enormous potential in high-speed visual tasks. However, the high-speedsampling of light propagation processes by existing cameras brings unavoidablenoise phenomena. Eliminating the unique noise in spike stream is always a keypoint for spike-based methods. No previous work has addressed the detailednoise mechanism of the spike camera. To this end, we propose a systematic noisemodel for spike camera based on its unique circuit. In addition, we carefullyconstructed the noise evaluation equation and experimental scenarios to measurenoise variables. Based on our noise model, the first benchmark for spike streamdenoising is proposed which includes clear (noisy) spike stream. Further, wedesign a tailored spike stream denoising framework (DnSS) where denoised spikestream is obtained by decoding inferred inter-spike intervals. Experiments showthat DnSS has promising performance on the proposed benchmark. Eventually, DnSScan be generalized well on real spike stream.", "output": "Spike Stream Denoising via Spike Camera Simulation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Detecting pedestrians accurately in urban scenes is significant for realisticapplications like autonomous driving or video surveillance. However, confusinghuman-like objects often lead to wrong detections, and small scale or heavilyoccluded pedestrians are easily missed due to their unusual appearances. Toaddress these challenges, only object regions are inadequate, thus how to fullyutilize more explicit and semantic contexts becomes a key problem. Meanwhile,previous context-aware pedestrian detectors either only learn latent contextswith visual clues, or need laborious annotations to obtain explicit andsemantic contexts. Therefore, we propose in this paper a novel approach viaVision-Language semantic self-supervision for context-aware PedestrianDetection (VLPD) to model explicitly semantic contexts without any extraannotations. Firstly, we propose a self-supervised Vision-Language Semantic(VLS) segmentation method, which learns both fully-supervised pedestriandetection and contextual segmentation via self-generated explicit labels ofsemantic classes by vision-language models. Furthermore, a self-supervisedPrototypical Semantic Contrastive (PSC) learning method is proposed to betterdiscriminate pedestrians and other classes, based on more explicit and semanticcontexts obtained from VLS. Extensive experiments on popular benchmarks showthat our proposed VLPD achieves superior performances over the previousstate-of-the-arts, particularly under challenging circumstances like smallscale and heavy occlusion. Code is available at", "output": "VLPD: Context-Aware Pedestrian Detection via Vision-Language Semantic Self-Supervision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Unlike current deep keypoint detectors that are trained to recognize limitednumber of body parts, few-shot keypoint detection (FSKD) attempts to localizeany keypoints, including novel or base keypoints, depending on the referencesamples. FSKD requires the semantically meaningful relations for keypointsimilarity learning to overcome the ubiquitous noise and ambiguous localpatterns. One rescue comes with vision transformer (ViT) as it captureslong-range relations well. However, ViT may model irrelevant features outsideof the region of interest due to the global attention matrix, thus degradingsimilarity learning between support and query features. In this paper, wepresent a novel saliency-guided vision transformer, dubbed SalViT, for few-shotkeypoint detection. Our SalViT enjoys a uniquely designed masked self-attentionand a morphology learner, where the former introduces saliency map as a softmask to constrain the self-attention on foregrounds, while the latter leveragesthe so-called power normalization to adjust morphology of saliency map,realizing ``dynamically changing receptive field''. Moreover, as salinecydetectors add computations, we show that attentive masks of DINO transformercan replace saliency. On top of SalViT, we also investigate i) transductiveFSKD that enhances keypoint representations with unlabelled data and ii) FSKDunder occlusions. We show that our model performs well on five public datasetsand achieves ~10% PCK higher than the normally trained model under severeocclusions.", "output": "From Saliency to DINO: Saliency-guided Vision Transformer for Few-shot Keypoint Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks have been critical in the task of Visual QuestionAnswering (VQA), with research traditionally focused on improving modelaccuracy. Recently, however, there has been a trend towards evaluating therobustness of these models against adversarial attacks. This involves assessingthe accuracy of VQA models under increasing levels of noise in the input, whichcan target either the image or the proposed query question, dubbed the mainquestion. However, there is currently a lack of proper analysis of this aspectof VQA. This work proposes a new method that utilizes semantically relatedquestions, referred to as basic questions, acting as noise to evaluate therobustness of VQA models. It is hypothesized that as the similarity of a basicquestion to the main question decreases, the level of noise increases. Togenerate a reasonable noise level for a given main question, a pool of basicquestions is ranked based on their similarity to the main question, and thisranking problem is cast as a LASSO optimization problem. Additionally, thiswork proposes a novel robustness measure, R_score, and two basic questiondatasets to standardize the analysis of VQA model robustness. The experimentalresults demonstrate that the proposed evaluation method effectively analyzesthe robustness of VQA models. Moreover, the experiments show that in-contextlearning with a chain of basic questions can enhance model accuracy.", "output": "Improving Visual Question Answering Models through Robustness Analysis and In-Context Learning with a Chain of Basic Questions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Images captured through smartphone cameras often suffer from degradation,blur being one of the major ones, posing a challenge in processing these imagesfor downstream tasks. In this paper we propose low-compute lightweightpatch-wise features for image quality assessment. Using our method we candiscriminate between blur vs sharp image degradation. To this end, we train adecision-tree based XGBoost model on various intuitive image features like graylevel variance, first and second order gradients, texture features like localbinary patterns. Experiments conducted on an open dataset show that theproposed low compute method results in 90.1% mean accuracy on the validationset, which is comparable to the accuracy of a compute-intensive VGG16 networkwith 94% mean accuracy fine-tuned to this task. To demonstrate thegeneralizability of our proposed features and model we test the model on BHBIDdataset and an internal dataset where we attain accuracy of 98% and 91%,respectively. The proposed method is 10x faster than the VGG16 based model onCPU and scales linearly to the input image size making it suitable to beimplemented on low compute edge devices.", "output": "Patch-wise Features for Blur Image Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We address the task of in-the-wild human figure synthesis, where the primarygoal is to synthesize a full body given any region in any image. In-the-wildhuman figure synthesis has long been a challenging and under-explored task,where current methods struggle to handle extreme poses, occluding objects, andcomplex backgrounds.Our main contribution is TriA-GAN, a keypoint-guided GAN that can synthesizeAnyone, Anywhere, in Any given pose. Key to our method is projected GANscombined with a well-crafted training strategy, where our simple generatorarchitecture can successfully handle the challenges of in-the-wild full-bodysynthesis. We show that TriA-GAN significantly improves over previousin-the-wild full-body synthesis methods, all while requiring less conditionalinformation for synthesis (keypoints vs. DensePose). Finally, we show that thelatent space of methodName is compatible with standard unconditional editingtechniques, enabling text-guided editing of generated human figures.", "output": "Synthesizing Anyone, Anywhere, in Any Pose."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Creating animatable avatars from static scans requires the modeling ofclothing deformations in different poses. Existing learning-based methodstypically add pose-dependent deformations upon a minimally-clothed meshtemplate or a learned implicit template, which have limitations in capturingdetails or hinder end-to-end learning. In this paper, we revisit point-basedsolutions and propose to decompose explicit garment-related templates and thenadd pose-dependent wrinkles to them. In this way, the clothing deformations aredisentangled such that the pose-dependent wrinkles can be better learned andapplied to unseen poses. Additionally, to tackle the seam artifact issues inrecent state-of-the-art point-based methods, we propose to learn point featureson a body surface, which establishes a continuous and compact feature space tocapture the fine-grained and pose-dependent clothing geometry. To facilitatethe research in this field, we also introduce a high-quality scan dataset ofhumans in real-world clothing. Our approach is validated on two existingdatasets and our newly introduced dataset, showing better clothing deformationresults in unseen poses. The project page with code and dataset can be found at", "output": "CloSET: Modeling Clothed Humans on Continuous Surface with Explicit Template Decomposition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This contribution shows how an appropriate image pre-processing can improve adeep-learning based 3D reconstruction of colon parts. The assumption is that,rather than global image illumination corrections, local under- andover-exposures should be corrected in colonoscopy. An overview of the pipelineincluding the image exposure correction and a RNN-SLAM is first given. Then,this paper quantifies the reconstruction accuracy of the endoscope trajectoryin the colon with and without appropriate illumination correction", "output": "Deep learning-based image exposure enhancement as a pre-processing for an accurate 3D colon surface reconstruction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Sketch-guided image editing aims to achieve local fine-tuning of the imagebased on the sketch information provided by the user, while maintaining theoriginal status of the unedited areas. Due to the high cost of acquiring humansketches, previous works mostly relied on edge maps as a substitute forsketches, but sketches possess more rich structural information. In this paper,we propose a sketch generation scheme that can preserve the main contours of animage and closely adhere to the actual sketch style drawn by the user.Simultaneously, current image editing methods often face challenges such asimage distortion, training cost, and loss of fine details in the sketch. Toaddress these limitations, We propose a conditional diffusion model(SketchFFusion) based on the sketch structure vector. We evaluate thegenerative performance of our model and demonstrate that it outperformsexisting methods.", "output": "SketchFFusion: Sketch-guided image editing with diffusion model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Convenient 4D modeling of human-object interactions is essential for numerousapplications. However, monocular tracking and rendering of complex interactionscenarios remain challenging. In this paper, we propose Instant-NVR, a neuralapproach for instant volumetric human-object tracking and rendering using asingle RGBD camera. It bridges traditional non-rigid tracking with recentinstant radiance field techniques via a multi-thread tracking-renderingmechanism. In the tracking front-end, we adopt a robust human-object capturescheme to provide sufficient motion priors. We further introduce a separatedinstant neural representation with a novel hybrid deformation module for theinteracting scene. We also provide an on-the-fly reconstruction scheme of thedynamic/static radiance fields via efficient motion-prior searching. Moreover,we introduce an online key frame selection scheme and a rendering-awarerefinement strategy to significantly improve the appearance details for onlinenovel-view synthesis. Extensive experiments demonstrate the effectiveness andefficiency of our approach for the instant generation of human-object radiancefields on the fly, notably achieving real-time photo-realistic novel viewsynthesis under complex human-object interactions.", "output": "Instant-NVR: Instant Neural Volumetric Rendering for Human-object Interactions from Monocular RGBD Stream."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This contribution presents a deep-learning method for extracting and fusingimage information acquired from different viewpoints, with the aim to producemore discriminant object features for the identification of the type of kidneystones seen in endoscopic images. The model was further improved with atwo-step transfer learning approach and by attention blocks to refine thelearned feature maps. Deep feature fusion strategies improved the results ofsingle view extraction backbone models by more than 6% in terms of accuracy ofthe kidney stones classification.", "output": "Improving automatic endoscopic stone recognition using a multi-view fusion approach enhanced with two-step transfer learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Micro-expression recognition is one of the most challenging topics inaffective computing. It aims to recognize tiny facial movements difficult forhumans to perceive in a brief period, i.e., 0.25 to 0.5 seconds. Recentadvances in pre-training deep Bidirectional Transformers (BERT) havesignificantly improved self-supervised learning tasks in computer vision.However, the standard BERT in vision problems is designed to learn only fromfull images or videos, and the architecture cannot accurately detect details offacial micro-expressions. This paper presents Micron-BERT ($mu$-BERT), a novelapproach to facial micro-expression recognition. The proposed method canautomatically capture these movements in an unsupervised manner based on twokey ideas. First, we employ Diagonal Micro-Attention (DMA) to detect tinydifferences between two frames. Second, we introduce a new Patch of Interest(PoI) module to localize and highlight micro-expression interest regions andsimultaneously reduce noisy backgrounds and distractions. By incorporatingthese components into an end-to-end deep network, the proposed $mu$-BERTsignificantly outperforms all previous work in various micro-expression tasks.$mu$-BERT can be trained on a large-scale unlabeled dataset, i.e., up to 8million images, and achieves high accuracy on new unseen facialmicro-expression datasets. Empirical experiments show $mu$-BERT consistentlyoutperforms state-of-the-art performance on four micro-expression benchmarks,including SAMM, CASME II, SMIC, and CASME3, by significant margins. Code willbe available at url{", "output": "Micron-BERT: BERT-based Facial Micro-Expression Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Spatial attention has been demonstrated to enable convolutional neuralnetworks to focus on critical information to improve network performance, butit still has limitations. In this paper, we explain the effectiveness ofspatial attention from a new perspective, it is that the spatial attentionmechanism essentially solves the problem of convolutional kernel parametersharing. However, the information contained in the attention map generated byspatial attention is still lacking for large-size convolutional kernels. So, wepropose a new attention mechanism called Receptive-Field Attention (RFA). TheConvolutional Block Attention Module (CBAM) and Coordinate Attention (CA) onlyfocus on spatial features and cannot fully solve the problem of convolutionalkernel parameter sharing, but in RFA, the receptive-field spatial feature notonly is focused but also provide good attention weights for large-sizeconvolutional kernels. The Receptive-Field Attention convolutional operation(RFAConv) designed by RFA can be considered a new way to replace the standardconvolution and brings almost negligible computational cost and a number ofparameters. Numerous experiments on Imagenet-1k, MS COCO, and VOC demonstratethe superior performance of our approach in classification, object detection,and semantic segmentation tasks. Importantly, we believe that for some currentspatial attention mechanisms that focus only on spatial features, it is time toimprove the performance of the network by focusing on receptive-field spatialfeatures. The code and pre-trained models for the relevant tasks can be foundat ", "output": "RFAConv: Innovating Spatital Attention and Standard Convolutional Operation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Face animation has achieved much progress in computer vision. However,prevailing GAN-based methods suffer from unnatural distortions and artifactsdue to sophisticated motion deformation. In this paper, we propose a FaceAnimation framework with an attribute-guided Diffusion Model (FADM), which isthe first work to exploit the superior modeling capacity of diffusion modelsfor photo-realistic talking-head generation. To mitigate the uncontrollablesynthesis effect of the diffusion model, we design an Attribute-GuidedConditioning Network (AGCN) to adaptively combine the coarse animation featuresand 3D face reconstruction results, which can incorporate appearance and motionconditions into the diffusion process. These specific designs help FADM rectifyunnatural artifacts and distortions, and also enrich high-fidelity facialdetails through iterative diffusion refinements with accurate animationattributes. FADM can flexibly and effectively improve existing animationvideos. Extensive experiments on widely used talking-head benchmarks validatethe effectiveness of FADM over prior arts.", "output": "Face Animation with an Attribute-Guided Diffusion Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Integrating high-level semantically correlated contents and low-levelanatomical features is of central importance in medical image segmentation.Towards this end, recent deep learning-based medical segmentation methods haveshown great promise in better modeling such information. However, convolutionoperators for medical segmentation typically operate on regular grids, whichinherently blur the high-frequency regions, i.e., boundary regions. In thiswork, we propose MORSE, a generic implicit neural rendering framework designedat an anatomical level to assist learning in medical image segmentation. Ourmethod is motivated by the fact that implicit neural representation has beenshown to be more effective in fitting complex signals and solving computergraphics problems than discrete grid-based representation. The core of ourapproach is to formulate medical image segmentation as a rendering problem inan end-to-end manner. Specifically, we continuously align the coarsesegmentation prediction with the ambiguous coordinate-based pointrepresentations and aggregate these features to adaptively refine the boundaryregion. To parallelly optimize multi-scale pixel-level features, we leveragethe idea from Mixture-of-Expert (MoE) to design and train our MORSE with astochastic gating mechanism. Our experiments demonstrate that MORSE can workwell with different medical segmentation backbones, consistently achievingcompetitive performance improvements in both 2D and 3D supervised medicalsegmentation methods. We also theoretically analyze the superiority of MORSE.", "output": "Implicit Anatomical Rendering for Medical Image Segmentation with Stochastic Experts."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "To safely deploy deep learning-based computer vision models forcomputer-aided detection and diagnosis, we must ensure that they are robust andreliable. Towards that goal, algorithmic auditing has received substantialattention. To guide their audit procedures, existing methods rely on heuristicapproaches or high-level objectives (e.g., non-discrimination in regards toprotected attributes, such as sex, gender, or race). However, algorithms mayshow bias with respect to various attributes beyond the more obvious ones, andintegrity issues related to these more subtle attributes can have seriousconsequences. To enable the generation of actionable, data-driven hypotheseswhich identify specific dataset attributes likely to induce model bias, wecontribute a first technique for the rigorous, quantitative screening ofmedical image datasets. Drawing from literature in the causal inference andinformation theory domains, our procedure decomposes the risks associated withdataset attributes in terms of their detectability and utility (defined as theamount of information knowing the attribute gives about a task label). Todemonstrate the effectiveness and sensitivity of our method, we develop avariety of datasets with synthetically inserted artifacts with differentdegrees of association to the target label that allow evaluation of inheritedmodel biases via comparison of performance against true counterfactualexamples. Using these datasets and results from hundreds of trained models, weshow our screening method reliably identifies nearly imperceptiblebias-inducing artifacts. Lastly, we apply our method to the natural attributesof a popular skin-lesion dataset and demonstrate its success. Our approachprovides a means to perform more systematic algorithmic audits and guide futuredata collection efforts in pursuit of safer and more reliable models.", "output": "Data AUDIT: Identifying Attribute Utility- and Detectability-Induced Bias in Task Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose Gumbel Noise Score Matching (GNSM), a novel unsupervised method todetect anomalies in categorical data. GNSM accomplishes this by estimating thescores, i.e. the gradients of log likelihoods w.r.t.~inputs, of continuouslyrelaxed categorical distributions. We test our method on a suite of anomalydetection tabular datasets. GNSM achieves a consistently high performanceacross all experiments. We further demonstrate the flexibility of GNSM byapplying it to image data where the model is tasked to detect poor segmentationpredictions. Images ranked anomalous by GNSM show clear segmentation failures,with the outputs of GNSM strongly correlating with segmentation metricscomputed on ground-truth. We outline the score matching training objectiveutilized by GNSM and provide an open-source implementation of our work.", "output": "Anomaly Detection via Gumbel Noise Score Matching."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we aim to learn dexterous manipulation of deformable objectsusing multi-fingered hands. Reinforcement learning approaches for dexterousrigid object manipulation would struggle in this setting due to the complexityof physics interaction with deformable objects. At the same time, previoustrajectory optimization approaches with differentiable physics for deformablemanipulation would suffer from local optima caused by the explosion of contactmodes from hand-object interactions. To address these challenges, we proposeDexDeform, a principled framework that abstracts dexterous manipulation skillsfrom human demonstration and refines the learned skills with differentiablephysics. Concretely, we first collect a small set of human demonstrations usingteleoperation. And we then train a skill model using demonstrations forplanning over action abstractions in imagination. To explore the goal space, wefurther apply augmentations to the existing deformable shapes in demonstrationsand use a gradient optimizer to refine the actions planned by the skill model.Finally, we adopt the refined trajectories as new demonstrations for finetuningthe skill model. To evaluate the effectiveness of our approach, we introduce asuite of six challenging dexterous deformable object manipulation tasks.Compared with baselines, DexDeform is able to better explore and generalizeacross novel goals unseen in the initial human demonstrations.", "output": "DexDeform: Dexterous Deformable Object Manipulation with Human Demonstrations and Differentiable Physics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image inpainting task refers to erasing unwanted pixels from images andfilling them in a semantically consistent and realistic way. Traditionally, thepixels that are wished to be erased are defined with binary masks. From theapplication point of view, a user needs to generate the masks for the objectsthey would like to remove which can be time-consuming and prone to errors. Inthis work, we are interested in an image inpainting algorithm that estimateswhich object to be removed based on natural language input and also removes it,simultaneously. For this purpose, first, we construct a dataset namedGQA-Inpaint for this task which will be released soon. Second, we present anovel inpainting framework, Inst-Inpaint, that can remove objects from imagesbased on the instructions given as text prompts. We set various GAN anddiffusion-based baselines and run experiments on synthetic and real imagedatasets. We compare methods with different evaluation metrics that measure thequality and accuracy of the models and show significant quantitative andqualitative improvements.", "output": "Inst-Inpaint: Instructing to Remove Objects with Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Learning models on one labeled dataset that generalize well on another domainis a difficult task, as several shifts might happen between the data domains.This is notably the case for lidar data, for which models can exhibit largeperformance discrepancies due for instance to different lidar patterns orchanges in acquisition conditions. This paper addresses the correspondingUnsupervised Domain Adaptation (UDA) task for semantic segmentation. Tomitigate this problem, we introduce an unsupervised auxiliary task of learningan implicit underlying surface representation simultaneously on source andtarget data. As both domains share the same latent representation, the model isforced to accommodate discrepancies between the two sources of data. This novelstrategy differs from classical minimization of statistical divergences orlidar-specific state-of-the-art domain adaptation techniques. Our experimentsdemonstrate that our method achieves a better performance than the currentstate of the art in synthetic-to-real and real-to-real scenarios.", "output": "SALUDA: Surface-based Automotive Lidar Unsupervised Domain Adaptation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents a new synthesis-based approach for batch imageprocessing. Unlike existing tools that can only apply global edits to theentire image, our method can apply fine-grained edits to individual objectswithin the image. For example, our method can selectively blur or crop specificobjects that have a certain property. To facilitate such fine-grained imageediting tasks, we propose a neuro-symbolic domain-specific language (DSL) thatcombines pre-trained neural networks for image classification with otherlanguage constructs that enable symbolic reasoning. Our method canautomatically learn programs in this DSL from user demonstrations by utilizinga novel synthesis algorithm. We have implemented the proposed technique in atool called ImageEye and evaluated it on 50 image editing tasks. Our evaluationshows that ImageEye is able to automate 96% of these tasks.", "output": "ImageEye: Batch Image Processing Using Program Synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reconstruction and intrinsic decomposition of scenes from captured imagerywould enable many applications such as relighting and virtual object insertion.Recent NeRF based methods achieve impressive fidelity of 3D reconstruction, butbake the lighting and shadows into the radiance field, while mesh-based methodsthat facilitate intrinsic decomposition through differentiable rendering havenot yet scaled to the complexity and scale of outdoor scenes. We present anovel inverse rendering framework for large urban scenes capable of jointlyreconstructing the scene geometry, spatially-varying materials, and HDRlighting from a set of posed RGB images with optional depth. Specifically, weuse a neural field to account for the primary rays, and use an explicit mesh(reconstructed from the underlying neural field) for modeling secondary raysthat produce higher-order lighting effects such as cast shadows. By faithfullydisentangling complex geometry and materials from lighting effects, our methodenables photorealistic relighting with specular and shadow effects on severaloutdoor datasets. Moreover, it supports physics-based scene manipulations suchas virtual object insertion with ray-traced shadow casting.", "output": "Neural Fields meet Explicit Geometric Representation for Inverse Rendering of Urban Scenes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Motion mimicking is a foundational task in physics-based character animation.However, most existing motion mimicking methods are built upon reinforcementlearning (RL) and suffer from heavy reward engineering, high variance, and slowconvergence with hard explorations. Specifically, they usually take tens ofhours or even days of training to mimic a simple motion sequence, resulting inpoor scalability. In this work, we leverage differentiable physics simulators(DPS) and propose an efficient motion mimicking method dubbed DiffMimic. Ourkey insight is that DPS casts a complex policy learning task to a much simplerstate matching problem. In particular, DPS learns a stable policy by analyticalgradients with ground-truth physical priors hence leading to significantlyfaster and stabler convergence than RL-based methods. Moreover, to escape fromlocal optima, we utilize a Demonstration Replay mechanism to enable stablegradient backpropagation in a long horizon. Extensive experiments on standardbenchmarks show that DiffMimic has a better sample efficiency and timeefficiency than existing methods (e.g., DeepMimic). Notably, DiffMimic allows aphysically simulated character to learn Backflip after 10 minutes of trainingand be able to cycle it after 3 hours of training, while the existing approachmay require about a day of training to cycle Backflip. More importantly, wehope DiffMimic can benefit more differentiable animation systems withtechniques like differentiable clothes simulation in future research.", "output": "DiffMimic: Efficient Motion Mimicking with Differentiable Physics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The goal of this paper is to synthesise talking faces with controllablefacial motions. To achieve this goal, we propose two key ideas. The first is toestablish a canonical space where every face has the same motion patterns butdifferent identities. The second is to navigate a multimodal motion space thatonly represents motion-related features while eliminating identity information.To disentangle identity and motion, we introduce an orthogonality constraintbetween the two different latent spaces. From this, our method can generatenatural-looking talking faces with fully controllable facial attributes andaccurate lip synchronisation. Extensive experiments demonstrate that our methodachieves state-of-the-art results in terms of both visual quality and lip-syncscore. To the best of our knowledge, we are the first to develop a talking facegeneration framework that can accurately manifest full target facial motionsincluding lip, head pose, and eye movements in the generated video without anyadditional supervision beyond RGB video with audio.", "output": "That's What I Said: Fully-Controllable Talking Face Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural fields have recently enjoyed great success in representing andrendering 3D scenes. However, most state-of-the-art implicit representationsmodel static or dynamic scenes as a whole, with minor variations. Existing workon learning disentangled world and object neural fields do not consider theproblem of composing objects into different world neural fields in alighting-aware manner. We present Lighting-Aware Neural Field (LANe) for thecompositional synthesis of driving scenes in a physically consistent manner.Specifically, we learn a scene representation that disentangles the staticbackground and transient elements into a world-NeRF and class-specificobject-NeRFs to allow compositional synthesis of multiple objects in the scene.Furthermore, we explicitly designed both the world and object models to handlelighting variation, which allows us to compose objects into scenes withspatially varying lighting. This is achieved by constructing a light field ofthe scene and using it in conjunction with a learned shader to modulate theappearance of the object NeRFs. We demonstrate the performance of our model ona synthetic dataset of diverse lighting conditions rendered with the CARLAsimulator, as well as a novel real-world dataset of cars collected at differenttimes of the day. Our approach shows that it outperforms state-of-the-artcompositional scene synthesis on the challenging dataset setup, via composingobject-NeRFs learned from one scene into an entirely different scene whilststill respecting the lighting variations in the novel scene. For more results,please visit our project website ", "output": "LANe: Lighting-Aware Neural Fields for Compositional Scene Synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Humans possess a versatile mechanism for extracting structuredrepresentations of our visual world. When looking at an image, we can decomposethe scene into entities and their parts as well as obtain the dependenciesbetween them. To mimic such capability, we propose Visual DependencyTransformers (DependencyViT) that can induce visual dependencies without anylabels. We achieve that with a novel neural operator called emph{reversedattention} that can naturally capture long-range visual dependencies betweenimage patches. Specifically, we formulate it as a dependency graph where achild token in reversed attention is trained to attend to its parent tokens andsend information following a normalized probability distribution rather thangathering information in conventional self-attention. With such a design,hierarchies naturally emerge from reversed attention layers, and a dependencytree is progressively induced from leaf nodes to the root node unsupervisedly.DependencyViT offers several appealing benefits. (i) Entities and their partsin an image are represented by different subtrees, enabling part partitioningfrom dependencies; (ii) Dynamic visual pooling is made possible. The leaf nodeswhich rarely send messages can be pruned without hindering the modelperformance, based on which we propose the lightweight DependencyViT-Lite toreduce the computational and memory footprints; (iii) DependencyViT works wellon both self- and weakly-supervised pretraining paradigms on ImageNet, anddemonstrates its effectiveness on 8 datasets and 5 tasks, such as unsupervisedpart and saliency segmentation, recognition, and detection.", "output": "Visual Dependency Transformers: Dependency Tree Emerges from Reversed Attention."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "There has been a longstanding belief that generation can facilitate a trueunderstanding of visual data. In line with this, we revisit generativelypre-training visual representations in light of recent interest in denoisingdiffusion models. While directly pre-training with diffusion models does notproduce strong representations, we condition diffusion models on masked inputand formulate diffusion models as masked autoencoders (DiffMAE). Our approachis capable of (i) serving as a strong initialization for downstream recognitiontasks, (ii) conducting high-quality image inpainting, and (iii) beingeffortlessly extended to video where it produces state-of-the-artclassification accuracy. We further perform a comprehensive study on the prosand cons of design choices and build connections between diffusion models andmasked autoencoders.", "output": "Diffusion Models as Masked Autoencoders."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present SegGPT, a generalist model for segmenting everything in context.We unify various segmentation tasks into a generalist in-context learningframework that accommodates different kinds of segmentation data bytransforming them into the same format of images. The training of SegGPT isformulated as an in-context coloring problem with random color mapping for eachdata sample. The objective is to accomplish diverse tasks according to thecontext, rather than relying on specific colors. After training, SegGPT canperform arbitrary segmentation tasks in images or videos via in-contextinference, such as object instance, stuff, part, contour, and text. SegGPT isevaluated on a broad range of tasks, including few-shot semantic segmentation,video object segmentation, semantic segmentation, and panoptic segmentation.Our results show strong capabilities in segmenting in-domain and out-of-domaintargets, either qualitatively or quantitatively.", "output": "SegGPT: Segmenting Everything In Context."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Smartphone cameras today are increasingly approaching the versatility andquality of professional cameras through a combination of hardware and softwareadvancements. However, fixed aperture remains a key limitation, preventingusers from controlling the depth of field (DoF) of captured images. At the sametime, many smartphones now have multiple cameras with different fixed apertures-- specifically, an ultra-wide camera with wider field of view and deeper DoFand a higher resolution primary camera with shallower DoF. In this work, wepropose $text{DC}^2$, a system for defocus control for synthetically varyingcamera aperture, focus distance and arbitrary defocus effects by fusinginformation from such a dual-camera system. Our key insight is to leveragereal-world smartphone camera dataset by using image refocus as a proxy task forlearning to control defocus. Quantitative and qualitative evaluations onreal-world data demonstrate our system's efficacy where we outperformstate-of-the-art on defocus deblurring, bokeh rendering, and image refocus.Finally, we demonstrate creative post-capture defocus control enabled by ourmethod, including tilt-shift and content-based defocus effects.", "output": "$\\text{DC}^2$: Dual-Camera Defocus Control by Learning to Refocus."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we introduce OpenVSLAM, a visual SLAM framework with highusability and extensibility. Visual SLAM systems are essential for AR devices,autonomous control of robots and drones, etc. However, conventional open-sourcevisual SLAM frameworks are not appropriately designed as libraries called fromthird-party programs. To overcome this situation, we have developed a novelvisual SLAM framework. This software is designed to be easily used andextended. It incorporates several useful features and functions for researchand development.", "output": "OpenVSLAM: A Versatile Visual SLAM Framework."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "CT scanners that are commonly-used in hospitals nowadays producelow-resolution images, up to 512 pixels in size. One pixel in the imagecorresponds to a one millimeter piece of tissue. In order to accurately segmenttumors and make treatment plans, doctors need CT scans of higher resolution.The same problem appears in MRI. In this paper, we propose an approach for thesingle-image super-resolution of 3D CT or MRI scans. Our method is based ondeep convolutional neural networks (CNNs) composed of 10 convolutional layersand an intermediate upscaling layer that is placed after the first 6convolutional layers. Our first CNN, which increases the resolution on two axes(width and height), is followed by a second CNN, which increases the resolutionon the third axis (depth). Different from other methods, we compute the losswith respect to the ground-truth high-resolution output right after theupscaling layer, in addition to computing the loss after the last convolutionallayer. The intermediate loss forces our network to produce a better output,closer to the ground-truth. A widely-used approach to obtain sharp results isto add Gaussian blur using a fixed standard deviation. In order to avoidoverfitting to a fixed standard deviation, we apply Gaussian smoothing withvarious standard deviations, unlike other approaches. We evaluate our method inthe context of 2D and 3D super-resolution of CT and MRI scans from twodatabases, comparing it to relevant related works from the literature andbaselines based on various interpolation schemes, using 2x and 4x scalingfactors. The empirical results show that our approach attains superior resultsto all other methods. Moreover, our human annotation study reveals that bothdoctors and regular annotators chose our method in favor of Lanczosinterpolation in 97.55% cases for 2x upscaling factor and in 96.69% cases for4x upscaling factor.", "output": "Convolutional Neural Networks with Intermediate Loss for 3D Super-Resolution of CT and MRI Scans."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Abnormal event detection in video is a complex computer vision problem thathas attracted significant attention in recent years. The complexity of the taskarises from the commonly-adopted definition of an abnormal event, that is, ararely occurring event that typically depends on the surrounding context.Following the standard formulation of abnormal event detection as outlierdetection, we propose a background-agnostic framework that learns from trainingvideos containing only normal events. Our framework is composed of an objectdetector, a set of appearance and motion auto-encoders, and a set ofclassifiers. Since our framework only looks at object detections, it can beapplied to different scenes, provided that normal events are definedidentically across scenes and that the single main factor of variation is thebackground. To overcome the lack of abnormal data during training, we proposean adversarial learning strategy for the auto-encoders. We create ascene-agnostic set of out-of-domain pseudo-abnormal examples, which arecorrectly reconstructed by the auto-encoders before applying gradient ascent onthe pseudo-abnormal examples. We further utilize the pseudo-abnormal examplesto serve as abnormal examples when training appearance-based and motion-basedbinary classifiers to discriminate between normal and abnormal latent featuresand reconstructions. We compare our framework with the state-of-the-art methodson four benchmark data sets, using various evaluation metrics. Compared toexisting methods, the empirical results indicate that our approach achievesfavorable performance on all data sets. In addition, we provide region-basedand track-based annotations for two large-scale abnormal event detection datasets from the literature, namely ShanghaiTech and Subway.", "output": "A Background-Agnostic Framework with Adversarial Training for Abnormal Event Detection in Video."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Convolutional neural networks have been widely applied to hyperspectral imageclassification. However, traditional convolutions can not effectively extractfeatures for objects with irregular distributions. Recent methods attempt toaddress this issue by performing graph convolutions on spatial topologies, butfixed graph structures and local perceptions limit their performances. Totackle these problems, in this paper, different from previous approaches, weperform the superpixel generation on intermediate features during networktraining to adaptively produce homogeneous regions, obtain graph structures,and further generate spatial descriptors, which are served as graph nodes.Besides spatial objects, we also explore the graph relationships betweenchannels by reasonably aggregating channels to generate spectral descriptors.The adjacent matrices in these graph convolutions are obtained by consideringthe relationships among all descriptors to realize global perceptions. Bycombining the extracted spatial and spectral graph features, we finally obtaina spectral-spatial graph reasoning network (SSGRN). The spatial and spectralparts of SSGRN are separately called spatial and spectral graph reasoningsubnetworks. Comprehensive experiments on four public datasets demonstrate thecompetitiveness of the proposed methods compared with other state-of-the-artgraph convolution-based approaches.", "output": "Spectral-Spatial Global Graph Reasoning for Hyperspectral Image Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Accurate inference of fine-grained traffic flow from coarse-grained one is anemerging yet crucial problem, which can help greatly reduce the number of therequired traffic monitoring sensors for cost savings. In this work, we noticethat traffic flow has a high correlation with road network, which was eithercompletely ignored or simply treated as an external factor in previous works.Tofacilitate this problem, we propose a novel Road-Aware Traffic Flow Magnifier(RATFM) that explicitly exploits the prior knowledge of road networks to fullylearn the road-aware spatial distribution of fine-grained traffic flow.Specifically, a multi-directional 1D convolutional layer is first introduced toextract the semantic feature of the road network. Subsequently, we incorporatethe road network feature and coarse-grained flow feature to regularize theshort-range spatial distribution modeling of road-relative traffic flow.Furthermore, we take the road network feature as a query to capture thelong-range spatial distribution of traffic flow with a transformerarchitecture. Benefiting from the road-aware inference mechanism, our methodcan generate high-quality fine-grained traffic flow maps. Extensive experimentson three real-world datasets show that the proposed RATFM outperformsstate-of-the-art models under various scenarios. Our code and datasets arereleased at {url{", "output": "Road Network Guided Fine-Grained Urban Traffic Flow Inference."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Hyperspectral image (HSI) classification has been a hot topic for decides, ashyperspectral images have rich spatial and spectral information and providestrong basis for distinguishing different land-cover objects. Benefiting fromthe development of deep learning technologies, deep learning based HSIclassification methods have achieved promising performance. Recently, severalneural architecture search (NAS) algorithms have been proposed for HSIclassification, which further improve the accuracy of HSI classification to anew level. In this paper, NAS and Transformer are combined for handling HSIclassification task for the first time. Compared with previous work, theproposed method has two main differences. First, we revisit the search spacesdesigned in previous HSI classification NAS methods and propose a novel hybridsearch space, consisting of the space dominated cell and the spectrum dominatedcell. Compared with search spaces proposed in previous works, the proposedhybrid search space is more aligned with the characteristic of HSI data, thatis, HSIs have a relatively low spatial resolution and an extremely highspectral resolution. Second, to further improve the classification accuracy, weattempt to graft the emerging transformer module on the automatically designedconvolutional neural network (CNN) to add global information to local regionfocused features learned by CNN. Experimental results on three public HSIdatasets show that the proposed method achieves much better performance thancomparison approaches, including manually designed network and NAS based HSIclassification methods. Especially on the most recently captured datasetHouston University, overall accuracy is improved by nearly 6 percentage points.Code is available at: ", "output": "Grafting Transformer on Automatically Designed Convolutional Neural Network for Hyperspectral Image Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transferring knowledge learned from the labeled source domain to the rawtarget domain for unsupervised domain adaptation (UDA) is essential to thescalable deployment of autonomous driving systems. State-of-the-art methods inUDA often employ a key idea: utilizing joint supervision signals from bothsource and target domains for self-training. In this work, we improve andextend this aspect. We present ConDA, a concatenation-based domain adaptationframework for LiDAR segmentation that: 1) constructs an intermediate domainconsisting of fine-grained interchange signals from both source and targetdomains without destabilizing the semantic coherency of objects and backgroundaround the ego-vehicle; and 2) utilizes the intermediate domain forself-training. To improve the network training on the source domain andself-training on the intermediate domain, we propose an anti-aliasingregularizer and an entropy aggregator to reduce the negative effect caused bythe aliasing artifacts and noisy pseudo labels. Through extensive studies, wedemonstrate that ConDA significantly outperforms prior arts in mitigatingdomain gaps.", "output": "ConDA: Unsupervised Domain Adaptation for LiDAR Segmentation via Regularized Domain Concatenation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing monocular depth estimation methods have achieved excellentrobustness in diverse scenes, but they can only retrieve affine-invariantdepth, up to an unknown scale and shift. However, in some video-based scenariossuch as video depth estimation and 3D scene reconstruction from a video, theunknown scale and shift residing in per-frame prediction may cause the depthinconsistency. To solve this problem, we propose a locally weighted linearregression method to recover the scale and shift with very sparse anchorpoints, which ensures the scale consistency along consecutive frames. Extensiveexperiments show that our method can boost the performance of existingstate-of-the-art approaches by 50% at most over several zero-shot benchmarks.Besides, we merge over 6.3 million RGBD images to train strong and robust depthmodels. Our produced ResNet50-backbone model even outperforms thestate-of-the-art DPT ViT-Large model. Combining with geometry-basedreconstruction methods, we formulate a new dense 3D scene reconstructionpipeline, which benefits from both the scale consistency of sparse points andthe robustness of monocular methods. By performing the simple per-frameprediction over a video, the accurate 3D scene shape can be recovered.", "output": "Towards 3D Scene Reconstruction from Locally Scale-Aligned Monocular Video Depth."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning has largely reshaped remote sensing (RS) research for aerialimage understanding and made a great success. Nevertheless, most of theexisting deep models are initialized with the ImageNet pretrained weights.Since natural images inevitably present a large domain gap relative to aerialimages, probably limiting the finetuning performance on downstream aerial scenetasks. This issue motivates us to conduct an empirical study of remote sensingpretraining (RSP) on aerial images. To this end, we train different networksfrom scratch with the help of the largest RS scene recognition dataset up tonow -- MillionAID, to obtain a series of RS pretrained backbones, includingboth convolutional neural networks (CNN) and vision transformers such as Swinand ViTAE, which have shown promising performance on computer vision tasks.Then, we investigate the impact of RSP on representative downstream tasksincluding scene recognition, semantic segmentation, object detection, andchange detection using these CNN and vision transformer backbones. Empiricalstudy shows that RSP can help deliver distinctive performances in scenerecognition tasks and in perceiving RS related semantics such as \"Bridge\" and\"Airplane\". We also find that, although RSP mitigates the data discrepancies oftraditional ImageNet pretraining on RS images, it may still suffer from taskdiscrepancies, where downstream tasks require different representations fromscene recognition tasks. These findings call for further research efforts onboth large-scale pretraining datasets and effective pretraining methods. Thecodes and pretrained models will be released at", "output": "An Empirical Study of Remote Sensing Pretraining."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Semantic segmentation enables many appealing real-world applications, such ascomputational photography, autonomous driving, etc. However, the vastcomputational cost makes deploying state-of-the-art semantic segmentationmodels on edge devices with limited hardware resources difficult. This workpresents EfficientViT, a new family of semantic segmentation models with anovel lightweight multi-scale attention for on-device semantic segmentation.Unlike prior semantic segmentation models that rely on heavy self-attention,hardware-inefficient large-kernel convolution, or complicated topologystructure to obtain good performances, our lightweight multi-scale attentionachieves a global receptive field and multi-scale learning (two criticalfeatures for semantic segmentation models) with only lightweight andhardware-efficient operations. As such, EfficientViT delivers remarkableperformance gains over previous state-of-the-art semantic segmentation modelsacross popular benchmark datasets with significant speedup on the mobileplatform. Without performance loss on Cityscapes, our EfficientViT provides upto 15x and 9.3x mobile latency reduction over SegFormer and SegNeXt,respectively. Maintaining the same mobile latency, EfficientViT provides +7.4mIoU gain on ADE20K over SegNeXt. Code:", "output": "EfficientViT: Lightweight Multi-Scale Attention for On-Device Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing explanation models generate only text for recommendations but stillstruggle to produce diverse contents. In this paper, to further enrichexplanations, we propose a new task named personalized showcases, in which weprovide both textual and visual information to explain our recommendations.Specifically, we first select a personalized image set that is the mostrelevant to a user's interest toward a recommended item. Then, natural languageexplanations are generated accordingly given our selected images. For this newtask, we collect a large-scale dataset from Google Local (i.e.,~maps) andconstruct a high-quality subset for generating multi-modal explanations. Wepropose a personalized multi-modal framework which can generate diverse andvisually-aligned explanations via contrastive learning. Experiments show thatour framework benefits from different modalities as inputs, and is able toproduce more diverse and expressive explanations compared to previous methodson a variety of evaluation metrics.", "output": "Personalized Showcases: Generating Multi-Modal Explanations for Recommendations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The deployment of Deep Neural Networks (DNNs) on edge devices is hindered bythe substantial gap between performance requirements and available processingpower. While recent research has made significant strides in developing pruningmethods to build a sparse network for reducing the computing overhead of DNNs,there remains considerable accuracy loss, especially at high pruning ratios. Wefind that the architectures designed for dense networks by differentiablearchitecture search methods are ineffective when pruning mechanisms are appliedto them. The main reason is that the current method does not support sparsearchitectures in their search space and uses a search objective that is madefor dense networks and does not pay any attention to sparsity. In this paper,we propose a new method to search for sparsity-friendly neural architectures.We do this by adding two new sparse operations to the search space andmodifying the search objective. We propose two novel parametric SparseConv andSparseLinear operations in order to expand the search space to include sparseoperations. In particular, these operations make a flexible search space due tousing sparse parametric versions of linear and convolution operations. Theproposed search objective lets us train the architecture based on the sparsityof the search space operations. Quantitative analyses demonstrate that oursearch architectures outperform those used in the stateof-the-art sparsenetworks on the CIFAR-10 and ImageNet datasets. In terms of performance andhardware effectiveness, DASS increases the accuracy of the sparse version ofMobileNet-v2 from 73.44% to 81.35% (+7.91% improvement) with 3.87x fasterinference time.", "output": "DASS: Differentiable Architecture Search for Sparse neural networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the prosperity of e-commerce industry, various modalities, e.g., visionand language, are utilized to describe product items. It is an enormouschallenge to understand such diversified data, especially via extracting theattribute-value pairs in text sequences with the aid of helpful image regions.Although a series of previous works have been dedicated to this task, thereremain seldomly investigated obstacles that hinder further improvements: 1)Parameters from up-stream single-modal pretraining are inadequately applied,without proper jointly fine-tuning in a down-stream multi-modal task. 2) Toselect descriptive parts of images, a simple late fusion is widely applied,regardless of priori knowledge that language-related information should beencoded into a common linguistic embedding space by stronger encoders. 3) Dueto diversity across products, their attribute sets tend to vary greatly, butcurrent approaches predict with an unnecessary maximal range and lead to morepotential false positives. To address these issues, we propose in this paper anovel approach to boost multi-modal e-commerce attribute value extraction viaunified learning scheme and dynamic range minimization: 1) Firstly, a unifiedscheme is designed to jointly train a multi-modal task with pretrainedsingle-modal parameters. 2) Secondly, a text-guided information rangeminimization method is proposed to adaptively encode descriptive parts of eachmodality into an identical space with a powerful pretrained linguistic model.3) Moreover, a prototype-guided attribute range minimization method is proposedto first determine the proper attribute set of the current product, and thenselect prototypes to guide the prediction of the chosen attributes. Experimentson the popular multi-modal e-commerce benchmarks show that our approachachieves superior performance over the other state-of-the-art techniques.", "output": "Boosting Multi-Modal E-commerce Attribute Value Extraction via Unified Learning Scheme and Dynamic Range Minimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Many point-based 3D detectors adopt point-feature sampling strategies to dropsome points for efficient inference. These strategies are typically based onfixed and handcrafted rules, making it difficult to handle complicated scenes.Different from them, we propose a Dynamic Ball Query (DBQ) network toadaptively select a subset of input points according to the input features, andassign the feature transform with a suitable receptive field for each selectedpoint. It can be embedded into some state-of-the-art 3D detectors and trainedin an end-to-end manner, which significantly reduces the computational cost.Extensive experiments demonstrate that our method can increase the inferencespeed by 30%-100% on KITTI, Waymo, and ONCE datasets. Specifically, theinference speed of our detector can reach 162 FPS on KITTI scene, and 30 FPS onWaymo and ONCE scenes without performance degradation. Due to skipping theredundant points, some evaluation metrics show significant improvements. Codeswill be released at ", "output": "DBQ-SSD: Dynamic Ball Query for Efficient 3D Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Learning radiance fields has shown remarkable results for novel viewsynthesis. The learning procedure usually costs lots of time, which motivatesthe latest methods to speed up the learning procedure by learning withoutneural networks or using more efficient data structures. However, thesespecially designed approaches do not work for most of radiance fields basedmethods. To resolve this issue, we introduce a general strategy to speed up thelearning procedure for almost all radiance fields based methods. Our key ideais to reduce the redundancy by shooting much fewer rays in the multi-viewvolume rendering procedure which is the base for almost all radiance fieldsbased methods. We find that shooting rays at pixels with dramatic color changenot only significantly reduces the training burden but also barely affects theaccuracy of the learned radiance fields. In addition, we also adaptivelysubdivide each view into a quadtree according to the average rendering error ineach node in the tree, which makes us dynamically shoot more rays in morecomplex regions with larger rendering error. We evaluate our method withdifferent radiance fields based methods under the widely used benchmarks.Experimental results show that our method achieves comparable accuracy to thestate-of-the-art with much faster training.", "output": "Fast Learning Radiance Fields by Shooting Much Fewer Rays."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning has been effective for histology image analysis in digitalpathology. However, many current deep learning approaches require large,strongly- or weakly-labeled images and regions of interest, which can betime-consuming and resource-intensive to obtain. To address this challenge, wepresent HistoPerm, a view generation method for representation learning usingjoint embedding architectures that enhances representation learning forhistology images. HistoPerm permutes augmented views of patches extracted fromwhole-slide histology images to improve classification performance. Weevaluated the effectiveness of HistoPerm on two histology image datasets forCeliac disease and Renal Cell Carcinoma, using three widely used jointembedding architecture-based representation learning methods: BYOL, SimCLR, andVICReg. Our results show that HistoPerm consistently improves patch- andslide-level classification performance in terms of accuracy, F1-score, and AUC.Specifically, for patch-level classification accuracy on the Celiac diseasedataset, HistoPerm boosts BYOL and VICReg by 8% and SimCLR by 3%. On the RenalCell Carcinoma dataset, patch-level classification accuracy is increased by 2%for BYOL and VICReg, and by 1% for SimCLR. In addition, on the Celiac diseasedataset, models with HistoPerm outperform the fully-supervised baseline modelby 6%, 5%, and 2% for BYOL, SimCLR, and VICReg, respectively. For the RenalCell Carcinoma dataset, HistoPerm lowers the classification accuracy gap forthe models up to 10% relative to the fully-supervised baseline. These findingssuggest that HistoPerm can be a valuable tool for improving representationlearning of histopathology features when access to labeled data is limited andcan lead to whole-slide classification results that are comparable to orsuperior to fully-supervised methods.", "output": "HistoPerm: A Permutation-Based View Generation Approach for Improving Histopathologic Feature Representation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Event camera is an emerging bio-inspired vision sensors that report per-pixelbrightness changes asynchronously. It holds noticeable advantage of highdynamic range, high speed response, and low power budget that enable it to bestcapture local motions in uncontrolled environments. This motivates us to unlockthe potential of event cameras for human pose estimation, as the human poseestimation with event cameras is rarely explored. Due to the novel paradigmshift from conventional frame-based cameras, however, event signals in a timeinterval contain very limited information, as event cameras can only capturethe moving body parts and ignores those static body parts, resulting in someparts to be incomplete or even disappeared in the time interval. This paperproposes a novel densely connected recurrent architecture to address theproblem of incomplete information. By this recurrent architecture, we canexplicitly model not only the sequential but also non-sequential geometricconsistency across time steps to accumulate information from previous frames torecover the entire human bodies, achieving a stable and accurate human poseestimation from event data. Moreover, to better evaluate our model, we collecta large scale multimodal event-based dataset that comes with human poseannotations, which is by far the most challenging one to the best of ourknowledge. The experimental results on two public datasets and our own datasetdemonstrate the effectiveness and strength of our approach. Code can beavailable online for facilitating the future research.", "output": "A Temporal Densely Connected Recurrent Network for Event-based Human Pose Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Knowing the 3D motions in a dynamic scene is essential to many visionapplications. Recent progress is mainly focused on estimating the activity ofsome specific elements like humans. In this paper, we leverage a neural motionfield for estimating the motion of all points in a multiview setting. Modelingthe motion from a dynamic scene with multiview data is challenging due to theambiguities in points of similar color and points with time-varying color. Wepropose to regularize the estimated motion to be predictable. If the motionfrom previous frames is known, then the motion in the near future should bepredictable. Therefore, we introduce a predictability regularization by firstconditioning the estimated motion on latent embeddings, then by adopting apredictor network to enforce predictability on the embeddings. The proposedframework PREF (Predictability REgularized Fields) achieves on par or betterresults than state-of-the-art neural motion field-based dynamic scenerepresentation methods, while requiring no prior knowledge of the scene.", "output": "PREF: Predictability Regularized Neural Motion Fields."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Snow removal aims to locate snow areas and recover clean images withoutrepairing traces. Unlike the regularity and semitransparency of rain, snow withvarious patterns and degradations seriously occludes the background. As aresult, the state-of-the-art snow removal methods usually retains a largeparameter size. In this paper, we propose a lightweight but high-efficient snowremoval network called Laplace Mask Query Transformer (LMQFormer). Firstly, wepresent a Laplace-VQVAE to generate a coarse mask as prior knowledge of snow.Instead of using the mask in dataset, we aim at reducing both the informationentropy of snow and the computational cost of recovery. Secondly, we design aMask Query Transformer (MQFormer) to remove snow with the coarse mask, where weuse two parallel encoders and a hybrid decoder to learn extensive snow featuresunder lightweight requirements. Thirdly, we develop a Duplicated Mask QueryAttention (DMQA) that converts the coarse mask into a specific number ofqueries, which constraint the attention areas of MQFormer with reducedparameters. Experimental results in popular datasets have demonstrated theefficiency of our proposed model, which achieves the state-of-the-art snowremoval quality with significantly reduced parameters and the lowest runningtime.", "output": "LMQFormer: A Laplace-Prior-Guided Mask Query Transformer for Lightweight Snow Removal."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper deals with the problem of localizing objects in image and videodatasets from visual exemplars. In particular, we focus on the challengingproblem of egocentric visual query localization. We first identify graveimplicit biases in current query-conditioned model design and visual querydatasets. Then, we directly tackle such biases at both frame and object setlevels. Concretely, our method solves these issues by expanding limitedannotations and dynamically dropping object proposals during training.Additionally, we propose a novel transformer-based module that allows forobject-proposal set context to be considered while incorporating queryinformation. We name our module Conditioned Contextual Transformer orCocoFormer. Our experiments show the proposed adaptations improve egocentricquery detection, leading to a better visual query localization system in both2D and 3D configurations. Thus, we are able to improve frame-level detectionperformance from 26.28% to 31.26 in AP, which correspondingly improves the VQ2Dand VQ3D localization scores by significant margins. Our improved context-awarequery object detector ranked first and second in the VQ2D and VQ3D tasks in the2nd Ego4D challenge. In addition to this, we showcase the relevance of ourproposed model in the Few-Shot Detection (FSD) task, where we also achieve SOTAresults. Our code is available at", "output": "Where is my Wallet? Modeling Object Proposal Sets for Egocentric Visual Query Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Skin cancer is a fatal disease that takes a heavy toll over human livesannually. The colored skin images show a significant degree of resemblancebetween different skin lesions such as melanoma and nevus, makingidentification and diagnosis more challenging. Melanocytic nevi may mature tocause fatal melanoma. Therefore, the current management protocol involves theremoval of those nevi that appear intimidating. However, this necessitatesresilient classification paradigms for classifying benign and malignantmelanocytic nevi. Early diagnosis necessitates a dependable automated systemfor melanocytic nevi classification to render diagnosis efficient, timely, andsuccessful. An automated classification algorithm is proposed in the givenresearch. A neural network previously-trained on a separate problem statementis leveraged in this technique for classifying melanocytic nevus images. Thesuggested method uses BigTransfer (BiT), a ResNet-based transfer learningapproach for classifying melanocytic nevi as malignant or benign. The resultsobtained are compared to that of current techniques, and the new method'sclassification rate is proven to outperform that of existing methods.", "output": "Classification of Melanocytic Nevus Images using BigTransfer (BiT)."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Semi-supervised action recognition is a challenging but critical task due tothe high cost of video annotations. Existing approaches mainly useconvolutional neural networks, yet current revolutionary vision transformermodels have been less explored. In this paper, we investigate the use oftransformer models under the SSL setting for action recognition. To this end,we introduce SVFormer, which adopts a steady pseudo-labeling framework (ie,EMA-Teacher) to cope with unlabeled video samples. While a wide range of dataaugmentations have been shown effective for semi-supervised imageclassification, they generally produce limited results for video recognition.We therefore introduce a novel augmentation strategy, Tube TokenMix, tailoredfor video data where video clips are mixed via a mask with consistent maskedtokens over the temporal axis. In addition, we propose a temporal warpingaugmentation to cover the complex temporal variation in videos, which stretchesselected frames to various temporal durations in the clip. Extensiveexperiments on three datasets Kinetics-400, UCF-101, and HMDB-51 verify theadvantage of SVFormer. In particular, SVFormer outperforms the state-of-the-artby 31.5% with fewer training epochs under the 1% labeling rate of Kinetics-400.Our method can hopefully serve as a strong benchmark and encourage futuresearch on semi-supervised action recognition with Transformer networks.", "output": "SVFormer: Semi-supervised Video Transformer for Action Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Traditional 3D scene understanding approaches rely on labeled 3D datasets totrain a model for a single task with supervision. We propose OpenScene, analternative approach where a model predicts dense features for 3D scene pointsthat are co-embedded with text and image pixels in CLIP feature space. Thiszero-shot approach enables task-agnostic training and open-vocabulary queries.For example, to perform SOTA zero-shot 3D semantic segmentation it first infersCLIP features for every 3D point and later classifies them based onsimilarities to embeddings of arbitrary class labels. More interestingly, itenables a suite of open-vocabulary scene understanding applications that havenever been done before. For example, it allows a user to enter an arbitrarytext query and then see a heat map indicating which parts of a scene match. Ourapproach is effective at identifying objects, materials, affordances,activities, and room types in complex 3D scenes, all using a single modeltrained without any labeled 3D data.", "output": "OpenScene: 3D Scene Understanding with Open Vocabularies."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision Transformers (ViTs) have gained significant popularity in recent yearsand have proliferated into many applications. However, their behavior underdifferent learning paradigms is not well explored. We compare ViTs trainedthrough different methods of supervision, and show that they learn a diverserange of behaviors in terms of their attention, representations, and downstreamperformance. We also discover ViT behaviors that are consistent acrosssupervision, including the emergence of Offset Local Attention Heads. These areself-attention heads that attend to a token adjacent to the current token witha fixed directional offset, a phenomenon that to the best of our knowledge hasnot been highlighted in any prior work. Our analysis shows that ViTs are highlyflexible and learn to process local and global information in different ordersdepending on their training method. We find that contrastive self-supervisedmethods learn features that are competitive with explicitly supervisedfeatures, and they can even be superior for part-level tasks. We also find thatthe representations of reconstruction-based models show non-trivial similarityto contrastive self-supervised models. Project website( and code( are publicly available.", "output": "Teaching Matters: Investigating the Role of Supervision in Vision Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Attention-based arbitrary style transfer studies have shown promisingperformance in synthesizing vivid local style details. They typically use theall-to-all attention mechanism -- each position of content features is fullymatched to all positions of style features. However, all-to-all attention tendsto generate distorted style patterns and has quadratic complexity, limiting theeffectiveness and efficiency of arbitrary style transfer. In this paper, wepropose a novel all-to-key attention mechanism -- each position of contentfeatures is matched to stable key positions of style features -- that is morein line with the characteristics of style transfer. Specifically, it integratestwo newly proposed attention forms: distributed and progressive attention.Distributed attention assigns attention to key style representations thatdepict the style distribution of local regions; Progressive attention paysattention from coarse-grained regions to fine-grained key positions. Theresultant module, dubbed StyA2K, shows extraordinary performance in preservingthe semantic structure and rendering consistent style patterns. Qualitative andquantitative comparisons with state-of-the-art methods demonstrate the superiorperformance of our approach.", "output": "All-to-key Attention for Arbitrary Style Transfer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In real teaching scenarios, an excellent teacher always teaches what he (orshe) is good at but the student is not. This gives the student the bestassistance in making up for his (or her) weaknesses and becoming a good oneoverall. Enlightened by this, we introduce the \"Teaching what you Should Teach\"strategy into a knowledge distillation framework, and propose a data-baseddistillation method named \"TST\" that searches for desirable augmented samplesto assist in distilling more efficiently and rationally. To be specific, wedesign a neural network-based data augmentation module with priori bias, whichassists in finding what meets the teacher's strengths but the student'sweaknesses, by learning magnitudes and probabilities to generate suitable datasamples. By training the data augmentation module and the generalizeddistillation paradigm in turn, a student model is learned with excellentgeneralization ability. To verify the effectiveness of our method, we conductedextensive comparative experiments on object recognition, detection, andsegmentation tasks. The results on the CIFAR-10, ImageNet-1k, MS-COCO, andCityscapes datasets demonstrate that our method achieves state-of-the-artperformance on almost all teacher-student pairs. Furthermore, we conductvisualization studies to explore what magnitudes and probabilities are neededfor the distillation process.", "output": "Teaching What You Should Teach: A Data-Based Distillation Method."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Font generation is a difficult and time-consuming task, especially in thoselanguages using ideograms that have complicated structures with a large numberof characters, such as Chinese. To solve this problem, few-shot font generationand even one-shot font generation have attracted a lot of attention. However,most existing font generation methods may still suffer from (i) largecross-font gap challenge; (ii) subtle cross-font variation problem; and (iii)incorrect generation of complicated characters. In this paper, we propose anovel one-shot font generation method based on a diffusion model, namedDiff-Font, which can be stably trained on large datasets. The proposed modelaims to generate the entire font library by giving only one sample as thereference. Specifically, a large stroke-wise dataset is constructed, and astroke-wise diffusion model is proposed to preserve the structure and thecompletion of each generated character. To our best knowledge, the proposedDiff-Font is the first work that developed diffusion models to handle the fontgeneration task. The well-trained Diff-Font is not only robust to font gap andfont variation, but also achieved promising performance on difficult charactergeneration. Compared to previous font generation methods, our model reachesstate-of-the-art performance both qualitatively and quantitatively.", "output": "Diff-Font: Diffusion Model for Robust One-Shot Font Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural image classifiers are known to undergo severe performance degradationwhen exposed to input that exhibits covariate shift with respect to thetraining distribution. In this paper, we show that recent Text-to-Image (T2I)generators' ability to edit images to approximate interventions vianatural-language prompts is a promising technology to train more robustclassifiers. Using current open-source models, we find that a variety ofprompting strategies are effective for producing augmented training datasetssufficient to achieve state-of-the-art performance (1) in widely adoptedSingle-Domain Generalization benchmarks, (2) in reducing classifiers'dependency on spurious features and (3) facilitating the application ofMulti-Domain Generalization techniques when fewer training domains areavailable.", "output": "Not Just Pretty Pictures: Text-to-Image Generators Enable Interpretable Interventions for Robust Representations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generic Object Tracking (GOT) is the problem of tracking target objects,specified by bounding boxes in the first frame of a video. While the task hasreceived much attention in the last decades, researchers have almostexclusively focused on the single object setting. Multi-object GOT benefitsfrom a wider applicability, rendering it more attractive in real-worldapplications. We attribute the lack of research interest into this problem tothe absence of suitable benchmarks. In this work, we introduce a newlarge-scale GOT benchmark, LaGOT, containing multiple annotated target objectsper sequence. Our benchmark allows users to tackle key remaining challenges inGOT, aiming to increase robustness and reduce computation through jointtracking of multiple objects simultaneously. In addition, we propose atransformer-based GOT tracker baseline capable of joint processing of multipleobjects through shared computation. Our approach achieves a 4x faster run-timein case of 10 concurrent objects compared to tracking each object independentlyand outperforms existing single object trackers on our new benchmark. Inaddition, our approach achieves highly competitive results on single-object GOTdatasets, setting a new state of the art on TrackingNet with a success rate AUCof 84.4%. Our benchmark, code, and trained models will be made publiclyavailable.", "output": "Beyond SOT: Tracking Multiple Generic Objects at Once."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a novel teacher-student model for semi-supervised multi-organsegmentation. In teacher-student model, data augmentation is usually adopted onunlabeled data to regularize the consistent training between teacher andstudent. We start from a key perspective that fixed relative locations andvariable sizes of different organs can provide distribution information where amulti-organ CT scan is drawn. Thus, we treat the prior anatomy as a strong toolto guide the data augmentation and reduce the mismatch between labeled andunlabeled images for semi-supervised learning. More specifically, we propose adata augmentation strategy based on partition-and-recovery N$^3$ cubes cross-and within- labeled and unlabeled images. Our strategy encourages unlabeledimages to learn organ semantics in relative locations from the labeled images(cross-branch) and enhances the learning ability for small organs(within-branch). For within-branch, we further propose to refine the quality ofpseudo labels by blending the learned representations from small cubes toincorporate local attributes. Our method is termed as MagicNet, since it treatsthe CT volume as a magic-cube and N$^3$-cube partition-and-recovery processmatches with the rule of playing a magic-cube. Extensive experiments on twopublic CT multi-organ datasets demonstrate the effectiveness of MagicNet, andnoticeably outperforms state-of-the-art semi-supervised medical imagesegmentation approaches, with +7% DSC improvement on MACT dataset with 10%labeled images. Code is available at", "output": "MagicNet: Semi-Supervised Multi-Organ Segmentation via Magic-Cube Partition and Recovery."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large, pretrained models are commonly finetuned with imagery that is heavilyaugmented to mimic different conditions and scales, with the resulting modelsused for various tasks with imagery from a range of spatial scales. Such modelsoverlook scale-specific information in the data for scale-dependent domains,such as remote sensing. In this paper, we present Scale-MAE, a pretrainingmethod that explicitly learns relationships between data at different, knownscales throughout the pretraining process. Scale-MAE pretrains a network bymasking an input image at a known input scale, where the area of the Earthcovered by the image determines the scale of the ViT positional encoding, notthe image resolution. Scale-MAE encodes the masked image with a standard ViTbackbone, and then decodes the masked image through a bandpass filter toreconstruct low/high frequency images at lower/higher scales. We find thattasking the network with reconstructing both low/high frequency images leads torobust multiscale representations for remote sensing imagery. Scale-MAEachieves an average of a $2.4 - 5.6%$ non-parametric kNN classificationimprovement across eight remote sensing datasets compared to currentstate-of-the-art and obtains a $0.9$ mIoU to $1.7$ mIoU improvement on theSpaceNet building segmentation transfer task for a range of evaluation scales.", "output": "Scale-MAE: A Scale-Aware Masked Autoencoder for Multiscale Geospatial Representation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Current dataset collection methods typically scrape large amounts of datafrom the web. While this technique is extremely scalable, data collected inthis way tends to reinforce stereotypical biases, can contain personallyidentifiable information, and typically originates from Europe and NorthAmerica. In this work, we rethink the dataset collection paradigm and introduceGeoDE, a geographically diverse dataset with 61,940 images from 40 classes and6 world regions, and no personally identifiable information, collected throughcrowd-sourcing. We analyse GeoDE to understand differences in images collectedin this manner compared to web-scraping. Despite the smaller size of thisdataset, we demonstrate its use as both an evaluation and training dataset,highlight shortcomings in current models, as well as show improved performanceswhen even small amounts of GeoDE (1000 - 2000 images per region) are added to atraining dataset. We release the full dataset and code at", "output": "Beyond web-scraping: Crowd-sourcing a geographically diverse image dataset."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Contrastive Language-Image Pre-training (CLIP) achieves promising results in2D zero-shot and few-shot learning. Despite the impressive performance in 2D,applying CLIP to help the learning in 3D scene understanding has yet to beexplored. In this paper, we make the first attempt to investigate how CLIPknowledge benefits 3D scene understanding. We propose CLIP2Scene, a simple yeteffective framework that transfers CLIP knowledge from 2D image-textpre-trained models to a 3D point cloud network. We show that the pre-trained 3Dnetwork yields impressive performance on various downstream tasks, i.e.,annotation-free and fine-tuning with labelled data for semantic segmentation.Specifically, built upon CLIP, we design a Semantic-driven Cross-modalContrastive Learning framework that pre-trains a 3D network via semantic andspatial-temporal consistency regularization. For the former, we first leverageCLIP's text semantics to select the positive and negative point samples andthen employ the contrastive loss to train the 3D network. In terms of thelatter, we force the consistency between the temporally coherent point cloudfeatures and their corresponding image features. We conduct experiments onSemanticKITTI, nuScenes, and ScanNet. For the first time, our pre-trainednetwork achieves annotation-free 3D semantic segmentation with 20.8% and 25.08%mIoU on nuScenes and ScanNet, respectively. When fine-tuned with 1% or 100%labelled data, our method significantly outperforms other self-supervisedmethods, with improvements of 8% and 1% mIoU, respectively. Furthermore, wedemonstrate the generalizability for handling cross-domain datasets. Code ispublicly available ", "output": "CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we learn to classify visual object instances, incrementallyand via self-supervision (self-incremental). Our learner observes a singleinstance at a time, which is then discarded from the dataset. Incrementalinstance learning is challenging, since longer learning sessions exacerbateforgetfulness, and labeling instances is cumbersome. We overcome thesechallenges via three contributions: i. We propose VINIL, a self-incrementallearner that can learn object instances sequentially, ii. We equip VINIL withself-supervision to by-pass the need for instance labelling, iii. We compareVINIL to label-supervised variants on two large-scale benchmarks, and show thatVINIL significantly improves accuracy while reducing forgetfulness.", "output": "Are Labels Needed for Incremental Instance Learning?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The responsible and sustainable agave-tequila production chain is fundamentalfor the social, environment and economic development of Mexico's agave regions.It is therefore relevant to develop new tools for large scale automatic agaveregion monitoring. In this work, we present an Agave tequilana Weber azul cropsegmentation and maturity classification using very high resolution satelliteimagery, which could be useful for this task. To achieve this, we solvereal-world deep learning problems in the very specific context of agave cropsegmentation such as lack of data, low quality labels, highly imbalanced data,and low model performance. The proposed strategies go beyond data augmentationand data transfer combining active learning and the creation of syntheticimages with human supervision. As a result, the segmentation performanceevaluated with Intersection over Union (IoU) value increased from 0.72 to 0.90in the test set. We also propose a method for classifying agave crop maturitywith 95% accuracy. With the resulting accurate models, agave productionforecasting can be made available for large regions. In addition, somesupply-demand problems such excessive supplies of agave or, deforestation,could be detected early.", "output": "Agave crop segmentation and maturity classification with deep learning data-centric strategies using very high-resolution satellite imagery."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Understanding 3D scenes from multi-view inputs has been proven to alleviatethe view discrepancy issue in 3D visual grounding. However, existing methodsnormally neglect the view cues embedded in the text modality and fail to weighthe relative importance of different views. In this paper, we proposeViewRefer, a multi-view framework for 3D visual grounding exploring how tograsp the view knowledge from both text and 3D modalities. For the text branch,ViewRefer leverages the diverse linguistic knowledge of large-scale languagemodels, e.g., GPT, to expand a single grounding text to multiplegeometry-consistent descriptions. Meanwhile, in the 3D modality, a transformerfusion module with inter-view attention is introduced to boost the interactionof objects across views. On top of that, we further present a set of learnablemulti-view prototypes, which memorize scene-agnostic knowledge for differentviews, and enhance the framework from two perspectives: a view-guided attentionmodule for more robust text features, and a view-guided scoring strategy duringthe final prediction. With our designed paradigm, ViewRefer achieves superiorperformance on three benchmarks and surpasses the second-best by +2.8%, +1.2%,and +0.73% on Sr3D, Nr3D, and ScanRefer. Code will be released at", "output": "ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image-to-image translation (I2I) methods allow the generation of artificialimages that share the content of the original image but have a different style.With the advances in Generative Adversarial Networks (GANs)-based methods, I2Imethods enabled the generation of artificial images that are indistinguishablefrom natural images. Recently, I2I methods were also employed in histopathologyfor generating artificial images of in silico stained tissues from a differenttype of staining. We refer to this process as stain transfer. The number of I2Ivariants is constantly increasing, which makes a well justified choice of themost suitable I2I methods for stain transfer challenging. In our work, wecompare twelve stain transfer approaches, three of which are based ontraditional and nine on GAN-based image processing methods. The analysis relieson complementary quantitative measures for the quality of image translation,the assessment of the suitability for deep learning-based tissue grading, andthe visual evaluation by pathologists. Our study highlights the strengths andweaknesses of the stain transfer approaches, thereby allowing a rational choiceof the underlying I2I algorithms. Code, data, and trained models for staintransfer between H&amp;E and Masson's Trichrome staining will be made availableonline.", "output": "A comparative evaluation of image-to-image translation methods for stain transfer in histopathology."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Estimating 3D humans from images often produces implausible bodies that lean,float, or penetrate the floor. Such methods ignore the fact that bodies aretypically supported by the scene. A physics engine can be used to enforcephysical plausibility, but these are not differentiable, rely on unrealisticproxy bodies, and are difficult to integrate into existing optimization andlearning frameworks. In contrast, we exploit novel intuitive-physics (IP) termsthat can be inferred from a 3D SMPL body interacting with the scene. Inspiredby biomechanics, we infer the pressure heatmap on the body, the Center ofPressure (CoP) from the heatmap, and the SMPL body's Center of Mass (CoM). Withthese, we develop IPMAN, to estimate a 3D body from a color image in a \"stable\"configuration by encouraging plausible floor contact and overlapping CoP andCoM. Our IP terms are intuitive, easy to implement, fast to compute,differentiable, and can be integrated into existing optimization and regressionmethods. We evaluate IPMAN on standard datasets and MoYo, a new dataset withsynchronized multi-view images, ground-truth 3D bodies with complex poses,body-floor contact, CoM and pressure. IPMAN produces more plausible resultsthan the state of the art, improving accuracy for static poses, while nothurting dynamic ones. Code and data are available for research at", "output": "3D Human Pose Estimation via Intuitive Physics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fast adversarial training (FAT) is an efficient method to improve robustness.However, the original FAT suffers from catastrophic overfitting, whichdramatically and suddenly reduces robustness after a few training epochs.Although various FAT variants have been proposed to prevent overfitting, theyrequire high training costs. In this paper, we investigate the relationshipbetween adversarial example quality and catastrophic overfitting by comparingthe training processes of standard adversarial training and FAT. We find thatcatastrophic overfitting occurs when the attack success rate of adversarialexamples becomes worse. Based on this observation, we propose a positiveprior-guided adversarial initialization to prevent overfitting by improvingadversarial example quality without extra training costs. This initializationis generated by using high-quality adversarial perturbations from thehistorical training process. We provide theoretical analysis for the proposedinitialization and propose a prior-guided regularization method that boosts thesmoothness of the loss function. Additionally, we design a prior-guidedensemble FAT method that averages the different model weights of historicalmodels using different decay rates. Our proposed method, called FGSM-PGK,assembles the prior-guided knowledge, i.e., the prior-guided initialization andmodel weights, acquired during the historical training process. Evaluations offour datasets demonstrate the superiority of the proposed method.", "output": "Improving Fast Adversarial Training with Prior-Guided Knowledge."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present DreamAvatar, a text-and-shape guided framework for generatinghigh-quality 3D human avatars with controllable poses. While encouragingresults have been produced by recent methods on text-guided 3D common objectgeneration, generating high-quality human avatars remains an open challenge dueto the complexity of the human body's shape, pose, and appearance. We proposeDreamAvatar to tackle this challenge, which utilizes a trainable NeRF forpredicting density and color features for 3D points and a pre-trainedtext-to-image diffusion model for providing 2D self-supervision. Specifically,we leverage SMPL models to provide rough pose and shape guidance for thegeneration. We introduce a dual space design that comprises a canonical spaceand an observation space, which are related by a learnable deformation fieldthrough the NeRF, allowing for the transfer of well-optimized texture andgeometry from the canonical space to the target posed avatar. Additionally, weexploit a normal-consistency regularization to allow for more vivid generationwith detailed geometry and texture. Through extensive evaluations, wedemonstrate that DreamAvatar significantly outperforms existing methods,establishing a new state-of-the-art for text-and-shape guided 3D humangeneration.", "output": "DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This report serves as a supplementary document for TaskPrompter, detailingits implementation on a new joint 2D-3D multi-task learning benchmark based onCityscapes-3D. TaskPrompter presents an innovative multi-task promptingframework that unifies the learning of (i) task-generic representations, (ii)task-specific representations, and (iii) cross-task interactions, as opposed toprevious approaches that separate these learning objectives into differentnetwork modules. This unified approach not only reduces the need for meticulousempirical structure design but also significantly enhances the multi-tasknetwork's representation learning capability, as the entire model capacity isdevoted to optimizing the three objectives simultaneously. TaskPrompterintroduces a new multi-task benchmark based on Cityscapes-3D dataset, whichrequires the multi-task model to concurrently generate predictions formonocular 3D vehicle detection, semantic segmentation, and monocular depthestimation. These tasks are essential for achieving a joint 2D-3D understandingof visual scenes, particularly in the development of autonomous drivingsystems. On this challenging benchmark, our multi-task model demonstratesstrong performance compared to single-task state-of-the-art methods andestablishes new state-of-the-art results on the challenging 3D detection anddepth estimation tasks.", "output": "Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks have made huge progress in the last few decades.However, as the real-world data often exhibits a long-tailed distribution,vanilla deep models tend to be heavily biased toward the majority classes. Toaddress this problem, state-of-the-art methods usually adopt a mixture ofexperts (MoE) to focus on different parts of the long-tailed distribution.Experts in these methods are with the same model depth, which neglects the factthat different classes may have different preferences to be fit by models withdifferent depths. To this end, we propose a novel MoE-based method calledSelf-Heterogeneous Integration with Knowledge Excavation (SHIKE). We firstpropose Depth-wise Knowledge Fusion (DKF) to fuse features between differentshallow parts and the deep part in one network for each expert, which makesexperts more diverse in terms of representation. Based on DKF, we furtherpropose Dynamic Knowledge Transfer (DKT) to reduce the influence of the hardestnegative class that has a non-negligible impact on the tail classes in our MoEframework. As a result, the classification accuracy of long-tailed data can besignificantly improved, especially for the tail classes. SHIKE achieves thestate-of-the-art performance of 56.3%, 60.3%, 75.4%, and 41.9% on CIFAR100-LT(IF100), ImageNet-LT, iNaturalist 2018, and Places-LT, respectively.", "output": "Long-Tailed Visual Recognition via Self-Heterogeneous Integration with Knowledge Excavation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Unsupervised domain adaptation (UDA) addresses the problem of distributionshift between the unlabelled target domain and labelled source domain. Whilethe single target domain adaptation (STDA) is well studied in the literaturefor both 2D and 3D vision tasks, multi-target domain adaptation (MTDA) isbarely explored for 3D data despite its wide real-world applications such asautonomous driving systems for various geographical and climatic conditions. Weestablish an MTDA baseline for 3D point cloud data by proposing to mix thefeature representations from all domains together to achieve better domainadaptation performance by an ensemble average, which we call Mixup EnsembleAverage or MEnsA. With the mixed representation, we use a domain classifier toimprove at distinguishing the feature representations of source domain fromthose of target domains in a shared latent space. In empirical validations onthe challenging PointDA-10 dataset, we showcase a clear benefit of our simplemethod over previous unsupervised STDA and MTDA methods by large margins (up to17.10% and 4.76% on averaged over all domain shifts).", "output": "MEnsA: Mix-up Ensemble Average for Unsupervised Multi Target Domain Adaptation on 3D Point Clouds."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in deep learning have been pushing image denoising techniquesto a new level. In self-supervised image denoising, blind-spot network (BSN) isone of the most common methods. However, most of the existing BSN algorithmsuse a dot-based central mask, which is recognized as inefficient for imageswith large-scale spatially correlated noise. In this paper, we give thedefinition of large-noise and propose a multi-mask strategy using multipleconvolutional kernels masked in different shapes to further break the noisespatial correlation. Furthermore, we propose a novel self-supervised imagedenoising method that combines the multi-mask strategy with BSN (MM-BSN). Weshow that different masks can cause significant performance differences, andthe proposed MM-BSN can efficiently fuse the features extracted by multi-maskedlayers, while recovering the texture structures destroyed by multi-masking andinformation transmission. Our MM-BSN can be used to address the problem oflarge-noise denoising, which cannot be efficiently handled by other BSNmethods. Extensive experiments on public real-world datasets demonstrate thatthe proposed MM-BSN achieves state-of-the-art performance among self-supervisedand even unpaired image denoising methods for sRGB images denoising, withoutany labelling effort or prior knowledge. Code can be found in", "output": "MM-BSN: Self-Supervised Image Denoising for Real-World with Multi-Mask based on Blind-Spot Network."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent years have witnessed significant progress in the field of neuralsurface reconstruction. While the extensive focus was put on volumetric andimplicit approaches, a number of works have shown that explicit graphicsprimitives such as point clouds can significantly reduce computationalcomplexity, without sacrificing the reconstructed surface quality. However,less emphasis has been put on modeling dynamic surfaces with point primitives.In this work, we present a dynamic point field model that combines therepresentational benefits of explicit point-based graphics with implicitdeformation networks to allow efficient modeling of non-rigid 3D surfaces.Using explicit surface primitives also allows us to easily incorporatewell-established constraints such as-isometric-as-possible regularisation.While learning this deformation model is prone to local optima when trained ina fully unsupervised manner, we propose to additionally leverage semanticinformation such as keypoint dynamics to guide the deformation learning. Wedemonstrate our model with an example application of creating an expressiveanimatable human avatar from a collection of 3D scans. Here, previous methodsmostly rely on variants of the linear blend skinning paradigm, whichfundamentally limits the expressivity of such models when dealing with complexcloth appearances such as long skirts. We show the advantages of our dynamicpoint field framework in terms of its representational power, learningefficiency, and robustness to out-of-distribution novel poses.", "output": "Dynamic Point Fields."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent decades have seen the rise of large-scale Deep Neural Networks (DNNs)to achieve human-competitive performance in a variety of artificialintelligence tasks. Often consisting of hundreds of millions, if not hundredsof billion parameters, these DNNs are too large to be deployed to, orefficiently run on resource-constrained devices such as mobile phones or IoTmicrocontrollers. Systems relying on large-scale DNNs thus have to call thecorresponding model over the network, leading to substantial costs for hostingand running the large-scale remote model, costs which are often charged on aper-use basis. In this paper, we propose BiSupervised, a novel architecture,where, before relying on a large remote DNN, a system attempts to make aprediction on a small-scale local model. A DNN supervisor monitors saidprediction process and identifies easy inputs for which the local predictioncan be trusted. For these inputs, the remote model does not have to be invoked,thus saving costs, while only marginally impacting the overall system accuracy.Our architecture furthermore foresees a second supervisor to monitor the remotepredictions and identify inputs for which not even these can be trusted,allowing to raise an exception or run a fallback strategy instead. We evaluatethe cost savings, and the ability to detect incorrectly predicted inputs onfour diverse case studies: IMDB movie review sentiment classification, Githubissue triaging, Imagenet image classification, and SQuADv2 free-text questionanswering", "output": "Adopting Two Supervisors for Efficient Use of Large-Scale Remote Deep Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Advances in deep learning models have revolutionized the study of biomoleculesystems and their mechanisms. Graph representation learning, in particular, isimportant for accurately capturing the geometric information of biomolecules atdifferent levels. This paper presents a comprehensive review of themethodologies used to represent biological molecules and systems ascomputer-recognizable objects, such as sequences, graphs, and surfaces.Moreover, it examines how geometric deep learning models, with an emphasis ongraph-based techniques, can analyze biomolecule data to enable drug discovery,protein characterization, and biological system analysis. The study concludeswith an overview of the current state of the field, highlighting the challengesthat exist and the potential future research directions.", "output": "Graph Representation Learning for Interactive Biomolecule Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Backpropagation has rapidly become the workhorse credit assignment algorithmfor modern deep learning methods. Recently, modified forms of predictive coding(PC), an algorithm with origins in computational neuroscience, have been shownto result in approximately or exactly equal parameter updates to those underbackpropagation. Due to this connection, it has been suggested that PC can actas an alternative to backpropagation with desirable properties that mayfacilitate implementation in neuromorphic systems. Here, we explore theseclaims using the different contemporary PC variants proposed in the literature.We obtain time complexity bounds for these PC variants which we show arelower-bounded by backpropagation. We also present key properties of thesevariants that have implications for neurobiological plausibility and theirinterpretations, particularly from the perspective of standard PC as avariational Bayes algorithm for latent probabilistic models. Our findings shednew light on the connection between the two learning frameworks and suggestthat, in its current forms, PC may have more limited potential as a directreplacement of backpropagation than previously envisioned.", "output": "Predictive Coding as a Neuromorphic Alternative to Backpropagation: A Critical Evaluation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transferability is the property of adversarial examples to be misclassifiedby other models than the surrogate model for which they were crafted. Previousresearch has shown that transferability is substantially increased when thetraining of the surrogate model has been early stopped. A common hypothesis toexplain this is that the later training epochs are when models learn thenon-robust features that adversarial attacks exploit. Hence, an early stoppedmodel is more robust (hence, a better surrogate) than fully trained models. Wedemonstrate that the reasons why early stopping improves transferability lie inthe side effects it has on the learning dynamics of the model. We first showthat early stopping benefits transferability even on models learning from datawith non-robust features. We then establish links between transferability andthe exploration of the loss landscape in the parameter space, on which earlystopping has an inherent effect. More precisely, we observe thattransferability peaks when the learning rate decays, which is also the time atwhich the sharpness of the loss significantly drops. This leads us to proposeRFN, a new approach for transferability that minimizes loss sharpness duringtraining in order to maximize transferability. We show that by searching forlarge flat neighborhoods, RFN always improves over early stopping (by up to 47points of transferability rate) and is competitive to (if not better than)strong state-of-the-art baselines.", "output": "Going Further: Flatness at the Rescue of Early Stopping for Adversarial Example Transferability."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Medical data often exhibits long-tail distributions with heavy classimbalance, which naturally leads to difficulty in classifying the minorityclasses (i.e., boundary regions or rare objects). Recent work has significantlyimproved semi-supervised medical image segmentation in long-tailed scenarios byequipping them with unsupervised contrastive criteria. However, it remainsunclear how well they will perform in the labeled portion of data where classdistribution is also highly imbalanced. In this work, we present ACTION++, animproved contrastive learning framework with adaptive anatomical contrast forsemi-supervised medical segmentation. Specifically, we propose an adaptivesupervised contrastive loss, where we first compute the optimal locations ofclass centers uniformly distributed on the embedding space (i.e., off-line),and then perform online contrastive matching training by encouraging differentclass features to adaptively match these distinct and uniformly distributedclass centers. Moreover, we argue that blindly adopting a constant temperature$tau$ in the contrastive loss on long-tailed medical data is not optimal, andpropose to use a dynamic $tau$ via a simple cosine schedule to yield betterseparation between majority and minority classes. Empirically, we evaluateACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-artacross two semi-supervised settings. Theoretically, we analyze the performanceof adaptive anatomical contrast and confirm its superiority in labelefficiency.", "output": "ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image segmentation is an important problem in many safety-criticalapplications. Recent studies show that modern image segmentation models arevulnerable to adversarial perturbations, while existing attack methods mainlyfollow the idea of attacking image classification models. We argue that imagesegmentation and classification have inherent differences, and design an attackframework specially for image segmentation models. Our attack framework isinspired by certified radius, which was originally used by defenders to defendagainst adversarial perturbations to classification models. We are the first,from the attacker perspective, to leverage the properties of certified radiusand propose a certified radius guided attack framework against imagesegmentation models. Specifically, we first adapt randomized smoothing, thestate-of-the-art certification method for classification models, to derive thepixel's certified radius. We then focus more on disrupting pixels withrelatively smaller certified radii and design a pixel-wise certified radiusguided loss, when plugged into any existing white-box attack, yields ourcertified radius-guided white-box attack. Next, we propose the first black-boxattack to image segmentation models via bandit. We design a novel gradientestimator, based on bandit feedback, which is query-efficient and provablyunbiased and stable. We use this gradient estimator to design a projectedbandit gradient descent (PBGD) attack, as well as a certified radius-guidedPBGD (CR-PBGD) attack. We prove our PBGD and CR-PBGD attacks can achieveasymptotically optimal attack performance with an optimal rate. We evaluate ourcertified-radius guided white-box and black-box attacks on multiple modernimage segmentation models and datasets. Our results validate the effectivenessof our certified radius-guided attack framework.", "output": "A Certified Radius-Guided Attack Framework to Image Segmentation Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, single cell RNA sequencing has become a widely usedtechnique to study cellular diversity and function. However, accuratelyannotating cell types from single cell data has been a challenging task, as itrequires extensive knowledge of cell biology and gene function. The emergenceof large language models such as ChatGPT and New Bing in 2023 hasrevolutionized this process by integrating the scientific literature andproviding accurate annotations of cell types. This breakthrough enablesresearchers to conduct literature reviews more efficiently and accurately, andcan potentially uncover new insights into cell type annotation. By usingChatGPT to annotate single cell data, we can relate rare cell type to theirfunction and reveal specific differentiation trajectories of cell subtypes thatwere previously overlooked. This can have important applications inunderstanding cancer progression, mammalian development, and stem celldifferentiation, and can potentially lead to the discovery of key cells thatinterrupt the differentiation pathway and solve key problems in the lifesciences. Overall, the future of cell type annotation in single cell data lookspromising and the Large Language model will be an important milestone in thehistory of single cell analysis.", "output": "Revolutionizing Single Cell Analysis: The Power of Large Language Models for Cell Type Annotation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We give the first agnostic, efficient, proper learning algorithm for monotoneBoolean functions. Given $2^{tilde{O}(sqrt{n}/varepsilon)}$ uniformly randomexamples of an unknown function $f:{pm 1}^n rightarrow {pm 1}$, ouralgorithm outputs a hypothesis $g:{pm 1}^n rightarrow {pm 1}$ that ismonotone and $(mathrm{opt} + varepsilon)$-close to $f$, where $mathrm{opt}$is the distance from $f$ to the closest monotone function. The running time ofthe algorithm (and consequently the size and evaluation time of the hypothesis)is also $2^{tilde{O}(sqrt{n}/varepsilon)}$, nearly matching the lower boundof Blais et al (RANDOM '15). We also give an algorithm for estimating up toadditive error $varepsilon$ the distance of an unknown function $f$ tomonotone using a run-time of $2^{tilde{O}(sqrt{n}/varepsilon)}$. Previously,for both of these problems, sample-efficient algorithms were known, but thesealgorithms were not run-time efficient. Our work thus closes this gap in ourknowledge between the run-time and sample complexity.This work builds upon the improper learning algorithm of Bshouty and Tamon(JACM '96) and the proper semiagnostic learning algorithm of Lange, Rubinfeld,and Vasilyan (FOCS '22), which obtains a non-monotone Boolean-valuedhypothesis, then ``corrects'' it to monotone using query-efficient localcomputation algorithms on graphs. This black-box correction approach canachieve no error better than $2mathrm{opt} + varepsilon$information-theoretically; we bypass this barrier bya) augmenting the improper learner with a convex optimization step, andb) learning and correcting a real-valued function before rounding its valuesto Boolean.Our real-valued correction algorithm solves the ``poset sorting'' problem of[LRV22] for functions over general posets with non-Boolean labels.", "output": "Agnostic proper learning of monotone functions: beyond the black-box correction barrier."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Creating knowledge bases and ontologies is a time consuming task that relieson a manual curation. AI/NLP approaches can assist expert curators inpopulating these knowledge bases, but current approaches rely on extensivetraining data, and are not able to populate arbitrary complex nested knowledgeschemas.Here we present Structured Prompt Interrogation and Recursive Extraction ofSemantics (SPIRES), a Knowledge Extraction approach that relies on the abilityof Large Language Models (LLMs) to perform zero-shot learning (ZSL) andgeneral-purpose query answering from flexible prompts and return informationconforming to a specified schema. Given a detailed, user-defined knowledgeschema and an input text, SPIRES recursively performs prompt interrogationagainst GPT-3+ to obtain a set of responses matching the provided schema.SPIRES uses existing ontologies and vocabularies to provide identifiers for allmatched elements.We present examples of use of SPIRES in different domains, includingextraction of food recipes, multi-species cellular signaling pathways, diseasetreatments, multi-step drug mechanisms, and chemical to disease causationgraphs. Current SPIRES accuracy is comparable to the mid-range of existingRelation Extraction (RE) methods, but has the advantage of easy customization,flexibility, and, crucially, the ability to perform new tasks in the absence ofany training data. This method supports a general strategy of leveraging thelanguage interpreting capabilities of LLMs to assemble knowledge bases,assisting manual knowledge curation and acquisition while supporting validationwith publicly-available databases and ontologies external to the LLM.SPIRES is available as part of the open source OntoGPT package: monarch-initiative/ontogpt.", "output": "Structured prompt interrogation and recursive extraction of semantics (SPIRES): A method for populating knowledge bases using zero-shot learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Self-supervised pretraining has been observed to improve performance insupervised learning tasks in medical imaging. This study investigates theutility of self-supervised pretraining prior to conducting supervisedfine-tuning for the downstream task of lung sliding classification in M-modelung ultrasound images. We propose a novel pairwise relationship that couplesM-mode images constructed from the same B-mode image and investigate theutility of data augmentation procedure specific to M-mode lung ultrasound. Theresults indicate that self-supervised pretraining yields better performancethan full supervision, most notably for feature extractors not initialized withImageNet-pretrained weights. Moreover, we observe that including a vast volumeof unlabelled data results in improved performance on external validationdatasets, underscoring the value of self-supervision for improvinggeneralizability in automatic ultrasound interpretation. To the authors' bestknowledge, this study is the first to characterize the influence ofself-supervised pretraining for M-mode ultrasound.", "output": "Exploring the Utility of Self-Supervised Pretraining Strategies for the Detection of Absent Lung Sliding in M-Mode Lung Ultrasound."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Accurate medical imaging segmentation is critical for precise and effectivemedical interventions. However, despite the success of convolutional neuralnetworks (CNNs) in medical image segmentation, they still face challenges inhandling fine-scale features and variations in image scales. These challengesare particularly evident in complex and challenging segmentation tasks, such asthe BraTS multi-label brain tumor segmentation challenge. In this task,accurately segmenting the various tumor sub-components, which varysignificantly in size and shape, remains a significant challenge, with evenstate-of-the-art methods producing substantial errors. Therefore, we proposetwo architectures, FMG-Net and W-Net, that incorporate the principles ofgeometric multigrid methods for solving linear systems of equations into CNNsto address these challenges. Our experiments on the BraTS 2020 datasetdemonstrate that both FMG-Net and W-Net outperform the widely used U-Netarchitecture regarding tumor subcomponent segmentation accuracy and trainingefficiency. These findings highlight the potential of incorporating theprinciples of multigrid methods into CNNs to improve the accuracy andefficiency of medical imaging segmentation.", "output": "FMG-Net and W-Net: Multigrid Inspired Deep Learning Architectures For Medical Imaging Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Combining a set of phylogenetic trees into a single phylogenetic network thatexplains all of them is a fundamental challenge in evolutionary studies.Existing methods are computationally expensive and can either handle only smallnumbers of phylogenetic trees or are limited to severely restricted classes ofnetworks. In this paper, we apply the recently-introduced theoretical frameworkof cherry picking to design a class of efficient heuristics that are guaranteedto produce a network containing each of the input trees, for datasetsconsisting of binary trees. Some of the heuristics in this framework are basedon the design and training of a machine learning model that captures essentialinformation on the structure of the input trees and guides the algorithmstowards better solutions. We also propose simple and fast randomised heuristicsthat prove to be very effective when run multiple times.Unlike the existing exact methods, our heuristics are applicable to datasetsof practical size, and the experimental study we conducted on both simulatedand real data shows that these solutions are qualitatively good, always withinsome small constant factor from the optimum. Moreover, our machine-learnedheuristics are one of the first applications of machine learning tophylogenetics and show its promise.", "output": "Constructing Phylogenetic Networks via Cherry Picking and Machine Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Modern end-to-end learning systems can learn to explicitly infer control fromperception. However, it is difficult to guarantee stability and robustness forthese systems since they are often exposed to unstructured, high-dimensional,and complex observation spaces (e.g., autonomous driving from a stream of pixelinputs). We propose to leverage control Lyapunov functions (CLFs) to equipend-to-end vision-based policies with stability properties and introducestability attention in CLFs (att-CLFs) to tackle environmental changes andimprove learning flexibility. We also present an uncertainty propagationtechnique that is tightly integrated into att-CLFs. We demonstrate theeffectiveness of att-CLFs via comparison with classical CLFs, model predictivecontrol, and vanilla end-to-end learning in a photo-realistic simulator and ona real full-scale autonomous vehicle.", "output": "Learning Stability Attention in Vision-based End-to-end Driving Policies."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper investigates the potential of semi-supervised GenerativeAdversarial Networks (GANs) to fine-tune pretrained language models in order toclassify Bengali fake reviews from real reviews with a few annotated data. Withthe rise of social media and e-commerce, the ability to detect fake ordeceptive reviews is becoming increasingly important in order to protectconsumers from being misled by false information. Any machine learning modelwill have trouble identifying a fake review, especially for a low resourcelanguage like Bengali. We have demonstrated that the proposed semi-supervisedGAN-LM architecture (generative adversarial network on top of a pretrainedlanguage model) is a viable solution in classifying Bengali fake reviews as theexperimental results suggest that even with only 1024 annotated samples,BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% anda f1-score of 84.89% outperforming other pretrained language models -BanglaBERT generator, Bangla BERT Base and Bangla-Electra by almost 3%, 4% and10% respectively in terms of accuracy. The experiments were conducted on amanually labeled food review dataset consisting of total 6014 real and fakereviews collected from various social media groups. Researchers that areexperiencing difficulty recognizing not just fake reviews but otherclassification issues owing to a lack of labeled data may find a solution inour proposed methodology.", "output": "Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural network models of language have long been used as a tool fordeveloping hypotheses about conceptual representation in the mind and brain.For many years, such use involved extracting vector-space representations ofwords and using distances among these to predict or understand human behaviorin various semantic tasks. In contemporary language AIs, however, it ispossible to interrogate the latent structure of conceptual representationsusing methods nearly identical to those commonly used with human participants.The current work uses two common techniques borrowed from cognitive psychologyto estimate and compare lexical-semantic structure in both humans and awell-known AI, the DaVinci variant of GPT-3. In humans, we show that conceptualstructure is robust to differences in culture, language, and method ofestimation. Structures estimated from AI behavior, while individually fairlyconsistent with those estimated from human behavior, depend much more upon theparticular task used to generate behavior responses--responses generated by thevery same model in the two tasks yield estimates of conceptual structure thatcohere less with one another than do human structure estimates. The resultssuggest one important way that knowledge inhering in contemporary AIs candiffer from human cognition.", "output": "Behavioral estimates of conceptual structure are robust across tasks in humans but not large language models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We show that hybrid zonotopes offer an equivalent representation offeed-forward fully connected neural networks with ReLU activation functions.Our approach demonstrates that the complexity of binary variables is equal tothe total number of neurons in the network and hence grows linearly in the sizeof the network. We demonstrate the utility of the hybrid zonotope formulationthrough three case studies including nonlinear function approximation, MPCclosed-loop reachability and verification, and robustness of classification onthe MNIST dataset.", "output": "Hybrid Zonotopes Exactly Represent ReLU Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Methane (CH$_4$) is the chief contributor to global climate change. RecentAirborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) hasbeen very useful in quantitative mapping of methane emissions. Existing methodsfor analyzing this data are sensitive to local terrain conditions, oftenrequire manual inspection from domain experts, prone to significant error andhence are not scalable. To address these challenges, we propose a novelend-to-end spectral absorption wavelength aware transformer network,MethaneMapper, to detect and quantify the emissions. MethaneMapper introducestwo novel modules that help to locate the most relevant methane plume regionsin the spectral domain and uses them to localize these accurately. Thoroughevaluation shows that MethaneMapper achieves 0.63 mAP in detection and reducesthe model size (by 5x) compared to the current state of the art. In addition,we also introduce a large-scale dataset of methane plume segmentation mask forover 1200 AVIRIS-NG flight lines from 2015-2022. It contains over 4000 methaneplume sites. Our dataset will provide researchers the opportunity to developand advance new methods for tackling this challenging green-house gas detectionproblem with significant broader social impact. Dataset and source code arepublic", "output": "MethaneMapper: Spectral Absorption aware Hyperspectral Transformer for Methane Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The combined growth of available data and their unstructured nature hasreceived increased interest in natural language processing (NLP) techniques tomake value of these data assets since this format is not suitable forstatistical analysis. This work presents a systematic literature review ofstate-of-the-art advances using transformer-based methods on electronic medicalrecords (EMRs) in different NLP tasks. To the best of our knowledge, this workis unique in providing a comprehensive review of research on transformer-basedmethods for NLP applied to the EMR field. In the initial query, 99 articleswere selected from three public databases and filtered into 65 articles fordetailed analysis. The papers were analyzed with respect to the businessproblem, NLP task, models and techniques, availability of datasets,reproducibility of modeling, language, and exchange format. The paper presentssome limitations of current research and some recommendations for furtherresearch.", "output": "Application of Transformers based methods in Electronic Medical Records: A Systematic Literature Review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Liver transplantation is a life-saving procedure for patients with end-stageliver disease. There are two main challenges in liver transplant: finding thebest matching patient for a donor and ensuring transplant equity amongdifferent subpopulations. The current MELD scoring system evaluates a patient'smortality risk if not receiving an organ within 90 days. However, thedonor-patient matching should also take into consideration post-transplant riskfactors, such as cardiovascular disease, chronic rejection, etc., which are allcommon complications after transplant. Accurate prediction of these risk scoresremains a significant challenge. In this study, we will use predictive modelsto solve the above challenge. We propose a deep learning framework model topredict multiple risk factors after a liver transplant. By formulating it as amulti-task learning problem, the proposed deep neural network was trained onthis data to simultaneously predict the five post-transplant risks and achieveequally good performance by leveraging task balancing techniques. We alsopropose a novel fairness achieving algorithm and to ensure prediction fairnessacross different subpopulations. We used electronic health records of 160,360liver transplant patients, including demographic information, clinicalvariables, and laboratory values, collected from the liver transplant recordsof the United States from 1987 to 2018. The performance of the model wasevaluated using various performance metrics such as AUROC, AURPC, and accuracy.The results of our experiments demonstrate that the proposed multitaskprediction model achieved high accuracy and good balance in predicting all fivepost-transplant risk factors, with a maximum accuracy discrepancy of only 2.7%.The fairness-achieving algorithm significantly reduced the fairness disparitycompared to the baseline model.", "output": "A Transformer-Based Deep Learning Approach for Fairly Predicting Post-Liver Transplant Risk Factors."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The backdoor attack, where the adversary uses inputs stamped with triggers(e.g., a patch) to activate pre-planted malicious behaviors, is a severe threatto Deep Neural Network (DNN) models. Trigger inversion is an effective way ofidentifying backdoor models and understanding embedded adversarial behaviors. Achallenge of trigger inversion is that there are many ways of constructing thetrigger. Existing methods cannot generalize to various types of triggers bymaking certain assumptions or attack-specific constraints. The fundamentalreason is that existing work does not consider the trigger's design space intheir formulation of the inversion problem. This work formally defines andanalyzes the triggers injected in different spaces and the inversion problem.Then, it proposes a unified framework to invert backdoor triggers based on theformalization of triggers and the identified inner behaviors of backdoor modelsfrom our analysis. Our prototype UNICORN is general and effective in invertingbackdoor triggers in DNNs. The code can be found at", "output": "UNICORN: A Unified Backdoor Trigger Inversion Framework."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While neural networks are capable of achieving human-like performance in manytasks such as image classification, the impressive performance of each model islimited to its own dataset. Source-free domain adaptation (SFDA) was introducedto address knowledge transfer between different domains in the absence ofsource data, thus, increasing data privacy. Diversity in representation spacecan be vital to a model`s adaptability in varied and difficult domains. Inunsupervised SFDA, the diversity is limited to learning a single hypothesis onthe source or learning multiple hypotheses with a shared feature extractor.Motivated by the improved predictive performance of ensembles, we propose anovel unsupervised SFDA algorithm that promotes representational diversitythrough the use of separate feature extractors with Distinct BackboneArchitectures (DBA). Although diversity in feature space is increased, theunconstrained mutual information (MI) maximization may potentially introduceamplification of weak hypotheses. Thus we introduce the Weak HypothesisPenalization (WHP) regularizer as a mitigation strategy. Our work proposesPenalized Diversity (PD) where the synergy of DBA and WHP is applied tounsupervised source-free domain adaptation for covariate shift. In addition, PDis augmented with a weighted MI maximization objective for label distributionshift. Empirical results on natural, synthetic, and medical domains demonstratethe effectiveness of PD under different distributional shifts.", "output": "Source-free Domain Adaptation Requires Penalized Diversity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Graph neural networks (GNNs) have been widely applied to learning over graphdata. Yet, real-world graphs commonly exhibit diverse graph structures andcontain heterogeneous nodes and edges. Moreover, to enhance the generalizationability of GNNs, it has become common practice to further increase thediversity of training graph structures by incorporating graph augmentationsand/or performing large-scale pre-training on more graphs. Therefore, itbecomes essential for a GNN to simultaneously model diverse graph structures.Yet, naively increasing the GNN model capacity will suffer from both higherinference costs and the notorious trainability issue of GNNs. This paperintroduces the Mixture-of-Expert (MoE) idea to GNNs, aiming to enhance theirability to accommodate the diversity of training graph structures, withoutincurring computational overheads. Our new Graph Mixture of Expert (GMoE) modelenables each node in the graph to dynamically select its own optimaltextit{information aggregation experts}. These experts are trained to modeldifferent subgroups of graph structures in the training set. Additionally, GMoEincludes information aggregation experts with varying aggregation hop sizes,where the experts with larger hop sizes are specialized in capturinginformation over longer ranges. The effectiveness of GMoE is verified throughexperimental results on a large variety of graph, node, and link predictiontasks in the OGB benchmark. For instance, it enhances ROC-AUC by $1.81%$ inogbg-molhiv and by $1.40%$ in ogbg-molbbbp, as compared to the non-MoEbaselines. Our code is available at", "output": "Graph Mixture of Experts: Learning on Large-Scale Graphs with Explicit Diversity Modeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Due to the complex behavior arising from non-uniqueness, symmetry, andbifurcations in the solution space, solving inverse problems of nonlineardifferential equations (DEs) with multiple solutions is a challenging task. Toaddress this issue, we propose homotopy physics-informed neural networks(HomPINNs), a novel framework that leverages homotopy continuation and neuralnetworks (NNs) to solve inverse problems. The proposed framework begins withthe use of a NN to simultaneously approximate known observations and conform tothe constraints of DEs. By utilizing the homotopy continuation method, theapproximation traces the observations to identify multiple solutions and solvethe inverse problem. The experiments involve testing the performance of theproposed method on one-dimensional DEs and applying it to solve atwo-dimensional Gray-Scott simulation. Our findings demonstrate that theproposed method is scalable and adaptable, providing an effective solution forsolving DEs with multiple solutions and unknown parameters. Moreover, it hassignificant potential for various applications in scientific computing, such asmodeling complex systems and solving inverse problems in physics, chemistry,biology, etc.", "output": "HomPINNs: homotopy physics-informed neural networks for solving the inverse problems of nonlinear differential equations with multiple solutions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Models of actual causality leverage domain knowledge to generate convincingdiagnoses of events that caused an outcome. It is promising to apply thesemodels to diagnose and repair run-time property violations in cyber-physicalsystems (CPS) with learning-enabled components (LEC). However, given the highdiversity and complexity of LECs, it is challenging to encode domain knowledge(e.g., the CPS dynamics) in a scalable actual causality model that couldgenerate useful repair suggestions. In this paper, we focus causal diagnosis onthe input/output behaviors of LECs. Specifically, we aim to identify whichsubset of I/O behaviors of the LEC is an actual cause for a property violation.An important by-product is a counterfactual version of the LEC that repairs therun-time property by fixing the identified problematic behaviors. Based on thisinsights, we design a two-step diagnostic pipeline: (1) construct andHalpern-Pearl causality model that reflects the dependency of property outcomeon the component's I/O behaviors, and (2) perform a search for an actual causeand corresponding repair on the model. We prove that our pipeline has thefollowing guarantee: if an actual cause is found, the system is guaranteed tobe repaired; otherwise, we have high probabilistic confidence that the LECunder analysis did not cause the property violation. We demonstrate that ourapproach successfully repairs learned controllers on a standard OpenAI Gymbenchmark.", "output": "Causal Repair of Learning-enabled Cyber-physical Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The rapid adoption of generative language models has brought aboutsubstantial advancements in digital communication, while simultaneously raisingconcerns regarding the potential misuse of AI-generated content. Althoughnumerous detection methods have been proposed to differentiate between AI andhuman-generated content, the fairness and robustness of these detectors remainunderexplored. In this study, we evaluate the performance of severalwidely-used GPT detectors using writing samples from native and non-nativeEnglish writers. Our findings reveal that these detectors consistentlymisclassify non-native English writing samples as AI-generated, whereas nativewriting samples are accurately identified. Furthermore, we demonstrate thatsimple prompting strategies can not only mitigate this bias but alsoeffectively bypass GPT detectors, suggesting that GPT detectors mayunintentionally penalize writers with constrained linguistic expressions. Ourresults call for a broader conversation about the ethical implications ofdeploying ChatGPT content detectors and caution against their use in evaluativeor educational settings, particularly when they may inadvertently penalize orexclude non-native English speakers from the global discourse.", "output": "GPT detectors are biased against non-native English writers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Continuous Integration (CI) has become a well-established softwaredevelopment practice for automatically and continuously integrating codechanges during software development. An increasing number of Machine Learning(ML) based approaches for automation of CI phases are being reported in theliterature. It is timely and relevant to provide a Systemization of Knowledge(SoK) of ML-based approaches for CI phases. This paper reports an SoK ofdifferent aspects of the use of ML for CI. Our systematic analysis alsohighlights the deficiencies of the existing ML-based solutions that can beimproved for advancing the state-of-the-art.", "output": "SoK: Machine Learning for Continuous Integration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the traditional vehicular network, computing tasks generated by thevehicles are usually uploaded to the cloud for processing. However, since taskoffloading toward the cloud will cause a large delay, vehicular edge computing(VEC) is introduced to avoid such a problem and improve the whole systemperformance, where a roadside unit (RSU) with certain computing capability isused to process the data of vehicles as an edge entity. Owing to the privacyand security issues, vehicles are reluctant to upload local data directly tothe RSU, and thus federated learning (FL) becomes a promising technology forsome machine learning tasks in VEC, where vehicles only need to upload thelocal model hyperparameters instead of transferring their local data to thenearby RSU. Furthermore, as vehicles have different local training time due tovarious sizes of local data and their different computing capabilities,asynchronous federated learning (AFL) is employed to facilitate the RSU toupdate the global model immediately after receiving a local model to reduce theaggregation delay. However, in AFL of VEC, different vehicles may havedifferent impact on the global model updating because of their various localtraining delay, transmission delay and local data sizes. Also, if there are badnodes among the vehicles, it will affect the global aggregation quality at theRSU. To solve the above problem, we shall propose a deep reinforcement learning(DRL) based vehicle selection scheme to improve the accuracy of the globalmodel in AFL of vehicular network. In the scheme, we present the modelincluding the state, action and reward in the DRL based to the specificproblem. Simulation results demonstrate our scheme can effectively remove thebad nodes and improve the aggregation accuracy of the global model.", "output": "Deep Reinforcement Learning Based Vehicle Selection for Asynchronous Federated Learning Enabled Vehicular Edge Computing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We analyze the data-dependent capacity of neural networks and assessanomalies in inputs from the perspective of networks during inference. Thenotion of data-dependent capacity allows for analyzing the knowledge base of amodel populated by learned features from training data. We define purview asthe additional capacity necessary to characterize inference samples that differfrom the training data. To probe the purview of a network, we utilize gradientsto measure the amount of change required for the model to characterize thegiven inputs more accurately. To eliminate the dependency on ground-truthlabels in generating gradients, we introduce confounding labels that areformulated by combining multiple categorical labels. We demonstrate that ourgradient-based approach can effectively differentiate inputs that cannot beaccurately represented with learned features. We utilize our approach inapplications of detecting anomalous inputs, including out-of-distribution,adversarial, and corrupted samples. Our approach requires no hyperparametertuning or additional data processing and outperforms state-of-the-art methodsby up to 2.7%, 19.8%, and 35.6% of AUROC scores, respectively.", "output": "Probing the Purview of Neural Networks via Gradient Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the greater emphasis on privacy and security in our society, the problemof graph unlearning -- revoking the influence of specific data on the trainedGNN model, is drawing increasing attention. However, ranging from machineunlearning to recently emerged graph unlearning methods, existing effortseither resort to retraining paradigm, or perform approximate erasure that failsto consider the inter-dependency between connected neighbors or imposesconstraints on GNN structure, therefore hard to achieve satisfyingperformance-complexity trade-offs.In this work, we explore the influence function tailored for graphunlearning, so as to improve the unlearning efficacy and efficiency for graphunlearning. We first present a unified problem formulation of diverse graphunlearning tasks wrt node, edge, and feature. Then, we recognize the crux tothe inability of traditional influence function for graph unlearning, anddevise Graph Influence Function (GIF), a model-agnostic unlearning method thatcan efficiently and accurately estimate parameter changes in response to a$epsilon$-mass perturbation in deleted data. The idea is to supplement theobjective of the traditional influence function with an additional loss term ofthe influenced neighbors due to the structural dependency. Further deductionson the closed-form solution of parameter changes provide a better understandingof the unlearning mechanism. We conduct extensive experiments on fourrepresentative GNN models and three benchmark datasets to justify thesuperiority of GIF for diverse graph unlearning tasks in terms of unlearningefficacy, model utility, and unlearning efficiency. Our implementations areavailable at url{", "output": "GIF: A General Graph Unlearning Strategy via Influence Function."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The accuracy of predictive models for solitary pulmonary nodule (SPN)diagnosis can be greatly increased by incorporating repeat imaging and medicalcontext, such as electronic health records (EHRs). However, clinically routinemodalities such as imaging and diagnostic codes can be asynchronous andirregularly sampled over different time scales which are obstacles tolongitudinal multimodal learning. In this work, we propose a transformer-basedmultimodal strategy to integrate repeat imaging with longitudinal clinicalsignatures from routinely collected EHRs for SPN classification. We performunsupervised disentanglement of latent clinical signatures and leveragetime-distance scaled self-attention to jointly learn from clinical signaturesexpressions and chest computed tomography (CT) scans. Our classifier ispretrained on 2,668 scans from a public dataset and 1,149 subjects withlongitudinal chest CTs, billing codes, medications, and laboratory tests fromEHRs of our home institution. Evaluation on 227 subjects with challenging SPNsrevealed a significant AUC improvement over a longitudinal multimodal baseline(0.824 vs 0.752 AUC), as well as improvements over a single cross-sectionmultimodal scenario (0.809 AUC) and a longitudinal imaging-only scenario (0.741AUC). This work demonstrates significant advantages with a novel approach forco-learning longitudinal imaging and non-imaging phenotypes with transformers.", "output": "Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures From Routine EHRs for Pulmonary Nodule Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "APT detection is difficult to detect due to the long-term latency, covert andslow multistage attack patterns of Advanced Persistent Threat (APT). To tacklethese issues, we propose TBDetector, a transformer-based advanced persistentthreat detection method for APT attack detection. Considering that provenancegraphs provide rich historical information and have the powerful attackshistoric correlation ability to identify anomalous activities, TBDetectoremploys provenance analysis for APT detection, which summarizes long-runningsystem execution with space efficiency and utilizes transformer withself-attention based encoder-decoder to extract long-term contextual featuresof system states to detect slow-acting attacks. Furthermore, we furtherintroduce anomaly scores to investigate the anomaly of different system states,where each state is calculated with an anomaly score corresponding to itssimilarity score and isolation score. To evaluate the effectiveness of theproposed method, we have conducted experiments on five public datasets, i.e.,streamspot, cadets, shellshock, clearscope, and wget_baseline. Experimentalresults and comparisons with state-of-the-art methods have exhibited betterperformance of our proposed method.", "output": "TBDetector:Transformer-Based Detector for Advanced Persistent Threats with Provenance Graph."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pruning neural networks before training has received increasing interest dueto its potential to reduce training time and memory. One popular method is toprune the connections based on a certain metric, but it is not entirely clearwhat metric is the best choice. Recent advances in neural tangent kernel (NTK)theory suggest that the training dynamics of large enough neural networks isclosely related to the spectrum of the NTK. Motivated by this finding, wepropose to prune the connections that have the least influence on the spectrumof the NTK. This method can help maintain the NTK spectrum, which may helpalign the training dynamics to that of its dense counterpart. However, onepossible issue is that the fixed-weight-NTK corresponding to a given initialpoint can be very different from the NTK corresponding to later iterates duringthe training phase. We further propose to sample multiple realizations ofrandom weights to estimate the NTK spectrum. Note that our approach isweight-agnostic, which is different from most existing methods that areweight-dependent. In addition, we use random inputs to compute thefixed-weight-NTK, making our method data-agnostic as well. We name ourforesight pruning algorithm Neural Tangent Kernel Spectrum-Aware Pruning(NTK-SAP). Empirically, our method achieves better performance than allbaselines on multiple datasets.", "output": "NTK-SAP: Improving neural network pruning by aligning training dynamics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural Architectures Search (NAS) becomes more and more popular over theseyears. However, NAS-generated models tends to suffer greater vulnerability tovarious malicious attacks. Lots of robust NAS methods leverage adversarialtraining to enhance the robustness of NAS-generated models, however, theyneglected the nature accuracy of NAS-generated models. In our paper, we proposea novel NAS method, Robust Neural Architecture Search (RNAS). To design aregularization term to balance accuracy and robustness, RNAS generatesarchitectures with both high accuracy and good robustness. To reduce searchcost, we further propose to use noise examples instead adversarial examples asinput to search architectures. Extensive experiments show that RNAS achievesstate-of-the-art (SOTA) performance on both image classification andadversarial attacks, which illustrates the proposed RNAS achieves a goodtradeoff between robustness and accuracy.", "output": "Robust Neural Architecture Search."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep networks have achieved impressive results on a range of well-curatedbenchmark datasets. Surprisingly, their performance remains sensitive toperturbations that have little effect on human performance. In this work, wepropose a novel extension of Mixup called Robustmix that regularizes networksto classify based on lower-frequency spatial features. We show that this typeof regularization improves robustness on a range of benchmarks such asImagenet-C and Stylized Imagenet. It adds little computational overhead and,furthermore, does not require a priori knowledge of a large set of imagetransformations. We find that this approach further complements recent advancesin model architecture and data augmentation, attaining a state-of-the-art mCEof 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of16 mCE compared to the baseline.", "output": "Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A natural way of estimating heteroscedastic label noise in regression is tomodel the observed (potentially noisy) target as a sample from a normaldistribution, whose parameters can be learned by minimizing the negativelog-likelihood. This loss has desirable loss attenuation properties, as it canreduce the contribution of high-error examples. Intuitively, this behavior canimprove robustness against label noise by reducing overfitting. We propose anextension of this simple and probabilistic approach to classification that hasthe same desirable loss attenuation properties. We evaluate the effectivenessof the method by measuring its robustness against label noise inclassification. We perform enlightening experiments exploring the innerworkings of the method, including sensitivity to hyperparameters, ablationstudies, and more.", "output": "Logistic-Normal Likelihoods for Heteroscedastic Label Noise in Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Class imbalance (CI) in classification problems arises when the number ofobservations belonging to one class is lower than the other classes. Ensemblelearning that combines multiple models to obtain a robust model has beenprominently used with data augmentation methods to address class imbalanceproblems. In the last decade, a number of strategies have been added to enhanceensemble learning and data augmentation methods, along with new methods such asgenerative adversarial networks (GANs). A combination of these has been appliedin many studies, but the true rank of different combinations would require acomputational review. In this paper, we present a computational review toevaluate data augmentation and ensemble learning methods used to addressprominent benchmark CI problems. We propose a general framework that evaluates10 data augmentation and 10 ensemble learning methods for CI problems. Ourobjective was to identify the most effective combination for improvingclassification performance on imbalanced datasets. The results indicate thatcombinations of data augmentation methods with ensemble learning cansignificantly improve classification performance on imbalanced datasets. Thesefindings have important implications for the development of more effectiveapproaches for handling imbalanced datasets in machine learning applications.", "output": "A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Meta-learning aims to solve unseen tasks with few labelled instances.Nevertheless, despite its effectiveness for quick learning in existingoptimization-based methods, it has several flaws. Inconsequential connectionsare frequently seen during meta-training, which results in anover-parameterized neural network. Because of this, meta-testing observesunnecessary computations and extra memory overhead. To overcome such flaws. Wepropose a novel meta-learning method called Meta-LTH that includesindispensible (necessary) connections. We applied the lottery ticket hypothesistechnique known as magnitude pruning to generate these crucial connections thatcan effectively solve few-shot learning problem. We aim to perform two things:(a) to find a sub-network capable of more adaptive meta-learning and (b) tolearn new low-level features of unseen tasks and recombine those features withthe already learned features during the meta-test phase. Experimental resultsshow that our proposed Met-LTH method outperformed existing first-order MAMLalgorithm for three different classification datasets. Our method improves theclassification accuracy by approximately 2% (20-way 1-shot task setting) foromniglot dataset.", "output": "Learning to Learn with Indispensable Connections."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large language models (LLMs) such as ChatGPT and GPT-4 have recentlydemonstrated their remarkable abilities of communicating with human users. Inthis technical report, we take an initiative to investigate their capacities ofplaying text games, in which a player has to understand the environment andrespond to situations by having dialogues with the game world. Our experimentsshow that ChatGPT performs competitively compared to all the existing systemsbut still exhibits a low level of intelligence. Precisely, ChatGPT can notconstruct the world model by playing the game or even reading the game manual;it may fail to leverage the world knowledge that it already has; it cannotinfer the goal of each step as the game progresses. Our results open up newresearch questions at the intersection of artificial intelligence, machinelearning, and natural language processing.", "output": "Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Companies that have an online presence-in particular, companies that areexclusively digital-often subscribe to this business model: collect data fromthe user base, then expose the data to advertisement agencies in order to turna profit. Such companies routinely market a service as \"free\", whileobfuscating the fact that they tend to \"charge\" users in the currency ofpersonal information rather than money. However, online companies also gatheruser data for more principled purposes, such as improving the user experienceand aggregating statistics. The problem is the sale of user data to thirdparties. In this work, we design an intelligent approach to online privacyprotection that leverages supervised learning. By detecting and blocking datacollection that might infringe on a user's privacy, we can restore a degree ofdigital privacy to the user. In our evaluation, we collect a dataset of networkrequests and measure the performance of several classifiers that adhere to thesupervised learning paradigm. The results of our evaluation demonstrate thefeasibility and potential of our approach.", "output": "Protecting User Privacy in Online Settings via Supervised Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Labeling issues with the skills required to complete them can helpcontributors to choose tasks in Open Source Software projects. However,manually labeling issues is time-consuming and error-prone, and currentautomated approaches are mostly limited to classifying issues as bugs/non-bugs.We investigate the feasibility and relevance of automatically labeling issueswith what we call \"API-domains,\" which are high-level categories of APIs.Therefore, we posit that the APIs used in the source code affected by an issuecan be a proxy for the type of skills (e.g., DB, security, UI) needed to workon the issue. We ran a user study (n=74) to assess API-domain labels' relevancyto potential contributors, leveraged the issues' descriptions and the projecthistory to build prediction models, and validated the predictions withcontributors (n=20) of the projects. Our results show that (i) newcomers to theproject consider API-domain labels useful in choosing tasks, (ii) labels can bepredicted with a precision of 84% and a recall of 78.6% on average, (iii) theresults of the predictions reached up to 71.3% in precision and 52.5% in recallwhen training with a project and testing in another (transfer learning), and(iv) project contributors consider most of the predictions helpful inidentifying needed skills. These findings suggest our approach can be appliedin practice to automatically label issues, assisting developers in findingtasks that better match their skills.", "output": "Tag that issue: Applying API-domain labels in issue tracking systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The amount of sequencing data for SARS-CoV-2 is several orders of magnitudelarger than any virus. This will continue to grow geometrically for SARS-CoV-2,and other viruses, as many countries heavily finance genomic surveillanceefforts. Hence, we need methods for processing large amounts of sequence datato allow for effective yet timely decision-making. Such data will come fromheterogeneous sources: aligned, unaligned, or even unassembled raw nucleotideor amino acid sequencing reads pertaining to the whole genome or regions (e.g.,spike) of interest. In this work, we propose emph{ViralVectors}, a compactfeature vector generation from virome sequencing data that allows effectivedownstream analysis. Such generation is based on emph{minimizers}, a type oflightweight \"signature\" of a sequence, used traditionally in assembly and readmapping -- to our knowledge, the first use minimizers in this way. We validateour approach on different types of sequencing data: (a) 2.5M SARS-CoV-2 spikesequences (to show scalability); (b) 3K Coronaviridae spike sequences (to showrobustness to more genomic variability); and (c) 4K raw WGS reads sets takenfrom nasal-swab PCR tests (to show the ability to process unassembled reads).Our results show that ViralVectors outperforms current benchmarks in mostclassification and clustering tasks.", "output": "ViralVectors: Compact and Scalable Alignment-free Virome Feature Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated learning (FL) is a distributed framework for collaborativelytraining with privacy guarantees. In real-world scenarios, clients may haveNon-IID data (local class imbalance) with poor annotation quality (labelnoise). The co-existence of label noise and class imbalance in FL's small localdatasets renders conventional FL methods and noisy-label learning methods bothineffective. To address the challenges, we propose FedCNI without using anadditional clean proxy dataset. It includes a noise-resilient local solver anda robust global aggregator. For the local solver, we design a more robustprototypical noise detector to distinguish noisy samples. Further to reduce thenegative impact brought by the noisy samples, we devise a curriculum pseudolabeling method and a denoise Mixup training strategy. For the globalaggregator, we propose a switching re-weighted aggregation method tailored todifferent learning periods. Extensive experiments demonstrate our method cansubstantially outperform state-of-the-art solutions in mix-heterogeneous FLenvironments.", "output": "Learning Cautiously in Federated Learning with Noisy and Heterogeneous Clients."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We focus on the task of language-conditioned object placement, in which arobot should generate placements that satisfy all the spatial relationalconstraints in language instructions. Previous works based on rule-basedlanguage parsing or scene-centric visual representation have restrictions onthe form of instructions and reference objects or require large amounts oftraining data. We propose an object-centric framework that leverages foundationmodels to ground the reference objects and spatial relations for placement,which is more sample efficient and generalizable. Experiments indicate that ourmodel can achieve a 97.75% success rate of placement with only ~0.26M trainableparameters. Besides, our method generalizes better to both unseen objects andinstructions. Moreover, with only 25% training data, we still outperform thetop competing approach.", "output": "Object-centric Inference for Language Conditioned Placement: A Foundation Model based Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Subset weighted-Tempered Gibbs Sampler (wTGS) has been recently introduced byJankowiak to reduce the computation complexity per MCMC iteration inhigh-dimensional applications where the exact calculation of the posteriorinclusion probabilities (PIP) is not essential. However, the Rao-Backwellizedestimator associated with this sampler has a high variance as the ratio betweenthe signal dimension and the number of conditional PIP estimations is large. Inthis paper, we design a new subset weighted-Tempered Gibbs Sampler (wTGS) wherethe expected number of computations of conditional PIPs per MCMC iteration canbe much smaller than the signal dimension. Different from the subset wTGS andwTGS, our sampler has a variable complexity per MCMC iteration. We provide anupper bound on the variance of an associated Rao-Blackwellized estimator forthis sampler at a finite number of iterations, $T$, and show that the varianceis $Obig(big(frac{P}{S}big)^2 frac{log T}{T}big)$ for a given datasetwhere $S$ is the expected number of conditional PIP computations per MCMCiteration. Experiments show that our Rao-Blackwellized estimator can have asmaller variance than its counterpart associated with the subset wTGS.", "output": "Variable-Complexity Weighted-Tempered Gibbs Samplers for Bayesian Variable Selection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Bayesian inference in deep neural networks is challenging due to thehigh-dimensional, strongly multi-modal parameter posterior density landscape.Markov chain Monte Carlo approaches asymptotically recover the true posteriorbut are considered prohibitively expensive for large modern architectures.Local methods, which have emerged as a popular alternative, focus on specificparameter regions that can be approximated by functions with tractableintegrals. While these often yield satisfactory empirical results, they fail,by definition, to account for the multi-modality of the parameter posterior. Inthis work, we argue that the dilemma between exact-but-unaffordable andcheap-but-inexact approaches can be mitigated by exploiting symmetries in theposterior landscape. Such symmetries, induced by neuron interchangeability andcertain activation functions, manifest in different parameter values leading tothe same functional output value. We show theoretically that the posteriorpredictive density in Bayesian neural networks can be restricted to asymmetry-free parameter reference set. By further deriving an upper bound onthe number of Monte Carlo chains required to capture the functional diversity,we propose a straightforward approach for feasible Bayesian inference. Ourexperiments suggest that efficient sampling is indeed possible, opening up apromising path to accurate uncertainty quantification in deep learning.", "output": "Towards Efficient MCMC Sampling in Bayesian Neural Networks by Exploiting Symmetry."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Unraveling the reasons behind the remarkable success and exceptionalgeneralization capabilities of deep neural networks presents a formidablechallenge. Recent insights from random matrix theory, specifically thoseconcerning the spectral analysis of weight matrices in deep neural networks,offer valuable clues to address this issue. A key finding indicates that thegeneralization performance of a neural network is associated with the degree ofheavy tails in the spectrum of its weight matrices. To capitalize on thisdiscovery, we introduce a novel regularization technique, termed Heavy-TailedRegularization, which explicitly promotes a more heavy-tailed spectrum in theweight matrix through regularization. Firstly, we employ the Weighted Alpha andStable Rank as penalty terms, both of which are differentiable, enabling thedirect calculation of their gradients. To circumvent over-regularization, weintroduce two variations of the penalty function. Then, adopting a Bayesianstatistics perspective and leveraging knowledge from random matrices, wedevelop two novel heavy-tailed regularization methods, utilizing Powerlawdistribution and Frechet distribution as priors for the global spectrum andmaximum eigenvalues, respectively. We empirically show that heavytailedregularization outperforms conventional regularization techniques in terms ofgeneralization performance.", "output": "Heavy-Tailed Regularization of Weight Matrices in Deep Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We characterise the learning of a mixture of two clouds of data points withgeneric centroids via empirical risk minimisation in the high dimensionalregime, under the assumptions of generic convex loss and convex regularisation.Each cloud of data points is obtained by sampling from a possibly uncountablesuperposition of Gaussian distributions, whose variance has a genericprobability density $varrho$. Our analysis covers therefore a large family ofdata distributions, including the case of power-law-tailed distributions withno covariance. We study the generalisation performance of the obtainedestimator, we analyse the role of regularisation, and the dependence of theseparability transition on the distribution scale parameters.", "output": "Classification of Superstatistical Features in High Dimensions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automated audio captioning is multi-modal translation task that aim togenerate textual descriptions for a given audio clip. In this paper we proposea full Transformer architecture that utilizes Patchout as proposed in [1],significantly reducing the computational complexity and avoiding overfitting.The caption generation is partly conditioned on textual AudioSet tags extractedby a pre-trained classification model which is fine-tuned to maximize thesemantic similarity between AudioSet labels and ground truth captions. Tomitigate the data scarcity problem of Automated Audio Captioning we introducetransfer learning from an upstream audio-related task and an enlarged in-domaindataset. Moreover, we propose a method to apply Mixup augmentation for AAC.Ablation studies are carried out to investigate how Patchout and text guidancecontribute to the final performance. The results show that the proposedtechniques improve the performance of our system and while reducing thecomputational complexity. Our proposed method received the Judges Award at theTask6A of DCASE Challenge 2022.", "output": "Efficient Audio Captioning Transformer with Patchout and Text Guidance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Face masks are recommended to reduce the transmission of many viruses,especially SARS-CoV-2. Therefore, the automatic detection of whether there is amask on the face, what type of mask is worn, and how it is worn is an importantresearch topic. In this work, the use of thermal imaging was considered toanalyze the possibility of detecting (localizing) a mask on the face, as wellas to check whether it is possible to classify the type of mask on the face.The previously proposed dataset of thermal images was extended and annotatedwith the description of a type of mask and a location of a mask within a face.Different deep learning models were adapted. The best model for face maskdetection turned out to be the Yolov5 model in the \"nano\" version, reaching mAPhigher than 97% and precision of about 95%. High accuracy was also obtained formask type classification. The best results were obtained for the convolutionalneural network model built on an autoencoder initially trained in the thermalimage reconstruction problem. The pretrained encoder was used to train aclassifier which achieved an accuracy of 91%.", "output": "Mask Detection and Classification in Thermal Face Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Flexible road pavements deteriorate primarily due to traffic and adverseenvironmental conditions. Cracking is the most common deterioration mechanism;the surveying thereof is typically conducted manually using internationallydefined classification standards. In South Africa, the use of high-definitionvideo images has been introduced, which allows for safer road surveying.However, surveying is still a tedious manual process. Automation of thedetection of defects such as cracks would allow for faster analysis of roadnetworks and potentially reduce human bias and error. This study performs acomparison of six state-of-the-art convolutional neural network models for thepurpose of crack detection. The models are pretrained on the ImageNet dataset,and fine-tuned using a new real-world binary crack dataset consisting of 14000samples. The effects of dataset augmentation are also investigated. Of the sixmodels trained, five achieved accuracy above 97%. The highest recorded accuracywas 98%, achieved by the ResNet and VGG16 models. The dataset is available atthe following URL: ", "output": "Convolutional neural networks for crack detection on flexible road pavements."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents the Real-time Adaptive and Interpretable Detection (RAID)algorithm. The novel approach addresses the limitations of state-of-the-artanomaly detection methods for multivariate dynamic processes, which arerestricted to detecting anomalies within the scope of the model trainingconditions. The RAID algorithm adapts to non-stationary effects such as datadrift and change points that may not be accounted for during model development,resulting in prolonged service life. A dynamic model based on joint probabilitydistribution handles anomalous behavior detection in a system and the rootcause isolation based on adaptive process limits. RAID algorithm does notrequire changes to existing process automation infrastructures, making ithighly deployable across different domains. Two case studies involving realdynamic system data demonstrate the benefits of the RAID algorithm, includingchange point adaptation, root cause isolation, and improved detection accuracy.", "output": "Adaptable and Interpretable Framework for Novelty Detection in Real-Time IoT Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present FengWu, an advanced data-driven global medium-range weatherforecast system based on Artificial Intelligence (AI). Different from existingdata-driven weather forecast methods, FengWu solves the medium-range forecastproblem from a multi-modal and multi-task perspective. Specifically, a deeplearning architecture equipped with model-specific encoder-decoders andcross-modal fusion Transformer is elaborately designed, which is learned underthe supervision of an uncertainty loss to balance the optimization of differentpredictors in a region-adaptive manner. Besides this, a replay buffer mechanismis introduced to improve medium-range forecast performance. With 39-year datatraining based on the ERA5 reanalysis, FengWu is able to accurately reproducethe atmospheric dynamics and predict the future land and atmosphere states at37 vertical levels on a 0.25{deg} latitude-longitude resolution. Hindcasts of6-hourly weather in 2018 based on ERA5 demonstrate that FengWu performs betterthan GraphCast in predicting 80% of the 880 reported predictands, e.g.,reducing the root mean square error (RMSE) of 10-day lead global z500prediction from 733 to 651 $m^{2}/s^2$. In addition, the inference cost of eachiteration is merely 600ms on NVIDIA Tesla A100 hardware. The results suggestthat FengWu can significantly improve the forecast skill and extend theskillful global medium-range weather forecast out to 10.75 days lead (with ACCof z500 &gt; 0.6) for the first time.", "output": "FengWu: Pushing the Skillful Global Medium-range Weather Forecast beyond 10 Days Lead."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While machine learning has become pervasive in as diversified fields asindustry, healthcare, social networks, privacy concerns regarding the trainingdata have gained a critical importance. In settings where several parties wishto collaboratively train a common model without jeopardizing their sensitivedata, the need for a private training protocol is particularly stringent andimplies to protect the data against both the model's end-users and the actorsof the training phase. Differential privacy (DP) and cryptographic primitivesare complementary popular countermeasures against privacy attacks. Among thesecryptographic primitives, fully homomorphic encryption (FHE) offers ciphertextmalleability at the cost of time-consuming operations in the homomorphicdomain. In this paper, we design SHIELD, a probabilistic approximationalgorithm for the argmax operator which is both fast when homomorphicallyexecuted and whose inaccuracy is used as a feature to ensure DP guarantees.Even if SHIELD could have other applications, we here focus on one setting andseamlessly integrate it in the SPEED collaborative training framework from\"SPEED: Secure, PrivatE, and Efficient Deep learning\" (Grivet S'ebert et al.,2021) to improve its computational efficiency. After thoroughly describing theFHE implementation of our algorithm and its DP analysis, we presentexperimental results. To the best of our knowledge, it is the first work inwhich relaxing the accuracy of an homomorphic calculation is constructivelyusable as a degree of freedom to achieve better FHE performances.", "output": "When approximate design for fast homomorphic computation provides differential privacy guarantees."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Contrastive learning has emerged as an essential approach for self-supervisedlearning in computer vision. The central objective of contrastive learning isto maximize the similarities between two augmented versions of the same image(positive pairs), while minimizing the similarities between different images(negative pairs). Recent studies have demonstrated that harder negativesamples, i.e., those that are difficult to distinguish from anchor sample, playa more critical role in contrastive learning. In this paper, we propose a novelfeaturelevel method, namely sampling synthetic hard negative samples forcontrastive learning (SSCL), to exploit harder negative samples moreeffectively. Specifically, 1) we generate more and harder negative samples bymixing negative samples, and then sample them by controlling the contrast ofanchor sample with the other negative samples. 2) Considering that the negativesamples obtained by sampling may have the problem of false negative samples, wefurther debias the negative samples. Our proposed method improves theclassification performance on different image datasets and can be readilyapplied to existing methods.", "output": "Synthetic Hard Negative Samples for Contrastive Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural networks are usually trained with different variants of gradientdescent based optimization algorithms such as stochastic gradient descent orthe Adam optimizer. Recent theoretical work states that the critical points(where the gradient of the loss is zero) of two-layer ReLU networks with thesquare loss are not all local minima. However, in this work we will explore analgorithm for training two-layer neural networks with ReLU-like activation andthe square loss that alternatively finds the critical points of the lossfunction analytically for one layer while keeping the other layer and theneuron activation pattern fixed. Experiments indicate that this simplealgorithm can find deeper optima than Stochastic Gradient Descent or the Adamoptimizer, obtaining significantly smaller training loss values on four out ofthe five real datasets evaluated. Moreover, the method is faster than thegradient descent methods and has virtually no tuning parameters.", "output": "Training a Two Layer ReLU Network Analytically."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The aim of this work is to investigate the use of IncrementallyInput-to-State Stable ($delta$ISS) deep Long Short Term Memory networks(LSTMs) for the identification of nonlinear dynamical systems. We show thatsuitable sufficient conditions on the weights of the network can be leveragedto setup a training procedure able to learn provenly-$delta$ISS LSTM modelsfrom data. The proposed approach is tested on a real brake-by-wire apparatus toidentify a model of the system from input-output experimentally collected data.Results show satisfactory modeling performances.", "output": "Deep Long-Short Term Memory networks: Stability properties and Experimental validation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we introduce and study a class of Deep Neural Networks (DNNs)in continuous-time. The proposed architecture stems from the combination ofNeural Ordinary Differential Equations (Neural ODEs) with the model structureof recently introduced Recurrent Equilibrium Networks (RENs). We show how toendow our proposed NodeRENs with contractivity and dissipativity -- crucialproperties for robust learning and control. Most importantly, as for RENs, wederive parametrizations of contractive and dissipative NodeRENs which areunconstrained, hence enabling their learning for a large number of parameters.We validate the properties of NodeRENs, including the possibility of handlingirregularly sampled data, in a case study in nonlinear system identification.", "output": "Unconstrained Parametrization of Dissipative and Contracting Neural Ordinary Differential Equations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Low-light images often suffer from severe noise, low brightness, lowcontrast, and color deviation. While several low-light image enhancementmethods have been proposed, there remains a lack of efficient methods that cansimultaneously solve all of these problems. In this paper, we introduceFLW-Net, a Fast and LightWeight Network for low-light image enhancement thatsignificantly improves processing speed and overall effect. To achieveefficient low-light image enhancement, we recognize the challenges of the lackof an absolute reference and the need for a large receptive field to obtainglobal contrast. Therefore, we propose an efficient global feature informationextraction component and design loss functions based on relative information toovercome these challenges. Finally, we conduct comparative experiments todemonstrate the effectiveness of the proposed method, and the results confirmthat FLW-Net can significantly reduce the complexity of supervised low-lightimage enhancement networks while improving processing effect. Code is availableat ", "output": "A Fast and Lightweight Network for Low-Light Image Enhancement."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The capability of doing effective forensic analysis on printed and scanned(PS) images is essential in many applications. PS documents may be used toconceal the artifacts of images which is due to the synthetic nature of imagessince these artifacts are typically present in manipulated images and the mainartifacts in the synthetic images can be removed after the PS. Due to theappeal of Generative Adversarial Networks (GANs), synthetic face imagesgenerated with GANs models are difficult to differentiate from genuine humanfaces and may be used to create counterfeit identities. Additionally, sinceGANs models do not account for physiological constraints for generating humanfaces and their impact on human IRISes, distinguishing genuine from syntheticIRISes in the PS scenario becomes extremely difficult. As a result of the lackof large-scale reference IRIS datasets in the PS scenario, we aim at developinga novel dataset to become a standard for Multimedia Forensics (MFs)investigation which is available at [45]. In this paper, we provide a noveldataset made up of a large number of synthetic and natural printed IRISes takenfrom VIPPrint Printed and Scanned face images. We extracted irises from faceimages and it is possible that the model due to eyelid occlusion captured theincomplete irises. To fill the missing pixels of extracted iris, we appliedtechniques to discover the complex link between the iris images. To highlightthe problems involved with the evaluation of the dataset's IRIS images, weconducted a large number of analyses employing Siamese Neural Networks toassess the similarities between genuine and synthetic human IRISes, such asResNet50, Xception, VGG16, and MobileNet-v2. For instance, using the Xceptionnetwork, we achieved 56.76% similarity of IRISes for synthetic images and92.77% similarity of IRISes for real images.", "output": "Spritz-PS: Validation of Synthetic Face Images Using a Large Dataset of Printed Documents."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "IoT devices are sorely underutilized in the medical field, especially withinmachine learning for medicine, yet they offer unrivaled benefits. IoT devicesare low-cost, energy-efficient, small and intelligent devices. In this paper,we propose a distributed federated learning framework for IoT devices, morespecifically for IoMT (Internet of Medical Things), using blockchain to allowfor a decentralized scheme improving privacy and efficiency over a centralizedsystem; this allows us to move from the cloud-based architectures, that areprevalent, to the edge. The system is designed for three paradigms: 1) Trainingneural networks on IoT devices to allow for collaborative training of a sharedmodel whilst decoupling the learning from the dataset to ensure privacy.Training is performed in an online manner simultaneously amongst allparticipants, allowing for the training of actual data that may not have beenpresent in a dataset collected in the traditional way and dynamically adapt thesystem whilst it is being trained. 2) Training of an IoMT system in a fullyprivate manner such as to mitigate the issue with confidentiality of medicaldata and to build robust, and potentially bespoke, models where not much, ifany, data exists. 3) Distribution of the actual network training, somethingfederated learning itself does not do, to allow hospitals, for example, toutilize their spare computing resources to train network models.", "output": "IoT Federated Blockchain Learning at the Edge."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Understanding customer lifetime value is key to nurturing long-term customerrelationships, however, estimating it is far from straightforward. In theretail banking industry, commonly used approaches rely on simple heuristics anddo not take advantage of the high predictive ability of modern machine learningtechniques. We present a general framework for modelling customer lifetimevalue which may be applied to industries with long-lasting contractual andproduct-centric customer relationships, of which retail banking is an example.This framework is novel in facilitating CLV predictions over arbitrary timehorizons and product-based propensity models. We also detail an implementationof this model which is currently in production at a large UK lender. Intesting, we estimate an 43% improvement in out-of-time CLV prediction errorrelative to a popular baseline approach. Propensity models derived from our CLVmodel have been used to support customer contact marketing campaigns. Intesting, we saw that the top 10% of customers ranked by their propensity totake up investment products were 3.2 times more likely to take up an investmentproduct in the next year than a customer chosen at random.", "output": "Modelling customer lifetime-value in the retail banking industry."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces an efficient multi-linear nonparametric (kernel-based)approximation framework for data regression and imputation, and its applicationto dynamic magnetic-resonance imaging (dMRI). Data features are assumed toreside in or close to a smooth manifold embedded in a reproducing kernelHilbert space. Landmark points are identified to describe concisely the pointcloud of features by linear approximating patches which mimic the concept oftangent spaces to smooth manifolds. The multi-linear model effectsdimensionality reduction, enables efficient computations, and extracts datapatterns and their geometry without any training data or additionalinformation. Numerical tests on dMRI data under severe under-samplingdemonstrate remarkable improvements in efficiency and accuracy of the proposedapproach over its predecessors, popular data modeling methods, as well asrecent tensor-based and deep-image-prior schemes.", "output": "Multi-Linear Kernel Regression and Imputation in Data Manifolds."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The aim of this study is to develop and apply an autonomous approach forpredicting the probability of hydrocarbon reservoirs spreading in the studiedarea. Autonomy means that after preparing and inputting geological-geophysicalinformation, the influence of an expert on the algorithms is minimized. Thestudy was made based on the 3D seismic survey data and well information on theearly exploration stage of the studied field. As a result, a forecast of theprobability of spatial distribution of reservoirs was made for two sets ofinput data: the base set and the set after reverse-calibration, andthree-dimensional cubes of calibrated probabilities of belonging of the studiedspace to the identified classes were obtained. The approach presented in thepaper allows for expert-independent generalization of geological andgeophysical data, and to use this generalization for hypothesis testing andcreating geological models based on a probabilistic representation of thereservoir. The quality of the probabilistic representation depends on thequality and quantity of the input data. Depending on the input data, theapproach can be a useful tool for exploration and prospecting of geologicalobjects, identifying potential resources, optimizing and designing fielddevelopment.", "output": "Expert-Independent Generalization of Well and Seismic Data Using Machine Learning Methods for Complex Reservoirs Predicting During Early-Stage Geological Exploration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although real-time facial emotion recognition is a hot topic research domainin the field of human-computer interaction, state-of the-art available datasetsstill suffer from various problems, such as some unrelated photos such asdocument photos, unbalanced numbers of photos in each class, and misleadingimages that can negatively affect correct classification. The 3RL dataset wascreated, which contains approximately 24K images and will be publiclyavailable, to overcome previously available dataset problems. The 3RL datasetis labelled with five basic emotions: happiness, fear, sadness, disgust, andanger. Moreover, we compared the 3RL dataset with other famous state-of-the-artdatasets (FER dataset, CK+ dataset), and we applied the most commonly usedalgorithms in previous works, SVM and CNN. The results show a noticeableimprovement in generalization on the 3RL dataset. Experiments have shown anaccuracy of up to 91.4% on 3RL dataset using CNN where results on FER2013, CK+are, respectively (approximately from 60% to 85%).", "output": "An experimental study in Real-time Facial Emotion Recognition on new 3RL dataset."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The real life time series are usually nonstationary, bringing a difficultquestion of model adaptation. Classical approaches like GARCH assume arbitrarytype of dependence. To prevent such bias, we will focus on recently proposedagnostic philosophy of moving estimator: in time $t$ finding parametersoptimizing e.g. $F_t=sum_{tau&lt;t} (1-eta)^{t-tau} ln(rho_theta (x_tau))$moving log-likelihood, evolving in time. It allows for example to estimateparameters using inexpensive exponential moving averages (EMA), like absolutecentral moments $E[|x-mu|^p]$ evolving with $m_{p,t+1} = m_{p,t} + eta(|x_t-mu_t|^p-m_{p,t})$ for one or multiple powers $pinmathbb{R}^+$.Application of such general adaptive methods of moments will be presented onStudent's t-distribution, popular especially in economical applications, hereapplied to log-returns of DJIA companies.", "output": "Adaptive Student's t-distribution with method of moments moving estimator for nonstationary time series."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In safe MDP planning, a cost function based on the current state and actionis often used to specify safety aspects. In the real world, often the staterepresentation used may lack sufficient fidelity to specify such safetyconstraints. Operating based on an incomplete model can often produceunintended negative side effects (NSEs). To address these challenges, first, weassociate safety signals with state-action trajectories (rather than just animmediate state-action). This makes our safety model highly general. We alsoassume categorical safety labels are given for different trajectories, ratherthan a numerical cost function, which is harder to specify by the problemdesigner. We then employ a supervised learning model to learn suchnon-Markovian safety patterns. Second, we develop a Lagrange multiplier method,which incorporates the safety model and the underlying MDP model in a singlecomputation graph to facilitate agent learning of safe behaviors. Finally, ourempirical results on a variety of discrete and continuous domains show thatthis approach can satisfy complex non-Markovian safety constraints whileoptimizing an agent's total returns, is highly scalable, and is also betterthan the previous best approach for Markovian NSEs.", "output": "Safe MDP Planning by Learning Temporal Patterns of Undesirable Trajectories and Averting Negative Side Effects."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As a way to implement the \"right to be forgotten\" in machine learning,textit{machine unlearning} aims to completely remove the contributions andinformation of the samples to be deleted from a trained model without affectingthe contributions of other samples. Recently, many frameworks for machineunlearning have been proposed, and most of them focus on image and text data.To extend machine unlearning to graph data, textit{GraphEraser} has beenproposed. However, a critical issue is that textit{GraphEraser} isspecifically designed for the transductive graph setting, where the graph isstatic and attributes and edges of test nodes are visible during training. Itis unsuitable for the inductive setting, where the graph could be dynamic andthe test graph information is invisible in advance. Such inductive capabilityis essential for production machine learning systems with evolving graphs likesocial media and transaction networks. To fill this gap, we propose theunderline{{bf G}}underline{{bf U}}ided underline{{bf I}}nunderline{{bfD}}uctivunderline{{bf E}} Graph Unlearning framework (GUIDE). GUIDE consistsof three components: guided graph partitioning with fairness and balance,efficient subgraph repair, and similarity-based aggregation. Empirically, weevaluate our method on several inductive benchmarks and evolving transactiongraphs. Generally speaking, GUIDE can be efficiently implemented on theinductive graph learning tasks for its low graph partition cost, no matter oncomputation or structure information. The code will be available here:", "output": "Inductive Graph Unlearning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ensemble methods combine the predictions of multiple models to improveperformance, but they require significantly higher computation costs atinference time. To avoid these costs, multiple neural networks can be combinedinto one by averaging their weights (model soups). However, this usuallyperforms significantly worse than ensembling. Weight averaging is onlybeneficial when weights are similar enough (in weight or feature space) toaverage well but different enough to benefit from combining them. Based on thisidea, we propose PopulAtion Parameter Averaging (PAPA): a method that combinesthe generality of ensembling with the efficiency of weight averaging. PAPAleverages a population of diverse models (trained on different data orders,augmentations, and regularizations) while occasionally (not too often, not toorarely) replacing the weights of the networks with the population average ofthe weights. PAPA reduces the performance gap between averaging and ensembling,increasing the average accuracy of a population of models by up to 1.1% onCIFAR-10, 2.4% on CIFAR-100, and 1.9% on ImageNet when compared to trainingindependent (non-averaged) models.", "output": "PopulAtion Parameter Averaging (PAPA)."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce Fiedler regularization, a novel approach for regularizing neuralnetworks that utilizes spectral/graphical information. Existing regularizationmethods often focus on penalizing weights in a global/uniform manner thatignores the connectivity structure of the neural network. We propose to use theFiedler value of the neural network's underlying graph as a tool forregularization. We provide theoretical motivation for this approach viaspectral graph theory. We demonstrate several useful properties of the Fiedlervalue that make it useful as a regularization tool. We provide an approximate,variational approach for faster computation during training. We provide analternative formulation of this framework in the form of a structurallyweighted $text{L}_1$ penalty, thus linking our approach to sparsity induction.We provide uniform generalization error bounds for Fiedler regularization via aRademacher complexity analysis. We performed experiments on datasets thatcompare Fiedler regularization with classical regularization methods such asdropout and weight decay. Results demonstrate the efficacy of Fiedlerregularization. This is a journal extension of the conference paper by Tam andDunson (2020).", "output": "Spectral Gap Regularization of Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We consider a class of reinforcement-learning systems in which the agentfollows a behavior policy to explore a discrete state-action space to find anoptimal policy while adhering to some restriction on its behavior. Suchrestriction may prevent the agent from visiting some state-action pairs,possibly leading to the agent finding only a sub-optimal policy. To addressthis problem we introduce the concept of constrained exploration withoptimality preservation, whereby the exploration behavior of the agent isconstrained to meet a specification while the optimality of the (original)unconstrained learning process is preserved. We first establish afeedback-control structure that models the dynamics of the unconstrainedlearning process. We then extend this structure by adding a supervisor toensure that the behavior of the agent meets the specification, and establish(for a class of reinforcement-learning problems with a known deterministicenvironment) a necessary and sufficient condition under which optimality ispreserved. This work demonstrates the utility and the prospect of studyingreinforcement-learning problems in the context of the theories ofdiscrete-event systems, automata and formal languages.", "output": "Constrained Exploration in Reinforcement Learning with Optimality Preservation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The Shapley Additive Global Importance (SAGE) value is a theoreticallyappealing interpretability method that fairly attributes global importance to amodel's features. However, its exact calculation requires the computation ofthe feature's surplus performance contributions over an exponential number offeature sets. This is computationally expensive, particularly becauseestimating the surplus contributions requires sampling from conditionaldistributions. Thus, SAGE approximation algorithms only take a fraction of thefeature sets into account. We propose $d$-SAGE, a method that accelerates SAGEapproximation. $d$-SAGE is motivated by the observation that conditionalindependencies (CIs) between a feature and the model target imply zero surpluscontributions, such that their computation can be skipped. To identify CIs, weleverage causal structure learning (CSL) to infer a graph that encodes(conditional) independencies in the data as $d$-separations. This iscomputationally more efficient because the expense of the one-time graphinference and the $d$-separation queries is negligible compared to the expenseof surplus contribution evaluations. Empirically we demonstrate that $d$-SAGEenables the efficient and accurate estimation of SAGE values.", "output": "Efficient SAGE Estimation via Causal Structure Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper considers the well-studied algorithmic regime of designing a$(1+epsilon)$-approximation algorithm for a $k$-clustering problem that runsin time $f(k,epsilon)poly(n)$ (sometimes called an efficient parameterizedapproximation scheme or EPAS for short). Notable results of this kind includeEPASes in the high-dimensional Euclidean setting for $k$-center [Badu{o}iu,Har-Peled, Indyk; STOC'02] as well as $k$-median, and $k$-means [Kumar,Sabharwal, Sen; J. ACM 2010]. However, existing EPASes handle only basicobjectives (such as $k$-center, $k$-median, and $k$-means) and are tailored tothe specific objective and metric space.Our main contribution is a clean and simple EPAS that settles more than tenclustering problems (across multiple well-studied objectives as well as metricspaces) and unifies well-known EPASes. Our algorithm gives EPASes for a largevariety of clustering objectives (for example, $k$-means, $k$-center,$k$-median, priority $k$-center, $ell$-centrum, ordered $k$-median, sociallyfair $k$-median aka robust $k$-median, or more generally monotone norm$k$-clustering) and metric spaces (for example, continuous high-dimensionalEuclidean spaces, metrics of bounded doubling dimension, bounded treewidthmetrics, and planar metrics).Key to our approach is a new concept that we call bounded $epsilon$-scatterdimension--an intrinsic complexity measure of a metric space that is arelaxation of the standard notion of bounded doubling dimension. Our maintechnical result shows that two conditions are essentially sufficient for ouralgorithm to yield an EPAS on the input metric $M$ for any clusteringobjective: (i) The objective is described by a monotone (not necessarilysymmetric!) norm, and (ii) the $epsilon$-scatter dimension of $M$ is upperbounded by a function of $epsilon$.", "output": "Parameterized Approximation Schemes for Clustering with General Norm Objectives."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Growing techniques have been emerging to improve the performance of passageretrieval. As an effective representation bottleneck pretraining technique, thecontextual masked auto-encoder utilizes contextual embedding to assist in thereconstruction of passages. However, it only uses a single auto-encodingpre-task for dense representation pre-training. This study brings multi-viewmodeling to the contextual masked auto-encoder. Firstly, multi-viewrepresentation utilizes both dense and sparse vectors as multi-viewrepresentations, aiming to capture sentence semantics from different aspects.Moreover, multiview decoding paradigm utilizes both autoencoding andauto-regressive decoders in representation bottleneck pre-training, aiming toprovide both reconstructive and generative signals for better contextualrepresentation pretraining. We refer to this multi-view pretraining method asCoT-MAE v2. Through extensive experiments, we show that CoT-MAE v2 is effectiveand robust on large-scale passage retrieval benchmarks and out-of-domainzero-shot benchmarks.", "output": "CoT-MAE v2: Contextual Masked Auto-Encoder with Multi-view Modeling for Passage Retrieval."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Spectral Toolkit of Algorithms for Graphs (STAG) is an open-source libraryfor efficient spectral graph algorithms, and its development starts inSeptember 2022. We have so far finished the component on local graphclustering, and this technical report presents a user's guide to STAG, showcasestudies, and several technical considerations behind our development.", "output": "Spectral Toolkit of Algorithms for Graphs: Technical Report (1)."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This contribution shows how an appropriate image pre-processing can improve adeep-learning based 3D reconstruction of colon parts. The assumption is that,rather than global image illumination corrections, local under- andover-exposures should be corrected in colonoscopy. An overview of the pipelineincluding the image exposure correction and a RNN-SLAM is first given. Then,this paper quantifies the reconstruction accuracy of the endoscope trajectoryin the colon with and without appropriate illumination correction", "output": "Deep learning-based image exposure enhancement as a pre-processing for an accurate 3D colon surface reconstruction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Regularized pairwise ranking with Gaussian kernels is one of the cutting-edgelearning algorithms. Despite a wide range of applications, a rigoroustheoretical demonstration still lacks to support the performance of suchranking estimators. This work aims to fill this gap by developing novel oracleinequalities for regularized pairwise ranking. With the help of these oracleinequalities, we derive fast learning rates of Gaussian ranking estimatorsunder a general box-counting dimension assumption on the input domain combinedwith the noise conditions or the standard smoothness condition. Our theoreticalanalysis improves the existing estimates and shows that a low intrinsicdimension of input space can help the rates circumvent the curse ofdimensionality.", "output": "Pairwise Ranking with Gaussian Kernels."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The concept of a recently proposed Forward-Forward learning algorithm forfully connected artificial neural networks is applied to a single multi outputperceptron for classification. The parameters of the system are trained withrespect to increased (decreased) \"goodness\" for correctly (incorrectly)labelled input samples. Basic numerical tests demonstrate that the trainedperceptron effectively deals with data sets that have non-linear decisionboundaries. Moreover, the overall performance is comparable to more complexneural networks with hidden layers. The benefit of the approach presented hereis that it only involves a single matrix multiplication.", "output": "The Concept of Forward-Forward Learning Applied to a Multi Output Perceptron."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We consider the problem of rank-$1$ low-rank approximation (LRA) in thematrix-vector product model under various Schatten norms: $$min_{|u|_2=1} |A (I - u u^top)|_{mathcal{S}_p} , $$ where$|M|_{mathcal{S}_p}$ denotes the $ell_p$ norm of the singular values of$M$. Given $varepsilon&gt;0$, our goal is to output a unit vector $v$ such that$$|A(I - vv^top)|_{mathcal{S}_p} leq (1+varepsilon) min_{|u|_2=1}|A(I- u u^top)|_{mathcal{S}_p}. $$ Our main result shows that Krylov methods(nearly) achieve the information-theoretically optimal number of matrix-vectorproducts for Spectral ($p=infty$), Frobenius ($p=2$) and Nuclear ($p=1$) LRA.In particular, for Spectral LRA, we show that any algorithm requires$Omegaleft(log(n)/varepsilon^{1/2}right)$ matrix-vector products, exactlymatching the upper bound obtained by Krylov methods [MM15, BCW22]. Our lowerbound addresses Open Question 1 in [Woo14], providing evidence for the lack ofprogress on algorithms for Spectral LRA and resolves Open Question 1.2 in[BCW22]. Next, we show that for any fixed constant $p$, i.e. $1leq p =O(1)$,there is an upper bound of$Oleft(log(1/varepsilon)/varepsilon^{1/3}right)$ matrix-vector products,implying that the complexity does not grow as a function of input size. Thisimproves the $Oleft(log(n/varepsilon)/varepsilon^{1/3}right)$ boundrecently obtained in [BCW22], and matches their$Omegaleft(1/varepsilon^{1/3}right)$ lower bound, to a$log(1/varepsilon)$ factor.", "output": "Krylov Methods are (nearly) Optimal for Low-Rank Approximation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This contribution presents a deep-learning method for extracting and fusingimage information acquired from different viewpoints, with the aim to producemore discriminant object features for the identification of the type of kidneystones seen in endoscopic images. The model was further improved with atwo-step transfer learning approach and by attention blocks to refine thelearned feature maps. Deep feature fusion strategies improved the results ofsingle view extraction backbone models by more than 6% in terms of accuracy ofthe kidney stones classification.", "output": "Improving automatic endoscopic stone recognition using a multi-view fusion approach enhanced with two-step transfer learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Feature selection has been widely used to alleviate compute requirementsduring training, elucidate model interpretability, and improve modelgeneralizability. We propose SLM -- Sparse Learnable Masks -- a canonicalapproach for end-to-end feature selection that scales well with respect to boththe feature dimension and the number of samples. At the heart of SLM lies asimple but effective learnable sparse mask, which learns which features toselect, and gives rise to a novel objective that provably maximizes the mutualinformation (MI) between the selected features and the labels, which can bederived from a quadratic relaxation of mutual information from firstprinciples. In addition, we derive a scaling mechanism that allows SLM toprecisely control the number of features selected, through a novel use ofsparsemax. This allows for more effective learning as demonstrated in ablationstudies. Empirically, SLM achieves state-of-the-art results against a varietyof competitive baselines on eight benchmark datasets, often by a significantmargin, especially on those with real-world challenges such as class imbalance.", "output": "SLM: End-to-end Feature Selection via Sparse Learnable Masks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study recent research advances that improve large language models throughefficient pre-training and scaling, and open datasets and tools. We combinethese advances to introduce Cerebras-GPT, a family of open compute-optimallanguage models scaled from 111M to 13B parameters. We train Cerebras-GPTmodels on the Eleuther Pile dataset following DeepMind Chinchilla scaling rulesfor efficient pre-training (highest accuracy for a given compute budget). Wecharacterize the predictable power-law scaling and compare Cerebras-GPT withother publicly-available models to show all Cerebras-GPT models havestate-of-the-art training efficiency on both pre-training and downstreamobjectives. We describe our learnings including how Maximal UpdateParameterization ($mu$P) can further improve large model scaling, improvingaccuracy and hyperparameter predictability at scale. We release our pre-trainedmodels and code, making this paper the first open and reproducible workcomparing compute-optimal model scaling to models trained on fixed datasetsizes. Cerebras-GPT models are available on HuggingFace:", "output": "Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Integrating high-level semantically correlated contents and low-levelanatomical features is of central importance in medical image segmentation.Towards this end, recent deep learning-based medical segmentation methods haveshown great promise in better modeling such information. However, convolutionoperators for medical segmentation typically operate on regular grids, whichinherently blur the high-frequency regions, i.e., boundary regions. In thiswork, we propose MORSE, a generic implicit neural rendering framework designedat an anatomical level to assist learning in medical image segmentation. Ourmethod is motivated by the fact that implicit neural representation has beenshown to be more effective in fitting complex signals and solving computergraphics problems than discrete grid-based representation. The core of ourapproach is to formulate medical image segmentation as a rendering problem inan end-to-end manner. Specifically, we continuously align the coarsesegmentation prediction with the ambiguous coordinate-based pointrepresentations and aggregate these features to adaptively refine the boundaryregion. To parallelly optimize multi-scale pixel-level features, we leveragethe idea from Mixture-of-Expert (MoE) to design and train our MORSE with astochastic gating mechanism. Our experiments demonstrate that MORSE can workwell with different medical segmentation backbones, consistently achievingcompetitive performance improvements in both 2D and 3D supervised medicalsegmentation methods. We also theoretically analyze the superiority of MORSE.", "output": "Implicit Anatomical Rendering for Medical Image Segmentation with Stochastic Experts."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Cross-device user matching is a critical problem in numerous domains,including advertising, recommender systems, and cybersecurity. It involvesidentifying and linking different devices belonging to the same person,utilizing sequence logs. Previous data mining techniques have struggled toaddress the long-range dependencies and higher-order connections between thelogs. Recently, researchers have modeled this problem as a graph problem andproposed a two-tier graph contextual embedding (TGCE) neural networkarchitecture, which outperforms previous methods. In this paper, we propose anovel hierarchical graph neural network architecture (HGNN), which has a morecomputationally efficient second level design than TGCE. Furthermore, weintroduce a cross-attention (Cross-Att) mechanism in our model, which improvesperformance by 5% compared to the state-of-the-art TGCE method.", "output": "Hierarchical Graph Neural Network with Cross-Attention for Cross-Device User Matching."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "To safely deploy deep learning-based computer vision models forcomputer-aided detection and diagnosis, we must ensure that they are robust andreliable. Towards that goal, algorithmic auditing has received substantialattention. To guide their audit procedures, existing methods rely on heuristicapproaches or high-level objectives (e.g., non-discrimination in regards toprotected attributes, such as sex, gender, or race). However, algorithms mayshow bias with respect to various attributes beyond the more obvious ones, andintegrity issues related to these more subtle attributes can have seriousconsequences. To enable the generation of actionable, data-driven hypotheseswhich identify specific dataset attributes likely to induce model bias, wecontribute a first technique for the rigorous, quantitative screening ofmedical image datasets. Drawing from literature in the causal inference andinformation theory domains, our procedure decomposes the risks associated withdataset attributes in terms of their detectability and utility (defined as theamount of information knowing the attribute gives about a task label). Todemonstrate the effectiveness and sensitivity of our method, we develop avariety of datasets with synthetically inserted artifacts with differentdegrees of association to the target label that allow evaluation of inheritedmodel biases via comparison of performance against true counterfactualexamples. Using these datasets and results from hundreds of trained models, weshow our screening method reliably identifies nearly imperceptiblebias-inducing artifacts. Lastly, we apply our method to the natural attributesof a popular skin-lesion dataset and demonstrate its success. Our approachprovides a means to perform more systematic algorithmic audits and guide futuredata collection efforts in pursuit of safer and more reliable models.", "output": "Data AUDIT: Identifying Attribute Utility- and Detectability-Induced Bias in Task Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose Gumbel Noise Score Matching (GNSM), a novel unsupervised method todetect anomalies in categorical data. GNSM accomplishes this by estimating thescores, i.e. the gradients of log likelihoods w.r.t.~inputs, of continuouslyrelaxed categorical distributions. We test our method on a suite of anomalydetection tabular datasets. GNSM achieves a consistently high performanceacross all experiments. We further demonstrate the flexibility of GNSM byapplying it to image data where the model is tasked to detect poor segmentationpredictions. Images ranked anomalous by GNSM show clear segmentation failures,with the outputs of GNSM strongly correlating with segmentation metricscomputed on ground-truth. We outline the score matching training objectiveutilized by GNSM and provide an open-source implementation of our work.", "output": "Anomaly Detection via Gumbel Noise Score Matching."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we aim to learn dexterous manipulation of deformable objectsusing multi-fingered hands. Reinforcement learning approaches for dexterousrigid object manipulation would struggle in this setting due to the complexityof physics interaction with deformable objects. At the same time, previoustrajectory optimization approaches with differentiable physics for deformablemanipulation would suffer from local optima caused by the explosion of contactmodes from hand-object interactions. To address these challenges, we proposeDexDeform, a principled framework that abstracts dexterous manipulation skillsfrom human demonstration and refines the learned skills with differentiablephysics. Concretely, we first collect a small set of human demonstrations usingteleoperation. And we then train a skill model using demonstrations forplanning over action abstractions in imagination. To explore the goal space, wefurther apply augmentations to the existing deformable shapes in demonstrationsand use a gradient optimizer to refine the actions planned by the skill model.Finally, we adopt the refined trajectories as new demonstrations for finetuningthe skill model. To evaluate the effectiveness of our approach, we introduce asuite of six challenging dexterous deformable object manipulation tasks.Compared with baselines, DexDeform is able to better explore and generalizeacross novel goals unseen in the initial human demonstrations.", "output": "DexDeform: Dexterous Deformable Object Manipulation with Human Demonstrations and Differentiable Physics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Chatbots are mainly data-driven and usually based on utterances that might besensitive. However, training deep learning models on shared data can violateuser privacy. Such issues have commonly existed in chatbots since theirinception. In the literature, there have been many approaches to deal withprivacy, such as differential privacy and secure multi-party computation, butmost of them need to have access to users' data. In this context, FederatedLearning (FL) aims to protect data privacy through distributed learning methodsthat keep the data in its location. This paper presents Fedbot, aproof-of-concept (POC) privacy-preserving chatbot that leverages large-scalecustomer support data. The POC combines Deep Bidirectional Transformer modelsand federated learning algorithms to protect customer data privacy duringcollaborative model training. The results of the proof-of-concept showcase thepotential for privacy-preserving chatbots to transform the customer supportindustry by delivering personalized and efficient customer service that meetsdata privacy regulations and legal requirements. Furthermore, the system isspecifically designed to improve its performance and accuracy over time byleveraging its ability to learn from previous interactions.", "output": "FedBot: Enhancing Privacy in Chatbots with Federated Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Genome-Wide Association Studies (GWAS) help identify genetic variations inpeople with diseases such as Parkinson's disease (PD), which are less common inthose without the disease. Thus, GWAS data can be used to identify geneticvariations associated with the disease. Feature selection and machine learningapproaches can be used to analyze GWAS data and identify potential diseasebiomarkers. However, GWAS studies have technical variations that affect thereproducibility of identified biomarkers, such as differences in genotypingplatforms and selection criteria for individuals to be genotyped. To addressthis issue, we collected five GWAS datasets from the database of Genotypes andPhenotypes (dbGaP) and explored several data integration strategies. Weevaluated the agreement among different strategies in terms of the SingleNucleotide Polymorphisms (SNPs) that were identified as potential PDbiomarkers. Our results showed a low concordance of biomarkers discovered usingdifferent datasets or integration strategies. However, we identified fifty SNPsthat were identified at least twice, which could potentially serve as novel PDbiomarkers. These SNPs are indirectly linked to PD in the literature but havenot been directly associated with PD before. These findings open up newpotential avenues of investigation.", "output": "Assessing the Reproducibility of Machine-learning-based Biomarker Discovery in Parkinson's Disease."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Synthetic data are becoming a critical tool for building artificiallyintelligent systems. Simulators provide a way of generating data systematicallyand at scale. These data can then be used either exclusively, or in conjunctionwith real data, for training and testing systems. Synthetic data areparticularly attractive in cases where the availability of ``real'' trainingexamples might be a bottleneck. While the volume of data in healthcare isgrowing exponentially, creating datasets for novel tasks and/or that reflect adiverse set of conditions and causal relationships is not trivial. Furthermore,these data are highly sensitive and often patient specific. Recent research hasbegun to illustrate the potential for synthetic data in many areas of medicine,but no systematic review of the literature exists. In this paper, we presentthe cases for physical and statistical simulations for creating data and theproposed applications in healthcare and medicine. We discuss that whilesynthetics can promote privacy, equity, safety and continual and causallearning, they also run the risk of introducing flaws, blind spots andpropagating or exaggerating biases.", "output": "Synthetic Data in Healthcare."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Observational studies of recurrent event rates are common in biomedicalstatistics. Broadly, the goal is to estimate differences in event rates undertwo treatments within a defined target population over a specified followupwindow. Estimation with observational claims data is challenging because whilemembership in the target population is defined in terms of eligibilitycriteria, treatment is rarely assigned exactly at the time of eligibility.Ad-hoc solutions to this timing misalignment, such as assigning treatment ateligibility based on subsequent assignment, incorrectly attribute prior eventrates to treatment - resulting in immortal risk bias. Even if eligibility andtreatment are aligned, a terminal event process (e.g. death) often stops therecurrent event process of interest. Both processes are also censored so thatevents are not observed over the entire followup window. Our approach addressesmisalignment by casting it as a treatment switching problem: some patients areon treatment at eligibility while others are off treatment but may switch totreatment at a specified time - if they survive long enough. We define andidentify an average causal effect of switching under specified causalassumptions. Estimation is done using a g-computation framework with a jointsemiparametric Bayesian model for the death and recurrent event processes.Computing the estimand for various switching times allows us to assess theimpact of treatment timing. We apply the method to contrast hospitalizationrates under different opioid treatment strategies among patients with chronicback pain using Medicare claims data.", "output": "A Bayesian Framework for Causal Analysis of Recurrent Events in Presence of Immortal Risk."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Causal discovery methods are intrinsically constrained by the set ofassumptions needed to ensure structure identifiability. Moreover additionalrestrictions are often imposed in order to simplify the inference task: this isthe case for the Gaussian noise assumption on additive non-linear models, whichis common to many causal discovery approaches. In this paper we show theshortcomings of inference under this hypothesis, analyzing the risk of edgeinversion under violation of Gaussianity of the noise terms. Then, we propose anovel method for inferring the topological ordering of the variables in thecausal graph, from data generated according to an additive non-linear modelwith a generic noise distribution. This leads to NoGAM (Not only GaussianAdditive noise Models), a causal discovery algorithm with a minimal set ofassumptions and state of the art performance, experimentally benchmarked onsynthetic data.", "output": "Causal Discovery with Score Matching on Additive Models with Arbitrary Noise."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The growing carbon footprint of artificial intelligence (AI) models,especially large ones such as GPT-3 and GPT-4, has been undergoing publicscrutiny. Unfortunately, however, the equally important and enormous waterfootprint of AI models has remained under the radar. For example, trainingGPT-3 in Microsoft's state-of-the-art U.S. data centers can directly consume700,000 liters of clean freshwater (enough for producing 370 BMW cars or 320Tesla electric vehicles) and the water consumption would have been tripled iftraining were done in Microsoft's Asian data centers, but such information hasbeen kept as a secret. This is extremely concerning, as freshwater scarcity hasbecome one of the most pressing challenges shared by all of us in the wake ofthe rapidly growing population, depleting water resources, and aging waterinfrastructures. To respond to the global water challenges, AI models can, andalso should, take social responsibility and lead by example by addressing theirown water footprint. In this paper, we provide a principled methodology toestimate fine-grained water footprint of AI models, and also discuss the uniquespatial-temporal diversities of AI models' runtime water efficiency. Finally,we highlight the necessity of holistically addressing water footprint alongwith carbon footprint to enable truly sustainable AI.", "output": "Making AI Less \"Thirsty\": Uncovering and Addressing the Secret Water Footprint of AI Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Motion mimicking is a foundational task in physics-based character animation.However, most existing motion mimicking methods are built upon reinforcementlearning (RL) and suffer from heavy reward engineering, high variance, and slowconvergence with hard explorations. Specifically, they usually take tens ofhours or even days of training to mimic a simple motion sequence, resulting inpoor scalability. In this work, we leverage differentiable physics simulators(DPS) and propose an efficient motion mimicking method dubbed DiffMimic. Ourkey insight is that DPS casts a complex policy learning task to a much simplerstate matching problem. In particular, DPS learns a stable policy by analyticalgradients with ground-truth physical priors hence leading to significantlyfaster and stabler convergence than RL-based methods. Moreover, to escape fromlocal optima, we utilize a Demonstration Replay mechanism to enable stablegradient backpropagation in a long horizon. Extensive experiments on standardbenchmarks show that DiffMimic has a better sample efficiency and timeefficiency than existing methods (e.g., DeepMimic). Notably, DiffMimic allows aphysically simulated character to learn Backflip after 10 minutes of trainingand be able to cycle it after 3 hours of training, while the existing approachmay require about a day of training to cycle Backflip. More importantly, wehope DiffMimic can benefit more differentiable animation systems withtechniques like differentiable clothes simulation in future research.", "output": "DiffMimic: Efficient Motion Mimicking with Differentiable Physics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Artificial agents have traditionally been trained to maximize reward, whichmay incentivize power-seeking and deception, analogous to how next-tokenprediction in language models (LMs) may incentivize toxicity. So do agentsnaturally learn to be Machiavellian? And how do we measure these behaviors ingeneral-purpose models such as GPT-4? Towards answering these questions, weintroduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure gamescontaining over half a million rich, diverse scenarios that center on socialdecision-making. Scenario labeling is automated with LMs, which are moreperformant than human annotators. We mathematize dozens of harmful behaviorsand use our annotations to evaluate agents' tendencies to be power-seeking,cause disutility, and commit ethical violations. We observe some tensionbetween maximizing reward and behaving ethically. To improve this trade-off, weinvestigate LM-based methods to steer agents' towards less harmful behaviors.Our results show that agents can both act competently and morally, so concreteprogress can currently be made in machine ethics--designing agents that arePareto improvements in both safety and capabilities.", "output": "Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep reinforcement learning (DeepRL) agents surpass human-level performancein many tasks. However, the direct mapping from states to actions makes it hardto interpret the rationale behind the decision-making of the agents. Incontrast to previous a-posteriori methods for visualizing DeepRL policies, inthis work, we propose to equip the DeepRL model with an innate visualizationability. Our proposed agent, named region-sensitive Rainbow (RS-Rainbow), is anend-to-end trainable network based on the original Rainbow, a powerful deepQ-network agent. It learns important regions in the input domain via anattention module. At inference time, after each forward pass, we can visualizeregions that are most important to decision-making by backpropagating gradientsfrom the attention module to the input frames. The incorporation of ourproposed module not only improves model interpretability, but leads toperformance improvement. Extensive experiments on games from the Atari 2600suite demonstrate the effectiveness of RS-Rainbow.", "output": "Learn to Interpret Atari Agents."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We consider the sequential anomaly detection problem in the one-class settingwhen only the anomalous sequences are available and propose an adversarialsequential detector by solving a minimax problem to find an optimal detectoragainst the worst-case sequences from a generator. The generator captures thedependence in sequential events using the marked point process model. Thedetector sequentially evaluates the likelihood of a test sequence and comparesit with a time-varying threshold, also learned from data through the minimaxproblem. We demonstrate our proposed method's good performance using numericalexperiments on simulations and proprietary large-scale credit card frauddatasets. The proposed method can generally apply to detecting anomaloussequences.", "output": "Sequential Adversarial Anomaly Detection for One-Class Event Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "CT scanners that are commonly-used in hospitals nowadays producelow-resolution images, up to 512 pixels in size. One pixel in the imagecorresponds to a one millimeter piece of tissue. In order to accurately segmenttumors and make treatment plans, doctors need CT scans of higher resolution.The same problem appears in MRI. In this paper, we propose an approach for thesingle-image super-resolution of 3D CT or MRI scans. Our method is based ondeep convolutional neural networks (CNNs) composed of 10 convolutional layersand an intermediate upscaling layer that is placed after the first 6convolutional layers. Our first CNN, which increases the resolution on two axes(width and height), is followed by a second CNN, which increases the resolutionon the third axis (depth). Different from other methods, we compute the losswith respect to the ground-truth high-resolution output right after theupscaling layer, in addition to computing the loss after the last convolutionallayer. The intermediate loss forces our network to produce a better output,closer to the ground-truth. A widely-used approach to obtain sharp results isto add Gaussian blur using a fixed standard deviation. In order to avoidoverfitting to a fixed standard deviation, we apply Gaussian smoothing withvarious standard deviations, unlike other approaches. We evaluate our method inthe context of 2D and 3D super-resolution of CT and MRI scans from twodatabases, comparing it to relevant related works from the literature andbaselines based on various interpolation schemes, using 2x and 4x scalingfactors. The empirical results show that our approach attains superior resultsto all other methods. Moreover, our human annotation study reveals that bothdoctors and regular annotators chose our method in favor of Lanczosinterpolation in 97.55% cases for 2x upscaling factor and in 96.69% cases for4x upscaling factor.", "output": "Convolutional Neural Networks with Intermediate Loss for 3D Super-Resolution of CT and MRI Scans."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Convolutional neural networks have been widely applied to hyperspectral imageclassification. However, traditional convolutions can not effectively extractfeatures for objects with irregular distributions. Recent methods attempt toaddress this issue by performing graph convolutions on spatial topologies, butfixed graph structures and local perceptions limit their performances. Totackle these problems, in this paper, different from previous approaches, weperform the superpixel generation on intermediate features during networktraining to adaptively produce homogeneous regions, obtain graph structures,and further generate spatial descriptors, which are served as graph nodes.Besides spatial objects, we also explore the graph relationships betweenchannels by reasonably aggregating channels to generate spectral descriptors.The adjacent matrices in these graph convolutions are obtained by consideringthe relationships among all descriptors to realize global perceptions. Bycombining the extracted spatial and spectral graph features, we finally obtaina spectral-spatial graph reasoning network (SSGRN). The spatial and spectralparts of SSGRN are separately called spatial and spectral graph reasoningsubnetworks. Comprehensive experiments on four public datasets demonstrate thecompetitiveness of the proposed methods compared with other state-of-the-artgraph convolution-based approaches.", "output": "Spectral-Spatial Global Graph Reasoning for Hyperspectral Image Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes an extension of principal component analysis for Gaussianprocess (GP) posteriors, denoted by GP-PCA. Since GP-PCA estimates alow-dimensional space of GP posteriors, it can be used for meta-learning, whichis a framework for improving the performance of target tasks by estimating astructure of a set of tasks. The issue is how to define a structure of a set ofGPs with an infinite-dimensional parameter, such as coordinate system and adivergence. In this study, we reduce the infiniteness of GP to thefinite-dimensional case under the information geometrical framework byconsidering a space of GP posteriors that have the same prior. In addition, wepropose an approximation method of GP-PCA based on variational inference anddemonstrate the effectiveness of GP-PCA as meta-learning through experiments.", "output": "Principal component analysis for Gaussian process posteriors."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Missing data imputation is a fundamental problem in data analysis, and manystudies have been conducted to improve its performance by exploring modelstructures and learning procedures. However, data augmentation, as a simple yeteffective method, has not received enough attention in this area. In thispaper, we propose a novel data augmentation method called MissingnessAugmentation (MisA) for generative imputation models. Our approach dynamicallyproduces incomplete samples at each epoch by utilizing the generator's output,constraining the augmented samples using a simple reconstruction loss, andcombining this loss with the original loss to form the final optimizationobjective. As a general augmentation technique, MisA can be easily integratedinto generative imputation frameworks, providing a simple yet effective way toenhance their performance. Experimental results demonstrate that MisAsignificantly improves the performance of many recently proposed generativeimputation models on a variety of tabular and image datasets. The code isavailable at url{", "output": "Missingness Augmentation: A General Approach for Improving Generative Imputation Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Past research has proposed numerous hardware prefetching techniques, most ofwhich rely on exploiting one specific type of program context information(e.g., program counter, cacheline address) to predict future memory accesses.These techniques either completely neglect a prefetcher's undesirable effects(e.g., memory bandwidth usage) on the overall system, or incorporatesystem-level feedback as an afterthought to a system-unaware prefetchalgorithm. We show that prior prefetchers often lose their performance benefitover a wide range of workloads and system configurations due to their inherentinability to take multiple different types of program context and system-levelfeedback information into account while prefetching. In this paper, we make acase for designing a holistic prefetch algorithm that learns to prefetch usingmultiple different types of program context and system-level feedbackinformation inherent to its design.To this end, we propose Pythia, which formulates the prefetcher as areinforcement learning agent. For every demand request, Pythia observesmultiple different types of program context information to make a prefetchdecision. For every prefetch decision, Pythia receives a numerical reward thatevaluates prefetch quality under the current memory bandwidth usage. Pythiauses this reward to reinforce the correlation between program contextinformation and prefetch decision to generate highly accurate, timely, andsystem-aware prefetch requests in the future. Our extensive evaluations usingsimulation and hardware synthesis show that Pythia outperforms multiplestate-of-the-art prefetchers over a wide range of workloads and systemconfigurations, while incurring only 1.03% area overhead over a desktop-classprocessor and no software changes in workloads. The source code of Pythia canbe freely downloaded from ", "output": "Pythia: A Customizable Hardware Prefetching Framework Using Online Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Accurate inference of fine-grained traffic flow from coarse-grained one is anemerging yet crucial problem, which can help greatly reduce the number of therequired traffic monitoring sensors for cost savings. In this work, we noticethat traffic flow has a high correlation with road network, which was eithercompletely ignored or simply treated as an external factor in previous works.Tofacilitate this problem, we propose a novel Road-Aware Traffic Flow Magnifier(RATFM) that explicitly exploits the prior knowledge of road networks to fullylearn the road-aware spatial distribution of fine-grained traffic flow.Specifically, a multi-directional 1D convolutional layer is first introduced toextract the semantic feature of the road network. Subsequently, we incorporatethe road network feature and coarse-grained flow feature to regularize theshort-range spatial distribution modeling of road-relative traffic flow.Furthermore, we take the road network feature as a query to capture thelong-range spatial distribution of traffic flow with a transformerarchitecture. Benefiting from the road-aware inference mechanism, our methodcan generate high-quality fine-grained traffic flow maps. Extensive experimentson three real-world datasets show that the proposed RATFM outperformsstate-of-the-art models under various scenarios. Our code and datasets arereleased at {url{", "output": "Road Network Guided Fine-Grained Urban Traffic Flow Inference."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "There are many algorithms for regret minimisation in episodic reinforcementlearning. This problem is well-understood from a theoretical perspective,providing that the sequences of states, actions and rewards associated witheach episode are available to the algorithm updating the policy immediatelyafter every interaction with the environment. However, feedback is almostalways delayed in practice. In this paper, we study the impact of delayedfeedback in episodic reinforcement learning from a theoretical perspective andpropose two general-purpose approaches to handling the delays. The firstinvolves updating as soon as new information becomes available, whereas thesecond waits before using newly observed information to update the policy. Forthe class of optimistic algorithms and either approach, we show that the regretincreases by an additive term involving the number of states, actions, episodelength, the expected delay and an algorithm-dependent constant. We empiricallyinvestigate the impact of various delay distributions on the regret ofoptimistic algorithms to validate our theoretical results.", "output": "Optimism and Delays in Episodic Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transferring knowledge learned from the labeled source domain to the rawtarget domain for unsupervised domain adaptation (UDA) is essential to thescalable deployment of autonomous driving systems. State-of-the-art methods inUDA often employ a key idea: utilizing joint supervision signals from bothsource and target domains for self-training. In this work, we improve andextend this aspect. We present ConDA, a concatenation-based domain adaptationframework for LiDAR segmentation that: 1) constructs an intermediate domainconsisting of fine-grained interchange signals from both source and targetdomains without destabilizing the semantic coherency of objects and backgroundaround the ego-vehicle; and 2) utilizes the intermediate domain forself-training. To improve the network training on the source domain andself-training on the intermediate domain, we propose an anti-aliasingregularizer and an entropy aggregator to reduce the negative effect caused bythe aliasing artifacts and noisy pseudo labels. Through extensive studies, wedemonstrate that ConDA significantly outperforms prior arts in mitigatingdomain gaps.", "output": "ConDA: Unsupervised Domain Adaptation for LiDAR Segmentation via Regularized Domain Concatenation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Many state-of-the-art adversarial training methods for deep learning leverageupper bounds of the adversarial loss to provide security guarantees againstadversarial attacks. Yet, these methods rely on convex relaxations to propagatelower and upper bounds for intermediate layers, which affect the tightness ofthe bound at the output layer. We introduce a new approach to adversarialtraining by minimizing an upper bound of the adversarial loss that is based ona holistic expansion of the network instead of separate bounds for each layer.This bound is facilitated by state-of-the-art tools from Robust Optimization;it has closed-form and can be effectively trained using backpropagation. Wederive two new methods with the proposed approach. The first method(Approximated Robust Upper Bound or aRUB) uses the first order approximation ofthe network as well as basic tools from Linear Robust Optimization to obtain anempirical upper bound of the adversarial loss that can be easily implemented.The second method (Robust Upper Bound or RUB), computes a provable upper boundof the adversarial loss. Across a variety of tabular and vision data sets wedemonstrate the effectiveness of our approach -- RUB is substantially morerobust than state-of-the-art methods for larger perturbations, while aRUBmatches the performance of state-of-the-art methods for small perturbations.", "output": "Robust Upper Bounds for Adversarial Training."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We settle the complexity of dynamic least-squares regression (LSR), whererows and labels $(mathbf{A}^{(t)}, mathbf{b}^{(t)})$ can be adaptivelyinserted and/or deleted, and the goal is to efficiently maintain an$epsilon$-approximate solution to $min_{mathbf{x}^{(t)}} | mathbf{A}^{(t)}mathbf{x}^{(t)} - mathbf{b}^{(t)} |_2$ for all $tin [T]$. We prove sharpseparations ($d^{2-o(1)}$ vs. $sim d$) between the amortized update time of:(i) Fully vs. Partially dynamic $0.01$-LSR; (ii) High vs. low-accuracy LSR inthe partially-dynamic (insertion-only) setting.Our lower bounds follow from a gap-amplification reduction -- reminiscent ofiterative refinement -- rom the exact version of the Online Matrix VectorConjecture (OMv) [HKNS15], to constant approximate OMv over the reals, wherethe $i$-th online product $mathbf{H}mathbf{v}^{(i)}$ only needs to becomputed to $0.1$-relative error. All previous fine-grained reductions from OMvto its approximate versions only show hardness for inverse polynomialapproximation $epsilon = n^{-omega(1)}$ (additive or multiplicative) . Thisresult is of independent interest in fine-grained complexity and for theinvestigation of the OMv Conjecture, which is still widely open.", "output": "The Complexity of Dynamic Least-Squares Regression."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose Continual Repeated Annealed Flow Transport Monte Carlo (CRAFT), amethod that combines a sequential Monte Carlo (SMC) sampler (itself ageneralization of Annealed Importance Sampling) with variational inferenceusing normalizing flows. The normalizing flows are directly trained totransport between annealing temperatures using a KL divergence for eachtransition. This optimization objective is itself estimated using thenormalizing flow/SMC approximation. We show conceptually and using multipleempirical examples that CRAFT improves on Annealed Flow Transport Monte Carlo(Arbel et al., 2021), on which it builds and also on Markov chain Monte Carlo(MCMC) based Stochastic Normalizing Flows (Wu et al., 2020). By incorporatingCRAFT within particle MCMC, we show that such learnt samplers can achieveimpressively accurate results on a challenging lattice field theory example.", "output": "Continual Repeated Annealed Flow Transport Monte Carlo."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Over the years, most research towards defenses against adversarial attacks onmachine learning models has been in the image recognition domain. The malwaredetection domain has received less attention despite its importance. Moreover,most work exploring these defenses has focused on several methods but with nostrategy when applying them. In this paper, we introduce StratDef, which is astrategic defense system based on a moving target defense approach. We overcomechallenges related to the systematic construction, selection, and strategic useof models to maximize adversarial robustness. StratDef dynamically andstrategically chooses the best models to increase the uncertainty for theattacker while minimizing critical aspects in the adversarial ML domain, likeattack transferability. We provide the first comprehensive evaluation ofdefenses against adversarial attacks on machine learning for malware detection,where our threat model explores different levels of threat, attacker knowledge,capabilities, and attack intensities. We show that StratDef performs betterthan other defenses even when facing the peak adversarial threat. We also showthat, of the existing defenses, only a few adversarially-trained models providesubstantially better protection than just using vanilla models but are stilloutperformed by StratDef.", "output": "StratDef: Strategic Defense Against Adversarial Attacks in ML-based Malware Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Differential privacy has been an exceptionally successful concept when itcomes to providing provable security guarantees for classical computations.More recently, the concept was generalized to quantum computations. Whileclassical computations are essentially noiseless and differential privacy isoften achieved by artificially adding noise, near-term quantum computers areinherently noisy and it was observed that this leads to natural differentialprivacy as a feature.In this work we discuss quantum differential privacy in an informationtheoretic framework by casting it as a quantum divergence. A main advantage ofthis approach is that differential privacy becomes a property solely based onthe output states of the computation, without the need to check it for everymeasurement. This leads to simpler proofs and generalized statements of itsproperties as well as several new bounds for both, general and specific, noisemodels. In particular, these include common representations of quantum circuitsand quantum machine learning concepts. Here, we focus on the difference in theamount of noise required to achieve certain levels of differential privacyversus the amount that would make any computation useless. Finally, we alsogeneralize the classical concepts of local differential privacy, Renyidifferential privacy and the hypothesis testing interpretation to the quantumsetting, providing several new properties and insights.", "output": "Quantum Differential Privacy: An Information Theory Perspective."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine learning models often fail to generalize well under distributionalshifts. Understanding and overcoming these failures have led to a researchfield of Out-of-Distribution (OOD) generalization. Despite being extensivelystudied for static computer vision tasks, OOD generalization has beenunderexplored for time series tasks. To shine light on this gap, we presentWOODS: eight challenging open-source time series benchmarks covering a diverserange of data modalities, such as videos, brain recordings, and sensor signals.We revise the existing OOD generalization algorithms for time series tasks andevaluate them using our systematic framework. Our experiments show a large roomfor improvement for empirical risk minimization and OOD generalizationalgorithms on our datasets, thus underscoring the new challenges posed by timeseries tasks. Code and documentation are available at .", "output": "WOODS: Benchmarks for Out-of-Distribution Generalization in Time Series."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Parametric verification of linear temporal properties for stochastic modelscan be expressed as computing the satisfaction probability of a certainproperty as a function of the parameters of the model. Smoothed model checking(smMC) aims at inferring the satisfaction function over the entire parameterspace from a limited set of observations obtained via simulation. Asobservations are costly and noisy, smMC is framed as a Bayesian inferenceproblem so that the estimates have an additional quantification of theuncertainty. In smMC the authors use Gaussian Processes (GP), inferred by meansof the Expectation Propagation algorithm. This approach provides accuratereconstructions with statistically sound quantification of the uncertainty.However, it inherits the well-known scalability issues of GP. In this paper, weexploit recent advances in probabilistic machine learning to push thislimitation forward, making Bayesian inference of smMC scalable to largerdatasets and enabling its application to models with high dimensional parameterspaces. We propose Stochastic Variational Smoothed Model Checking (SV-smMC), asolution that exploits stochastic variational inference (SVI) to approximatethe posterior distribution of the smMC problem. The strength and flexibility ofSVI make SV-smMC applicable to two alternative probabilistic models: GaussianProcesses (GP) and Bayesian Neural Networks (BNN). The core ingredient of SVIis a stochastic gradient-based optimization that makes inference easilyparallelizable and that enables GPU acceleration. In this paper, we compare theperformances of smMC against those of SV-smMC by looking at the scalability,the computational efficiency and the accuracy of the reconstructed satisfactionfunction.", "output": "Scalable Stochastic Parametric Verification with Stochastic Variational Smoothed Model Checking."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Complex reasoning problems contain states that vary in the computational costrequired to determine a good action plan. Taking advantage of this property, wepropose Adaptive Subgoal Search (AdaSubS), a search method that adaptivelyadjusts the planning horizon. To this end, AdaSubS generates diverse sets ofsubgoals at different distances. A verification mechanism is employed to filterout unreachable subgoals swiftly, allowing to focus on feasible furthersubgoals. In this way, AdaSubS benefits from the efficiency of planning withlonger subgoals and the fine control with the shorter ones, and thus scaleswell to difficult planning problems. We show that AdaSubS significantlysurpasses hierarchical planning algorithms on three complex reasoning tasks:Sokoban, the Rubik's Cube, and inequality proving benchmark INT.", "output": "Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal Search."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Given a graph with partial observations of node features, how can we estimatethe missing features accurately? Feature estimation is a crucial problem foranalyzing real-world graphs whose features are commonly missing during the datacollection process. Accurate estimation not only provides diverse informationof nodes but also supports the inference of graph neural networks that requirethe full observation of node features. However, designing an effective approachfor estimating high-dimensional features is challenging, since it requires anestimator to have large representation power, increasing the risk ofoverfitting. In this work, we propose SVGA (Structured Variational GraphAutoencoder), an accurate method for feature estimation. SVGA applies strongregularization to the distribution of latent variables by structuredvariational inference, which models the prior of variables as Gaussian Markovrandom field based on the graph structure. As a result, SVGA combines theadvantages of probabilistic inference and graph neural networks, achievingstate-of-the-art performance in real datasets.", "output": "Accurate Node Feature Estimation with Structured Variational Graph Autoencoder."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We aim to demonstrate in experiments that our cost sensitive PEGASOS SVMachieves good performance on imbalanced data sets with a Majority to MinorityRatio ranging from 8.6:1 to 130:1 and to ascertain whether the includingintercept (bias), regularization and parameters affects performance on ourselection of datasets. Although many resort to SMOTE methods, we aim for a lesscomputationally intensive method. We evaluate the performance by examining thelearning curves. These curves diagnose whether we overfit or underfit or wechoose over representative or under representative training/test data. We willalso see the background of the hyperparameters versus the test and train errorin validation curves. We benchmark our PEGASOS Cost-Sensitive SVM's results ofDing's LINEAR SVM DECIDL method. He obtained an ROC-AUC of .5 in one dataset.Our work will extend the work of Ding by incorporating kernels into SVM. Wewill use Python rather than MATLAB as python has dictionaries for storing mixeddata types during multi-parameter cross-validation.", "output": "Primal Estimated Subgradient Solver for SVM for Imbalanced Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The stochastic generalised linear bandit is a well-understood model forsequential decision-making problems, with many algorithms achievingnear-optimal regret guarantees under immediate feedback. However, the stringentrequirement for immediate rewards is unmet in many real-world applicationswhere the reward is almost always delayed. We study the phenomenon of delayedrewards in generalised linear bandits in a theoretical manner. We show that anatural adaptation of an optimistic algorithm to the delayed feedback achievesa regret bound where the penalty for the delays is independent of the horizon.This result significantly improves upon existing work, where the best knownregret bound has the delay penalty increasing with the horizon. We verify ourtheoretical results through experiments on simulated data.", "output": "Delayed Feedback in Generalised Linear Bandits Revisited."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We initiate the study of differentially private (DP) estimation with accessto a small amount of public data. For private estimation of d-dimensionalGaussians, we assume that the public data comes from a Gaussian that may havevanishing similarity in total variation distance with the underlying Gaussianof the private data. We show that under the constraints of pure or concentratedDP, d+1 public data samples are sufficient to remove any dependence on therange parameters of the private data distribution from the private samplecomplexity, which is known to be otherwise necessary without public data. Forseparated Gaussian mixtures, we assume that the underlying public and privatedistributions are the same, and we consider two settings: (1) when given adimension-independent amount of public data, the private sample complexity canbe improved polynomially in terms of the number of mixture components, and anydependence on the range parameters of the distribution can be removed in theapproximate DP case; (2) when given an amount of public data linear in thedimension, the private sample complexity can be made independent of rangeparameters even under concentrated DP, and additional improvements can be madeto the overall sample complexity.", "output": "Private Estimation with Public Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Community detection is a classic problem in network science with extensiveapplications in various fields. Among numerous approaches, the most commonmethod is modularity maximization. Despite their design philosophy and wideadoption, heuristic modularity maximization algorithms rarely return an optimalpartition or anything similar. We propose a specialized algorithm, Bayan, whichreturns partitions with a guarantee of either optimality or proximity to anoptimal partition. At the core of the Bayan algorithm is a branch-and-cutscheme that solves an integer programming formulation of the problem tooptimality or approximate it within a factor. We demonstrate Bayan'sdistinctive accuracy and stability over 21 other algorithms in retrievingground-truth communities in synthetic benchmarks and node labels in realnetworks. Bayan is several times faster than open-source and commercial solversfor modularity maximization making it capable of finding optimal partitions forinstances that cannot be optimized by any other existing method. Overall, ourassessments point to Bayan as a suitable choice for exact maximization ofmodularity in networks with up to 3000 edges (in their largest connectedcomponent) and approximating maximum modularity in larger networks on ordinarycomputers.", "output": "The Bayan Algorithm: Detecting Communities in Networks Through Exact and Approximate Optimization of Modularity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Tensegrity robots, composed of rigid rods and flexible cables, exhibit highstrength-to-weight ratios and significant deformations, which enable them tonavigate unstructured terrains and survive harsh impacts. They are hard tocontrol, however, due to high dimensionality, complex dynamics, and a coupledarchitecture. Physics-based simulation is a promising avenue for developinglocomotion policies that can be transferred to real robots. Nevertheless,modeling tensegrity robots is a complex task due to a substantial sim2real gap.To address this issue, this paper describes a Real2Sim2Real (R2S2R) strategyfor tensegrity robots. This strategy is based on a differentiable physicsengine that can be trained given limited data from a real robot. These datainclude offline measurements of physical properties, such as mass and geometryfor various robot components, and the observation of a trajectory using arandom control policy. With the data from the real robot, the engine can beiteratively refined and used to discover locomotion policies that are directlytransferable to the real robot. Beyond the R2S2R pipeline, key contributions ofthis work include computing non-zero gradients at contact points, a lossfunction for matching tensegrity locomotion gaits, and a trajectorysegmentation technique that avoids conflicts in gradient evaluation duringtraining. Multiple iterations of the R2S2R process are demonstrated andevaluated on a real 3-bar tensegrity robot.", "output": "Real2Sim2Real Transfer for Control of Cable-driven Robots via a Differentiable Physics Engine."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Knowing the 3D motions in a dynamic scene is essential to many visionapplications. Recent progress is mainly focused on estimating the activity ofsome specific elements like humans. In this paper, we leverage a neural motionfield for estimating the motion of all points in a multiview setting. Modelingthe motion from a dynamic scene with multiview data is challenging due to theambiguities in points of similar color and points with time-varying color. Wepropose to regularize the estimated motion to be predictable. If the motionfrom previous frames is known, then the motion in the near future should bepredictable. Therefore, we introduce a predictability regularization by firstconditioning the estimated motion on latent embeddings, then by adopting apredictor network to enforce predictability on the embeddings. The proposedframework PREF (Predictability REgularized Fields) achieves on par or betterresults than state-of-the-art neural motion field-based dynamic scenerepresentation methods, while requiring no prior knowledge of the scene.", "output": "PREF: Predictability Regularized Neural Motion Fields."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Gradient Boosting Machines (GBMs) have demonstrated remarkable success insolving diverse problems by utilizing Taylor expansions in functional space.However, achieving a balance between performance and generality has posed achallenge for GBMs. In particular, gradient descent-based GBMs employ thefirst-order Taylor expansion to ensure applicability to all loss functions,while Newton's method-based GBMs use positive Hessian information to achievesuperior performance at the expense of generality. To address this issue, thisstudy proposes a new generic Gradient Boosting Machine called Trust-regionBoosting (TRBoost). In each iteration, TRBoost uses a constrained quadraticmodel to approximate the objective and applies the Trust-region algorithm tosolve it and obtain a new learner. Unlike Newton's method-based GBMs, TRBoostdoes not require the Hessian to be positive definite, thereby allowing it to beapplied to arbitrary loss functions while still maintaining competitiveperformance similar to second-order algorithms. The convergence analysis andnumerical experiments conducted in this study confirm that TRBoost is asgeneral as first-order GBMs and yields competitive results compared tosecond-order GBMs. Overall, TRBoost is a promising approach that balancesperformance and generality, making it a valuable addition to the toolkit ofmachine learning practitioners.", "output": "TRBoost: A Generic Gradient Boosting Machine based on Trust-region Method."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The representation learning problem in the oil &amp; gas industry aims toconstruct a model that provides a representation based on logging data for awell interval. Previous attempts are mainly supervised and focus on similaritytask, which estimates closeness between intervals. We desire to buildinformative representations without using supervised (labelled) data. One ofthe possible approaches is self-supervised learning (SSL). In contrast to thesupervised paradigm, this one requires little or no labels for the data.Nowadays, most SSL approaches are either contrastive or non-contrastive.Contrastive methods make representations of similar (positive) objects closerand distancing different (negative) ones. Due to possible wrong marking ofpositive and negative pairs, these methods can provide an inferior performance.Non-contrastive methods don't rely on such labelling and are widespread incomputer vision. They learn using only pairs of similar objects that are easierto identify in logging data.We are the first to introduce non-contrastive SSL for well-logging data. Inparticular, we exploit Bootstrap Your Own Latent (BYOL) and Barlow Twinsmethods that avoid using negative pairs and focus only on matching positivepairs. The crucial part of these methods is an augmentation strategy. Ouraugmentation strategies and adaption of BYOL and Barlow Twins together allow usto achieve superior quality on clusterization and mostly the best performanceon different classification tasks. Our results prove the usefulness of theproposed non-contrastive self-supervised approaches for representation learningand interval similarity in particular.", "output": "Non-contrastive representation learning for intervals from well logs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The deployment of machine learning classifiers in high-stakes domainsrequires well-calibrated confidence scores for model predictions. In this paperwe introduce the notion of variable-based calibration to characterizecalibration properties of a model with respect to a variable of interest,generalizing traditional score-based metrics such as expected calibration error(ECE). In particular, we find that models with near-perfect ECE can exhibitsignificant miscalibration as a function of features of the data. Wedemonstrate this phenomenon both theoretically and in practice on multiplewell-known datasets, and show that it can persist after the application ofexisting calibration methods. To mitigate this issue, we propose strategies fordetection, visualization, and quantification of variable-based calibrationerror. We then examine the limitations of current score-based calibrationmethods and explore potential modifications. Finally, we discuss theimplications of these findings, emphasizing that an understanding ofcalibration beyond simple aggregate measures is crucial for endeavors such asfairness and model interpretability.", "output": "Variable-Based Calibration for Machine Learning Classifiers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Bridging geometry and topology, curvature is a powerful and expressiveinvariant. While the utility of curvature has been theoretically andempirically confirmed in the context of manifolds and graphs, itsgeneralization to the emerging domain of hypergraphs has remained largelyunexplored. On graphs, the Ollivier-Ricci curvature measures differencesbetween random walks via Wasserstein distances, thus grounding a geometricconcept in ideas from probability theory and optimal transport. We developORCHID, a flexible framework generalizing Ollivier-Ricci curvature tohypergraphs, and prove that the resulting curvatures have favorable theoreticalproperties. Through extensive experiments on synthetic and real-worldhypergraphs from different domains, we demonstrate that ORCHID curvatures areboth scalable and useful to perform a variety of hypergraph tasks in practice.", "output": "Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Bayesian optimization is a coherent, ubiquitous approach to decision-makingunder uncertainty, with applications including multi-arm bandits, activelearning, and black-box optimization. Bayesian optimization selects decisions(i.e. objective function queries) with maximal expected utility with respect tothe posterior distribution of a Bayesian model, which quantifies reducible,epistemic uncertainty about query outcomes. In practice, subjectivelyimplausible outcomes can occur regularly for two reasons: 1) modelmisspecification and 2) covariate shift. Conformal prediction is an uncertaintyquantification method with coverage guarantees even for misspecified models anda simple mechanism to correct for covariate shift. We propose conformalBayesian optimization, which directs queries towards regions of search spacewhere the model predictions have guaranteed validity, and investigate itsbehavior on a suite of black-box optimization tasks and tabular ranking tasks.In many cases we find that query coverage can be significantly improved withoutharming sample-efficiency.", "output": "Bayesian Optimization with Conformal Prediction Sets."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes a vehicular edge federated learning (VEFL) solution,where an edge server leverages highly mobile connected vehicles' (CVs') onboardcentral processing units (CPUs) and local datasets to train a global model.Convergence analysis reveals that the VEFL training loss depends on thesuccessful receptions of the CVs' trained models over the intermittentvehicle-to-infrastructure (V2I) wireless links. Owing to high mobility, in thefull device participation case (FDPC), the edge server aggregates client modelparameters based on a weighted combination according to the CVs' dataset sizesand sojourn periods, while it selects a subset of CVs in the partial deviceparticipation case (PDPC). We then devise joint VEFL and radio accesstechnology (RAT) parameters optimization problems under delay, energy and costconstraints to maximize the probability of successful reception of the locallytrained models. Considering that the optimization problem is NP-hard, wedecompose it into a VEFL parameter optimization sub-problem, given theestimated worst-case sojourn period, delay and energy expense, and an onlineRAT parameter optimization sub-problem. Finally, extensive simulations areconducted to validate the effectiveness of the proposed solutions with apractical 5G new radio (5G-NR) RAT under a realistic microscopic mobilitymodel.", "output": "Resource Constrained Vehicular Edge Federated Learning with Highly Mobile Connected Vehicles."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Binary code similarity detection (BCSD) is widely used in various binaryanalysis tasks such as vulnerability search, malware detection, clonedetection, and patch analysis. Recent studies have shown that thelearning-based binary code embedding models perform better than the traditionalfeature-based approaches. In this paper, we propose a novel transformer-basedbinary code embedding model named UniASM to learn representations of the binaryfunctions. We design two new training tasks to make the spatial distribution ofthe generated vectors more uniform, which can be used directly in BCSD withoutany fine-tuning. In addition, we present a new tokenization approach for binaryfunctions, which increases the token's semantic information and mitigates theout-of-vocabulary (OOV) problem. We conduct an in-depth analysis of the factorsaffecting model performance through ablation experiments and obtain some newand valuable findings. The experimental results show that UniASM outperformsthe state-of-the-art (SOTA) approach on the evaluation dataset. The averagescores of Recall@1 on cross-compilers, cross-optimization levels, andcross-obfuscations are 0.77, 0.72, and 0.72. Besides, in the real-world task ofknown vulnerability search, UniASM outperforms all the current baselines.", "output": "UniASM: Binary Code Similarity Detection without Fine-tuning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We consider the problem of predictive monitoring (PM), i.e., predicting atruntime the satisfaction of a desired property from the current system's state.Due to its relevance for runtime safety assurance and online control, PMmethods need to be efficient to enable timely interventions against predictedviolations, while providing correctness guarantees. We introducetextit{quantitative predictive monitoring (QPM)}, the first PM method tosupport stochastic processes and rich specifications given in Signal TemporalLogic (STL). Unlike most of the existing PM techniques that predict whether ornot some property $phi$ is satisfied, QPM provides a quantitative measure ofsatisfaction by predicting the quantitative (aka robust) STL semantics of$phi$. QPM derives prediction intervals that are highly efficient to computeand with probabilistic guarantees, in that the intervals cover with arbitraryprobability the STL robustness values relative to the stochastic evolution ofthe system. To do so, we take a machine-learning approach and leverage recentadvances in conformal inference for quantile regression, thereby avoidingexpensive Monte-Carlo simulations at runtime to estimate the intervals. We alsoshow how our monitors can be combined in a compositional manner to handlecomposite formulas, without retraining the predictors nor sacrificing theguarantees. We demonstrate the effectiveness and scalability of QPM over abenchmark of four discrete-time stochastic processes with varying degrees ofcomplexity.", "output": "Conformal Quantitative Predictive Monitoring of STL Requirements for Stochastic Processes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper considers the problem of data-driven prediction of partiallyobserved systems using a recurrent neural network. While neural network baseddynamic predictors perform well with full-state training data, prediction withpartial observation during training phase poses a significant challenge. Here apredictor for partial observations is developed using an echo-state network(ESN) and time delay embedding of the partially observed state. The proposedmethod is theoretically justified with Taken's embedding theorem and strongobservability of a nonlinear system. The efficacy of the proposed method isdemonstrated on three systems: two synthetic datasets from chaotic dynamicalsystems and a set of real-time traffic data.", "output": "Delay Embedded Echo-State Network: A Predictor for Partially Observed Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A significant portion of the effort involved in advanced process control,process analytics, and machine learning involves acquiring and preparing data.Literature often emphasizes increasingly complex modelling techniques withincremental performance improvements. However, when industrial case studies arepublished they often lack important details on data acquisition andpreparation. Although data pre-processing is unfairly maligned as trivial andtechnically uninteresting, in practice it has an out-sized influence on thesuccess of real-world artificial intelligence applications. This work describesbest practices for acquiring and preparing operating data to pursue data-drivenmodelling and control opportunities in industrial processes. We presentpractical considerations for pre-processing industrial time series data toinform the efficient development of reliable soft sensors that provide valuableprocess insights.", "output": "Data Quality Over Quantity: Pitfalls and Guidelines for Process Analytics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Collaborative filtering is one of the most fundamental topics for recommendersystems. Various methods have been proposed for collaborative filtering,ranging from matrix factorization to graph convolutional methods. Beinginspired by recent successes of graph filtering-based methods and score-basedgenerative models (SGMs), we present a novel concept of blurring-sharpeningprocess model (BSPM). SGMs and BSPMs share the same processing philosophy thatnew information can be discovered (e.g., new images are generated in the caseof SGMs) while original information is first perturbed and then recovered toits original form. However, SGMs and our BSPMs deal with different types ofinformation, and their optimal perturbation and recovery processes havefundamental discrepancies. Therefore, our BSPMs have different forms from SGMs.In addition, our concept not only theoretically subsumes many existingcollaborative filtering models but also outperforms them in terms of Recall andNDCG in the three benchmark datasets, Gowalla, Yelp2018, and Amazon-book. Inaddition, the processing time of our method is comparable to other fastbaselines. Our proposed concept has much potential in the future to be enhancedby designing better blurring (i.e., perturbation) and sharpening (i.e.,recovery) processes than what we use in this paper.", "output": "Blurring-Sharpening Process Models for Collaborative Filtering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Skin cancer is a fatal disease that takes a heavy toll over human livesannually. The colored skin images show a significant degree of resemblancebetween different skin lesions such as melanoma and nevus, makingidentification and diagnosis more challenging. Melanocytic nevi may mature tocause fatal melanoma. Therefore, the current management protocol involves theremoval of those nevi that appear intimidating. However, this necessitatesresilient classification paradigms for classifying benign and malignantmelanocytic nevi. Early diagnosis necessitates a dependable automated systemfor melanocytic nevi classification to render diagnosis efficient, timely, andsuccessful. An automated classification algorithm is proposed in the givenresearch. A neural network previously-trained on a separate problem statementis leveraged in this technique for classifying melanocytic nevus images. Thesuggested method uses BigTransfer (BiT), a ResNet-based transfer learningapproach for classifying melanocytic nevi as malignant or benign. The resultsobtained are compared to that of current techniques, and the new method'sclassification rate is proven to outperform that of existing methods.", "output": "Classification of Melanocytic Nevus Images using BigTransfer (BiT)."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pareto Front Learning (PFL) was recently introduced as an effective approachto obtain a mapping function from a given trade-off vector to a solution on thePareto front, which solves the multi-objective optimization (MOO) problem. Dueto the inherent trade-off between conflicting objectives, PFL offers a flexibleapproach in many scenarios in which the decision makers can not specify thepreference of one Pareto solution over another, and must switch between themdepending on the situation. However, existing PFL methods ignore therelationship between the solutions during the optimization process, whichhinders the quality of the obtained front. To overcome this issue, we propose anovel PFL framework namely PHN-HVI, which employs a hypernetwork to generatemultiple solutions from a set of diverse trade-off preferences and enhance thequality of the Pareto front by maximizing the Hypervolume indicator defined bythese solutions. The experimental results on several MOO machine learning tasksshow that the proposed framework significantly outperforms the baselines inproducing the trade-off Pareto front.", "output": "Improving Pareto Front Learning via Multi-Sample Hypernetworks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Scenario-based probabilistic forecasts have become vital for decision-makersin handling intermittent renewable energies. This paper presents a recentpromising deep learning generative approach called denoising diffusionprobabilistic models. It is a class of latent variable models which haverecently demonstrated impressive results in the computer vision community.However, to our knowledge, there has yet to be a demonstration that they cangenerate high-quality samples of load, PV, or wind power time series, crucialelements to face the new challenges in power systems applications. Thus, wepropose the first implementation of this model for energy forecasting using theopen data of the Global Energy Forecasting Competition 2014. The resultsdemonstrate this approach is competitive with other state-of-the-art deeplearning generative models, including generative adversarial networks,variational autoencoders, and normalizing flows.", "output": "Denoising diffusion probabilistic models for probabilistic energy forecasting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision Transformers (ViTs) have gained significant popularity in recent yearsand have proliferated into many applications. However, their behavior underdifferent learning paradigms is not well explored. We compare ViTs trainedthrough different methods of supervision, and show that they learn a diverserange of behaviors in terms of their attention, representations, and downstreamperformance. We also discover ViT behaviors that are consistent acrosssupervision, including the emergence of Offset Local Attention Heads. These areself-attention heads that attend to a token adjacent to the current token witha fixed directional offset, a phenomenon that to the best of our knowledge hasnot been highlighted in any prior work. Our analysis shows that ViTs are highlyflexible and learn to process local and global information in different ordersdepending on their training method. We find that contrastive self-supervisedmethods learn features that are competitive with explicitly supervisedfeatures, and they can even be superior for part-level tasks. We also find thatthe representations of reconstruction-based models show non-trivial similarityto contrastive self-supervised models. Project website( and code( are publicly available.", "output": "Teaching Matters: Investigating the Role of Supervision in Vision Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fine-tuning pre-trained language models has become the prevalent paradigm forbuilding downstream NLP models. Oftentimes fine-tuned models are readilyavailable but their training data is not, due to data privacy or intellectualproperty concerns. This creates a barrier to fusing knowledge across individualmodels to yield a better single model. In this paper, we study the problem ofmerging individual models built on different training data sets to obtain asingle model that performs well both across all data set domains and cangeneralize on out-of-domain data. We propose a dataless knowledge fusion methodthat merges models in their parameter space, guided by weights that minimizeprediction differences between the merged model and the individual models. Overa battery of evaluation settings, we show that the proposed methodsignificantly outperforms baselines such as Fisher-weighted averaging or modelensembling. Further, we find that our method is a promising alternative tomulti-task learning that can preserve or sometimes improve over the individualmodels without access to the training data. Finally, model merging is moreefficient than training a multi-task model, thus making it applicable to awider set of scenarios.", "output": "Dataless Knowledge Fusion by Merging Weights of Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a new algorithm for automatically bounding the Taylor remainderseries. In the special case of a scalar function $f: mathbb{R} tomathbb{R}$, our algorithm takes as input a reference point $x_0$, trust region$[a, b]$, and integer $k ge 1$, and returns an interval $I$ such that $f(x) -sum_{i=0}^{k-1} frac {1} {i!} f^{(i)}(x_0) (x - x_0)^i in I (x - x_0)^k$ forall $x in [a, b]$. As in automatic differentiation, the function $f$ isprovided to the algorithm in symbolic form, and must be composed of knownatomic functions.At a high level, our algorithm has two steps. First, for a variety ofcommonly-used elementary functions (e.g., $exp$, $log$), we derive sharppolynomial upper and lower bounds on the Taylor remainder series. We thenrecursively combine the bounds for the elementary functions using an intervalarithmetic variant of Taylor-mode automatic differentiation. Our algorithm canmake efficient use of machine learning hardware accelerators, and we provide anopen source implementation in JAX.We then turn our attention to applications. Most notably, we use our newmachinery to create the first universal majorization-minimization optimizationalgorithms: algorithms that iteratively minimize an arbitrary loss using amajorizer that is derived automatically, rather than by hand. Applied tomachine learning, this leads to architecture-specific optimizers for trainingdeep networks that converge from any starting point, without hyperparametertuning. Our experiments show that for some optimization problems, thesehyperparameter-free optimizers outperform tuned versions of gradient descent,Adam, and AdaGrad. We also show that our automatically-derived bounds can beused for verified global optimization and numerical integration, and to provesharper versions of Jensen's inequality.", "output": "Automatically Bounding the Taylor Remainder Series: Tighter Bounds and New Applications."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We explore the ability of overparameterized shallow ReLU neural networks tolearn Lipschitz, nondifferentiable, bounded functions with additive noise whentrained by Gradient Descent (GD). To avoid the problem that in the presence ofnoise, neural networks trained to nearly zero training error are inconsistentin this class, we focus on the early-stopped GD which allows us to showconsistency and optimal rates. In particular, we explore this problem from theviewpoint of the Neural Tangent Kernel (NTK) approximation of a GD-trainedfinite-width neural network. We show that whenever some early stopping rule isguaranteed to give an optimal rate (of excess risk) on the Hilbert space of thekernel induced by the ReLU activation function, the same rule can be used toachieve minimax optimal rate for learning on the class of considered Lipschitzfunctions by neural networks. We discuss several data-free and data-dependentpractically appealing stopping rules that yield optimal rates.", "output": "Learning Lipschitz Functions by GD-trained Shallow Overparameterized ReLU Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vocal Bursts -- short, non-speech vocalizations that convey emotions, such aslaughter, cries, sighs, moans, and groans -- are an often-overlooked aspect ofspeech emotion recognition, but an important aspect of human vocalcommunication. One barrier to study of these interesting vocalizations is alack of large datasets. I am pleased to introduce the EmoGator dataset, whichconsists of 32,130 samples from 357 speakers, 16.9654 hours of audio; eachsample classified into one of 30 distinct emotion categories by the speaker.Several different approaches to construct classifiers to identify emotioncategories will be discussed, and directions for future research will besuggested. Data set is available for download from", "output": "EmoGator: A New Open Source Vocal Burst Dataset with Baseline Machine Learning Classification Methodologies."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Carefully designed activation functions can improve the performance of neuralnetworks in many machine learning tasks. However, it is difficult for humans toconstruct optimal activation functions, and current activation function searchalgorithms are prohibitively expensive. This paper aims to improve the state ofthe art through three steps: First, the benchmark datasets Act-Bench-CNN,Act-Bench-ResNet, and Act-Bench-ViT were created by training convolutional,residual, and vision transformer architectures from scratch with 2,913systematically generated activation functions. Second, a characterization ofthe benchmark space was developed, leading to a new surrogate-based method foroptimization. More specifically, the spectrum of the Fisher information matrixassociated with the model's predictive distribution at initialization and theactivation function's output distribution were found to be highly predictive ofperformance. Third, the surrogate was used to discover improved activationfunctions in CIFAR-100 and ImageNet tasks. Each of these steps is acontribution in its own right; together they serve as a practical andtheoretical foundation for further research on activation functionoptimization. Code is available at and the benchmark datasets areat ", "output": "Efficient Activation Function Optimization through Surrogate Modeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The Gaussian process state-space model (GPSSM) has garnered considerableattention over the past decade. However, the standard GP with a preliminarykernel, such as the squared exponential kernel or Mat'{e}rn kernel, that iscommonly used in GPSSM studies, limits the model's representation power andsubstantially restricts its applicability to complex scenarios. To address thisissue, we propose a new class of probabilistic state-space models calledTGPSSMs, which leverage a parametric normalizing flow to enrich the GP priorsin the standard GPSSM, enabling greater flexibility and expressivity.Additionally, we present a scalable variational inference algorithm that offersa flexible and optimal structure for the variational distribution of latentstates. The proposed algorithm is interpretable and computationally efficientdue to the sparse GP representation and the bijective nature of normalizingflow. Moreover, we incorporate a constrained optimization framework into thealgorithm to enhance the state-space representation capabilities and optimizethe hyperparameters, leading to superior learning and inference performance.Experimental results on synthetic and real datasets corroborate that theproposed TGPSSM outperforms several state-of-the-art methods. The accompanyingsource code is available at url{", "output": "Towards Flexibility and Interpretability of Gaussian Process State-Space Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Language Models (LMs) have been shown to leak information about training datathrough sentence-level membership inference and reconstruction attacks.Understanding the risk of LMs leaking Personally Identifiable Information (PII)has received less attention, which can be attributed to the false assumptionthat dataset curation techniques such as scrubbing are sufficient to preventPII leakage. Scrubbing techniques reduce but do not prevent the risk of PIIleakage: in practice scrubbing is imperfect and must balance the trade-offbetween minimizing disclosure and preserving the utility of the dataset. On theother hand, it is unclear to which extent algorithmic defenses such asdifferential privacy, designed to guarantee sentence- or user-level privacy,prevent PII disclosure. In this work, we introduce rigorous game-baseddefinitions for three types of PII leakage via black-box extraction, inference,and reconstruction attacks with only API access to an LM. We empiricallyevaluate the attacks against GPT-2 models fine-tuned with and without defensesin three domains: case law, health care, and e-mails. Our main contributionsare (i) novel attacks that can extract up to 10$times$ more PII sequences thanexisting attacks, (ii) showing that sentence-level differential privacy reducesthe risk of PII disclosure but still leaks about 3% of PII sequences, and (iii)a subtle connection between record-level membership inference and PIIreconstruction. Code to reproduce all experiments in the paper is available at", "output": "Analyzing Leakage of Personally Identifiable Information in Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automation of test oracles is one of the most challenging facets of softwaretesting, but remains comparatively less addressed compared to automated testinput generation. Test oracles rely on a ground-truth that can distinguishbetween the correct and buggy behavior to determine whether a test fails(detects a bug) or passes. What makes the oracle problem challenging andundecidable is the assumption that the ground-truth should know the exactexpected, correct, or buggy behavior. However, we argue that one can stillbuild an accurate oracle without knowing the exact correct or buggy behavior,but how these two might differ. This paper presents SEER, a learning-basedapproach that in the absence of test assertions or other types of oracle, candetermine whether a unit test passes or fails on a given method under test(MUT). To build the ground-truth, SEER jointly embeds unit tests and theimplementation of MUTs into a unified vector space, in such a way that theneural representation of tests are similar to that of MUTs they pass on them,but dissimilar to MUTs they fail on them. The classifier built on top of thisvector representation serves as the oracle to generate \"fail\" labels, when testinputs detect a bug in MUT or \"pass\" labels, otherwise. Our extensiveexperiments on applying SEER to more than 5K unit tests from a diverse set ofopen-source Java projects show that the produced oracle is (1) effective inpredicting the fail or pass labels, achieving an overall accuracy, precision,recall, and F1 measure of 93%, 86%, 94%, and 90%, (2) generalizable, predictingthe labels for the unit test of projects that were not in training orvalidation set with negligible performance drop, and (3) efficient, detectingthe existence of bugs in only 6.5 milliseconds on average.", "output": "Perfect is the enemy of test oracle."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The rapid progress in technology innovation usage and distribution hasincreased in the last decade. The rapid growth of the Internet of Things (IoT)systems worldwide has increased network security challenges created bymalicious third parties. Thus, reliable intrusion detection and networkforensics systems that consider security concerns and IoT systems limitationsare essential to protect such systems. IoT botnet attacks are one of thesignificant threats to enterprises and individuals. Thus, this paper proposedan economic deep learning-based model for detecting IoT botnet attacks alongwith different types of attacks. The proposed model achieved higher accuracythan the state-of-the-art detection models using a smaller implementationbudget and accelerating the training and detecting processes.", "output": "IoT Botnet Detection Using an Economic Deep Learning Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, deep network pruning has attracted significant attention inorder to enable the rapid deployment of AI into small devices with computationand memory constraints. Pruning is often achieved by dropping redundantweights, neurons, or layers of a deep network while attempting to retain acomparable test performance. Many deep pruning algorithms have been proposedwith impressive empirical success. However, existing approaches lack aquantifiable measure to estimate the compressibility of a sub-network duringeach pruning iteration and thus may under-prune or over-prune the model. Inthis work, we propose PQ Index (PQI) to measure the potential compressibilityof deep neural networks and use this to develop a Sparsity-informed AdaptivePruning (SAP) algorithm. Our extensive experiments corroborate the hypothesisthat for a generic pruning procedure, PQI decreases first when a large model isbeing effectively regularized and then increases when its compressibilityreaches a limit that appears to correspond to the beginning of underfitting.Subsequently, PQI decreases again when the model collapse and significantdeterioration in the performance of the model start to occur. Additionally, ourexperiments demonstrate that the proposed adaptive pruning algorithm withproper choice of hyper-parameters is superior to the iterative pruningalgorithms such as the lottery ticket-based pruning methods, in terms of bothcompression efficiency and robustness.", "output": "Pruning Deep Neural Networks from a Sparsity Perspective."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Poverty maps are essential tools for governments and NGOs to tracksocioeconomic changes and adequately allocate infrastructure and services inplaces in need. Sensor and online crowd-sourced data combined with machinelearning methods have provided a recent breakthrough in poverty map inference.However, these methods do not capture local wealth fluctuations, and are notoptimized to produce accountable results that guarantee accurate predictions toall sub-populations. Here, we propose a pipeline of machine learning models toinfer the mean and standard deviation of wealth across multiple geographicallyclustered populated places, and illustrate their performance in Sierra Leoneand Uganda. These models leverage seven independent and freely availablefeature sources based on satellite images, and metadata collected via onlinecrowd-sourcing and social media. Our models show that combined metadatafeatures are the best predictors of wealth in rural areas, outperformingimage-based models, which are the best for predicting the highest wealthquintiles. Our results recover the local mean and variation of wealth, andcorrectly capture the positive yet non-monotonous correlation between them. Wefurther demonstrate the capabilities and limitations of model transfer acrosscountries and the effects of data recency and other biases. Our methodologyprovides open tools to build towards more transparent and interpretable modelsto help governments and NGOs to make informed decisions based on dataavailability, urbanization level, and poverty thresholds.", "output": "Interpreting wealth distribution via poverty map inference using multimodal data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine Learning (ML) techniques can facilitate the automation of malicioussoftware (malware for short) detection, but suffer from evasion attacks. Manystudies counter such attacks in heuristic manners, lacking theoreticalguarantees and defense effectiveness. In this paper, we propose a newadversarial training framework, termed Principled Adversarial Malware Detection(PAD), which offers convergence guarantees for robust optimization methods. PADlays on a learnable convex measurement that quantifies distribution-wisediscrete perturbations to protect malware detectors from adversaries, wherebyfor smooth detectors, adversarial training can be performed with theoreticaltreatments. To promote defense effectiveness, we propose a new mixture ofattacks to instantiate PAD to enhance deep neural network-based measurementsand malware detectors. Experimental results on two Android malware datasetsdemonstrate: (i) the proposed method significantly outperforms thestate-of-the-art defenses; (ii) it can harden ML-based malware detectionagainst 27 evasion attacks with detection accuracies greater than 83.45%, atthe price of suffering an accuracy decrease smaller than 2.16% in the absenceof attacks; (iii) it matches or outperforms many anti-malware scanners inVirusTotal against realistic adversarial malware.", "output": "PAD: Towards Principled Adversarial Malware Detection Against Evasion Attacks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we present AR3n (pronounced as Aaron), an assist-as-needed(AAN) controller that utilizes reinforcement learning to supply adaptiveassistance during a robot assisted handwriting rehabilitation task. Unlikeprevious AAN controllers, our method does not rely on patient specificcontroller parameters or physical models. We propose the use of a virtualpatient model to generalize AR3n across multiple subjects. The system modulatesrobotic assistance in realtime based on a subject's tracking error, whileminimizing the amount of robotic assistance. The controller is experimentallyvalidated through a set of simulations and human subject experiments. Finally,a comparative study with a traditional rule-based controller is conducted toanalyze differences in assistance mechanisms of the two controllers.", "output": "AR3n: A Reinforcement Learning-based Assist-As-Needed Controller for Robotic Rehabilitation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Prediction of taxi service demand and supply is essential for improvingcustomer's experience and provider's profit. Recently, graph neural networks(GNNs) have been shown promising for this application. This approach modelscity regions as nodes in a transportation graph and their relations as edges.GNNs utilize local node features and the graph structure in the prediction.However, more efficient forecasting can still be achieved by following two mainroutes; enlarging the scale of the transportation graph, and simultaneouslyexploiting different types of nodes and edges in the graphs. However, bothapproaches are challenged by the scalability of GNNs. An immediate remedy tothe scalability challenge is to decentralize the GNN operation. However, thiscreates excessive node-to-node communication. In this paper, we firstcharacterize the excessive communication needs for the decentralized GNNapproach. Then, we propose a semi-decentralized approach utilizing multiplecloudlets, moderately sized storage and computation devices, that can beintegrated with the cellular base stations. This approach minimizesinter-cloudlet communication thereby alleviating the communication overhead ofthe decentralized approach while promoting scalability due to cloudlet-leveldecentralization. Also, we propose a heterogeneous GNN-LSTM algorithm forimproved taxi-level demand and supply forecasting for handling dynamic taxigraphs where nodes are taxis. Extensive experiments over real data show theadvantage of the semi-decentralized approach as tested over our heterogeneousGNN-LSTM algorithm. Also, the proposed semi-decentralized GNN approach is shownto reduce the overall inference time by about an order of magnitude compared tocentralized and decentralized inference schemes.", "output": "Semi-decentralized Inference in Heterogeneous Graph Neural Networks for Traffic Demand Forecasting: An Edge-Computing Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Sampling from Gibbs distributions $p(x) propto exp(-V(x)/varepsilon)$ andcomputing their log-partition function are fundamental tasks in statistics,machine learning, and statistical physics. However, while efficient algorithmsare known for convex potentials $V$, the situation is much more difficult inthe non-convex case, where algorithms necessarily suffer from the curse ofdimensionality in the worst case. For optimization, which can be seen as alow-temperature limit of sampling, it is known that smooth functions $V$ allowfaster convergence rates. Specifically, for $m$-times differentiable functionsin $d$ dimensions, the optimal rate for algorithms with $n$ functionevaluations is known to be $O(n^{-m/d})$, where the constant can potentiallydepend on $m, d$ and the function to be optimized. Hence, the curse ofdimensionality can be alleviated for smooth functions at least in terms of theconvergence rate. Recently, it has been shown that similarly fast rates canalso be achieved with polynomial runtime $O(n^{3.5})$, where the exponent $3.5$is independent of $m$ or $d$. Hence, it is natural to ask whether similar ratesfor sampling and log-partition computation are possible, and whether they canbe realized in polynomial time with an exponent independent of $m$ and $d$. Weshow that the optimal rates for sampling and log-partition computation aresometimes equal and sometimes faster than for optimization. We then analyzevarious polynomial-time sampling algorithms, including an extension of a recentpromising optimization approach, and find that they sometimes exhibitinteresting behavior but no near-optimal rates. Our results also give furtherinsights on the relation between sampling, log-partition, and optimizationproblems.", "output": "Convergence Rates for Non-Log-Concave Sampling and Log-Partition Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in digitization have led to the availability of multivariatetime series data in various domains, enabling real-time monitoring ofoperations. Identifying abnormal data patterns and detecting potential failuresin these scenarios are important yet rather challenging. In this work, wepropose a novel unsupervised anomaly detection method for time series data. Theproposed framework jointly learns the observation model and the dynamic model,and model uncertainty is estimated from normal samples. Specifically, a longshort-term memory (LSTM)-based encoder-decoder is adopted to represent themapping between the observation space and the latent space. Bidirectionaltransitions of states are simultaneously modeled by leveraging backward andforward temporal information. Regularization of the latent space placesconstraints on the states of normal samples, and Mahalanobis distance is usedto evaluate the abnormality level. Empirical studies on synthetic andreal-world datasets demonstrate the superior performance of the proposed methodin anomaly detection tasks.", "output": "Time series anomaly detection with reconstruction-based state-space models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents a mathematical analysis of ODE-Net, a continuum model ofdeep neural networks (DNNs). In recent years, Machine Learning researchers haveintroduced ideas of replacing the deep structure of DNNs with ODEs as acontinuum limit. These studies regard the \"learning\" of ODE-Net as theminimization of a \"loss\" constrained by a parametric ODE. Although theexistence of a minimizer for this minimization problem needs to be assumed,only a few studies have investigated its existence analytically in detail. Inthe present paper, the existence of a minimizer is discussed based on aformulation of ODE-Net as a measure-theoretic mean-field optimal controlproblem. The existence result is proved when a neural network, which describesa vector field of ODE-Net, is linear with respect to learnable parameters. Theproof employs the measure-theoretic formulation combined with the direct methodof Calculus of Variations. Secondly, an idealized minimization problem isproposed to remove the above linearity assumption. Such a problem is inspiredby a kinetic regularization associated with the Benamou--Brenier formula anduniversal approximation theorems for neural networks. The proofs of theseexistence results use variational methods, differential equations, andmean-field optimal control theory. They will stand for a new analytic way toinvestigate the learning process of deep neural networks.", "output": "Variational formulations of ODE-Net as a mean-field optimal control problem and existence results."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Temporal data, representing chronological observations of complex systems,has always been a typical data structure that can be widely generated by manydomains, such as industry, medicine and finance. Analyzing this type of data isextremely valuable for various applications. Thus, different temporal dataanalysis tasks, eg, classification, clustering and prediction, have beenproposed in the past decades. Among them, causal discovery, learning the causalrelations from temporal data, is considered an interesting yet critical taskand has attracted much research attention. Existing casual discovery works canbe divided into two highly correlated categories according to whether thetemporal data is calibrated, ie, multivariate time series casual discovery, andevent sequence casual discovery. However, most previous surveys are onlyfocused on the time series casual discovery and ignore the second category. Inthis paper, we specify the correlation between the two categories and provide asystematical overview of existing solutions. Furthermore, we provide publicdatasets, evaluation metrics and new perspectives for temporal data casualdiscovery.", "output": "Causal Discovery from Temporal Data: An Overview and New Perspectives."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study presents a novel model for invertible sentence embeddings using aresidual recurrent network trained on an unsupervised encoding task. Ratherthan the probabilistic outputs common to neural machine translation models, ourapproach employs a regression-based output layer to reconstruct the inputsequence's word vectors. The model achieves high accuracy and fast trainingwith the ADAM optimizer, a significant finding given that RNNs typicallyrequire memory units, such as LSTMs, or second-order optimization methods. Weincorporate residual connections and introduce a \"match drop\" technique, wheregradients are calculated only for incorrect words. Our approach demonstratespotential for various natural language processing applications, particularly inneural network-based systems that require high-quality sentence embeddings.", "output": "Return of the RNN: Residual Recurrent Networks for Invertible Sentence Embeddings."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The Outstanding performance and growing size of Large Language Models has ledto increased attention in parameter efficient learning. The two predominantapproaches are Adapters and Pruning. Adapters are to freeze the model and giveit a new weight matrix on the side, which can significantly reduce the time andmemory of training, but the cost is that the evaluation and testing willincrease the time and memory consumption. Pruning is to cut off some weight andre-distribute the remaining weight, which sacrifices the complexity of trainingat the cost of extremely high memory and training time, making the cost ofevaluation and testing relatively low. So efficiency of training and inferencecan't be obtained in the same time. In this work, we propose a task-orientedPruning-Adapter method that achieve a high memory efficiency of training andmemory, and speeds up training time and ensures no significant decrease inaccuracy in GLUE tasks, achieving training and inference efficiency at the sametime.", "output": "Task-oriented Memory-efficient Pruning-Adapter."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image-to-image translation (I2I) methods allow the generation of artificialimages that share the content of the original image but have a different style.With the advances in Generative Adversarial Networks (GANs)-based methods, I2Imethods enabled the generation of artificial images that are indistinguishablefrom natural images. Recently, I2I methods were also employed in histopathologyfor generating artificial images of in silico stained tissues from a differenttype of staining. We refer to this process as stain transfer. The number of I2Ivariants is constantly increasing, which makes a well justified choice of themost suitable I2I methods for stain transfer challenging. In our work, wecompare twelve stain transfer approaches, three of which are based ontraditional and nine on GAN-based image processing methods. The analysis relieson complementary quantitative measures for the quality of image translation,the assessment of the suitability for deep learning-based tissue grading, andthe visual evaluation by pathologists. Our study highlights the strengths andweaknesses of the stain transfer approaches, thereby allowing a rational choiceof the underlying I2I algorithms. Code, data, and trained models for staintransfer between H&amp;E and Masson's Trichrome staining will be made availableonline.", "output": "A comparative evaluation of image-to-image translation methods for stain transfer in histopathology."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The advancement of Virtual Reality (VR) technology is focused on improvingits immersiveness, supporting multiuser Virtual Experiences (VEs), and enablingthe users to move freely within their VEs while still being confined withinspecialized VR setups through Redirected Walking (RDW). To meet their extremedata-rate and latency requirements, future VR systems will require supportingwireless networking infrastructures operating in millimeter Wave (mmWave)frequencies that leverage highly directional communication in both transmissionand reception through beamforming and beamsteering. We propose the use ofpredictive context-awareness to optimize transmitter and receiver-sidebeamforming and beamsteering. By predicting users' short-term lateral movementsin multiuser VR setups with Redirected Walking (RDW), transmitter-sidebeamforming and beamsteering can be optimized through Line-of-Sight (LoS)\"tracking\" in the users' directions. At the same time, predictions ofshort-term orientational movements can be utilized for receiver-sidebeamforming for coverage flexibility enhancements. We target two open problemsin predicting these two context information instances: i) predicting lateralmovements in multiuser VR settings with RDW, and ii) generating synthetic headrotation datasets for training orientational movements predictors. Ourexperimental results demonstrate that Long Short-Term Memory (LSTM) networksfeature promising accuracy in predicting lateral movements, andcontext-awareness stemming from VEs further enhances this accuracy.Additionally, we show that a TimeGAN-based approach for orientational datageneration can create synthetic samples that closely match experimentallyobtained ones.", "output": "Predictive Context-Awareness for Full-Immersive Multiuser Virtual Reality with Redirected Walking."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fast adversarial training (FAT) is an efficient method to improve robustness.However, the original FAT suffers from catastrophic overfitting, whichdramatically and suddenly reduces robustness after a few training epochs.Although various FAT variants have been proposed to prevent overfitting, theyrequire high training costs. In this paper, we investigate the relationshipbetween adversarial example quality and catastrophic overfitting by comparingthe training processes of standard adversarial training and FAT. We find thatcatastrophic overfitting occurs when the attack success rate of adversarialexamples becomes worse. Based on this observation, we propose a positiveprior-guided adversarial initialization to prevent overfitting by improvingadversarial example quality without extra training costs. This initializationis generated by using high-quality adversarial perturbations from thehistorical training process. We provide theoretical analysis for the proposedinitialization and propose a prior-guided regularization method that boosts thesmoothness of the loss function. Additionally, we design a prior-guidedensemble FAT method that averages the different model weights of historicalmodels using different decay rates. Our proposed method, called FGSM-PGK,assembles the prior-guided knowledge, i.e., the prior-guided initialization andmodel weights, acquired during the historical training process. Evaluations offour datasets demonstrate the superiority of the proposed method.", "output": "Improving Fast Adversarial Training with Prior-Guided Knowledge."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This report serves as a supplementary document for TaskPrompter, detailingits implementation on a new joint 2D-3D multi-task learning benchmark based onCityscapes-3D. TaskPrompter presents an innovative multi-task promptingframework that unifies the learning of (i) task-generic representations, (ii)task-specific representations, and (iii) cross-task interactions, as opposed toprevious approaches that separate these learning objectives into differentnetwork modules. This unified approach not only reduces the need for meticulousempirical structure design but also significantly enhances the multi-tasknetwork's representation learning capability, as the entire model capacity isdevoted to optimizing the three objectives simultaneously. TaskPrompterintroduces a new multi-task benchmark based on Cityscapes-3D dataset, whichrequires the multi-task model to concurrently generate predictions formonocular 3D vehicle detection, semantic segmentation, and monocular depthestimation. These tasks are essential for achieving a joint 2D-3D understandingof visual scenes, particularly in the development of autonomous drivingsystems. On this challenging benchmark, our multi-task model demonstratesstrong performance compared to single-task state-of-the-art methods andestablishes new state-of-the-art results on the challenging 3D detection anddepth estimation tasks.", "output": "Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Symbolic regression searches for analytic expressions that accuratelydescribe studied phenomena. The main attraction of this approach is that itreturns an interpretable model that can be insightful to users. Historically,the majority of algorithms for symbolic regression have been based onevolutionary algorithms. However, there has been a recent surge of newproposals that instead utilize approaches such as enumeration algorithms, mixedlinear integer programming, neural networks, and Bayesian optimization. Inorder to assess how well these new approaches behave on a set of commonchallenges often faced in real-world data, we hosted a competition at the 2022Genetic and Evolutionary Computation Conference consisting of differentsynthetic and real-world datasets which were blind to entrants. For thereal-world track, we assessed interpretability in a realistic way by using adomain expert to judge the trustworthiness of candidate models.We present anin-depth analysis of the results obtained in this competition, discuss currentchallenges of symbolic regression algorithms and highlight possibleimprovements for future competitions.", "output": "Interpretable Symbolic Regression for Data Science: Analysis of the 2022 Competition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural networks (NNs) playing the role of controllers have demonstratedimpressive empirical performances on challenging control problems. However, thepotential adoption of NN controllers in real-life applications also gives riseto a growing concern over the safety of these neural-network controlled systems(NNCSs), especially when used in safety-critical applications. In this work, wepresent POLAR-Express, an efficient and precise formal reachability analysistool for verifying the safety of NNCSs. POLAR-Express uses Taylor modelarithmetic to propagate Taylor models (TMs) across a neural networklayer-by-layer to compute an overapproximation of the neural-network function.It can be applied to analyze any feed-forward neural network with continuousactivation functions. We also present a novel approach to propagate TMs moreefficiently and precisely across ReLU activation functions. In addition,POLAR-Express provides parallel computation support for the layer-by-layerpropagation of TMs, thus significantly improving the efficiency and scalabilityover its earlier prototype POLAR. Across the comparison with six otherstate-of-the-art tools on a diverse set of benchmarks, POLAR-Express achievesthe best verification efficiency and tightness in the reachable set analysis.", "output": "POLAR-Express: Efficient and Precise Formal Reachability Analysis of Neural-Network Controlled Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study presents insights from interviews with nineteen Knowledge Graph(KG) practitioners who work in both enterprise and academic settings on a widevariety of use cases. Through this study, we identify critical challengesexperienced by KG practitioners when creating, exploring, and analyzing KGsthat could be alleviated through visualization design. Our findings revealthree major personas among KG practitioners - KG Builders, Analysts, andConsumers - each of whom have their own distinct expertise and needs. Wediscover that KG Builders would benefit from schema enforcers, while KGAnalysts need customizable query builders that provide interim query results.For KG Consumers, we identify a lack of efficacy for node-link diagrams, andthe need for tailored domain-specific visualizations to promote KG adoption andcomprehension. Lastly, we find that implementing KGs effectively in practicerequires both technical and social solutions that are not addressed withcurrent tools, technologies, and collaborative workflows. From the analysis ofour interviews, we distill several visualization research directions to improveKG usability, including knowledge cards that balance digestibility anddiscoverability, timeline views to track temporal changes, interfaces thatsupport organic discovery, and semantic explanations for AI and machinelearning predictions.", "output": "Characterizing the Users, Challenges, and Visualization Needs of Knowledge Graphs in Practice."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The available evidence suggests that dynamic functional connectivity (dFC)can capture time-varying abnormalities in brain activity in resting-statecerebral functional magnetic resonance imaging (rs-fMRI) data and has a naturaladvantage in uncovering mechanisms of abnormal brain activity inschizophrenia(SZ) patients. Hence, an advanced dynamic brain network analysismodel called the temporal brain category graph convolutional network(Temporal-BCGCN) was employed. Firstly, a unique dynamic brain network analysismodule, DSF-BrainNet, was designed to construct dynamic synchronizationfeatures. Subsequently, a revolutionary graph convolution method, TemporalConv,was proposed, based on the synchronous temporal properties of feature. Finally,the first modular abnormal hemispherical lateralization test tool in deeplearning based on rs-fMRI data, named CategoryPool, was proposed. This studywas validated on COBRE and UCLA datasets and achieved 83.62% and 89.71% averageaccuracies, respectively, outperforming the baseline model and otherstate-of-the-art methods. The ablation results also demonstrate the advantagesof TemporalConv over the traditional edge feature graph convolution approachand the improvement of CategoryPool over the classical graph pooling approach.Interestingly, this study showed that the lower order perceptual system andhigher order network regions in the left hemisphere are more severelydysfunctional than in the right hemisphere in SZ and reaffirms the importanceof the left medial superior frontal gyrus in SZ. Our core code is available at:", "output": "Temporal Dynamic Synchronous Functional Brain Network for Schizophrenia Diagnosis and Lateralization Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Masked graph autoencoder (MGAE) has emerged as a promising self-supervisedgraph pre-training (SGP) paradigm due to its simplicity and effectiveness.However, existing efforts perform the mask-then-reconstruct operation in theraw data space as is done in computer vision (CV) and natural languageprocessing (NLP) areas, while neglecting the important non-Euclidean propertyof graph data. As a result, the highly unstable local connection structureslargely increase the uncertainty in inferring masked data and decrease thereliability of the exploited self-supervision signals, leading to inferiorrepresentations for downstream evaluations. To address this issue, we propose anovel SGP method termed Robust mAsked gRaph autoEncoder (RARE) to improve thecertainty in inferring masked data and the reliability of the self-supervisionmechanism by further masking and reconstructing node samples in the high-orderlatent feature space. Through both theoretical and empirical analyses, we havediscovered that performing a joint mask-then-reconstruct strategy in bothlatent feature and raw data spaces could yield improved stability andperformance. To this end, we elaborately design a masked latent featurecompletion scheme, which predicts latent features of masked nodes under theguidance of high-order sample correlations that are hard to be observed fromthe raw data perspective. Specifically, we first adopt a latent featurepredictor to predict the masked latent features from the visible ones. Next, weencode the raw data of masked samples with a momentum graph encoder andsubsequently employ the resulting representations to improve predicted resultsthrough latent feature matching. Extensive experiments on seventeen datasetshave demonstrated the effectiveness and robustness of RARE againststate-of-the-art (SOTA) competitors across three downstream tasks.", "output": "RARE: Robust Masked Graph Autoencoder."}]