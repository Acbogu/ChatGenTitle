[{"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Tracking single molecules is instrumental for quantifying the transport ofmolecules and nanoparticles in biological samples, e.g., in brain drug deliverystudies. Existing intensity-based localisation methods are not developed forimaging with a scanning microscope, typically used for in vivo imaging. Lowsignal-to-noise ratios, movement of molecules out-of-focus, and high motionblur on images recorded with scanning two-photon microscopy (2PM) in vivo posea challenge to the accurate localisation of molecules. Using data-driven modelsis challenging due to low data volumes, typical for in vivo experiments. Wedeveloped a 2PM image simulator to supplement scarce training data. Thesimulator mimics realistic motion blur, background fluorescence, and shot noiseobserved in vivo imaging. Training a data-driven model with simulated dataimproves localisation quality in simulated images and shows why intensity-basedmethods fail.", "output": "Deep Learning-Assisted Localisation of Nanoparticles in synthetically generated two-photon microscopy images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A range of complicated real-world problems have inspired the development ofseveral optimization methods. Here, a novel hybrid version of the Ant colonyoptimization (ACO) method is developed using the sample space reductiontechnique of the Cohort Intelligence (CI) Algorithm. The algorithm isdeveloped, and accuracy is tested by solving 35 standard benchmark testfunctions. Furthermore, the constrained version of the algorithm is used tosolve two mechanical design problems involving stepped cantilever beams andI-section beams. The effectiveness of the proposed technique of solution isevaluated relative to contemporary algorithmic approaches that are already inuse. The results show that our proposed hybrid ACO-CI algorithm will takelesser number of iterations to produce the desired output which means lessercomputational time. For the minimization of weight of stepped cantilever beamand deflection in I-section beam a proposed hybrid ACO-CI algorithm yieldedbest results when compared to other existing algorithms. The proposed workcould be investigate for variegated real world applications encompassingdomains of engineering, combinatorial and health care problems.", "output": "Hybrid ACO-CI Algorithm for Beam Design problems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Can foundation models (such as ChatGPT) clean your data? In this proposal, wedemonstrate that indeed ChatGPT can assist in data cleaning by suggestingcorrections for specific cells in a data table (scenario 1). However, ChatGPTmay struggle with datasets it has never encountered before (e.g., localenterprise data) or when the user requires an explanation of the source of thesuggested clean values. To address these issues, we developed a retrieval-basedmethod that complements ChatGPT's power with a user-provided data lake. Thedata lake is first indexed, we then retrieve the top-k relevant tuples to theuser's query tuple and finally leverage ChatGPT to infer the correct value(scenario 2). Nevertheless, sharing enterprise data with ChatGPT, an externallyhosted model, might not be feasible for privacy reasons. To assist with thisscenario, we developed a custom RoBERTa-based foundation model that can belocally deployed. By fine-tuning it on a small number of examples, it caneffectively make value inferences based on the retrieved tuples (scenario 3).Our proposed system, RetClean, seamlessly supports all three scenarios andprovides a user-friendly GUI that enables the VLDB audience to explore andexperiment with the system.", "output": "RetClean: Retrieval-Based Data Cleaning Using Foundation Models and Data Lakes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the field of functional genomics, the analysis of gene expression profilesthrough Machine and Deep Learning is increasingly providing meaningful insightinto a number of diseases. The paper proposes a novel algorithm to performFeature Selection on genomic-scale data, which exploits the reconstructioncapabilities of autoencoders and an ad-hoc defined Explainable ArtificialIntelligence-based score in order to select the most informative genes fordiagnosis, prognosis, and precision medicine. Results of the application on aChronic Lymphocytic Leukemia dataset evidence the effectiveness of thealgorithm, by identifying and suggesting a set of meaningful genes for furthermedical investigation.", "output": "A New Deep Learning and XAI-Based Algorithm for Features Selection in Genomics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural Architecture Search (NAS) benchmarks significantly improved thecapability of developing and comparing NAS methods while at the same timedrastically reduced the computational overhead by providing meta-informationabout thousands of trained neural networks. However, tabular benchmarks haveseveral drawbacks that can hinder fair comparisons and provide unreliableresults. These usually focus on providing a small pool of operations in heavilyconstrained search spaces -- usually cell-based neural networks withpre-defined outer-skeletons. In this work, we conducted an empirical analysisof the widely used NAS-Bench-101, NAS-Bench-201 and TransNAS-Bench-101benchmarks in terms of their generability and how different operationsinfluence the performance of the generated architectures. We found that only asubset of the operation pool is required to generate architectures close to theupper-bound of the performance range. Also, the performance distribution isnegatively skewed, having a higher density of architectures in the upper-boundrange. We consistently found convolution layers to have the highest impact onthe architecture's performance, and that specific combination of operationsfavors top-scoring architectures. These findings shed insights on the correctevaluation and comparison of NAS methods using NAS benchmarks, showing thatdirectly searching on NAS-Bench-201, ImageNet16-120 and TransNAS-Bench-101produces more reliable results than searching only on CIFAR-10. Furthermore,with this work we provide suggestions for future benchmark evaluations anddesign. The code used to conduct the evaluations is available at", "output": "Are Neural Architecture Search Benchmarks Well Designed? A Deeper Look Into Operation Importance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Encoding 2-player games in QBF correctly and efficiently is challenging anderror-prone. To enable concise specifications and uniform encodings of gamesplayed on grid boards, like Tic-Tac-Toe, Connect-4, Domineering, Pursuer-Evaderand Breakthrough, we introduce Board-game Domain Definition Language (BDDL),inspired by the success of PDDL in the planning domain.We provide an efficient translation from BDDL into QBF, encoding theexistence of a winning strategy of bounded depth. Our lifted encoding treatsboard positions symbolically and allows concise definitions of conditions,effects and winning configurations, relative to symbolic board positions. Thesize of the encoding grows linearly in the input model and the considereddepth.To show the feasibility of such a generic approach, we use QBF solvers tocompute the critical depths of winning strategies for instances of severalknown games. For several games, our work provides the first QBF encoding.Unlike plan validation in SAT-based planning, validating QBF-based winningstrategies is difficult. We show how to validate winning strategies using QBFcertificates and interactive game play.", "output": "Concise QBF Encodings for Games on a Grid (extended version)."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Conventional optimization methods in machine learning and controls relyheavily on first-order update rules. Selecting the right method andhyperparameters for a particular task often involves trial-and-error orpractitioner intuition, motivating the field of meta-learning. We generalize abroad family of preexisting update rules by proposing a meta-learning frameworkin which the inner loop optimization step involves solving a differentiableconvex optimization (DCO). We illustrate the theoretical appeal of thisapproach by showing that it enables one-step optimization of a family of linearleast squares problems, given that the meta-learner has sufficient exposure tosimilar tasks. Various instantiations of the DCO update rule are compared toconventional optimizers on a range of illustrative experimental settings.", "output": "Meta-Learning Parameterized First-Order Optimizers using Differentiable Convex Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper studies how a domain-independent planner and combinatorial searchcan be employed to play Angry Birds, a well established AI challenge problem.To model the game, we use PDDL+, a planning language for mixeddiscrete/continuous domains that supports durative processes and exogenousevents. The paper describes the model and identifies key design decisions thatreduce the problem complexity. In addition, we propose several domain-specificenhancements including heuristics and a search technique similar to preferredoperators. Together, they alleviate the complexity of combinatorial search. Weevaluate our approach by comparing its performance with dedicateddomain-specific solvers on a range of Angry Birds levels. The results show thatour performance is on par with these domain-specific approaches in most levels,even without using our domain-specific search enhancements.", "output": "Heuristic Search For Physics-Based Problems: Angry Birds in PDDL+."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present Queer in AI as a case study for community-led participatory designin AI. We examine how participatory design and intersectional tenets startedand shaped this community's programs over the years. We discuss differentchallenges that emerged in the process, look at ways this organization hasfallen short of operationalizing participatory and intersectional principles,and then assess the organization's impact. Queer in AI provides importantlessons and insights for practitioners and theorists of participatory methodsbroadly through its rejection of hierarchy in favor of decentralization,success at building aid and programs by and for the queer community, and effortto change actors and institutions outside of the queer community. Finally, wetheorize how communities like Queer in AI contribute to the participatorydesign in AI more broadly by fostering cultures of participation in AI,welcoming and empowering marginalized participants, critiquing poor orexploitative participatory practices, and bringing participation toinstitutions outside of individual research projects. Queer in AI's work servesas a case study of grassroots activism and participatory methods within AI,demonstrating the potential of community-led participatory methods andintersectional praxis, while also providing challenges, case studies, andnuanced insights to researchers developing and using participatory methods.", "output": "Queer In AI: A Case Study in Community-Led Participatory AI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Many natural language processing (NLP) tasks make use of massivelypre-trained language models, which are computationally expensive. However,access to high computational resources added to the issue of data scarcity ofAfrican languages constitutes a real barrier to research experiments on theselanguages. In this work, we explore the applicability of low-compute approachessuch as language adapters in the context of this low-resource double-bind. Weintend to answer the following question: do language adapters allow those whoare doubly bound by data and compute to practically build useful models?Through fine-tuning experiments on African languages, we evaluate theireffectiveness as cost-effective approaches to low-resource African NLP. Usingsolely free compute resources, our results show that language adapters achievecomparable performances to massive pre-trained language models which are heavyon computational resources. This opens the door to further experimentation andexploration on full-extent of language adapters capacities.", "output": "Adapting to the Low-Resource Double-Bind: Investigating Low-Compute Methods on Low-Resource African Languages."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, the study of linear misspecified bandits has generated intriguingimplications of the hardness of learning in bandits and reinforcement learning(RL). In particular, Du et al. (2020) show that even if a learner is givenlinear features in $mathbb{R}^d$ that approximate the rewards in a bandit orRL with a uniform error of $varepsilon$, searching for an$O(varepsilon)$-optimal action requires pulling at least $Omega(exp(d))$queries. Furthermore, Lattimore et al. (2020) show that a degraded$O(varepsilonsqrt{d})$-optimal solution can be learned within$operatorname{poly}(d/varepsilon)$ queries. Yet it is unknown whether astructural assumption on the ground-truth parameter, such as sparsity, couldbreak the $varepsilonsqrt{d}$ barrier. In this paper, we address thisquestion by showing that algorithms can obtain $O(varepsilon)$-optimal actionsby querying $O(varepsilon^{-s}d^s)$ actions, where $s$ is the sparsityparameter, removing the $exp(d)$-dependence. We then establishinformation-theoretical lower bounds, i.e., $Omega(exp(s))$, to show that ourupper bound on sample complexity is nearly tight if one demands an error $O(s^{delta}varepsilon)$ for $0&lt;delta&lt;1$. For $deltageq 1$, we further showthat $operatorname{poly}(s/varepsilon)$ queries are possible when the linearfeatures are \"good\" and even in general settings. These results provide anearly complete picture of how sparsity can help in misspecified banditlearning and provide a deeper understanding of when linear features are\"useful\" for bandit and reinforcement learning with misspecification.", "output": "Does Sparsity Help in Learning Misspecified Linear Bandits?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The present study aims to explore the capabilities of Language Models (LMs)in tackling high-stakes multiple-choice tests, represented here by the ExameNacional do Ensino M'edio (ENEM), a multidisciplinary entrance examinationwidely adopted by Brazilian universities. This exam poses challenging tasks forLMs, since its questions may span into multiple fields of knowledge, requiringunderstanding of information from diverse domains. For instance, a question mayrequire comprehension of both statistics and biology to be solved. This workanalyzed responses generated by GPT-3.5 and GPT-4 models for questionspresented in the 2009-2017 exams, as well as for questions of the 2022 exam,which were made public after the training of the models was completed.Furthermore, different prompt strategies were tested, including the use ofChain-of-Thought (CoT) prompts to generate explanations for answers. On the2022 edition, the best-performing model, GPT-4 with CoT, achieved an accuracyof 87%, largely surpassing GPT-3.5 by 11 points. The code and data used onexperiments are available at ", "output": "Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "ChatGPT is built on a large language model trained on an enormous corpus ofhuman text to emulate human conversation. Despite lacking any explicitprogramming regarding the laws of physics, recent work by Kortemeyer (2023) hasdemonstrated that ChatGPT-3.5 could pass an introductory physics course at somenominal level and register something close to a minimal understanding ofNewtonian Mechanics on the Force Concept Inventory. This work replicates thoseresults and also demonstrates that the latest version, ChatGPT-4, has reached amuch higher mark in the latter context. Indeed, its responses come quite closeto perfectly demonstrating expert-level competence, with a few very notableexceptions and limitations. We briefly comment on the implications of this forthe future of physics education and pedagogy.", "output": "Advances in apparent conceptual physics reasoning in ChatGPT-4."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Answer set programming is a declarative logic programming paradigm gearedtowards solving difficult combinatorial search problems. While different logicprograms can encode the same problem, their performance may vary significantly.It is not always easy to identify which version of the program performs thebest. We present the system Predictor (and its algorithmic backend) forestimating the grounding size of programs, a metric that can influence aperformance of a system processing a program. We evaluate the impact ofPredictor when used as a guide for rewritings produced by the answer setprogramming rewriting tools Projector and Lpopt. The results demonstratepotential to this approach.", "output": "System Predictor: Grounding Size Estimator for Logic Programs under Answer Set Semantics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The fervor for Non-Fungible Tokens (NFTs) attracted countless creators,leading to a Big Bang of digital assets driven by latent or explicit forms ofinspiration, as in many creative processes. This work exploits VisionTransformers and graph-based modeling to delve into visual inspirationphenomena between NFTs over the years. Our goals include unveiling the mainstructural traits that shape visual inspiration networks, exploring theinterrelation between visual inspiration and asset performances, investigatingcrypto influence on inspiration processes, and explaining the inspirationrelationships among NFTs. Our findings unveil how the pervasiveness ofinspiration led to a temporary saturation of the visual feature space, theimpact of the dichotomy between inspiring and inspired NFTs on their financialperformance, and an intrinsic self-regulatory mechanism between markets andinspiration waves. Our work can serve as a starting point for gaining a broaderview of the evolution of Web3.", "output": "Visually Wired NFTs: Exploring the Role of Inspiration in Non-Fungible Tokens."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "When training a machine learning model with differential privacy, one sets aprivacy budget. This budget represents a maximal privacy violation that anyuser is willing to face by contributing their data to the training set. Weargue that this approach is limited because different users may have differentprivacy expectations. Thus, setting a uniform privacy budget across all pointsmay be overly conservative for some users or, conversely, not sufficientlyprotective for others. In this paper, we capture these preferences throughindividualized privacy budgets. To demonstrate their practicality, we introducea variant of Differentially Private Stochastic Gradient Descent (DP-SGD) whichsupports such individualized budgets. DP-SGD is the canonical approach totraining models with differential privacy. We modify its data sampling andgradient noising mechanisms to arrive at our approach, which we callIndividualized DP-SGD (IDP-SGD). Because IDP-SGD provides privacy guaranteestailored to the preferences of individual users and their data points, we findit empirically improves privacy-utility trade-offs.", "output": "Have it your way: Individualized Privacy Assignment for DP-SGD."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a methodology for formulating simplifying abstractions in machinelearning systems by identifying and harnessing the utility structure ofdecisions. Machine learning tasks commonly involve high-dimensional outputspaces (e.g., predictions for every pixel in an image or node in a graph), eventhough a coarser output would often suffice for downstream decision-making(e.g., regions of an image instead of pixels). Developers often hand-engineerabstractions of the output space, but numerous abstractions are possible and itis unclear how the choice of output space for a model impacts its usefulness indownstream decision-making. We propose a method that configures the outputspace automatically in order to minimize the loss of decision-relevantinformation. Taking a geometric perspective, we formulate a step of thealgorithm as a projection of the probability simplex, termed fold, thatminimizes the total loss of decision-related information in the H-entropysense. Crucially, learning in the abstracted outcome space requires less data,leading to a net improvement in decision quality. We demonstrate the method intwo domains: data acquisition for deep neural network training and aclosed-loop wildfire management task.", "output": "Ideal Abstractions for Decision-Focused Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large language models (LLMs) have emerged as valuable tools for many naturallanguage understanding tasks. In safety-critical applications such ashealthcare, the utility of these models is governed by their ability togenerate outputs that are factually accurate and complete. In this work, wepresent dialog-enabled resolving agents (DERA). DERA is a paradigm madepossible by the increased conversational abilities of LLMs, namely GPT-4. Itprovides a simple, interpretable forum for models to communicate feedback anditeratively improve output. We frame our dialog as a discussion between twoagent types - a Researcher, who processes information and identifies crucialproblem components, and a Decider, who has the autonomy to integrate theResearcher's information and makes judgments on the final output.We test DERA against three clinically-focused tasks. For medical conversationsummarization and care plan generation, DERA shows significant improvement overthe base GPT-4 performance in both human expert preference evaluations andquantitative metrics. In a new finding, we also show that GPT-4's performance(70%) on an open-ended version of the MedQA question-answering (QA) dataset(Jin et al. 2021, USMLE) is well above the passing level (60%), with DERAshowing similar performance. We release the open-ended MEDQA dataset at", "output": "DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We have defined the Conscious Turing Machine (CTM) for the purpose ofinvestigating a Theoretical Computer Science (TCS) approach to consciousness.For this, we have hewn to the TCS demand for simplicity and understandability.The CTM is consequently and intentionally a simple machine. It is not a modelof the brain, though its design has greatly benefited - and continues tobenefit - from neuroscience and psychology. The CTM is a model of and forconsciousness.Although it is developed to understand consciousness, the CTM offers athoughtful and novel guide to the creation of an Artificial GeneralIntelligence (AGI). For example, the CTM has an enormous number of powerfulprocessors, some with specialized expertise, others unspecialized but poised todevelop an expertise. For whatever problem must be dealt with, the CTM has anexcellent way to utilize those processors that have the required knowledge,ability, and time to work on the problem, even if it is not aware of which onesthese may be.", "output": "Viewpoint: A Theoretical Computer Science Perspective on Consciousness and Artificial General Intelligence."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reliable confidence estimation for deep neural classifiers is a challengingyet fundamental requirement in high-stakes applications. Unfortunately, moderndeep neural networks are often overconfident for their erroneous predictions.In this work, we exploit the easily available outlier samples, i.e., unlabeledsamples coming from non-target classes, for helping detect misclassificationerrors. Particularly, we find that the well-known Outlier Exposure, which ispowerful in detecting out-of-distribution (OOD) samples from unknown classes,does not provide any gain in identifying misclassification errors. Based onthese observations, we propose a novel method called OpenMix, whichincorporates open-world knowledge by learning to reject uncertainpseudo-samples generated via outlier transformation. OpenMix significantlyimproves confidence reliability under various scenarios, establishing a strongand unified framework for detecting both misclassified samples from knownclasses and OOD samples from unknown classes. The code is publicly available at", "output": "OpenMix: Exploring Outlier Samples for Misclassification Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study contextual combinatorial bandits with probabilistically triggeredarms (C$^2$MAB-T) under a variety of smoothness conditions that capture a widerange of applications, such as contextual cascading bandits and contextualinfluence maximization bandits. Under the triggering probability modulated(TPM) condition, we devise the C$^2$-UCB-T algorithm and propose a novelanalysis that achieves an $tilde{O}(dsqrt{KT})$ regret bound, removing apotentially exponentially large factor $O(1/p_{min})$, where $d$ is thedimension of contexts, $p_{min}$ is the minimum positive probability that anyarm can be triggered, and batch-size $K$ is the maximum number of arms that canbe triggered per round. Under the variance modulated (VM) or triggeringprobability and variance modulated (TPVM) conditions, we propose a newvariance-adaptive algorithm VAC$^2$-UCB and derive a regret bound$tilde{O}(dsqrt{T})$, which is independent of the batch-size $K$. As avaluable by-product, we find our analysis technique and variance-adaptivealgorithm can be applied to the CMAB-T and C$^2$MAB~setting, improving existingresults there as well. We also include experiments that demonstrate theimproved performance of our algorithms compared with benchmark algorithms onsynthetic and real-world datasets.", "output": "Contextual Combinatorial Bandits with Probabilistically Triggered Arms."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the phenomenal success of diffusion models and ChatGPT, deep generationmodels (DGMs) have been experiencing explosive growth from 2022. Not limited tocontent generation, DGMs are also widely adopted in Internet of Things,Metaverse, and digital twin, due to their outstanding ability to representcomplex patterns and generate plausible samples. In this article, we explorethe applications of DGMs in a crucial task, i.e., improving the efficiency ofwireless network management. Specifically, we firstly overview the generativeAI, as well as three representative DGMs. Then, a DGM-empowered framework forwireless network management is proposed, in which we elaborate the issues ofthe conventional network management approaches, why DGMs can address themefficiently, and the step-by-step workflow for applying DGMs in managingwireless networks. Moreover, we conduct a case study on network economics,using the state-of-the-art DGM model, i.e., diffusion model, to generateeffective contracts for incentivizing the mobile AI-Generated Content (AIGC)services. Last but not least, we discuss important open directions for thefurther research.", "output": "Deep Generative Model and Its Applications in Efficient Wireless Network Management: A Tutorial and Case Study."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The software engineering community recently has witnessed widespreaddeployment of AI programming assistants, such as GitHub Copilot. However, inpractice, developers do not accept AI programming assistants' initialsuggestions at a high frequency. This leaves a number of open questions relatedto the usability of these tools. To understand developers' practices whileusing these tools and the important usability challenges they face, weadministered a survey to a large population of developers and receivedresponses from a diverse set of 410 developers. Through a mix of qualitativeand quantitative analyses, we found that developers are most motivated to useAI programming assistants because they help developers reduce key-strokes,finish programming tasks quickly, and recall syntax, but resonate less withusing them to help brainstorm potential solutions. We also found the mostimportant reasons why developers do not use these tools are because these toolsdo not output code that addresses certain functional or non-functionalrequirements and because developers have trouble controlling the tool togenerate the desired output. Our findings have implications for both creatorsand users of AI programming assistants, such as designing minimal cognitiveeffort interactions with these tools to reduce distractions for users whilethey are programming.", "output": "Understanding the Usability of AI Programming Assistants."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Real-time perception, or streaming perception, is a crucial aspect ofautonomous driving that has yet to be thoroughly explored in existing research.To address this gap, we present DAMO-StreamNet, an optimized framework thatcombines recent advances from the YOLO series with a comprehensive analysis ofspatial and temporal perception mechanisms, delivering a cutting-edge solution.The key innovations of DAMO-StreamNet are: (1) A robust neck structureincorporating deformable convolution, enhancing the receptive field and featurealignment capabilities. (2) A dual-branch structure that integrates short-pathsemantic features and long-path temporal features, improving motion stateprediction accuracy. (3) Logits-level distillation for efficient optimization,aligning the logits of teacher and student networks in semantic space. (4) Areal-time forecasting mechanism that updates support frame features with thecurrent frame, ensuring seamless streaming perception during inference. Ourexperiments demonstrate that DAMO-StreamNet surpasses existing state-of-the-artmethods, achieving 37.8% (normal size (600, 960)) and 43.3% (large size (1200,1920)) sAP without using extra data. This work not only sets a new benchmarkfor real-time perception but also provides valuable insights for futureresearch. Additionally, DAMO-StreamNet can be applied to various autonomoussystems, such as drones and robots, paving the way for real-time perception.", "output": "DAMO-StreamNet: Optimizing Streaming Perception in Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in text-to-image diffusion models have enabled the generationof diverse and high-quality images. However, generated images often fall shortof depicting subtle details and are susceptible to errors due to ambiguity inthe input text. One way of alleviating these issues is to train diffusionmodels on class-labeled datasets. This comes with a downside, doing so limitstheir expressive power: (i) supervised datasets are generally small compared tolarge-scale scraped text-image datasets on which text-to-image models aretrained, and so the quality and diversity of generated images are severelyaffected, or (ii) the input is a hard-coded label, as opposed to free-formtext, which limits the control over the generated images.In this work, we propose a non-invasive fine-tuning technique thatcapitalizes on the expressive potential of free-form text while achieving highaccuracy through discriminative signals from a pretrained classifier, whichguides the generation. This is done by iteratively modifying the embedding of asingle input token of a text-to-image diffusion model, using the classifier, bysteering generated images toward a given target class. Our method is fastcompared to prior fine-tuning methods and does not require a collection ofin-class images or retraining of a noise-tolerant classifier. We evaluate ourmethod extensively, showing that the generated images are: (i) more accurateand of higher quality than standard diffusion models, (ii) can be used toaugment training data in a low-resource setting, and (iii) reveal informationabout the data used to train the guiding classifier. The code is available aturl{", "output": "Discriminative Class Tokens for Text-to-Image Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Autoregressive (AR) encoder-decoder neural networks have proved successful inmany NLP problems, including Semantic Parsing -- a task that translates naturallanguage to machine-readable parse trees. However, the sequential predictionprocess of AR models can be slow. To accelerate AR for semantic parsing, weintroduce a new technique called TreePiece that tokenizes a parse tree intosubtrees and generates one subtree per decoding step. On TopV2 benchmark,TreePiece shows 4.6 times faster decoding speed than standard AR, andcomparable speed but significantly higher accuracy compared toNon-Autoregressive (NAR).", "output": "TreePiece: Faster Semantic Parsing via Tree Tokenization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We investigated some difficulties that students often face when studyinglinear algebra at the undergraduate level, and identified some common mistakesand difficulties they often encountered when dealing with topics that requirealgorithmic thinking skills such as matrix factorization. In particular, wefocused on (orthogonal) diagonalization and singular value decomposition (SVD).We also offered the possibility of exploring these topics using SageMath, aPython-based free open software computer algebra system (CAS) that has beenidentified to be useful for assisting many students in the computationalprocess even though its output is static by nature. We then explored dynamicChatGPT by inquiring the chatbot about the topic, either by asking to providean example or to solve a problem, that is by constructing an (orthogonal)diagonalization or SVD from a particular matrix. By consolidating essentialconcepts in linear algebra and improving computational skills through effectivepractice, mastering these topics would become easier and mistakes could beminimized. Static SageMath, in particular, is a great aid for calculationconfirmation and handling tedious computations. Although dynamic ChatGPT isrelatively unreliable for solving problems in linear algebra, the mistakes itproduces could become a valuable tool for improving critical thinking skills.", "output": "Matrix diagonalization and singular value decomposition: Static SageMath and dynamic ChatGPT juxtaposed."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pre-training Large Language Models (LLMs) require massive amounts of textdata, and the performance of the LLMs typically correlates with the scale andquality of the datasets. This means that it may be challenging to build LLMsfor smaller languages such as Nordic ones, where the availability of textcorpora is limited. In order to facilitate the development of the LLMS in theNordic languages, we curate a high-quality dataset consisting of 1.2TB of text,in all of the major North Germanic languages (Danish, Icelandic, Norwegian, andSwedish), as well as some high-quality English data. This paper details ourconsiderations and processes for collecting, cleaning, and filtering thedataset.", "output": "The Nordic Pile: A 1.2TB Nordic Dataset for Language Modeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently reported state-of-the-art results in visual speech recognition (VSR)often rely on increasingly large amounts of video data, while the publiclyavailable transcribed video datasets are limited in size. In this paper, forthe first time, we study the potential of leveraging synthetic visual data forVSR. Our method, termed SynthVSR, substantially improves the performance of VSRsystems with synthetic lip movements. The key idea behind SynthVSR is toleverage a speech-driven lip animation model that generates lip movementsconditioned on the input speech. The speech-driven lip animation model istrained on an unlabeled audio-visual dataset and could be further optimizedtowards a pre-trained VSR model when labeled videos are available. As plenty oftranscribed acoustic data and face images are available, we are able togenerate large-scale synthetic data using the proposed lip animation model forsemi-supervised VSR training. We evaluate the performance of our approach onthe largest public VSR benchmark - Lip Reading Sentences 3 (LRS3). SynthVSRachieves a WER of 43.3% with only 30 hours of real labeled data, outperformingoff-the-shelf approaches using thousands of hours of video. The WER is furtherreduced to 27.9% when using all 438 hours of labeled data from LRS3, which ison par with the state-of-the-art self-supervised AV-HuBERT method. Furthermore,when combined with large-scale pseudo-labeled audio-visual data SynthVSR yieldsa new state-of-the-art VSR WER of 16.9% using publicly available data only,surpassing the recent state-of-the-art approaches trained with 29 times morenon-public machine-transcribed video data (90,000 hours). Finally, we performextensive ablation studies to understand the effect of each component in ourproposed method.", "output": "SynthVSR: Scaling Up Visual Speech Recognition With Synthetic Supervision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Interest in autonomous driving (AD) and intelligent vehicles (IVs) is growingat a rapid pace due to the convenience, safety, and economic benefits. Althougha number of surveys have reviewed research achievements in this field, they arestill limited in specific tasks, lack of systematic summary and researchdirections in the future. Here we propose a Survey of Surveys (SoS) for totaltechnologies of AD and IVs that reviews the history, summarizes the milestones,and provides the perspectives, ethics, and future research directions. To ourknowledge, this article is the first SoS with milestones in AD and IVs, whichconstitutes our complete research work together with two other technicalsurveys. We anticipate that this article will bring novel and diverse insightsto researchers and abecedarians, and serve as a bridge between past and future.", "output": "Milestones in Autonomous Driving and Intelligent Vehicles: Survey of Surveys."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Object detection is a fundamental task in computer vision, which has beengreatly progressed through developing large and intricate deep learning models.However, the lack of transparency is a big challenge that may not allow thewidespread adoption of these models. Explainable artificial intelligence is afield of research where methods are developed to help users understand thebehavior, decision logics, and vulnerabilities of AI-based systems. Black-boxexplanation refers to explaining decisions of an AI system without havingaccess to its internals. In this paper, we design and implement a black-boxexplanation method named Black-box Object Detection Explanation by Masking(BODEM) through adopting a new masking approach for AI-based object detectionsystems. We propose local and distant masking to generate multiple versions ofan input image. Local masks are used to disturb pixels within a target objectto figure out how the object detector reacts to these changes, while distantmasks are used to assess how the detection model's decisions are affected bydisturbing pixels outside the object. A saliency map is then created byestimating the importance of pixels through measuring the difference betweenthe detection output before and after masking. Finally, a heatmap is createdthat visualizes how important pixels within the input image are to the detectedobjects. The experimentations on various object detection datasets and modelsshowed that BODEM can be effectively used to explain the behavior of objectdetectors and reveal their vulnerabilities. This makes BODEM suitable forexplaining and validating AI based object detection systems in black-boxsoftware testing scenarios. Furthermore, we conducted data augmentationexperiments that showed local masks produced by BODEM can be used for furthertraining the object detectors and improve their detection accuracy androbustness.", "output": "Model-agnostic explainable artificial intelligence for object detection in image data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The science of social bots seeks knowledge and solutions to one of the mostdebated forms of online misinformation. Yet, social bots research is plagued bywidespread biases, hyped results, and misconceptions that set the stage forambiguities, unrealistic expectations, and seemingly irreconcilable findings.Overcoming such issues is instrumental towards ensuring reliable solutions andreaffirming the validity of the scientific method. In this contribution werevise some recent results in social bots research, highlighting and correctingfactual errors as well as methodological and conceptual issues. Moreimportantly, we demystify common misconceptions, addressing fundamental pointson how social bots research is discussed. Our analysis surfaces the need todiscuss misinformation research in a rigorous, unbiased, and responsible way.This article bolsters such effort by identifying and refuting common fallaciousarguments used by both proponents and opponents of social bots research as wellas providing indications on the correct methodologies and sound directions forfuture research in the field.", "output": "Demystifying Misconceptions in Social Bots Research."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In a context of constant evolution and proliferation of AI technology, HybridIntelligence is gaining popularity to refer a balanced coexistence betweenhuman and artificial intelligence. On the other side, the concept has beenextensively used in the past two decades to define models of intelligenceinvolving more than one technology. This paper aims to provide (i) a conciseand focused overview of the adoption of Ontology in the broad context of HybridIntelligence regardless of its definition and (ii) a critical discussion on thepossible role of Ontology to reduce the gap between human and artificialintelligence within hybrid intelligent systems. Beside the typical benefitsprovided by an effective use of ontologies, at a conceptual level, the analysisconducted has pointed out a significant contribution to quality and accuracy,as well as a more specific role to enable extended interoperability, systemengineering and explainable/transparent systems. On the other side, anapplication-oriented analysis has shown a significant role in present systems(70+% of the cases) and, potentially, in future systems. However, a properholistic discussion on the establishment of the next generation ofhybrid-intelligent environments with a balanced co-existence of human andartificial intelligence is fundamentally missed in literature. Last but not theleast, there is currently a relatively low explicit focus on automaticreasoning and inference.", "output": "Ontology in Hybrid Intelligence: a concise literature review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Increase in computational scale and fine-tuning has seen a dramaticimprovement in the quality of outputs of large language models (LLMs) like GPT.Given that both GPT-3 and GPT-4 were trained on large quantities ofhuman-generated text, we might ask to what extent their outputs reflectpatterns of human thinking, both for correct and incorrect cases. The EroteticTheory of Reason (ETR) provides a symbolic generative model of both humansuccess and failure in thinking, across propositional, quantified, andprobabilistic reasoning, as well as decision-making. We presented GPT-3,GPT-3.5, and GPT-4 with 61 central inference and judgment problems from arecent book-length presentation of ETR, consisting of experimentally verifieddata-points on human judgment and extrapolated data-points predicted by ETR,with correct inference patterns as well as fallacies and framing effects (theETR61 benchmark). ETR61 includes classics like Wason's card task, illusoryinferences, the decoy effect, and opportunity-cost neglect, among others. GPT-3showed evidence of ETR-predicted outputs for 59% of these examples, rising to77% in GPT-3.5 and 75% in GPT-4. Remarkably, the production of human-likefallacious judgments increased from 18% in GPT-3 to 33% in GPT-3.5 and 34% inGPT-4. This suggests that larger and more advanced LLMs may develop a tendencytoward more human-like mistakes, as relevant thought patterns are inherent inhuman-produced training data. According to ETR, the same fundamental patternsare involved both in successful and unsuccessful ordinary reasoning, so thatthe \"bad\" cases could paradoxically be learned from the \"good\" cases. Wefurther present preliminary evidence that ETR-inspired prompt engineering couldreduce instances of these mistakes.", "output": "Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Convolutional neural networks (CNNs) are increasingly being used to automatesegmentation of organs-at-risk in radiotherapy. Since large sets of highlycurated data are scarce, we investigated how much data is required to trainaccurate and robust head and neck auto-segmentation models. For this, anestablished 3D CNN was trained from scratch with different sized datasets(25-1000 scans) to segment the brainstem, parotid glands and spinal cord inCTs. Additionally, we evaluated multiple ensemble techniques to improve theperformance of these models. The segmentations improved with training set sizeup to 250 scans and the ensemble methods significantly improved performance forall organs. The impact of the ensemble methods was most notable in the smallestdatasets, demonstrating their potential for use in cases where large trainingdatasets are difficult to obtain.", "output": "The impact of training dataset size and ensemble inference strategies on head and neck auto-segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Along with the rapid evolution of mobile communication technologies, such as5G, there has been a drastically increase in telecom fraud, which significantlydissipates individual fortune and social wealth. In recent years, graph miningtechniques are gradually becoming a mainstream solution for detecting telecomfraud. However, the graph imbalance problem, caused by the Pareto principle,brings severe challenges to graph data mining. This is a new and challengingproblem, but little previous work has been noticed. In this paper, we propose aGraph ATtention network with COst-sensitive BOosting (GAT-COBO) for the graphimbalance problem. First, we design a GAT-based base classifier to learn theembeddings of all nodes in the graph. Then, we feed the embeddings into awell-designed cost-sensitive learner for imbalanced learning. Next, we updatethe weights according to the misclassification cost to make the model focusmore on the minority class. Finally, we sum the node embeddings obtained bymultiple cost-sensitive learners to obtain a comprehensive node representation,which is used for the downstream anomaly detection task. Extensive experimentson two real-world telecom fraud detection datasets demonstrate that ourproposed method is effective for the graph imbalance problem, outperforming thestate-of-the-art GNNs and GNN-based fraud detectors. In addition, our model isalso helpful for solving the widespread over-smoothing problem in GNNs. TheGAT-COBO code and datasets are available at ", "output": "GAT-COBO: Cost-Sensitive Graph Neural Network for Telecom Fraud Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "There has been a recent explosion of computer vision models which performmany tasks and are composed of an image encoder (usually a ViT) and anautoregressive decoder (usually a Transformer). However, most of this worksimply presents one system and its results, leaving many questions regardingdesign decisions and trade-offs of such systems unanswered. In this work, weaim to provide such answers. We take a close look at autoregressive decodersfor multi-task learning in multimodal computer vision, includingclassification, captioning, visual question answering, and optical characterrecognition. Through extensive systematic experiments, we study the effects oftask and data mixture, training and regularization hyperparameters,conditioning type and specificity, modality combination, and more. Importantly,we compare these to well-tuned single-task baselines to highlight the costincurred by multi-tasking. A key finding is that a small decoder learned on topof a frozen pretrained encoder works surprisingly well. We call this setuplocked-image tuning with decoder (LiT-decoder). It can be seen as teaching adecoder to interact with a pretrained vision model via natural language.", "output": "A Study of Autoregressive Decoders for Multi-Tasking in Computer Vision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "RGB-thermal semantic segmentation is one potential solution to achievereliable semantic scene understanding in adverse weather and lightingconditions. However, the previous studies mostly focus on designing amulti-modal fusion module without consideration of the nature of multi-modalityinputs. Therefore, the networks easily become over-reliant on a singlemodality, making it difficult to learn complementary and meaningfulrepresentations for each modality. This paper proposes 1) a complementaryrandom masking strategy of RGB-T images and 2) self-distillation loss betweenclean and masked input modalities. The proposed masking strategy preventsover-reliance on a single modality. It also improves the accuracy androbustness of the neural network by forcing the network to segment and classifyobjects even when one modality is partially available. Also, the proposedself-distillation loss encourages the network to extract complementary andmeaningful representations from a single modality or complementary maskedmodalities. Based on the proposed method, we achieve state-of-the-artperformance over three RGB-T semantic segmentation benchmarks. Our source codeis available at ", "output": "Complementary Random Masking for RGB-Thermal Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The current state of the art systems in Artificial Intelligence (AI) enabledintrusion detection use a variety of black box methods. These black box methodsare generally trained using Error Based Learning (EBL) techniques with a focuson creating accurate models. These models have high performative costs and arenot easily explainable. A white box Competitive Learning (CL) based eXplainableIntrusion Detection System (X-IDS) offers a potential solution to theseproblem. CL models utilize an entirely different learning paradigm than EBLapproaches. This different learning process makes the CL family of algorithmsinnately explainable and less resource intensive. In this paper, we create anX-IDS architecture that is based on DARPA's recommendation for explainablesystems. In our architecture we leverage CL algorithms like, Self OrganizingMaps (SOM), Growing Self Organizing Maps (GSOM), and Growing Hierarchical SelfOrganizing Map (GHSOM). The resulting models can be data-mined to createstatistical and visual explanations. Our architecture is tested using NSL-KDDand CIC-IDS-2017 benchmark datasets, and produces accuracies that are 1% - 3%less than EBL models. However, CL models are much more explainable than EBLmodels. Additionally, we use a pruning process that is able to significantlyreduce the size of these CL based models. By pruning our models, we are able toincrease prediction speeds. Lastly, we analyze the statistical and visualexplanations generated by our architecture, and we give a strategy that userscould use to help navigate the set of explanations. These explanations willhelp users build trust with an Intrusion Detection System (IDS), and allowusers to discover ways to increase the IDS's potency.", "output": "Explainable Intrusion Detection Systems Using Competitive Learning Techniques."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-Agent Pickup and Delivery (MAPD) is the problem of computingcollision-free paths for a group of agents such that they can safely reachdelivery locations from pickup ones. These locations are provided at runtime,making MAPD a combination between classical Multi-Agent Path Finding (MAPF) andonline task assignment. Current algorithms for MAPD do not consider many of thepractical issues encountered in real applications: real agents often do notfollow the planned paths perfectly, and may be subject to delays and failures.In this paper, we study the problem of MAPD with delays, and we present twosolution approaches that provide robustness guarantees by planning paths thatlimit the effects of imperfect execution. In particular, we introduce twoalgorithms, k-TP and p-TP, both based on a decentralized algorithm typicallyused to solve MAPD, Token Passing (TP), which offer deterministic andprobabilistic guarantees, respectively. Experimentally, we compare ouralgorithms against a version of TP enriched with online replanning. k-TP andp-TP provide robust solutions, significantly reducing the number of replanscaused by delays, with little or no increase in solution cost and running time.", "output": "Robust Multi-Agent Pickup and Delivery with Delays."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Maintaining genetic diversity as a means to avoid premature convergence iscritical in Genetic Programming. Several approaches have been proposed toachieve this, with some focusing on the mating phase from coupling dissimilarsolutions to some form of self-adaptive selection mechanism. In nature, geneticdiversity can be the consequence of many different factors, but whenconsidering reproduction Sexual Selection can have an impact on promotingvariety within a species. Specifically, Mate Choice often results in differentselective pressures between sexes, which in turn may trigger evolutionarydifferences among them. Although some mechanisms of Sexual Selection have beenapplied to Genetic Programming in the past, the literature is scarce when itcomes to mate choice. Recently, a way of modelling mating preferences by idealmate representations was proposed, achieving good results when compared to astandard approach. These mating preferences evolve freely in a self-adaptivefashion, creating an evolutionary driving force of its own alongside fitnesspressure. The inner mechanisms of this approach operate from personal choice,as each individual has its own representation of a perfect mate which affectsthe mate to be selected. In this paper, we compare this method against a randommate choice to assess whether there are advantages in evolving personalpreferences. We conducted experiments using three symbolic regression problemsand different mutation rates. The results show that self-adaptive matingpreferences are able to create a more diverse set of solutions when compared tothe traditional approach and a random mate approach (with statisticallysignificant differences) and have a higher success rate in three of the sixinstances tested.", "output": "All You Need Is Sex for Diversity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Talking face generation, also known as speech-to-lip generation, reconstructsfacial motions concerning lips given coherent speech input. The previousstudies revealed the importance of lip-speech synchronization and visualquality. Despite much progress, they hardly focus on the content of lipmovements i.e., the visual intelligibility of the spoken words, which is animportant aspect of generation quality. To address the problem, we proposeusing a lip-reading expert to improve the intelligibility of the generated lipregions by penalizing the incorrect generation results. Moreover, to compensatefor data scarcity, we train the lip-reading expert in an audio-visualself-supervised manner. With a lip-reading expert, we propose a novelcontrastive learning to enhance lip-speech synchronization, and a transformerto encode audio synchronically with video, while considering global temporaldependency of audio. For evaluation, we propose a new strategy with twodifferent lip-reading experts to measure intelligibility of the generatedvideos. Rigorous experiments show that our proposal is superior to otherState-of-the-art (SOTA) methods, such as Wav2Lip, in reading intelligibilityi.e., over 38% Word Error Rate (WER) on LRS2 dataset and 27.8% accuracy on LRWdataset. We also achieve the SOTA performance in lip-speech synchronization andcomparable performances in visual quality.", "output": "Seeing What You Said: Talking Face Generation Guided by a Lip Reading Expert."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As an emerging concept cognitive learning model, partial order formalstructure analysis (POFSA) has been widely used in the field of knowledgeprocessing. In this paper, we propose the method named three-way causalattribute partial order structure (3WCAPOS) to evolve the POFSA from setcoverage to causal coverage in order to increase the interpretability andclassification performance of the model. First, the concept of causal factor(CF) is proposed to evaluate the causal correlation between attributes anddecision attributes in the formal decision context. Then, combining CF withattribute partial order structure, the concept of causal attribute partialorder structure is defined and makes set coverage evolve into causal coverage.Finally, combined with the idea of three-way decision, 3WCAPOS is formed, whichmakes the purity of nodes in the structure clearer and the changes betweenlevels more obviously. In addition, the experiments are carried out from theclassification ability and the interpretability of the structure through thesix datasets. Through these experiments, it is concluded the accuracy of3WCAPOS is improved by 1% - 9% compared with classification and regressiontree, and more interpretable and the processing of knowledge is more reasonablecompared with attribute partial order structure.", "output": "Three-way causal attribute partial order structure analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Many networks, such as transportation, power, and water distribution, can berepresented as graphs. Crucial challenge in graph representations isidentifying the importance of graph edges and their influence on overallnetwork efficiency and information flow performance. For example, importantedges in a transportation network are those roads that, when affected, willsignificantly alter the network's overall efficiency. Commonly used approach tofinding such important edges is ``edge betweenness centrality'' (EBC), an edgeranking measure to determine the influential edges of the graph based onconnectivity and information spread. Computing the EBC utilizing the commonBrandes algorithm involves calculating the shortest paths for every node pair,which can be computationally expensive and restrictive, especially for largegraphs. Changes in the graph parameters, e.g., in the edge weight or theaddition and deletion of nodes or edges, require the recalculation of the EBC.As the main contribution, we propose an approximate method to estimate the EBCusing a Graph Neural Network (GNN), a deep learning-based approach. We showthat it is computationally efficient compared to the conventional method,especially for large graphs. The proposed method of GNN-based edge ranking isevaluated on several synthetic graphs and a real-world transportation data set.We show that this framework can estimate the approximate edge ranking muchfaster compared to the conventional method. This approach is inductive, i.e.,training and testing are performed on different sets of graphs with varyingnumbers of nodes and edges. The proposed method is especially suitable forapplications on large-scale networks when edge information is desired, forexample, in urban infrastructure improvement projects, power, and water networkresilience analyses, and optimizing resource allocations in engineeringnetworks.", "output": "Edge Ranking of Graphs in Transportation Networks using a Graph Neural Network (GNN)."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the rapid development of mobile networks, the people's social contactshave been considerably facilitated. However, the rise of mobile social networkfraud upon those networks, has caused a great deal of distress, in case ofdepleting personal and social wealth, then potentially doing significanteconomic harm. To detect fraudulent users, call detail record (CDR) data, whichportrays the social behavior of users in mobile networks, has been widelyutilized. But the imbalance problem in the aforementioned data, which couldseverely hinder the effectiveness of fraud detectors based on graph neuralnetworks(GNN), has hardly been addressed in previous work. In this paper, weare going to present a novel Cost-Sensitive Graph Neural Network (CSGNN) bycreatively combining cost-sensitive learning and graph neural networks. Weconduct extensive experiments on two open-source realworld mobile network frauddatasets. The results show that CSGNN can effectively solve the graph imbalanceproblem and then achieve better detection performance than the state-of-the-artalgorithms. We believe that our research can be applied to solve the graphimbalance problems in other fields. The CSGNN code and datasets are publiclyavailable at ", "output": "Cost Sensitive GNN-based Imbalanced Learning for Mobile Social Network Fraud Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Agents capable of carrying out general tasks on a computer can improveefficiency and productivity by automating repetitive tasks and assisting incomplex problem-solving. Ideally, such agents should be able to solve newcomputer tasks presented to them through natural language commands. However,previous approaches to this problem require large amounts of expertdemonstrations and task-specific reward functions, both of which areimpractical for new tasks. In this work, we show that a pre-trained largelanguage model (LLM) agent can execute computer tasks guided by naturallanguage using a simple prompting scheme where the agent recursively criticizesand improves its output (RCI). The RCI approach significantly outperformsexisting LLM methods for automating computer tasks and surpasses supervisedlearning (SL) and reinforcement learning (RL) approaches on the MiniWoB++benchmark. RCI is competitive with the state-of-the-art SL+RL method, usingonly a handful of demonstrations per task rather than tens of thousands, andwithout a task-specific reward function. Furthermore, we demonstrate RCIprompting's effectiveness in enhancing LLMs' reasoning abilities on a suite ofnatural language reasoning tasks, outperforming chain of thought (CoT)prompting. We find that RCI combined with CoT performs better than eitherseparately.", "output": "Language Models can Solve Computer Tasks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents a white-box intention-aware decision-making for thehandling of interactions between a pedestrian and an automated vehicle (AV) inan unsignalized street crossing scenario. Moreover, a design framework has beendeveloped, which enables automated parameterization of the decision-making.This decision-making is designed in such a manner that it can understandpedestrians in urban traffic and can react accordingly to their intentions.That way, a human-like response to the actions of the pedestrian is ensured,leading to a higher acceptance of AVs. The core notion of this paper is thatthe intention prediction of the pedestrian to cross the street anddecision-making are divided into two subsystems. On the one hand, the intentiondetection is a data-driven, black-box model. Thus, it can model the complexbehavior of the pedestrians. On the other hand, the decision-making is awhite-box model to ensure traceability and to enable a rapid verification andvalidation of AVs. This white-box decision-making provides human-like behaviorand a guaranteed prevention of deadlocks. An additional benefit is that theproposed decision-making requires low computational resources only enablingreal world usage. The automated parameterization uses a particle swarmoptimization and compares two different models of the pedestrian: The socialforce model and the Markov decision process model. Consequently, a rapid designof the decision-making is possible and different pedestrian behaviors can betaken into account. The results reinforce the applicability of the proposedintention-aware decision-making.", "output": "Intention-Aware Decision-Making for Mixed Intersection Scenarios."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose Pgx, a collection of board game simulators written in JAX. Thanksto auto-vectorization and Just-In-Time compilation of JAX, Pgx scales easily tothousands of parallel execution on GPU/TPU accelerators. We found that thesimulation of Pgx on a single A100 GPU is 10x faster than that of existingreinforcement learning libraries. Pgx implements games considered vitalbenchmarks in artificial intelligence research, such as Backgammon, Shogi, andGo. Pgx is available at ", "output": "Pgx: Hardware-accelerated parallel game simulation for reinforcement learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Humans learn quickly even in tasks that contain complex visual information.This is due in part to the efficient formation of compressed representations ofvisual information, allowing for better generalization and robustness. However,compressed representations alone are insufficient for explaining the high speedof human learning. Reinforcement learning (RL) models that seek to replicatethis impressive efficiency may do so through the use of factoredrepresentations of tasks. These informationally simplistic representations oftasks are similarly motivated as the use of compressed representations ofvisual information. Recent studies have connected biological visual perceptionto disentangled and compressed representations. This raises the question of howhumans learn to efficiently represent visual information in a manner useful forlearning tasks. In this paper we present a model of human factoredrepresentation learning based on an altered form of a $beta$-VariationalAuto-encoder used in a visual learning task. Modelling results demonstrate atrade-off in the informational complexity of model latent dimension spaces,between the speed of learning and the accuracy of reconstructions.", "output": "Learning in Factored Domains with Information-Constrained Visual Representations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "An Artificially Intelligent system (an AI) has debatable personhood if it'sepistemically possible either that the AI is a person or that it falls farshort of personhood. Debatable personhood is a likely outcome of AI developmentand might arise soon. Debatable AI personhood throws us into a catastrophicmoral dilemma: Either treat the systems as moral persons and risk sacrificingreal human interests for the sake of entities without interests worth thesacrifice, or don't treat the systems as moral persons and risk perpetratinggrievous moral wrongs against them. The moral issues become even moreperplexing if we consider cases of possibly conscious AI that are subhuman,superhuman, or highly divergent from us in their morally relevant properties.", "output": "The Full Rights Dilemma for A.I. Systems of Debatable Personhood."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Natural language processing based on large language models (LLMs) is abooming field of AI research. After neural networks have proven to outperformhumans in games and practical domains based on pattern recognition, we mightstand now at a road junction where artificial entities might eventually enterthe realm of human communication. However, this comes with serious risks. Dueto the inherent limitations regarding the reliability of neural networks,overreliance on LLMs can have disruptive consequences. Since it will beincreasingly difficult to distinguish between human-written andmachine-generated text, one is confronted with new ethical challenges. Thisbegins with the no longer undoubtedly verifiable human authorship and continueswith various types of fraud, such as a new form of plagiarism. This alsoconcerns the violation of privacy rights, the possibility of circulatingcounterfeits of humans, and, last but not least, it makes a massive spread ofmisinformation possible.", "output": "On pitfalls (and advantages) of sophisticated large language models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Quantum computing has entered the Noisy Intermediate-Scale Quantum (NISQ)era. Currently, the quantum processors we have are sensitive to environmentalvariables like radiation and temperature, thus producing noisy outputs.Although many proposed algorithms and applications exist for NISQ processors,we still face uncertainties when interpreting their noisy results.Specifically, how much confidence do we have in the quantum states we arepicking as the output? This confidence is important since a NISQ computer willoutput a probability distribution of its qubit measurements, and it issometimes hard to distinguish whether the distribution represents meaningfulcomputation or just random noise. This paper presents a novel approach toattack this problem by framing quantum circuit fidelity prediction as a TimeSeries Forecasting problem, therefore making it possible to utilize the powerof Long Short-Term Memory (LSTM) neural networks. A complete workflow to buildthe training circuit dataset and LSTM architecture is introduced, including anintuitive method of calculating the quantum circuit fidelity. The trained LSTMsystem, Q-fid, can predict the output fidelity of a quantum circuit running ona specific processor, without the need for any separate input of hardwarecalibration data or gate error rates. Evaluated on the QASMbench NISQ benchmarksuite, Q-fid's prediction achieves an average RMSE of 0.0515, up to 24.7x moreaccurate than the default Qiskit transpile tool mapomatic. When used to findthe high-fidelity circuit layouts from the available circuit transpilations,Q-fid predicts the fidelity for the top 10% layouts with an average RMSE of0.0252, up to 32.8x more accurate than mapomatic.", "output": "Quantum Circuit Fidelity Improvement with Long Short-Term Memory Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image editing using diffusion models has witnessed extremely fast-pacedgrowth recently. There are various ways in which previous works enablecontrolling and editing images. Some works use high-level conditioning such astext, while others use low-level conditioning. Nevertheless, most of them lackfine-grained control over the properties of the different objects present inthe image, i.e. object-level image editing. In this work, we consider an imageas a composition of multiple objects, each defined by various properties. Outof these properties, we identify structure and appearance as the most intuitiveto understand and useful for editing purposes. We proposeStructure-and-Appearance Paired Diffusion model (PAIR-Diffusion), which istrained using structure and appearance information explicitly extracted fromthe images. The proposed model enables users to inject a reference image'sappearance into the input image at both the object and global levels.Additionally, PAIR-Diffusion allows editing the structure while maintaining thestyle of individual components of the image unchanged. We extensively evaluateour method on LSUN datasets and the CelebA-HQ face dataset, and we demonstratefine-grained control over both structure and appearance at the object level. Wealso applied the method to Stable Diffusion to edit any real image at theobject level.", "output": "PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Language models (LMs) are increasingly being used in open-ended contexts,where the opinions reflected by LMs in response to subjective queries can havea profound impact, both on user satisfaction, as well as shaping the views ofsociety at large. In this work, we put forth a quantitative framework toinvestigate the opinions reflected by LMs -- by leveraging high-quality publicopinion polls and their associated human responses. Using this framework, wecreate OpinionsQA, a new dataset for evaluating the alignment of LM opinionswith those of 60 US demographic groups over topics ranging from abortion toautomation. Across topics, we find substantial misalignment between the viewsreflected by current LMs and those of US demographic groups: on par with theDemocrat-Republican divide on climate change. Notably, this misalignmentpersists even after explicitly steering the LMs towards particular demographicgroups. Our analysis not only confirms prior observations about theleft-leaning tendencies of some human feedback-tuned LMs, but also surfacesgroups whose opinions are poorly reflected by current LMs (e.g., 65+ andwidowed individuals). Our code and data are available at", "output": "Whose Opinions Do Language Models Reflect?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Intersectionality is a critical framework that, through inquiry and praxis,allows us to examine how social inequalities persist through domains ofstructure and discipline. Given AI fairness' raison d'^etre of ``fairness,''we argue that adopting intersectionality as an analytical framework is pivotalto effectively operationalizing fairness. Through a critical review of howintersectionality is discussed in 30 papers from the AI fairness literature, wedeductively and inductively: 1) map how intersectionality tenets operate withinthe AI fairness paradigm and 2) uncover gaps between the conceptualization andoperationalization of intersectionality. We find that researchersoverwhelmingly reduce intersectionality to optimizing for fairness metrics overdemographic subgroups. They also fail to discuss their social context and whenmentioning power, they mostly situate it only within the AI pipeline. We: 3)outline and assess the implications of these gaps for critical inquiry andpraxis, and 4) provide actionable recommendations for AI fairness researchersto engage with intersectionality in their work by grounding it in AIepistemology.", "output": "Factoring the Matrix of Domination: A Critical Review and Reimagination of Intersectionality in AI Fairness."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The debate about the concept of the so called right to explanation in AI isthe subject of a wealth of literature. It has focused, in the legalscholarship, on art. 22 GDPR and, in the technical scholarship, on techniquesthat help explain the output of a certain model (XAI). The purpose of this workis to investigate if the new provisions introduced by the proposal for aRegulation laying down harmonised rules on artificial intelligence (AI Act), incombination with Convention 108 plus and GDPR, are enough to indicate theexistence of a right to technical explainability in the EU legal framework and,if not, whether the EU should include it in its current legislation. This is apreliminary work submitted to the online event organised by the InformationSociety Law Center and it will be later developed into a full paper.", "output": "The AI Act proposal: a new right to technical interpretability?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "During the preceding biennium, vision-language pre-training has achievednoteworthy success on several downstream tasks. Nevertheless, acquiringhigh-quality image-text pairs, where the pairs are entirely exclusive of eachother, remains a challenging task, and noise exists in the commonly useddatasets. To address this issue, we propose SoftCLIP, a novel approach thatrelaxes the strict one-to-one constraint and achieves a soft cross-modalalignment by introducing a softened target, which is generated from thefine-grained intra-modal self-similarity. The intra-modal guidance isindicative to enable two pairs have some local similarities and modelmany-to-many relationships between the two modalities. Besides, since thepositive still dominates in the softened target distribution, we disentanglethe negatives in the distribution to further boost the relation alignment withthe negatives in the cross-modal learning. Extensive experiments demonstratethe effectiveness of SoftCLIP. In particular, on ImageNet zero-shotclassification task, using CC3M/CC12M as pre-training dataset, SoftCLIP bringsa top-1 accuracy improvement of 6.8%/7.2% over the CLIP baseline.", "output": "SoftCLIP: Softer Cross-modal Alignment Makes CLIP Stronger."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The use of NLP in the realm of financial technology is broad and complex,with applications ranging from sentiment analysis and named entity recognitionto question answering. Large Language Models (LLMs) have been shown to beeffective on a variety of tasks; however, no LLM specialized for the financialdomain has been reported in literature. In this work, we present BloombergGPT,a 50 billion parameter language model that is trained on a wide range offinancial data. We construct a 363 billion token dataset based on Bloomberg'sextensive data sources, perhaps the largest domain-specific dataset yet,augmented with 345 billion tokens from general purpose datasets. We validateBloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suiteof internal benchmarks that most accurately reflect our intended usage. Ourmixed dataset training leads to a model that outperforms existing models onfinancial tasks by significant margins without sacrificing performance ongeneral LLM benchmarks. Additionally, we explain our modeling choices, trainingprocess, and evaluation methodology. As a next step, we plan to releasetraining logs (Chronicles) detailing our experience in training BloombergGPT.", "output": "BloombergGPT: A Large Language Model for Finance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large pre-trained code generation models, such as OpenAI Codex, can generatesyntax- and function-correct code, making the coding of programmers moreproductive and our pursuit of artificial general intelligence closer. In thispaper, we introduce CodeGeeX, a multilingual model with 13 billion parametersfor code generation. CodeGeeX is pre-trained on 850 billion tokens of 23programming languages as of June 2022. Our extensive experiments suggest thatCodeGeeX outperforms multilingual code models of similar scale for both thetasks of code generation and translation on HumanEval-X. Building uponHumanEval (Python only), we develop the HumanEval-X benchmark for evaluatingmultilingual models by hand-writing the solutions in C++, Java, JavaScript, andGo. In addition, we build CodeGeeX-based extensions on Visual Studio Code,JetBrains, and Cloud Studio, generating 4.7 billion tokens for tens ofthousands of active users per week. Our user study demonstrates that CodeGeeXcan help to increase coding efficiency for 83.4% of its users. Finally,CodeGeeX is publicly accessible and in Sep. 2022, we open-sourced its code,model weights (the version of 850B tokens), API, extensions, and HumanEval-X at", "output": "CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present an artificial intelligence system to remotely assess the motorperformance of individuals with Parkinson's disease (PD). Participantsperformed a motor task (i.e., tapping fingers) in front of a webcam, and datafrom 250 global participants were rated by three expert neurologists followingthe Movement Disorder Society Unified Parkinson's Disease Rating Scale(MDS-UPDRS). The neurologists' ratings were highly reliable, with anintra-class correlation coefficient (ICC) of 0.88. We developed computeralgorithms to obtain objective measurements that align with the MDS-UPDRSguideline and are strongly correlated with the neurologists' ratings. Ourmachine learning model trained on these measures outperformed an MDS-UPDRScertified rater, with a mean absolute error (MAE) of 0.59 compared to therater's MAE of 0.79. However, the model performed slightly worse than theexpert neurologists (0.53 MAE). The methodology can be replicated for similarmotor tasks, providing the possibility of evaluating individuals with PD andother movement disorders remotely, objectively, and in areas with limitedaccess to neurological care.", "output": "Using AI to Measure Parkinson's Disease Severity at Home."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ideally, dialogue systems should generate responses that are faithful to theknowledge contained in relevant documents. However, many models generatehallucinated responses instead that contradict it or contain unverifiableinformation. To mitigate such undesirable behaviour, it has been proposed tofine-tune a `negative expert' on negative examples and subtract its parametersfrom those of a pre-trained model. However, intuitively, this does not takeinto account that some parameters are more responsible than others in causinghallucinations. Thus, we propose to weigh their individual importance via (anapproximation of) the Fisher Information matrix, which measures the uncertaintyof their estimate. We call this method Elastic Weight Removal (EWR). Weevaluate our method -- using different variants of Flan-T5 as a backbonelanguage model -- on multiple datasets for information-seeking dialoguegeneration and compare our method with state-of-the-art techniques forfaithfulness, such as CTRL, Quark, DExperts, and Noisy Channel reranking.Extensive automatic and human evaluation shows that EWR systematicallyincreases faithfulness at minor costs in terms of other metrics. However, wenotice that only discouraging hallucinations may increase extractiveness, i.e.shallow copy-pasting of document spans, which can be undesirable. Hence, as asecond main contribution, we show that our method can be extended tosimultaneously discourage hallucinations and extractive responses. We publiclyrelease the code for reproducing EWR and all baselines.", "output": "Elastic Weight Removal for Faithful and Abstractive Dialogue Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automated generation of clinically accurate radiology reports can improvepatient care. Previous report generation methods that rely on image captioningmodels often generate incoherent and incorrect text due to their lack ofrelevant domain knowledge, while retrieval-based attempts frequently retrievereports that are irrelevant to the input image. In this work, we proposeContrastive X-Ray REport Match (X-REM), a novel retrieval-based radiologyreport generation module that uses an image-text matching score to measure thesimilarity of a chest X-ray image and radiology report for report retrieval. Weobserve that computing the image-text matching score with a language-imagemodel can effectively capture the fine-grained interaction between image andtext that is often lost when using cosine similarity. X-REM outperformsmultiple prior radiology report generation modules in terms of both naturallanguage and clinical metrics. Human evaluation of the generated reportssuggests that X-REM increased the number of zero-error reports and decreasedthe average error severity compared to the baseline retrieval approach. Ourcode is available at: ", "output": "Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Solving complicated AI tasks with different domains and modalities is a keystep toward artificial general intelligence (AGI). While there are abundant AImodels available for different domains and modalities, they cannot handlecomplicated AI tasks. Considering large language models (LLMs) have exhibitedexceptional ability in language understanding, generation, interaction, andreasoning, we advocate that LLMs could act as a controller to manage existingAI models to solve complicated AI tasks and language could be a genericinterface to empower this. Based on this philosophy, we present HuggingGPT, asystem that leverages LLMs (e.g., ChatGPT) to connect various AI models inmachine learning communities (e.g., HuggingFace) to solve AI tasks.Specifically, we use ChatGPT to conduct task planning when receiving a userrequest, select models according to their function descriptions available inHuggingFace, execute each subtask with the selected AI model, and summarize theresponse according to the execution results. By leveraging the strong languagecapability of ChatGPT and abundant AI models in HuggingFace, HuggingGPT is ableto cover numerous sophisticated AI tasks in different modalities and domainsand achieve impressive results in language, vision, speech, and otherchallenging tasks, which paves a new way towards AGI.", "output": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The unlearning problem of deep learning models, once primarily an academicconcern, has become a prevalent issue in the industry. The significant advancesin text-to-image generation techniques have prompted global discussions onprivacy, copyright, and safety, as numerous unauthorized personal IDs, content,artistic creations, and potentially harmful materials have been learned bythese models and later utilized to generate and distribute uncontrolledcontent. To address this challenge, we propose textbf{Forget-Me-Not}, anefficient and low-cost solution designed to safely remove specified IDs,objects, or styles from a well-configured text-to-image model in as little as30 seconds, without impairing its ability to generate other content. Alongsideour method, we introduce the textbf{Memorization Score (M-Score)} andtextbf{ConceptBench} to measure the models' capacity to generate generalconcepts, grouped into three primary categories: ID, object, and style. UsingM-Score and ConceptBench, we demonstrate that Forget-Me-Not can effectivelyeliminate targeted concepts while maintaining the model's performance on otherconcepts. Furthermore, Forget-Me-Not offers two practical extensions: a)removal of potentially harmful or NSFW content, and b) enhancement of modelaccuracy, inclusion and diversity through textbf{concept correction anddisentanglement}. It can also be adapted as a lightweight model patch forStable Diffusion, allowing for concept manipulation and convenientdistribution. To encourage future research in this critical area and promotethe development of safe and inclusive generative models, we will open-sourceour code and ConceptBench athref{", "output": "Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Complexity and limited ability have profound effect on how we learn and makedecisions under uncertainty. Using the theory of finite automaton to modelbelief formation, this paper studies the characteristics of optimal learningbehavior in small and big worlds, where the complexity of the environment islow and high, respectively, relative to the cognitive ability of the decisionmaker. Optimal behavior is well approximated by the Bayesian benchmark in verysmall world but is more different as the world gets bigger. In addition, in bigworlds, the optimal learning behavior could exhibit a wide range ofwell-documented non-Bayesian learning behavior, including the use ofheuristics, correlation neglect, persistent over-confidence, inattentivelearning, and other behaviors of model simplification or misspecification.These results establish a clear and testable relationship among the prominenceof non-Bayesian learning behavior, complexity, and cognitive ability.", "output": "Learning in a Small/Big World."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In Machine Learning, the $mathsf{SHAP}$-score is a version of the Shapleyvalue that is used to explain the result of a learned model on a specificentity by assigning a score to every feature. While in general computingShapley values is an intractable problem, we prove a strong positive resultstating that the $mathsf{SHAP}$-score can be computed in polynomial time overdeterministic and decomposable Boolean circuits. Such circuits are studied inthe field of Knowledge Compilation and generalize a wide range of Booleancircuits and binary decision diagrams classes, including binary decision treesand Ordered Binary Decision Diagrams (OBDDs).We also establish the computational limits of the SHAP-score by observingthat computing it over a class of Boolean models is always polynomially as hardas the model counting problem for that class. This implies that bothdeterminism and decomposability are essential properties for the circuits thatwe consider. It also implies that computing $mathsf{SHAP}$-scores isintractable as well over the class of propositional formulas in DNF. Based onthis negative result, we look for the existence of fully-polynomial randomizedapproximation schemes (FPRAS) for computing $mathsf{SHAP}$-scores over suchclass. In contrast to the model counting problem for DNF formulas, which admitsan FPRAS, we prove that no such FPRAS exists for the computation of$mathsf{SHAP}$-scores. Surprisingly, this negative result holds even for theclass of monotone formulas in DNF. These techniques can be further extended toprove another strong negative result: Under widely believed complexityassumptions, there is no polynomial-time algorithm that checks, given amonotone DNF formula $varphi$ and features $x,y$, whether the$mathsf{SHAP}$-score of $x$ in $varphi$ is smaller than the$mathsf{SHAP}$-score of $y$ in $varphi$.", "output": "On the Complexity of SHAP-Score-Based Explanations: Tractability via Knowledge Compilation and Non-Approximability Results."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep convolutional neural networks are shown to be overkill with highparametric and computational redundancy in many application scenarios, and anincreasing number of works have explored model pruning to obtain lightweightand efficient networks. However, most existing pruning approaches are driven byempirical heuristic and rarely consider the joint impact of channels, leadingto unguaranteed and suboptimal performance. In this paper, we propose a novelchannel pruning method via Class-Aware Trace Ratio Optimization (CATRO) toreduce the computational burden and accelerate the model inference. Utilizingclass information from a few samples, CATRO measures the joint impact ofmultiple channels by feature space discriminations and consolidates thelayer-wise impact of preserved channels. By formulating channel pruning as asubmodular set function maximization problem, CATRO solves it efficiently via atwo-stage greedy iterative optimization procedure. More importantly, we presenttheoretical justifications on convergence of CATRO and performance of prunednetworks. Experimental results demonstrate that CATRO achieves higher accuracywith similar computation cost or lower computation cost with similar accuracythan other state-of-the-art channel pruning algorithms. In addition, because ofits class-aware property, CATRO is suitable to prune efficient networksadaptively for various classification subtasks, enhancing handy deployment andusage of deep networks in real-world applications.", "output": "CATRO: Channel Pruning via Class-Aware Trace Ratio Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Continual learning (CL) aims to learn a sequence of tasks over time, withdata distributions shifting from one task to another. When training on new taskdata, data representations from old tasks may drift. Some negativerepresentation drift can result in catastrophic forgetting, by causing thelocally learned class prototypes and data representations to correlate poorlyacross tasks. To mitigate such representation drift, we propose a method thatfinds global prototypes to guide the learning, and learns data representationswith the regularization of the self-supervised information. Specifically, forNLP tasks, we formulate each task in a masked language modeling style, andlearn the task via a neighbor attention mechanism over a pre-trained languagemodel. Experimental results show that our proposed method can learn fairlyconsistent representations with less representation drift, and significantlyreduce catastrophic forgetting in CL without resampling data from past tasks.", "output": "Enhancing Continual Learning with Global Prototypes: Counteracting Negative Representation Drift."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Modern image captioning models are usually trained with text similarityobjectives. However, since reference captions in public datasets often describethe most salient common objects, models trained with text similarity objectivestend to ignore specific and detailed aspects of an image that distinguish itfrom others. Toward more descriptive and distinctive caption generation, wepropose using CLIP, a multimodal encoder trained on huge image-text pairs fromweb, to calculate multimodal similarity and use it as a reward function. Wealso propose a simple finetuning strategy of the CLIP text encoder to improvegrammar that does not require extra text annotation. This completely eliminatesthe need for reference captions during the reward computation. Tocomprehensively evaluate descriptive captions, we introduce FineCapEval, a newdataset for caption evaluation with fine-grained criteria: overall, background,object, relations. In our experiments on text-to-image retrieval andFineCapEval, the proposed CLIP-guided model generates more distinctive captionsthan the CIDEr-optimized model. We also show that our unsupervised grammarfinetuning of the CLIP text encoder alleviates the degeneration problem of thenaive CLIP reward. Lastly, we show human analysis where the annotators stronglyprefer the CLIP reward to the CIDEr and MLE objectives according to variouscriteria. Code and Data: ", "output": "Fine-grained Image Captioning with CLIP Reward."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automated and semi-automated techniques in biomedical electron microscopy(EM) enable the acquisition of large datasets at a high rate. Segmentationmethods are therefore essential to analyze and interpret these large volumes ofdata, which can no longer completely be labeled manually. In recent years, deeplearning algorithms achieved impressive results in both pixel-level labeling(semantic segmentation) and the labeling of separate instances of the sameclass (instance segmentation). In this review, we examine how these algorithmswere adapted to the task of segmenting cellular and sub-cellular structures inEM images. The special challenges posed by such images and the networkarchitectures that overcame some of them are described. Moreover, a thoroughoverview is also provided on the notable datasets that contributed to theproliferation of deep learning in EM. Finally, an outlook of current trends andfuture prospects of EM segmentation is given, especially in the area oflabel-free learning.", "output": "Segmentation in large-scale cellular electron microscopy with deep learning: A literature survey."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-scale architectures and attention modules have shown effectiveness inmany deep learning-based image de-raining methods. However, manually designingand integrating these two components into a neural network requires a bulk oflabor and extensive expertise. In this article, a high-performance multi-scaleattentive neural architecture search (MANAS) framework is technically developedfor image deraining. The proposed method formulates a new multi-scale attentionsearch space with multiple flexible modules that are favorite to the imagede-raining task. Under the search space, multi-scale attentive cells are built,which are further used to construct a powerful image de-raining network. Theinternal multiscale attentive architecture of the de-raining network issearched automatically through a gradient-based search algorithm, which avoidsthe daunting procedure of the manual design to some extent. Moreover, in orderto obtain a robust image de-raining model, a practical and effectivemulti-to-one training strategy is also presented to allow the de-rainingnetwork to get sufficient background information from multiple rainy imageswith the same background scene, and meanwhile, multiple loss functionsincluding external loss, internal loss, architecture regularization loss, andmodel complexity loss are jointly optimized to achieve robust de-rainingperformance and controllable model complexity. Extensive experimental resultson both synthetic and realistic rainy images, as well as the down-stream visionapplications (i.e., objection detection and segmentation) consistentlydemonstrate the superiority of our proposed method. The code is publiclyavailable at ", "output": "Multi-scale Attentive Image De-raining Networks via Neural Architecture Search."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We address the task of controlled generation of small molecules, whichentails finding novel molecules with desired properties under certainconstraints (e.g., similarity to a reference molecule). Here we introduceMolMIM, a probabilistic auto-encoder for small molecule drug discovery thatlearns an informative and clustered latent space. MolMIM is trained with MutualInformation Machine (MIM) learning, and provides a fixed length representationof variable length SMILES strings. Since encoder-decoder models can learnrepresentations with ``holes'' of invalid samples, here we propose a novelextension to the training procedure which promotes a dense latent space, andallows the model to sample valid molecules from random perturbations of latentcodes. We provide a thorough comparison of MolMIM to several variable-size andfixed-size encoder-decoder models, demonstrating MolMIM's superior generationas measured in terms of validity, uniqueness, and novelty. We then utilizeCMA-ES, a naive black-box and gradient free search algorithm, over MolMIM'slatent space for the task of property guided molecule optimization. We achievestate-of-the-art results in several constrained single property optimizationtasks as well as in the challenging task of multi-objective optimization,improving over previous success rate SOTA by more than 5% . We attribute thestrong results to MolMIM's latent representation which clusters similarmolecules in the latent space, whereas CMA-ES is often used as a baselineoptimization method. We also demonstrate MolMIM to be favourable in a computelimited regime, making it an attractive model for such cases.", "output": "Improving Small Molecule Generation using Mutual Information Machine."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Conformance checking techniques allow us to evaluate how well some exhibitedbehaviour, represented by a trace of monitored events, conforms to a specifiedprocess model. Modern monitoring and activity recognition technologies, such asthose relying on sensors, the IoT, statistics and AI, can produce a wealth ofrelevant event data. However, this data is typically characterised by noise anduncertainty, in contrast to the assumption of a deterministic event logrequired by conformance checking algorithms. In this paper, we extendalignment-based conformance checking to function under a probabilistic eventlog. We introduce a weighted trace model and weighted alignment cost function,and a custom threshold parameter that controls the level of confidence on theevent data vs. the process model. The resulting algorithm considers activitiesof lower but sufficiently high probability that better align with the processmodel. We explain the algorithm and its motivation both from formal andintuitive perspectives, and demonstrate its functionality in comparison withdeterministic alignment using real-life datasets.", "output": "Alignment-based conformance checking over probabilistic events."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks (DNNs) have demonstrated their superiority in practice.Arguably, the rapid development of DNNs is largely benefited from high-quality(open-sourced) datasets, based on which researchers and developers can easilyevaluate and improve their learning methods. Since the data collection isusually time-consuming or even expensive, how to protect their copyrights is ofgreat significance and worth further exploration. In this paper, we revisitdataset ownership verification. We find that existing verification methodsintroduced new security risks in DNNs trained on the protected dataset, due tothe targeted nature of poison-only backdoor watermarks. To alleviate thisproblem, in this work, we explore the untargeted backdoor watermarking scheme,where the abnormal model behaviors are not deterministic. Specifically, weintroduce two dispersibilities and prove their correlation, based on which wedesign the untargeted backdoor watermark under both poisoned-label andclean-label settings. We also discuss how to use the proposed untargetedbackdoor watermark for dataset ownership verification. Experiments on benchmarkdatasets verify the effectiveness of our methods and their resistance toexisting backdoor defenses. Our codes are available aturl{", "output": "Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Decoding human visual neural representations is a challenging task with greatscientific significance in revealing vision-processing mechanisms anddeveloping brain-like intelligent machines. Most existing methods are difficultto generalize to novel categories that have no corresponding neural data fortraining. The two main reasons are 1) the under-exploitation of the multimodalsemantic knowledge underlying the neural data and 2) the small number of paired(stimuli-responses) training data. To overcome these limitations, this paperpresents a generic neural decoding method called BraVL that uses multimodallearning of brain-visual-linguistic features. We focus on modeling therelationships between brain, visual and linguistic features via multimodal deepgenerative models. Specifically, we leverage the mixture-of-product-of-expertsformulation to infer a latent code that enables a coherent joint generation ofall three modalities. To learn a more consistent joint representation andimprove the data efficiency in the case of limited brain activity data, weexploit both intra- and inter-modality mutual information maximizationregularization terms. In particular, our BraVL model can be trained undervarious semi-supervised scenarios to incorporate the visual and textualfeatures obtained from the extra categories. Finally, we construct threetrimodal matching datasets, and the extensive experiments lead to someinteresting conclusions and cognitive insights: 1) decoding novel visualcategories from human brain activity is practically possible with goodaccuracy; 2) decoding models using the combination of visual and linguisticfeatures perform much better than those using either of them alone; 3) visualperception may be accompanied by linguistic influences to represent thesemantics of visual stimuli. Code and data: ", "output": "Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, there is a lot of interest in modeling students' digitaltraces in Learning Management System (LMS) to understand students' learningbehavior patterns including aspects of meta-cognition and self-regulation, withthe ultimate goal to turn those insights into actionable information to supportstudents to improve their learning outcomes. In achieving this goal, however,there are two main issues that need to be addressed given the existingliterature. Firstly, most of the current work is course-centered (i.e. modelsare built from data for a specific course) rather than student-centered;secondly, a vast majority of the models are correlational rather than causal.Those issues make it challenging to identify the most promising actionablefactors for intervention at the student level where most of the campus-wideacademic support is designed for. In this paper, we explored a student-centricanalytical framework for LMS activity data that can provide not onlycorrelational but causal insights mined from observational data. Wedemonstrated this approach using a dataset of 1651 computing major students ata public university in the US during one semester in the Fall of 2019. Thisdataset includes students' fine-grained LMS interaction logs and administrativedata, e.g. demographics and academic performance. In addition, we expand therepository of LMS behavior indicators to include those that can characterizethe time-of-the-day of login (e.g. chronotype). Our analysis showed thatstudent login volume, compared with other login behavior indicators, is bothstrongly correlated and causally linked to student academic performance,especially among students with low academic performance. We envision that thoseinsights will provide convincing evidence for college student support groups tolaunch student-centered and targeted interventions that are effective andscalable.", "output": "Student-centric Model of Learning Management System Activity and Academic Performance: from Correlation to Causation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing Visual Object Tracking (VOT) only takes the target area in the firstframe as a template. This causes tracking to inevitably fail in fast-changingand crowded scenes, as it cannot account for changes in object appearancebetween frames. To this end, we revamped the tracking framework withProgressive Context Encoding Transformer Tracker (ProContEXT), which coherentlyexploits spatial and temporal contexts to predict object motion trajectories.Specifically, ProContEXT leverages a context-aware self-attention module toencode the spatial and temporal context, refining and updating the multi-scalestatic and dynamic templates to progressively perform accurately tracking. Itexplores the complementary between spatial and temporal context, raising a newpathway to multi-context modeling for transformer-based trackers. In addition,ProContEXT revised the token pruning technique to reduce computationalcomplexity. Extensive experiments on popular benchmark datasets such as GOT-10kand TrackingNet demonstrate that the proposed ProContEXT achievesstate-of-the-art performance.", "output": "ProContEXT: Exploring Progressive Context Transformer for Tracking."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Streaming perception is a critical task in autonomous driving that requiresbalancing the latency and accuracy of the autopilot system. However, currentmethods for streaming perception are limited as they only rely on the currentand adjacent two frames to learn movement patterns. This restricts theirability to model complex scenes, often resulting in poor detection results. Toaddress this limitation, we propose LongShortNet, a novel dual-path networkthat captures long-term temporal motion and integrates it with short-termspatial semantics for real-time perception. LongShortNet is notable as it isthe first work to extend long-term temporal modeling to streaming perception,enabling spatiotemporal feature fusion. We evaluate LongShortNet on thechallenging Argoverse-HD dataset and demonstrate that it outperforms existingstate-of-the-art methods with almost no additional computational cost.", "output": "LongShortNet: Exploring Temporal and Semantic Features Fusion in Streaming Perception."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, massive architectures based on Convolutional Neural Network (CNN)and self-attention mechanisms have become necessary for audio classification.While these techniques are state-of-the-art, these works' effectiveness canonly be guaranteed with huge computational costs and parameters, large amountsof data augmentation, transfer from large datasets and some other tricks. Byutilizing the lightweight nature of audio, we propose an efficient networkstructure called Paired Inverse Pyramid Structure (PIP) and a network calledPaired Inverse Pyramid Structure MLP Network (PIPMN). The PIPMN reaches 96% ofEnvironmental Sound Classification (ESC) accuracy on the UrbanSound8K datasetand 93.2% of Music Genre Classification (MGC) on the GTAZN dataset, with only1 million parameters. Both of the results are achieved without dataaugmentation or model transfer. Public code is available at:", "output": "Effective Audio Classification Network Based on Paired Inverse Pyramid Structure and Dense MLP Block."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, large-scale pre-trained Vision-and-Language (VL) foundation modelshave demonstrated remarkable capabilities in many zero-shot downstream tasks,achieving competitive results for recognizing objects defined by as little asshort text prompts. However, it has also been shown that VL models are stillbrittle in Structured VL Concept (SVLC) reasoning, such as the ability torecognize object attributes, states, and inter-object relations. This leads toreasoning mistakes, which need to be corrected as they occur by teaching VLmodels the missing SVLC skills; often this must be done using private datawhere the issue was found, which naturally leads to a data-free continual (notask-id) VL learning setting. In this work, we introduce the first ContinualData-Free Structured VL Concepts Learning (ConStruct-VL) benchmark and show itis challenging for many existing data-free CL strategies. We, therefore,propose a data-free method comprised of a new approach of AdversarialPseudo-Replay (APR) which generates adversarial reminders of past tasks frompast task models. To use this method efficiently, we also propose a continualparameter-efficient Layered-LoRA (LaLo) neural architecture allowingno-memory-cost access to all past models at train time. We show this approachoutperforms all data-free methods by as much as ~7% while even matching somelevels of experience-replay (prohibitive for applications where data-privacymust be preserved). Our code is publicly available at", "output": "ConStruct-VL: Data-Free Continual Structured VL Concepts Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Computer vision models suffer from a phenomenon known as catastrophicforgetting when learning novel concepts from continuously shifting trainingdata. Typical solutions for this continual learning problem require extensiverehearsal of previously seen data, which increases memory costs and may violatedata privacy. Recently, the emergence of large-scale pre-trained visiontransformer models has enabled prompting approaches as an alternative todata-rehearsal. These approaches rely on a key-query mechanism to generateprompts and have been found to be highly resistant to catastrophic forgettingin the well-established rehearsal-free continual learning setting. However, thekey mechanism of these methods is not trained end-to-end with the tasksequence. Our experiments show that this leads to a reduction in theirplasticity, hence sacrificing new task accuracy, and inability to benefit fromexpanded parameter capacity. We instead propose to learn a set of promptcomponents which are assembled with input-conditioned weights to produceinput-conditioned prompts, resulting in a novel attention-based end-to-endkey-query scheme. Our experiments show that we outperform the current SOTAmethod DualPrompt on established benchmarks by as much as 4.5% in average finalaccuracy. We also outperform the state of art by as much as 4.4% accuracy on acontinual learning benchmark which contains both class-incremental anddomain-incremental task shifts, corresponding to many practical settings. Ourcode is available at ", "output": "CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Standard multi-modal models assume the use of the same modalities in trainingand inference stages. However, in practice, the environment in whichmulti-modal models operate may not satisfy such assumption. As such, theirperformances degrade drastically if any modality is missing in the inferencestage. We ask: how can we train a model that is robust to missing modalities?This paper seeks a set of good practices for multi-modal action recognition,with a particular interest in circumstances where some modalities are notavailable at an inference time. First, we study how to effectively regularizethe model during training (e.g., data augmentation). Second, we investigate onfusion methods for robustness to missing modalities: we find thattransformer-based fusion shows better robustness for missing modality thansummation or concatenation. Third, we propose a simple modular network,ActionMAE, which learns missing modality predictive coding by randomly droppingmodality features and tries to reconstruct them with the remaining modalityfeatures. Coupling these good practices, we build a model that is not onlyeffective in multi-modal action recognition but also robust to modalitymissing. Our model achieves the state-of-the-arts on multiple benchmarks andmaintains competitive performances even in missing modality scenarios. Codesare available at ", "output": "Towards Good Practices for Missing Modality Robust Action Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Learning semantic-rich representations from raw unlabeled time series data iscritical for downstream tasks such as classification and forecasting.Contrastive learning has recently shown its promising representation learningcapability in the absence of expert annotations. However, existing contrastiveapproaches generally treat each instance independently, which leads to falsenegative pairs that share the same semantics. To tackle this problem, wepropose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model,which exploits semantic information obtained from the hierarchical structureconsisting of multiple latent partitions for multivariate time series.Motivated by the observation that fine-grained clustering preserves higherpurity while coarse-grained one reflects higher-level semantics, we propose anovel downward masking strategy to filter out fake negatives and supplementpositives by incorporating the multi-granularity information from theclustering hierarchy. In addition, a novel upward masking strategy is designedin MHCCL to remove outliers of clusters at each partition to refine prototypes,which helps speed up the hierarchical clustering process and improves theclustering quality. We conduct experimental evaluations on seven widely-usedmultivariate time series datasets. The results demonstrate the superiority ofMHCCL over the state-of-the-art approaches for unsupervised time seriesrepresentation learning.", "output": "MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study focuses on using large language models (LLMs) as a planner forembodied agents that can follow natural language instructions to completecomplex tasks in a visually-perceived environment. The high data cost and poorsample efficiency of existing methods hinders the development of versatileagents that are capable of many tasks and can learn new tasks quickly. In thiswork, we propose a novel method, LLM-Planner, that harnesses the power of largelanguage models to do few-shot planning for embodied agents. We further proposea simple but effective way to enhance LLMs with physical grounding to generateand update plans that are grounded in the current environment. Experiments onthe ALFRED dataset show that our method can achieve very competitive few-shotperformance: Despite using less than 0.5% of paired training data, LLM-Plannerachieves competitive performance with recent baselines that are trained usingthe full training data. Existing methods can barely complete any tasksuccessfully under the same few-shot setting. Our work opens the door fordeveloping versatile and sample-efficient embodied agents that can quicklylearn many tasks. Website: ", "output": "LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We re-replicate 14 psychology studies from the Many Labs 2 replicationproject (Klein et al., 2018) with OpenAI's text-davinci-003 model, colloquiallyknown as GPT3.5. Among the eight studies we could analyse, our GPT samplereplicated 37.5% of the original results and 37.5% of the Many Labs 2 results.We could not analyse the remaining six studies, due to an unexpected phenomenonwe call the \"correct answer\" effect. Different runs of GPT3.5 answered nuancedquestions probing political orientation, economic preference, judgement, andmoral philosophy with zero or near-zero variation in responses: with thesupposedly \"correct answer.\" Most but not all of these \"correct answers\" wererobust to changing the order of answer choices. One exception occurred in theMoral Foundations Theory survey (Graham et al., 2009), for which GPT3.5 almostalways identified as a conservative in the original condition (N=1,030, 99.6%)and as a liberal in the reverse-order condition (N=1,030, 99.3%). GPT3.5'sresponses to subsequent questions revealed post-hoc rationalisation; there wasa relative bias in the direction of its previously reported politicalorientation. But both self-reported GPT conservatives and self-reported GPTliberals revealed right-leaning Moral Foundations, although the right-leaningbias of self-reported GPT liberals was weaker. We hypothesise that this patternwas learned from a conservative bias in the model's largely Internet-basedtraining data. Since AI models of the future may be trained on much of the sameInternet data as GPT3.5, our results raise concerns that a hypothetical AI-ledfuture may be subject to a diminished diversity of thought.", "output": "\"Correct answers\" from the psychology of artificial intelligence."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Object detection with on-board sensors (e.g., lidar, radar, and camera) playa crucial role in autonomous driving (AD), and these sensors complement eachother in modalities. While crowdsensing may potentially exploit these sensors(of huge quantity) to derive more comprehensive knowledge, textit{federatedlearning} (FL) appears to be the necessary tool to reach this potential: itenables autonomous vehicles (AVs) to train machine learning models withoutexplicitly sharing raw sensory data. However, the multimodal sensors introducevarious data heterogeneity across distributed AVs (e.g., label quantity skewsand varied modalities), posing critical challenges to effective FL. To thisend, we present AutoFed as a heterogeneity-aware FL framework to fully exploitmultimodal sensory data on AVs and thus enable robust AD. Specifically, wefirst propose a novel model leveraging pseudo-labeling to avoid mistakenlytreating unlabeled objects as the background. We also propose anautoencoder-based data imputation method to fill missing data modality (ofcertain AVs) with the available ones. To further reconcile the heterogeneity,we finally present a client selection mechanism exploiting the similaritiesamong client models to improve both training stability and convergence rate.Our experiments on benchmark dataset confirm that AutoFed substantiallyimproves over status quo approaches in both precision and recall, whiledemonstrating strong robustness to adverse weather conditions.", "output": "AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pretrained Foundation Models (PFMs) are regarded as the foundation forvarious downstream tasks with different data modalities. A PFM (e.g., BERT,ChatGPT, and GPT-4) is trained on large-scale data which provides a reasonableparameter initialization for a wide range of downstream applications. BERTlearns bidirectional encoder representations from Transformers, which aretrained on large datasets as contextual language models. Similarly, thegenerative pretrained transformer (GPT) method employs Transformers as thefeature extractor and is trained using an autoregressive paradigm on largedatasets. Recently, ChatGPT shows promising success on large language models,which applies an autoregressive language model with zero shot or few shotprompting. The remarkable achievements of PFM have brought significantbreakthroughs to various fields of AI. Numerous studies have proposed differentmethods, raising the demand for an updated survey. This study provides acomprehensive review of recent research advancements, challenges, andopportunities for PFMs in text, image, graph, as well as other data modalities.The review covers the basic components and existing pretraining methods used innatural language processing, computer vision, and graph learning. Additionally,it explores advanced PFMs used for different data modalities and unified PFMsthat consider data quality and quantity. The review also discusses researchrelated to the fundamentals of PFMs, such as model efficiency and compression,security, and privacy. Finally, the study provides key implications, futureresearch directions, challenges, and open problems in the field of PFMs.Overall, this survey aims to shed light on the research of the PFMs onscalability, security, logical reasoning ability, cross-domain learningability, and the user-friendly interactive ability for artificial generalintelligence.", "output": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Whole slide image (WSI) has been widely used to assist automated diagnosisunder the deep learning fields. However, most previous works only discuss theSINGLE task setting which is not aligned with real clinical setting, wherepathologists often conduct multiple diagnosis tasks simultaneously. Also, it iscommonly recognized that the multi-task learning paradigm can improve learningefficiency by exploiting commonalities and differences across multiple tasks.To this end, we present a novel multi-task framework (i.e., MulGT) for WSIanalysis by the specially designed Graph-Transformer equipped with Task-awareKnowledge Injection and Domain Knowledge-driven Graph Pooling modules.Basically, with the Graph Neural Network and Transformer as the buildingcommons, our framework is able to learn task-agnostic low-level localinformation as well as task-specific high-level global representation.Considering that different tasks in WSI analysis depend on different featuresand properties, we also design a novel Task-aware Knowledge Injection module totransfer the task-shared graph embedding into task-specific feature spaces tolearn more accurate representation for different tasks. Further, we elaboratelydesign a novel Domain Knowledge-driven Graph Pooling module for each task toimprove both the accuracy and robustness of different tasks by leveragingdifferent diagnosis patterns of multiple tasks. We evaluated our method on twopublic WSI datasets from TCGA projects, i.e., esophageal carcinoma and kidneycarcinoma. Experimental results show that our method outperforms single-taskcounterparts and the state-of-theart methods on both tumor typing and stagingtasks.", "output": "MulGT: Multi-task Graph-Transformer with Task-aware Knowledge Injection and Domain Knowledge-driven Pooling for Whole Slide Image Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent years have shown an increased development of methods for justifyingthe predictions of neural networks through visual explanations. Theseexplanations usually take the form of heatmaps which assign a saliency (orrelevance) value to each pixel of the input image that expresses how relevantthe pixel is for the prediction of a label.Complementing this development, evaluation methods have been proposed toassess the \"goodness\" of such explanations. On the one hand, some of thesemethods rely on synthetic datasets. However, this introduces the weakness ofhaving limited guarantees regarding their applicability on more realisticsettings. On the other hand, some methods rely on metrics for objectiveevaluation. However the level to which some of these evaluation methods performwith respect to each other is uncertain.Taking this into account, we conduct a comprehensive study on a subset of theImageNet-1k validation set where we evaluate a number of differentcommonly-used explanation methods following a set of evaluation methods. Wecomplement our study with sanity checks on the studied evaluation methods as ameans to investigate their reliability and the impact of characteristics of theexplanations on the evaluation methods.Results of our study suggest that there is a lack of coherency on the gradingprovided by some of the considered evaluation methods. Moreover, we haveidentified some characteristics of the explanations, e.g. sparsity, which canhave a significant effect on the performance.", "output": "On The Coherence of Quantitative Evaluation of Visual Explanations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "textit{Objective:} In this paper, we introduce Physics-Informed FourierNetworks for Electrical Properties Tomography (PIFON-EPT), a novel deeplearning-based method that solves an inverse scattering problem based on noisyand/or incomplete magnetic resonance (MR) measurements. textit{Methods:} Weused two separate fully-connected neural networks, namely $B_1^{+}$ Net and EPNet, to solve the Helmholtz equation in order to learn a de-noised version ofthe input $B_1^{+}$ maps and estimate the object's EP. A random Fourierfeatures mapping was embedded into $B_1^{+}$ Net, to learn the high-frequencydetails of $B_1^{+}$ more efficiently. The two neural networks were trainedjointly by minimizing the combination of a physics-informed loss and a datamismatch loss via gradient descent. textit{Results:} We performed severalnumerical experiments, showing that PIFON-EPT could provide physicallyconsistent reconstructions of the EP and transmit field. Even when only $50%$of the noisy MR measurements were used as inputs, our method could stillreconstruct the EP and transmit field with average error $2.49%$, $4.09%$ and$0.32%$ for the relative permittivity, conductivity and $B_{1}^{+}$,respectively, over the entire volume of the phantom. The generalized version ofPIFON-EPT that accounts for gradients of EP yielded accurate results at theinterface between regions of different EP values without requiring any boundaryconditions. textit{Conclusion:} This work demonstrated the feasibility ofPIFON-EPT, suggesting it could be an accurate and effective method for EPestimation. textit{Significance:} PIFON-EPT can efficiently de-noise $B_1^{+}$maps, which has the potential to improve other MR-based EPT techniques.Furthermore, PIFON-EPT is the first technique that can reconstruct EP and$B_{1}^{+}$ simultaneously from incomplete noisy MR measurements.", "output": "PIFON-EPT: MR-Based Electrical Property Tomography Using Physics-Informed Fourier Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Classical semantics assumes that one can model reference, predication andquantification with respect to a fixed domain of precise referent objects.Non-logical terms and quantification are then interpreted directly in terms ofelements and subsets of this domain. We explore ways to generalise thisclassical picture of precise predicates and objects to account for variabilityof meaning due to factors such as vagueness, context and diversity ofdefinitions or opinions. Both names and predicative expressions can be giveneither multiple semantic referents or be associated with semantic referentsthat incorporate some model of variability. We present a semantic framework,Variable Reference Semantics, that can accommodate several modes of variabilityin relation to both predicates and objects.", "output": "Vagueness in Predicates and Objects."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Autonomous agents that operate in the real world must often deal with partialobservability, which is commonly modeled as partially observable Markovdecision processes (POMDPs). However, traditional POMDP models rely on theassumption of complete knowledge of the observation source, known as fullyobservable data association. To address this limitation, we propose a planningalgorithm that maintains multiple data association hypotheses, represented as abelief mixture, where each component corresponds to a different dataassociation hypothesis. However, this method can lead to an exponential growthin the number of hypotheses, resulting in significant computational overhead.To overcome this challenge, we introduce a pruning-based approach for planningwith ambiguous data associations. Our key contribution is to derive boundsbetween the value function based on the complete set of hypotheses and thevalue function based on a pruned-subset of the hypotheses, enabling us toestablish a trade-off between computational efficiency and performance. Wedemonstrate how these bounds can both be used to certify any pruning heuristicin retrospect and propose a novel approach to determine which hypotheses toprune in order to ensure a predefined limit on the loss. We evaluate ourapproach in simulated environments and demonstrate its efficacy in handlingmulti-modal belief hypotheses with ambiguous data associations.", "output": "Data Association Aware POMDP Planning with Hypothesis Pruning Performance Guarantees."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, a plethora of spectral graph neural networks (GNN) methodshave utilized polynomial basis with learnable coefficients to achieve top-tierperformances on many node-level tasks. Although various kinds of polynomialbases have been explored, each such method adopts a fixed polynomial basiswhich might not be the optimal choice for the given graph. Besides, we identifythe so-called over-passing issue of these methods and show that it is somewhatrooted in their less-principled regularization strategy and unnormalized basis.In this paper, we make the first attempts to address these two issues.Leveraging Jacobi polynomials, we design a novel spectral GNN, LON-GNN, withLearnable OrthoNormal bases and prove that regularizing coefficients becomesequivalent to regularizing the norm of learned filter function now. We conductextensive experiments on diverse graph datasets to evaluate the fitting andgeneralization capability of LON-GNN, where the results imply its superiority.", "output": "LON-GNN: Spectral GNNs with Learnable Orthonormal Basis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Major depressive disorder (MDD) is a heterogeneous condition; multipleunderlying neurobiological substrates could be associated with treatmentresponse variability. Understanding the sources of this variability andpredicting outcomes has been elusive. Machine learning has shown promise inpredicting treatment response in MDD, but one limitation has been the lack ofclinical interpretability of machine learning models. We analyzed data from sixclinical trials of pharmacological treatment for depression (total n = 5438)using the Differential Prototypes Neural Network (DPNN), a neural network modelthat derives patient prototypes which can be used to derive treatment-relevantpatient clusters while learning to generate probabilities for differentialtreatment response. A model classifying remission and outputting individualremission probabilities for five first-line monotherapies and three combinationtreatments was trained using clinical and demographic data. Model validity andclinical utility were measured based on area under the curve (AUC) and expectedimprovement in sample remission rate with model-guided treatment, respectively.Post-hoc analyses yielded clusters (subgroups) based on patient prototypeslearned during training. Prototypes were evaluated for interpretability byassessing differences in feature distributions and treatment-specific outcomes.A 3-prototype model achieved an AUC of 0.66 and an expected absoluteimprovement in population remission rate compared to the sample remission rate.We identified three treatment-relevant patient clusters which were clinicallyinterpretable. It is possible to produce novel treatment-relevant patientprofiles using machine learning models; doing so may improve precision medicinefor depression. Note: This model is not currently the subject of any activeclinical trials and is not intended for clinical use.", "output": "Towards Outcome-Driven Patient Subgroups: A Machine Learning Analysis Across Six Depression Treatment Studies."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a simple pairwise sigmoid loss for image-text pre-training. Unlikestandard contrastive learning with softmax normalization, the sigmoid lossoperates solely on image-text pairs and does not require a global view of thepairwise similarities for normalization. The sigmoid loss simultaneously allowsfurther scaling up the batch size, while also performing better at smallerbatch sizes. With only four TPUv4 chips, we can train a Base CLIP model at 4kbatch size and a Large LiT model at 20k batch size, the latter achieves 84.5%ImageNet zero-shot accuracy in two days. This disentanglement of the batch sizefrom the loss further allows us to study the impact of examples vs pairs andnegative to positive ratio. Finally, we push the batch size to the extreme, upto one million, and find that the benefits of growing batch size quicklydiminish, with a more reasonable batch size of 32k being sufficient. We hopeour research motivates further explorations in improving the quality andefficiency of language-image pre-training.", "output": "Sigmoid Loss for Language Image Pre-Training."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision Transformers (ViTs) emerge to achieve impressive performance on manydata-abundant computer vision tasks by capturing long-range dependencies amonglocal features. However, under few-shot learning (FSL) settings on smalldatasets with only a few labeled data, ViT tends to overfit and suffers fromsevere performance degradation due to its absence of CNN-alike inductive bias.Previous works in FSL avoid such problem either through the help ofself-supervised auxiliary losses, or through the dextile uses of labelinformation under supervised settings. But the gap between self-supervised andsupervised few-shot Transformers is still unfilled. Inspired by recent advancesin self-supervised knowledge distillation and masked image modeling (MIM), wepropose a novel Supervised Masked Knowledge Distillation model (SMKD) forfew-shot Transformers which incorporates label information intoself-distillation frameworks. Compared with previous self-supervised methods,we allow intra-class knowledge distillation on both class and patch tokens, andintroduce the challenging task of masked patch tokens reconstruction acrossintra-class images. Experimental results on four few-shot classificationbenchmark datasets show that our method with simple design outperforms previousmethods by a large margin and achieves a new start-of-the-art. Detailedablation studies confirm the effectiveness of each component of our model. Codefor this paper is available here: ", "output": "Supervised Masked Knowledge Distillation for Few-Shot Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Road network digital twins (RNDTs) play a critical role in the development ofnext-generation intelligent transportation systems, enabling more precisetraffic planning and control. To support just-in-time (JIT) decision making,RNDTs require a model that dynamically learns the traffic patterns from onlinesensor data and generates high-fidelity simulation results. Although currenttraffic prediction techniques based on graph neural networks have achievedstate-of-the-art performance, these techniques only predict future traffic bymining correlations in historical traffic data, disregarding the causes oftraffic generation, such as traffic demands and route selection. Therefore,their performance is unreliable for JIT decision making. To fill this gap, weintroduce a novel deep learning framework called TraffNet that learns thecausality of traffic volume from vehicle trajectory data. First, we use aheterogeneous graph to represent the road network, allowing the model toincorporate causal features of traffic volumes. Next, motivated by the trafficdomain knowledge, we propose a traffic causality learning method to learn anembedding vector that encodes travel demands and path-level dependencies foreach road segment. Then, we model temporal dependencies to match the underlyingprocess of traffic generation. Finally, the experiments verify the utility ofTraffNet. The code of TraffNet is available at", "output": "TraffNet: Learning Causality of Traffic Generation for Road Network Digital Twins."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study presents a novel approach to bone age assessment (BAA) using amulti-view, multi-task classification model based on the Sauvegrain method. Astraightforward solution to automating the Sauvegrain method, which assesses amaturity score for each landmark in the elbow and predicts the bone age, is totrain classifiers independently to score each region of interest (RoI), butthis approach limits the accessible information to local morphologies andincreases computational costs. As a result, this work proposes aself-accumulative vision transformer (SAT) that mitigates anisotropic behavior,which usually occurs in multi-view, multi-task problems and limits theeffectiveness of a vision transformer, by applying token replay and regionalattention bias. A number of experiments show that SAT successfully exploits therelationships between landmarks and learns global morphological features,resulting in a mean absolute error of BAA that is 0.11 lower than that of theprevious work. Additionally, the proposed SAT has four times reduced parametersthan an ensemble of individual classifiers of the previous work. Lastly, thiswork also provides informative implications for clinical practice, improvingthe accuracy and efficiency of BAA in diagnosing abnormal growth inadolescents.", "output": "Self-accumulative Vision Transformer for Bone Age Assessment Using the Sauvegrain Method."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The fairness of a deep neural network is strongly affected by dataset biasand spurious correlations, both of which are usually present in modernfeature-rich and complex visual datasets. Due to the difficulty and variabilityof the task, no single de-biasing method has been universally successful. Inparticular, implicit methods not requiring explicit knowledge of bias variablesare especially relevant for real-world applications. We propose a novelimplicit mitigation method using a Bayesian neural network, allowing us toleverage the relationship between epistemic uncertainties and the presence ofbias or spurious correlations in a sample. Our proposed posterior estimatesharpening procedure encourages the network to focus on core features that donot contribute to high uncertainties. Experimental results on three benchmarkdatasets demonstrate that Bayesian networks with sharpened posterior estimatesperform comparably to prior existing methods and show potential worthy offurther exploration.", "output": "Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a Bayesian Neural Network."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The use of Semantic Technologies - in particular the Semantic Web - hasrevealed to be a great tool for describing the cultural heritage domain andartistic practices. However, the panorama of ontologies for musicologicalapplications seems to be limited and restricted to specific applications. Inthis research, we propose HaMSE, an ontology capable of describing musicalfeatures that can assist musicological research. More specifically, HaMSEproposes to address sues that have been affecting musicological research fordecades: the representation of music and the relationship between quantitativeand qualitative data. To do this, HaMSE allows the alignment between differentmusic representation systems and describes a set of musicological features thatcan allow the music analysis at different granularity levels.", "output": "The HaMSE Ontology: Using Semantic Technologies to support Music Representation Interoperability and Musicological Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Tracking single molecules is instrumental for quantifying the transport ofmolecules and nanoparticles in biological samples, e.g., in brain drug deliverystudies. Existing intensity-based localisation methods are not developed forimaging with a scanning microscope, typically used for in vivo imaging. Lowsignal-to-noise ratios, movement of molecules out-of-focus, and high motionblur on images recorded with scanning two-photon microscopy (2PM) in vivo posea challenge to the accurate localisation of molecules. Using data-driven modelsis challenging due to low data volumes, typical for in vivo experiments. Wedeveloped a 2PM image simulator to supplement scarce training data. Thesimulator mimics realistic motion blur, background fluorescence, and shot noiseobserved in vivo imaging. Training a data-driven model with simulated dataimproves localisation quality in simulated images and shows why intensity-basedmethods fail.", "output": "Deep Learning-Assisted Localisation of Nanoparticles in synthetically generated two-photon microscopy images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ground-glass opacity is a hallmark of numerous lung diseases, includingpatients with COVID19 and pneumonia. This brief note presents experimentalresults of a proof-of-concept framework that got implemented and tested overthree days as driven by the third challenge entitled \"COVID-19 Competition\",hosted at the AI-Enabled Medical Image Analysis Workshop of the 2023 IEEEInternational Conference on Acoustics, Speech and Signal Processing (ICASSP2023). Using a newly built virtual environment (created on March 17, 2023), weinvestigated various pre-trained two-dimensional convolutional neural networks(CNN) such as Dense Neural Network, Residual Neural Networks (ResNet), andVision Transformers, as well as the extent of fine-tuning. Based on empiricalexperiments, we opted to fine-tune them using ADAM's optimization algorithmwith a standard learning rate of 0.001 for all CNN architectures and applyearly-stopping whenever the validation loss reached a plateau. For each trainedCNN, the model state with the best validation accuracy achieved during trainingwas stored and later reloaded for new classifications of unseen samples drawnfrom the validation set provided by the challenge organizers. According to theorganizers, few of these 2D CNNs yielded performance comparable to anarchitecture that combined ResNet and Recurrent Neural Network (Gated RecurrentUnits). As part of the challenge requirement, the source code produced duringthe course of this exercise is posted at  Wealso hope that other researchers may find this light prototype consisting offew Python files based on PyTorch 1.13.1 and TorchVision 0.14.1 approachable.", "output": "Severity classification of ground-glass opacity via 2-D convolutional neural network and lung CT scans: a 3-day exploration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural Architecture Search (NAS) benchmarks significantly improved thecapability of developing and comparing NAS methods while at the same timedrastically reduced the computational overhead by providing meta-informationabout thousands of trained neural networks. However, tabular benchmarks haveseveral drawbacks that can hinder fair comparisons and provide unreliableresults. These usually focus on providing a small pool of operations in heavilyconstrained search spaces -- usually cell-based neural networks withpre-defined outer-skeletons. In this work, we conducted an empirical analysisof the widely used NAS-Bench-101, NAS-Bench-201 and TransNAS-Bench-101benchmarks in terms of their generability and how different operationsinfluence the performance of the generated architectures. We found that only asubset of the operation pool is required to generate architectures close to theupper-bound of the performance range. Also, the performance distribution isnegatively skewed, having a higher density of architectures in the upper-boundrange. We consistently found convolution layers to have the highest impact onthe architecture's performance, and that specific combination of operationsfavors top-scoring architectures. These findings shed insights on the correctevaluation and comparison of NAS methods using NAS benchmarks, showing thatdirectly searching on NAS-Bench-201, ImageNet16-120 and TransNAS-Bench-101produces more reliable results than searching only on CIFAR-10. Furthermore,with this work we provide suggestions for future benchmark evaluations anddesign. The code used to conduct the evaluations is available at", "output": "Are Neural Architecture Search Benchmarks Well Designed? A Deeper Look Into Operation Importance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Object detection utilizing Frequency Modulated Continous Wave radar isbecoming increasingly popular in the field of autonomous systems. Radar doesnot possess the same drawbacks seen by other emission-based sensors such asLiDAR, primarily the degradation or loss of return signals due to weatherconditions such as rain or snow. However, radar does possess traits that makeit unsuitable for standard emission-based deep learning representations such aspoint clouds. Radar point clouds tend to be sparse and therefore informationextraction is not efficient. To overcome this, more traditional digital signalprocessing pipelines were adapted to form inputs residing directly in thefrequency domain via Fast Fourier Transforms. Commonly, three transformationswere used to form Range-Azimuth-Doppler cubes in which deep learning algorithmscould perform object detection. This too has drawbacks, namely thepre-processing costs associated with performing multiple Fourier Transforms andnormalization. We explore the possibility of operating on raw radar inputs fromanalog to digital converters via the utilization of complex transformationlayers. Moreover, we introduce hierarchical Swin Vision transformers to thefield of radar object detection and show their capability to operate on inputsvarying in pre-processing, along with different radar configurations, i.e.relatively low and high numbers of transmitters and receivers, while obtainingon par or better results than the state-of-the-art.", "output": "T-FFTRadNet: Object Detection with Swin Vision Transformers from Raw ADC Radar Signals."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Dense Self-Supervised Learning (SSL) methods address the limitations of usingimage-level feature representations when handling images with multiple objects.Although the dense features extracted by employing segmentation maps andbounding boxes allow networks to perform SSL for each object, we show that theysuffer from coupling and positional bias, which arise from the receptive fieldincreasing with layer depth and zero-padding. We address this by introducingthree data augmentation strategies, and leveraging them in (i) a decouplingmodule that aims to robustify the network to variations in the object'ssurroundings, and (ii) a de-positioning module that encourages the network todiscard positional object information. We demonstrate the benefits of ourmethod on COCO and on a new challenging benchmark, OpenImage-MINI, for objectclassification, semantic segmentation, and object detection. Our extensiveexperiments evidence the better generalization of our method compared to theSOTA dense SSL methods", "output": "De-coupling and De-positioning Dense Self-supervised Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Learning a generalizable object manipulation policy is vital for an embodiedagent to work in complex real-world scenes. Parts, as the shared components indifferent object categories, have the potential to increase the generalizationability of the manipulation policy and achieve cross-category objectmanipulation. In this work, we build the first large-scale, part-basedcross-category object manipulation benchmark, PartManip, which is composed of11 object categories, 494 objects, and 1432 tasks in 6 task classes. Comparedto previous work, our benchmark is also more diverse and realistic, i.e.,having more objects and using sparse-view point cloud as input without oracleinformation like part segmentation. To tackle the difficulties of vision-basedpolicy learning, we first train a state-based expert with our proposedpart-based canonicalization and part-aware rewards, and then distill theknowledge to a vision-based student. We also find an expressive backbone isessential to overcome the large diversity of different objects. Forcross-category generalization, we introduce domain adversarial learning fordomain-invariant feature extraction. Extensive experiments in simulation showthat our learned policy can outperform other methods by a large margin,especially on unseen object categories. We also demonstrate our method cansuccessfully manipulate novel objects in the real world.", "output": "PartManip: Learning Cross-Category Generalizable Part Manipulation Policy from Point Cloud Observations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "To enable progress towards egocentric agents capable of understandingeveryday tasks specified in natural language, we propose a benchmark and asynthetic dataset called Egocentric Task Verification (EgoTV). EgoTV containsmulti-step tasks with multiple sub-task decompositions, state changes, objectinteractions, and sub-task ordering constraints, in addition to abstracted taskdescriptions that contain only partial details about ways to accomplish a task.We also propose a novel Neuro-Symbolic Grounding (NSG) approach to enable thecausal, temporal, and compositional reasoning of such tasks. We demonstrateNSG's capability towards task tracking and verification on our EgoTV datasetand a real-world dataset derived from CrossTask (CTV). Our contributionsinclude the release of the EgoTV and CTV datasets, and the NSG model for futureresearch on egocentric assistive agents.", "output": "EgoTV: Egocentric Task Verification from Natural Language Task Descriptions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Advancements in the generation quality of various Generative Models (GMs) hasmade it necessary to not only perform binary manipulation detection but alsolocalize the modified pixels in an image. However, prior works termed aspassive for manipulation localization exhibit poor generalization performanceover unseen GMs and attribute modifications. To combat this issue, we propose aproactive scheme for manipulation localization, termed MaLP. We encrypt thereal images by adding a learned template. If the image is manipulated by anyGM, this added protection from the template not only aids binary detection butalso helps in identifying the pixels modified by the GM. The template islearned by leveraging local and global-level features estimated by a two-brancharchitecture. We show that MaLP performs better than prior passive works. Wealso show the generalizability of MaLP by testing on 22 different GMs,providing a benchmark for future research on manipulation localization.Finally, we show that MaLP can be used as a discriminator for improving thegeneration quality of GMs. Our models/codes are available atwww.github.com/vishal3477/pro_loc.", "output": "MaLP: Manipulation Localization Using a Proactive Scheme."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Spatio-temporal grounding describes the task of localizing events in spaceand time, e.g., in video data, based on verbal descriptions only. Models forthis task are usually trained with human-annotated sentences and bounding boxsupervision. This work addresses this task from a multimodal supervisionperspective, proposing a framework for spatio-temporal action grounding trainedon loose video and subtitle supervision only, without human annotation. To thisend, we combine local representation learning, which focuses on leveragingfine-grained spatial information, with a global representation encoding thatcaptures higher-level representations and incorporates both in a jointapproach. To evaluate this challenging task in a real-life setting, a newbenchmark dataset is proposed providing dense spatio-temporal groundingannotations in long, untrimmed, multi-action instructional videos for over 5Kevents. We evaluate the proposed approach and other methods on the proposed andstandard downstream tasks showing that our method improves over currentbaselines in various settings, including spatial, temporal, and untrimmedmulti-action spatio-temporal grounding.", "output": "What, when, and where? -- Self-Supervised Spatio-Temporal Grounding in Untrimmed Multi-Action Videos from Narrated Instructions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Robotic underwater systems, e.g., Autonomous Underwater Vehicles (AUVs) andRemotely Operated Vehicles (ROVs), are promising tools for collectingbiogeochemical data at the ice-water interface for scientific advancements.However, state estimation, i.e., localization, is a well-known problem forrobotic systems, especially, for the ones that travel underwater. In thispaper, we present a tightly-coupled multi-sensors fusion framework to increaselocalization accuracy that is robust to sensor failure. Visual images, DopplerVelocity Log (DVL), Inertial Measurement Unit (IMU) and Pressure sensor areintegrated into the state-of-art Multi-State Constraint Kalman Filter (MSCKF)for state estimation. Besides that a new keyframe-based state clone mechanismand a new DVL-aided feature enhancement are presented to further improve thelocalization performance. The proposed method is validated with a data setcollected in the field under frozen ice, and the result is compared with 6other different sensor fusion setups. Overall, the result with the keyframeenabled and DVL-aided feature enhancement yields the best performance with aRoot-mean-square error of less than 2 m compared to the ground truth path witha total traveling distance of about 200 m.", "output": "Tightly-coupled Visual-DVL-Inertial Odometry for Robot-based Ice-water Boundary Exploration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image-to-image translation (I2I) methods allow the generation of artificialimages that share the content of the original image but have a different style.With the advances in Generative Adversarial Networks (GANs)-based methods, I2Imethods enabled the generation of artificial images that are indistinguishablefrom natural images. Recently, I2I methods were also employed in histopathologyfor generating artificial images of in silico stained tissues from a differenttype of staining. We refer to this process as stain transfer. The number of I2Ivariants is constantly increasing, which makes a well justified choice of themost suitable I2I methods for stain transfer challenging. In our work, wecompare twelve stain transfer approaches, three of which are based ontraditional and nine on GAN-based image processing methods. The analysis relieson complementary quantitative measures for the quality of image translation,the assessment of the suitability for deep learning-based tissue grading, andthe visual evaluation by pathologists. Our study highlights the strengths andweaknesses of the stain transfer approaches, thereby allowing a rational choiceof the underlying I2I algorithms. Code, data, and trained models for staintransfer between H&amp;E and Masson's Trichrome staining will be made availableonline.", "output": "A comparative evaluation of image-to-image translation methods for stain transfer in histopathology."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Implicit neural fields, typically encoded by a multilayer perceptron (MLP)that maps from coordinates (e.g., xyz) to signals (e.g., signed distances),have shown remarkable promise as a high-fidelity and compact representation.However, the lack of a regular and explicit grid structure also makes itchallenging to apply generative modeling directly on implicit neural fields inorder to synthesize new data. To this end, we propose HyperDiffusion, a novelapproach for unconditional generative modeling of implicit neural fields.HyperDiffusion operates directly on MLP weights and generates new neuralimplicit fields encoded by synthesized MLP parameters. Specifically, acollection of MLPs is first optimized to faithfully represent individual datasamples. Subsequently, a diffusion process is trained in this MLP weight spaceto model the underlying distribution of neural implicit fields. HyperDiffusionenables diffusion modeling over a implicit, compact, and yet high-fidelityrepresentation of complex signals across 3D shapes and 4D mesh animationswithin one single unified framework.", "output": "HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "To drive safely in complex traffic environments, autonomous vehicles need tomake an accurate prediction of the future trajectories of nearby heterogeneoustraffic agents (i.e., vehicles, pedestrians, bicyclists, etc). Due to theinteractive nature, human drivers are accustomed to infer what the futuresituations will become if they are going to execute different maneuvers. Tofully exploit the impacts of interactions, this paper proposes a ego-planningguided multi-graph convolutional network (EPG-MGCN) to predict the trajectoriesof heterogeneous agents using both historical trajectory information and egovehicle's future planning information. The EPG-MGCN first models the socialinteractions by employing four graph topologies, i.e., distance graphs,visibility graphs, planning graphs and category graphs. Then, the planninginformation of the ego vehicle is encoded by both the planning graph and thesubsequent planning-guided prediction module to reduce uncertainty in thetrajectory prediction. Finally, a category-specific gated recurrent unit(CS-GRU) encoder-decoder is designed to generate future trajectories for eachspecific type of agents. Our network is evaluated on two real-world trajectorydatasets: ApolloScape and NGSIM. The experimental results show that theproposed EPG-MGCN achieves state-of-the-art performance compared to existingmethods.", "output": "EPG-MGCN: Ego-Planning Guided Multi-Graph Convolutional Network for Heterogeneous Agent Trajectory Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The fervor for Non-Fungible Tokens (NFTs) attracted countless creators,leading to a Big Bang of digital assets driven by latent or explicit forms ofinspiration, as in many creative processes. This work exploits VisionTransformers and graph-based modeling to delve into visual inspirationphenomena between NFTs over the years. Our goals include unveiling the mainstructural traits that shape visual inspiration networks, exploring theinterrelation between visual inspiration and asset performances, investigatingcrypto influence on inspiration processes, and explaining the inspirationrelationships among NFTs. Our findings unveil how the pervasiveness ofinspiration led to a temporary saturation of the visual feature space, theimpact of the dichotomy between inspiring and inspired NFTs on their financialperformance, and an intrinsic self-regulatory mechanism between markets andinspiration waves. Our work can serve as a starting point for gaining a broaderview of the evolution of Web3.", "output": "Visually Wired NFTs: Exploring the Role of Inspiration in Non-Fungible Tokens."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the recent raise of foundation models in computer vision and NLP, thepretrain-and-adapt strategy, where a large-scale model is fine-tuned ondownstream tasks, is gaining popularity. However, traditional fine-tuningapproaches may still require significant resources and yield sub-optimalresults when the labeled data of the target task is scarce. This is especiallythe case in clinical settings. To address this challenge, we formalize few-shotefficient fine-tuning (FSEFT), a novel and realistic setting for medical imagesegmentation. Furthermore, we introduce a novel parameter-efficient fine-tuningstrategy tailored to medical image segmentation, with (a) spatial adaptermodules that are more appropriate for dense prediction tasks; and (b) aconstrained transductive inference, which leverages task-specific priorknowledge. Our comprehensive experiments on a collection of public CT datasetsfor organ segmentation reveal the limitations of standard fine-tuning methodsin few-shot scenarios, point to the potential of vision adapters andtransductive inference, and confirm the suitability of foundation models.", "output": "Transductive few-shot adapters for medical image segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Sound source localization is a typical and challenging task that predicts thelocation of sound sources in a video. Previous single-source methods mainlyused the audio-visual association as clues to localize sounding objects in eachimage. Due to the mixed property of multiple sound sources in the originalspace, there exist rare multi-source approaches to localizing multiple sourcessimultaneously, except for one recent work using a contrastive random walk inthe graph with images and separated sound as nodes. Despite their promisingperformance, they can only handle a fixed number of sources, and they cannotlearn compact class-aware representations for individual sources. To alleviatethis shortcoming, in this paper, we propose a novel audio-visual groupingnetwork, namely AVGN, that can directly learn category-wise semantic featuresfor each source from the input audio mixture and image to localize multiplesources simultaneously. Specifically, our AVGN leverages learnable audio-visualclass tokens to aggregate class-aware source features. Then, the aggregatedsemantic features for each source can be used as guidance to localize thecorresponding visual regions. Compared to existing multi-source methods, ournew framework can localize a flexible number of sources and disentanglecategory-aware audio-visual representations for individual sound sources. Weconduct extensive experiments on MUSIC, VGGSound-Instruments, and VGG-SoundSources benchmarks. The results demonstrate that the proposed AVGN can achievestate-of-the-art sounding object localization performance on both single-sourceand multi-source scenarios. Code is available aturl{", "output": "Audio-Visual Grouping Network for Sound Localization from Mixtures."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Inspired by the ConvNets with structured hidden representations, we propose aTensor-based Neural Network, TCNN. Different from ConvNets, TCNNs are composedof structured neurons rather than scalar neurons, and the basic operation isneuron tensor transformation. Unlike other structured ConvNets, where thepart-whole relationships are modeled explicitly, the relationships are learnedimplicitly in TCNNs. Also, the structured neurons in TCNNs are high-ranktensors rather than vectors or matrices. We compare TCNNs with current popularConvNets, including ResNets, MobileNets, EfficientNets, RegNets, etc., onCIFAR10, CIFAR100, and Tiny ImageNet. The experiment shows that TCNNs havehigher efficiency in terms of parameters. TCNNs also show higher robustnessagainst white-box adversarial attacks on MNIST compared to ConvNets.", "output": "A Tensor-based Convolutional Neural Network for Small Dataset Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present DiffCollage, a compositional diffusion model that can generatelarge content by leveraging diffusion models trained on generating pieces ofthe large content. Our approach is based on a factor graph representation whereeach factor node represents a portion of the content and a variable noderepresents their overlap. This representation allows us to aggregateintermediate outputs from diffusion models defined on individual nodes togenerate content of arbitrary size and shape in parallel without resorting toan autoregressive generation procedure. We apply DiffCollage to various tasks,including infinite image generation, panorama image generation, andlong-duration text-guided motion generation. Extensive experimental resultswith a comparison to strong autoregressive baselines verify the effectivenessof our approach.", "output": "DiffCollage: Parallel Generation of Large Content with Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, methods for neural surface representation and rendering, forexample NeuS, have shown that learning neural implicit surfaces through volumerendering is becoming increasingly popular and making good progress. However,these methods still face some challenges. Existing methods lack a directrepresentation of depth information, which makes object reconstructionunrestricted by geometric features, resulting in poor reconstruction of objectswith texture and color features. This is because existing methods only usesurface normals to represent implicit surfaces without using depth information.Therefore, these methods cannot model the detailed surface features of objectswell. To address this problem, we propose a neural implicit surface learningmethod called Depth-NeuS based on depth information optimization for multi-viewreconstruction. In this paper, we introduce depth loss to explicitly constrainSDF regression and introduce geometric consistency loss to optimize forlow-texture areas. Specific experiments show that Depth-NeuS outperformsexisting technologies in multiple scenarios and achieves high-quality surfacereconstruction in multiple scenarios.", "output": "Depth-NeuS: Neural Implicit Surfaces Learning for Multi-view Reconstruction Based on Depth Information Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce an approach to enhance the novel view synthesis from imagestaken from a freely moving camera. The introduced approach focuses on outdoorscenes where recovering accurate geometric scaffold and camera pose ischallenging, leading to inferior results using the state-of-the-art stable viewsynthesis (SVS) method. SVS and related methods fail for outdoor scenesprimarily due to (i) over-relying on the multiview stereo (MVS) for geometricscaffold recovery and (ii) assuming COLMAP computed camera poses as the bestpossible estimates, despite it being well-studied that MVS 3D reconstructionaccuracy is limited to scene disparity and camera-pose accuracy is sensitive tokey-point correspondence selection. This work proposes a principled way toenhance novel view synthesis solutions drawing inspiration from the basics ofmultiple view geometry. By leveraging the complementary behavior of MVS andmonocular depth, we arrive at a better scene depth per view for nearby and farpoints, respectively. Moreover, our approach jointly refines camera poses withimage-based rendering via multiple rotation averaging graph optimization. Therecovered scene depth and the camera-pose help better view-dependent on-surfacefeature aggregation of the entire scene. Extensive evaluation of our approachon the popular benchmark dataset, such as Tanks and Temples, shows substantialimprovement in view synthesis results compared to the prior art. For instance,our method shows 1.5 dB of PSNR improvement on the Tank and Temples. Similarstatistics are observed when tested on other benchmark datasets such as FVS,Mip-NeRF 360, and DTU.", "output": "Enhanced Stable View Synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent studies have shown that higher accuracy on ImageNet usually leads tobetter robustness against different corruptions. Therefore, in this paper,instead of following the traditional research paradigm that investigates newout-of-distribution corruptions or perturbations deep models may encounter, weconduct model debugging in in-distribution data to explore which objectattributes a model may be sensitive to. To achieve this goal, we create atoolkit for object editing with controls of backgrounds, sizes, positions, anddirections, and create a rigorous benchmark named ImageNet-E(diting) forevaluating the image classifier robustness in terms of object attributes. Withour ImageNet-E, we evaluate the performance of current deep learning models,including both convolutional neural networks and vision transformers. We findthat most models are quite sensitive to attribute changes. A small change inthe background can lead to an average of 9.23% drop on top-1 accuracy. We alsoevaluate some robust models including both adversarially trained models andother robust trained models and find that some models show worse robustnessagainst attribute changes than vanilla models. Based on these findings, wediscover ways to enhance attribute robustness with preprocessing, architecturedesigns, and training strategies. We hope this work can provide some insightsto the community and open up a new avenue for research in robust computervision. The code and dataset are available at", "output": "ImageNet-E: Benchmarking Neural Network Robustness via Attribute Editing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Integrating LiDAR and Camera information into Bird's-Eye-View (BEV) hasbecome an essential topic for 3D object detection in autonomous driving.Existing methods mostly adopt an independent dual-branch framework to generateLiDAR and camera BEV, then perform an adaptive modality fusion. Since pointclouds provide more accurate localization and geometry information, they couldserve as a reliable spatial prior to acquiring relevant semantic informationfrom the images. Therefore, we design a LiDAR-Guided View Transformer (LGVT) toeffectively obtain the camera representation in BEV space and thus benefit thewhole dual-branch fusion system. LGVT takes camera BEV as the primitivesemantic query, repeatedly leveraging the spatial cue of LiDAR BEV forextracting image features across multiple camera views. Moreover, we extend ourframework into the temporal domain with our proposed Temporal DeformableAlignment (TDA) module, which aims to aggregate BEV features from multiplehistorical frames. Including these two modules, our framework dubbedBEVFusion4D achieves state-of-the-art results in 3D object detection, with72.0% mAP and 73.5% NDS on the nuScenes validation set, and 73.3% mAP and 74.7%NDS on nuScenes test set, respectively.", "output": "BEVFusion4D: Learning LiDAR-Camera Fusion Under Bird's-Eye-View via Cross-Modality Guidance and Temporal Aggregation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Differences in forgery attributes of images generated in CNN-synthesized andimage-editing domains are large, and such differences make a unified imageforgery detection and localization (IFDL) challenging. To this end, we presenta hierarchical fine-grained formulation for IFDL representation learning.Specifically, we first represent forgery attributes of a manipulated image withmultiple labels at different levels. Then we perform fine-grainedclassification at these levels using the hierarchical dependency between them.As a result, the algorithm is encouraged to learn both comprehensive featuresand inherent hierarchical nature of different forgery attributes, therebyimproving the IFDL representation. Our proposed IFDL framework contains threecomponents: multi-branch feature extractor, localization and classificationmodules. Each branch of the feature extractor learns to classify forgeryattributes at one level, while localization and classification modules segmentthe pixel-level forgery region and detect image-level forgery, respectively.Lastly, we construct a hierarchical fine-grained dataset to facilitate ourstudy. We demonstrate the effectiveness of our method on $7$ differentbenchmarks, for both tasks of IFDL and forgery attribute classification. Oursource code and dataset can be found:href{", "output": "Hierarchical Fine-Grained Image Forgery Detection and Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As a cross-topic of multi-view learning and multi-label classification,multi-view multi-label classification has gradually gained traction in recentyears. The application of multi-view contrastive learning has furtherfacilitated this process, however, the existing multi-view contrastive learningmethods crudely separate the so-called negative pair, which largely results inthe separation of samples belonging to the same category or similar ones.Besides, plenty of multi-view multi-label learning methods ignore the possibleabsence of views and labels. To address these issues, in this paper, we proposean incomplete multi-view partial multi-label classification network named RANK.In this network, a label-driven multi-view contrastive learning strategy isproposed to leverage supervised information to preserve the structure withinview and perform consistent alignment across views. Furthermore, we breakthrough the view-level weights inherent in existing methods and propose aquality-aware sub-network to dynamically assign quality scores to each view ofeach sample. The label correlation information is fully utilized in the finalmulti-label cross-entropy classification loss, effectively improving thediscriminative power. Last but not least, our model is not only able to handlecomplete multi-view multi-label datasets, but also works on datasets withmissing instances and labels. Extensive experiments confirm that our RANKoutperforms existing state-of-the-art methods.", "output": "Learning Reliable Representations for Incomplete Multi-View Partial Multi-Label Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a novel framework for exemplar based image translation. Recentadvanced methods for this task mainly focus on establishing cross-domainsemantic correspondence, which sequentially dominates image generation in themanner of local style control. Unfortunately, cross-domain semantic matching ischallenging; and matching errors ultimately degrade the quality of generatedimages. To overcome this challenge, we improve the accuracy of matching on theone hand, and diminish the role of matching in image generation on the otherhand. To achieve the former, we propose a masked and adaptive transformer (MAT)for learning accurate cross-domain correspondence, and executing context-awarefeature augmentation. To achieve the latter, we use source features of theinput and global style codes of the exemplar, as supplementary information, fordecoding an image. Besides, we devise a novel contrastive style learningmethod, for acquire quality-discriminative style representations, which in turnbenefit high-quality image generation. Experimental results show that ourmethod, dubbed MATEBIT, performs considerably better than state-of-the-artmethods, in diverse image translation tasks. The codes are available aturl{", "output": "Masked and Adaptive Transformer for Exemplar Based Image Translation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Metric learning is a fundamental problem in computer vision whereby a modelis trained to learn a semantically useful embedding space via ranking losses.Traditionally, the effectiveness of a ranking loss depends on the minibatchsize, and is, therefore, inherently limited by the memory constraints of theunderlying hardware. While simply accumulating the embeddings acrossminibatches has proved useful (Wang et al. [2020]), we show that it is equallyimportant to ensure that the accumulated embeddings are up to date. Inparticular, it is necessary to circumvent the representational drift betweenthe accumulated embeddings and the feature embeddings at the current trainingiteration as the learnable parameters are being updated. In this paper, wemodel representational drift as distribution misalignment and tackle it usingmoment matching. The result is a simple method for updating the storedembeddings to match the first and second moments of the current embeddings ateach training iteration. Experiments on three popular image retrieval datasets,namely, SOP, In-Shop, and DeepFashion2, demonstrate that our approachsignificantly improves the performance in all scenarios.", "output": "Adaptive Cross Batch Normalization for Metric Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Unsupervised domain adaptation (UDA) approaches focus on adapting modelstrained on a labeled source domain to an unlabeled target domain. UDA methodshave a strong assumption that the source data is accessible during adaptation,which may not be feasible in many real-world scenarios due to privacy concernsand resource constraints of devices. In this regard, source-free domainadaptation (SFDA) excels as access to source data is no longer required duringadaptation. Recent state-of-the-art (SOTA) methods on SFDA mostly focus onpseudo-label refinement based self-training which generally suffers from twoissues: i) inevitable occurrence of noisy pseudo-labels that could lead toearly training time memorization, ii) refinement process requires maintaining amemory bank which creates a significant burden in resource constraintscenarios. To address these concerns, we propose C-SFDA, a curriculum learningaided self-training framework for SFDA that adapts efficiently and reliably tochanges across domains based on selective pseudo-labeling. Specifically, weemploy a curriculum learning scheme to promote learning from a restrictedamount of pseudo labels selected based on their reliabilities. This simple yeteffective step successfully prevents label noise propagation during differentstages of adaptation and eliminates the need for costly memory-bank based labelrefinement. Our extensive experimental evaluations on both image recognitionand semantic segmentation tasks confirm the effectiveness of our method. C-SFDAis readily applicable to online test-time domain adaptation and alsooutperforms previous SOTA methods in this task.", "output": "C-SFDA: A Curriculum Learning Aided Self-Training Framework for Efficient Source Free Domain Adaptation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Online camera-to-ground calibration is to generate a non-rigid bodytransformation between the camera and the road surface in a real-time manner.Existing solutions utilize static calibration, suffering from environmentalvariations such as tire pressure changes, vehicle loading volume variations,and road surface diversity. Other online solutions exploit the usage of roadelements or photometric consistency between overlapping views across images,which require continuous detection of specific targets on the road orassistance with multiple cameras to facilitate calibration. In our work, wepropose an online monocular camera-to-ground calibration solution that does notutilize any specific targets while driving. We perform a coarse-to-fineapproach for ground feature extraction through wheel odometry and estimate thecamera-to-ground calibration parameters through a sliding-window-based factorgraph optimization. Considering the non-rigid transformation ofcamera-to-ground while driving, we provide metrics to quantify calibrationperformance and stopping criteria to report/broadcast our satisfyingcalibration results. Extensive experiments using real-world data demonstratethat our algorithm is effective and outperforms state-of-the-art techniques.", "output": "Online Camera-to-ground Calibration for Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Contrastive learning methods train visual encoders by comparing views fromone instance to others. Typically, the views created from one instance are setas positive, while views from other instances are negative. This binaryinstance discrimination is studied extensively to improve featurerepresentations in self-supervised learning. In this paper, we rethink theinstance discrimination framework and find the binary instance labelinginsufficient to measure correlations between different samples. For anintuitive example, given a random image instance, there may exist other imagesin a mini-batch whose content meanings are the same (i.e., belonging to thesame category) or partially related (i.e., belonging to a similar category).How to treat the images that correlate similarly to the current image instanceleaves an unexplored problem. We thus propose to support the current image byexploring other correlated instances (i.e., soft neighbors). We first carefullycultivate a candidate neighbor set, which will be further utilized to explorethe highly-correlated instances. A cross-attention module is then introduced topredict the correlation score (denoted as positiveness) of other correlatedinstances with respect to the current one. The positiveness scorequantitatively measures the positive support from each correlated instance, andis encoded into the objective for pretext training. To this end, our proposedmethod benefits in discriminating uncorrelated instances while absorbingcorrelated instances for SSL. We evaluate our soft neighbor contrastivelearning method (SNCLR) on standard visual recognition benchmarks, includingimage classification, object detection, and instance segmentation. Thestate-of-the-art recognition performance shows that SNCLR is effective inimproving feature representations from both ViT and CNN encoders.", "output": "Soft Neighbors are Positive Supporters in Contrastive Visual Representation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Real-time perception, or streaming perception, is a crucial aspect ofautonomous driving that has yet to be thoroughly explored in existing research.To address this gap, we present DAMO-StreamNet, an optimized framework thatcombines recent advances from the YOLO series with a comprehensive analysis ofspatial and temporal perception mechanisms, delivering a cutting-edge solution.The key innovations of DAMO-StreamNet are: (1) A robust neck structureincorporating deformable convolution, enhancing the receptive field and featurealignment capabilities. (2) A dual-branch structure that integrates short-pathsemantic features and long-path temporal features, improving motion stateprediction accuracy. (3) Logits-level distillation for efficient optimization,aligning the logits of teacher and student networks in semantic space. (4) Areal-time forecasting mechanism that updates support frame features with thecurrent frame, ensuring seamless streaming perception during inference. Ourexperiments demonstrate that DAMO-StreamNet surpasses existing state-of-the-artmethods, achieving 37.8% (normal size (600, 960)) and 43.3% (large size (1200,1920)) sAP without using extra data. This work not only sets a new benchmarkfor real-time perception but also provides valuable insights for futureresearch. Additionally, DAMO-StreamNet can be applied to various autonomoussystems, such as drones and robots, paving the way for real-time perception.", "output": "DAMO-StreamNet: Optimizing Streaming Perception in Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a novel differentiable rendering framework for joint geometry,material, and lighting estimation from multi-view images. In contrast toprevious methods which assume a simplified environment map or co-locatedflashlights, in this work, we formulate the lighting of a static scene as oneneural incident light field (NeILF) and one outgoing neural radiance field(NeRF). The key insight of the proposed method is the union of the incident andoutgoing light fields through physically-based rendering and inter-reflectionsbetween surfaces, making it possible to disentangle the scene geometry,material, and lighting from image observations in a physically-based manner.The proposed incident light and inter-reflection framework can be easilyapplied to other NeRF systems. We show that our method can not only decomposethe outgoing radiance into incident lights and surface materials, but alsoserve as a surface refinement module that further improves the reconstructiondetail of the neural surface. We demonstrate on several datasets that theproposed method is able to achieve state-of-the-art results in terms ofgeometry reconstruction quality, material estimation accuracy, and the fidelityof novel view rendering.", "output": "NeILF++: Inter-Reflectable Light Fields for Geometry and Material Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Masked Autoencoder (MAE) has demonstrated superior performance on variousvision tasks via randomly masking image patches and reconstruction. However,effective data augmentation strategies for MAE still remain open questions,different from those in contrastive learning that serve as the most importantpart. This paper studies the prevailing mixing augmentation for MAE. We firstdemonstrate that naive mixing will in contrast degenerate model performance dueto the increase of mutual information (MI). To address, we propose homologousrecognition, an auxiliary pretext task, not only to alleviate the MIincreasement by explicitly requiring each patch to recognize homologouspatches, but also to perform object-aware self-supervised pre-training forbetter downstream dense perception performance. With extensive experiments, wedemonstrate that our proposed Mixed Autoencoder (MixedAE) achieves thestate-of-the-art transfer results among masked image modeling (MIM)augmentations on different downstream tasks with significant efficiency.Specifically, our MixedAE outperforms MAE by +0.3% accuracy, +1.7 mIoU and +0.9AP on ImageNet-1K, ADE20K and COCO respectively with a standard ViT-Base.Moreover, MixedAE surpasses iBOT, a strong MIM method combined with instancediscrimination, while accelerating training by 2x. To our best knowledge, thisis the very first work to consider mixing for MIM from the perspective ofpretext task design. Code will be made available.", "output": "Mixed Autoencoder for Self-supervised Visual Representation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in text-to-image diffusion models have enabled the generationof diverse and high-quality images. However, generated images often fall shortof depicting subtle details and are susceptible to errors due to ambiguity inthe input text. One way of alleviating these issues is to train diffusionmodels on class-labeled datasets. This comes with a downside, doing so limitstheir expressive power: (i) supervised datasets are generally small compared tolarge-scale scraped text-image datasets on which text-to-image models aretrained, and so the quality and diversity of generated images are severelyaffected, or (ii) the input is a hard-coded label, as opposed to free-formtext, which limits the control over the generated images.In this work, we propose a non-invasive fine-tuning technique thatcapitalizes on the expressive potential of free-form text while achieving highaccuracy through discriminative signals from a pretrained classifier, whichguides the generation. This is done by iteratively modifying the embedding of asingle input token of a text-to-image diffusion model, using the classifier, bysteering generated images toward a given target class. Our method is fastcompared to prior fine-tuning methods and does not require a collection ofin-class images or retraining of a noise-tolerant classifier. We evaluate ourmethod extensively, showing that the generated images are: (i) more accurateand of higher quality than standard diffusion models, (ii) can be used toaugment training data in a low-resource setting, and (iii) reveal informationabout the data used to train the guiding classifier. The code is available aturl{", "output": "Discriminative Class Tokens for Text-to-Image Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generative Adversarial Networks (GANs) rely heavily on large-scale trainingdata for training high-quality image generation models. With limited trainingdata, the GAN discriminator often suffers from severe overfitting whichdirectly leads to degraded generation especially in generation diversity.Inspired by the recent advances in knowledge distillation (KD), we proposeKD-DLGAN, a knowledge-distillation based generation framework that introducespre-trained vision-language models for training effective data-limitedgeneration models. KD-DLGAN consists of two innovative designs. The first isaggregated generative KD that mitigates the discriminator overfitting bychallenging the discriminator with harder learning tasks and distilling moregeneralizable knowledge from the pre-trained models. The second is correlatedgenerative KD that improves the generation diversity by distilling andpreserving the diverse image-text correlation within the pre-trained models.Extensive experiments over multiple benchmarks show that KD-DLGAN achievessuperior image generation with limited training data. In addition, KD-DLGANcomplements the state-of-the-art with consistent and substantial performancegains.", "output": "KD-DLGAN: Data Limited Image Generation via Knowledge Distillation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In orthogonal world coordinates, a Manhattan world lying along cuboidbuildings is widely useful for various computer vision tasks. However, theManhattan world has much room for improvement because the origin of pan anglesfrom an image is arbitrary, that is, four-fold rotational symmetric ambiguityof pan angles. To address this problem, we propose a definition for thepan-angle origin based on the directions of the roads with respect to a cameraand the direction of travel. We propose a learning-based calibration methodthat uses heatmap regression to remove the ambiguity by each direction oflabeled image coordinates, similar to pose estimation keypoints.Simultaneously, our two-branched network recovers the rotation and removesfisheye distortion from a general scene image. To alleviate the lack ofvanishing points in images, we introduce auxiliary diagonal points that havethe optimal 3D arrangement of spatial uniformity. Extensive experimentsdemonstrated that our method outperforms conventional methods on large-scaledatasets and with off-the-shelf cameras.", "output": "Deep Single Image Camera Calibration by Heatmap Regression to Recover Fisheye Images Under ManhattanWorld AssumptionWithout Ambiguity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Most existing approaches for point cloud normal estimation aim to locally fita geometric surface and calculate the normal from the fitted surface. Recently,learning-based methods have adopted a routine of predicting point-wise weightsto solve the weighted least-squares surface fitting problem. Despite achievingremarkable progress, these methods overlook the approximation error of thefitting problem, resulting in a less accurate fitted surface. In this paper, wefirst carry out in-depth analysis of the approximation error in the surfacefitting problem. Then, in order to bridge the gap between estimated and precisesurface normals, we present two basic design principles: 1) applies the$Z$-direction Transform to rotate local patches for a better surface fittingwith a lower approximation error; 2) models the error of the normal estimationas a learnable term. We implement these two principles using deep neuralnetworks, and integrate them with the state-of-the-art (SOTA) normal estimationmethods in a plug-and-play manner. Extensive experiments verify our approachesbring benefits to point cloud normal estimation and push the frontier ofstate-of-the-art performance on both synthetic and real-world datasets.", "output": "Rethinking the Approximation Error in 3D Surface Fitting for Point Cloud Normal Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Prompt learning has become one of the most efficient paradigms for adaptinglarge pre-trained vision-language models to downstream tasks. Currentstate-of-the-art methods, like CoOp and ProDA, tend to adopt soft prompts tolearn an appropriate prompt for each specific task. Recent CoCoOp furtherboosts the base-to-new generalization performance via an image-conditionalprompt. However, it directly fuses identical image semantics to prompts ofdifferent labels and significantly weakens the discrimination among differentclasses as shown in our experiments. Motivated by this observation, we firstpropose a class-aware text prompt (CTP) to enrich generated prompts withlabel-related image information. Unlike CoCoOp, CTP can effectively involveimage semantics and avoid introducing extra ambiguities into different prompts.On the other hand, instead of reserving the complete image representations, wepropose text-guided feature tuning (TFT) to make the image branch attend toclass-related representation. A contrastive loss is employed to align suchaugmented text and image representations on downstream tasks. In this way, theimage-to-text CTP and text-to-image TFT can be mutually promoted to enhance theadaptation of VLMs for downstream tasks. Extensive experiments demonstrate thatour method outperforms the existing methods by a significant margin.Especially, compared to CoCoOp, we achieve an average improvement of 4.03% onnew classes and 3.19% on harmonic-mean over eleven classification benchmarks.", "output": "Task-Oriented Multi-Modal Mutual Leaning for Vision-Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Few datasets contain self-identified sensitive attributes, inferringattributes risks introducing additional biases, and collecting attributes cancarry legal risks. Besides, categorical labels can fail to reflect thecontinuous nature of human phenotypic diversity, making it difficult to comparethe similarity between same-labeled faces. To address these issues, we presentA View From Somewhere (AVFS) -- a dataset of 638,180 human judgments of facesimilarity. We demonstrate the utility of AVFS for learning a continuous,low-dimensional embedding space aligned with human perception. Our embeddingspace, induced under a novel conditional framework, not only enables theaccurate prediction of face similarity, but also provides a human-interpretabledecomposition of the dimensions used in the human-decision making process, andthe importance distinct annotators place on each dimension. We additionallyshow the practicality of the dimensions for collecting continuous attributes,performing classification, and comparing dataset attribute disparities.", "output": "A View From Somewhere: Human-Centric Face Representations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we propose an approach for view-time interpolation of stereovideos. Specifically, we build upon X-Fields that approximates aninterpolatable mapping between the input coordinates and 2D RGB images using aconvolutional decoder. Our main contribution is to analyze and identify thesources of the problems with using X-Fields in our application and proposenovel techniques to overcome these challenges. Specifically, we observe thatX-Fields struggles to implicitly interpolate the disparities for large baselinecameras. Therefore, we propose multi-plane disparities to reduce the spatialdistance of the objects in the stereo views. Moreover, we propose non-uniformtime coordinates to handle the non-linear and sudden motion spikes in videos.We additionally introduce several simple, but important, improvements overX-Fields. We demonstrate that our approach is able to produce better resultsthan the state of the art, while running in near real-time rates and having lowmemory and storage costs.", "output": "Implicit View-Time Interpolation of Stereo Videos using Multi-Plane Disparities and Non-Uniform Coordinates."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, diffusion models have achieved great success in image synthesis.However, when it comes to the layout-to-image generation where an image oftenhas a complex scene of multiple objects, how to make strong control over boththe global layout map and each detailed object remains a challenging task. Inthis paper, we propose a diffusion model named LayoutDiffusion that can obtainhigher generation quality and greater controllability than the previous works.To overcome the difficult multimodal fusion of image and layout, we propose toconstruct a structural image patch with region information and transform thepatched image into a special layout to fuse with the normal layout in a unifiedform. Moreover, Layout Fusion Module (LFM) and Object-aware Cross Attention(OaCA) are proposed to model the relationship among multiple objects anddesigned to be object-aware and position-sensitive, allowing for preciselycontrolling the spatial related information. Extensive experiments show thatour LayoutDiffusion outperforms the previous SOTA methods on FID, CAS byrelatively 46.35%, 26.70% on COCO-stuff and 44.29%, 41.82% on VG. Code isavailable at ", "output": "LayoutDiffusion: Controllable Diffusion Model for Layout-to-image Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently reported state-of-the-art results in visual speech recognition (VSR)often rely on increasingly large amounts of video data, while the publiclyavailable transcribed video datasets are limited in size. In this paper, forthe first time, we study the potential of leveraging synthetic visual data forVSR. Our method, termed SynthVSR, substantially improves the performance of VSRsystems with synthetic lip movements. The key idea behind SynthVSR is toleverage a speech-driven lip animation model that generates lip movementsconditioned on the input speech. The speech-driven lip animation model istrained on an unlabeled audio-visual dataset and could be further optimizedtowards a pre-trained VSR model when labeled videos are available. As plenty oftranscribed acoustic data and face images are available, we are able togenerate large-scale synthetic data using the proposed lip animation model forsemi-supervised VSR training. We evaluate the performance of our approach onthe largest public VSR benchmark - Lip Reading Sentences 3 (LRS3). SynthVSRachieves a WER of 43.3% with only 30 hours of real labeled data, outperformingoff-the-shelf approaches using thousands of hours of video. The WER is furtherreduced to 27.9% when using all 438 hours of labeled data from LRS3, which ison par with the state-of-the-art self-supervised AV-HuBERT method. Furthermore,when combined with large-scale pseudo-labeled audio-visual data SynthVSR yieldsa new state-of-the-art VSR WER of 16.9% using publicly available data only,surpassing the recent state-of-the-art approaches trained with 29 times morenon-public machine-transcribed video data (90,000 hours). Finally, we performextensive ablation studies to understand the effect of each component in ourproposed method.", "output": "SynthVSR: Scaling Up Visual Speech Recognition With Synthetic Supervision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a method to estimate 3D human poses from substantially blurredimages. The key idea is to tackle the inverse problem of image deblurring bymodeling the forward problem with a 3D human model, a texture map, and asequence of poses to describe human motion. The blurring process is thenmodeled by a temporal image aggregation step. Using a differentiable renderer,we can solve the inverse problem by backpropagating the pixel-wise reprojectionerror to recover the best human motion representation that explains a single ormultiple input images. Since the image reconstruction loss alone isinsufficient, we present additional regularization terms. To the best of ourknowledge, we present the first method to tackle this problem. Our methodconsistently outperforms other methods on significantly blurry inputs sincethey lack one or multiple key functionalities that our method unifies, i.e.image deblurring with sub-frame accuracy and explicit 3D modeling of non-rigidhuman motion.", "output": "Human from Blur: Human Pose Tracking from Blurry Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Encoder-decoder based architecture has been widely used in the generator ofgenerative adversarial networks for facial manipulation. However, we observethat the current architecture fails to recover the input image color, richfacial details such as skin color or texture and introduces artifacts as well.In this paper, we present a novel method named SARGAN that addresses theabove-mentioned limitations from three perspectives. First, we employed spatialattention-based residual block instead of vanilla residual blocks to properlycapture the expression-related features to be changed while keeping the otherfeatures unchanged. Second, we exploited a symmetric encoder-decoder network toattend facial features at multiple scales. Third, we proposed to train thecomplete network with a residual connection which relieves the generator ofpressure to generate the input face image thereby producing the desiredexpression by directly feeding the input image towards the end of thegenerator. Both qualitative and quantitative experimental results show that ourproposed model performs significantly better than state-of-the-art methods. Inaddition, existing models require much larger datasets for training but theirperformance degrades on out-of-distribution images. In contrast, SARGAN can betrained on smaller facial expressions datasets, which generalizes well onout-of-distribution images including human photographs, portraits, avatars andstatues.", "output": "SARGAN: Spatial Attention-based Residuals for Facial Expression Manipulation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Supervised keypoint localization methods rely on large manually labeled imagedatasets, where objects can deform, articulate, or occlude. However, creatingsuch large keypoint labels is time-consuming and costly, and is oftenerror-prone due to inconsistent labeling. Thus, we desire an approach that canlearn keypoint localization with fewer yet consistently annotated images. Tothis end, we present a novel formulation that learns to localize semanticallyconsistent keypoint definitions, even for occluded regions, for varying objectcategories. We use a few user-labeled 2D images as input examples, which areextended via self-supervision using a larger unlabeled dataset. Unlikeunsupervised methods, the few-shot images act as semantic shape constraints forobject localization. Furthermore, we introduce 3D geometry-aware constraints touplift keypoints, achieving more accurate 2D localization. Our general-purposeformulation paves the way for semantically conditioned generative modeling andattains competitive or state-of-the-art accuracy on several datasets, includinghuman faces, eyes, animals, cars, and never-before-seen mouth interior (teeth)localization tasks, not attempted by the previous few-shot methods. Projectpage:", "output": "Few-shot Geometry-Aware Keypoint Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "For Human Action Recognition tasks (HAR), 3D Convolutional Neural Networkshave proven to be highly effective, achieving state-of-the-art results. Thisstudy introduces a novel streaming architecture based toolflow for mapping suchmodels onto FPGAs considering the model's inherent characteristics and thefeatures of the targeted FPGA device. The HARFLOW3D toolflow takes as input a3D CNN in ONNX format and a description of the FPGA characteristics, generatinga design that minimizes the latency of the computation. The toolflow iscomprised of a number of parts, including i) a 3D CNN parser, ii) a performanceand resource model, iii) a scheduling algorithm for executing 3D models on thegenerated hardware, iv) a resource-aware optimization engine tailored for 3Dmodels, v) an automated mapping to synthesizable code for FPGAs. The ability ofthe toolflow to support a broad range of models and devices is shown through anumber of experiments on various 3D CNN and FPGA system pairs. Furthermore, thetoolflow has produced high-performing results for 3D CNN models that have notbeen mapped to FPGAs before, demonstrating the potential of FPGA-based systemsin this space. Overall, HARFLOW3D has demonstrated its ability to delivercompetitive latency compared to a range of state-of-the-art hand-tunedapproaches being able to achieve up to 5$times$ better performance compared tosome of the existing works.", "output": "HARFLOW3D: A Latency-Oriented 3D-CNN Accelerator Toolflow for HAR on FPGA Devices."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The classification of forged videos has been a challenge for the past fewyears. Deepfake classifiers can now reliably predict whether or not videoframes have been tampered with. However, their performance is tied to both thedataset used for training and the analyst's computational power. We propose adeepfake classification method that operates in the latent space of astate-of-the-art generative adversarial network (GAN) trained on high-qualityface images. The proposed method leverages the structure of the latent space ofStyleGAN to learn a lightweight classification model. Experimental results on astandard dataset reveal that the proposed approach outperforms otherstate-of-the-art deepfake classification methods. To the best of our knowledge,this is the first study showing the interest of the latent space of StyleGANfor deepfake classification. Combined with other recent studies on theinterpretation and manipulation of this latent space, we believe that theproposed approach can help in developing robust deepfake classification methodsbased on interpretable high-level properties of face images.", "output": "LatentForensics: Towards lighter deepfake detection in the StyleGAN latent space."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, open-vocabulary learning has emerged to accomplish segmentation forarbitrary categories of text-based descriptions, which popularizes thesegmentation system to more general-purpose application scenarios. However,existing methods devote to designing specialized architectures or parametersfor specific segmentation tasks. These customized design paradigms lead tofragmentation between various segmentation tasks, thus hindering the uniformityof segmentation models. Hence in this paper, we propose FreeSeg, a genericframework to accomplish Unified, Universal and Open-Vocabulary ImageSegmentation. FreeSeg optimizes an all-in-one network via one-shot training andemploys the same architecture and parameters to handle diverse segmentationtasks seamlessly in the inference procedure. Additionally, adaptive promptlearning facilitates the unified model to capture task-aware andcategory-sensitive concepts, improving model robustness in multi-task andvaried scenarios. Extensive experimental results demonstrate that FreeSegestablishes new state-of-the-art results in performance and generalization onthree segmentation tasks, which outperforms the best task-specificarchitectures by a large margin: 5.5% mIoU on semantic segmentation, 17.6% mAPon instance segmentation, 20.1% PQ on panoptic segmentation for the unseenclass on COCO.", "output": "FreeSeg: Unified, Universal and Open-Vocabulary Image Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Video understanding tasks have traditionally been modeled by two separatearchitectures, specially tailored for two distinct tasks. Sequence-based videotasks, such as action recognition, use a video backbone to directly extractspatiotemporal features, while frame-based video tasks, such as multiple objecttracking (MOT), rely on single fixed-image backbone to extract spatialfeatures. In contrast, we propose to unify video understanding tasks into onenovel streaming video architecture, referred to as Streaming Vision Transformer(S-ViT). S-ViT first produces frame-level features with a memory-enabledtemporally-aware spatial encoder to serve the frame-based video tasks. Then theframe features are input into a task-related temporal decoder to obtainspatiotemporal features for sequence-based tasks. The efficiency and efficacyof S-ViT is demonstrated by the state-of-the-art accuracy in the sequence-basedaction recognition task and the competitive advantage over conventionalarchitecture in the frame-based MOT task. We believe that the concept ofstreaming video model and the implementation of S-ViT are solid steps towards aunified deep learning architecture for video understanding. Code will beavailable at ", "output": "Streaming Video Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Magnetic Resonance Imaging allows high resolution data acquisition with thedownside of motion sensitivity due to relatively long acquisition times. Evenduring the acquisition of a single 2D slice, motion can severely corrupt theimage. Retrospective motion correction strategies do not interfere duringacquisition time but operate on the motion affected data. Known methods suitedto this scenario are compressed sensing (CS), generative adversarial networks(GANs), and motion estimation. In this paper we propose a strategy to correctfor motion artifacts using Deep Convolutional Neuronal Networks (Deep CNNs) ina reliable and verifiable manner by explicit motion estimation. The sensitivityencoding (SENSE) redundancy that multiple receiver coils provide, has in thepast been used for acceleration, noise reduction and rigid motion compensation.We show that using Deep CNNs the concepts of rigid motion compensation can begeneralized to more complex motion fields. Using a simulated synthetic dataset, our proposed supervised network is evaluated on motion corrupted MRIs ofabdomen and head. We compare our results with rigid motion compensation andGANs.", "output": "Retrospective Motion Correction in Gradient Echo MRI by Explicit Motion Estimation Using Deep CNNs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-view clustering (MvC) aims at exploring the category structure amongmulti-view data without label supervision. Multiple views provide moreinformation than single views and thus existing MvC methods can achievesatisfactory performance. However, their performance might seriously degeneratewhen the views are noisy in practical scenarios. In this paper, we firstformally investigate the drawback of noisy views and then propose atheoretically grounded deep MvC method (namely MvCAN) to address this issue.Specifically, we propose a novel MvC objective that enables un-sharedparameters and inconsistent clustering predictions across multiple views toreduce the side effects of noisy views. Furthermore, a non-parametric iterativeprocess is designed to generate a robust learning target for mining multipleviews' useful information. Theoretical analysis reveals that MvCAN works byachieving the multi-view consistency, complementarity, and noise robustness.Finally, experiments on public datasets demonstrate that MvCAN outperformsstate-of-the-art methods and is robust against the existence of noisy views.", "output": "Investigating and Mitigating the Side Effects of Noisy Views in Multi-view Clustering in Practical Scenarios."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The detection of digital face manipulation in video has attracted extensiveattention due to the increased risk to public trust. To counteract themalicious usage of such techniques, deep learning-based deepfake detectionmethods have been developed and have shown impressive results. However, theperformance of these detectors is often evaluated using benchmarks that hardlyreflect real-world situations. For example, the impact of various videoprocessing operations on detection accuracy has not been systematicallyassessed. To address this gap, this paper first analyzes numerous real-worldinfluencing factors and typical video processing operations. Then, a moresystematic assessment methodology is proposed, which allows for a quantitativeevaluation of a detector's robustness under the influence of differentprocessing operations. Moreover, substantial experiments have been carried outon three popular deepfake detectors, which give detailed analyses on the impactof each operation and bring insights to foster future research.", "output": "Impact of Video Processing Operations in Deepfake Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Object detection is a fundamental task in computer vision, which has beengreatly progressed through developing large and intricate deep learning models.However, the lack of transparency is a big challenge that may not allow thewidespread adoption of these models. Explainable artificial intelligence is afield of research where methods are developed to help users understand thebehavior, decision logics, and vulnerabilities of AI-based systems. Black-boxexplanation refers to explaining decisions of an AI system without havingaccess to its internals. In this paper, we design and implement a black-boxexplanation method named Black-box Object Detection Explanation by Masking(BODEM) through adopting a new masking approach for AI-based object detectionsystems. We propose local and distant masking to generate multiple versions ofan input image. Local masks are used to disturb pixels within a target objectto figure out how the object detector reacts to these changes, while distantmasks are used to assess how the detection model's decisions are affected bydisturbing pixels outside the object. A saliency map is then created byestimating the importance of pixels through measuring the difference betweenthe detection output before and after masking. Finally, a heatmap is createdthat visualizes how important pixels within the input image are to the detectedobjects. The experimentations on various object detection datasets and modelsshowed that BODEM can be effectively used to explain the behavior of objectdetectors and reveal their vulnerabilities. This makes BODEM suitable forexplaining and validating AI based object detection systems in black-boxsoftware testing scenarios. Furthermore, we conducted data augmentationexperiments that showed local masks produced by BODEM can be used for furthertraining the object detectors and improve their detection accuracy androbustness.", "output": "Model-agnostic explainable artificial intelligence for object detection in image data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While today's high dynamic range (HDR) image fusion algorithms are capable ofblending multiple exposures, the acquisition is often controlled so that thedynamic range within one exposure is narrow. For HDR imaging in photon-limitedsituations, the dynamic range can be enormous and the noise within one exposureis spatially varying. Existing image denoising algorithms and HDR fusionalgorithms both fail to handle this situation, leading to severe limitations inlow-light HDR imaging. This paper presents two contributions. Firstly, weidentify the source of the problem. We find that the issue is associated withthe co-existence of (1) spatially varying signal-to-noise ratio, especially theexcessive noise due to very dark regions, and (2) a wide luminance range withineach exposure. We show that while the issue can be handled by a bank ofdenoisers, the complexity is high. Secondly, we propose a new method called thespatially varying high dynamic range (SV-HDR) fusion network to simultaneouslydenoise and fuse images. We introduce a new exposure-shared block within ourcustom-designed multi-scale transformer framework. In a variety of testingconditions, the performance of the proposed SV-HDR is better than the existingmethods.", "output": "HDR Imaging with Spatially Varying Signal-to-Noise Ratios."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The research on single image dehazing task has been widely explored. However,as far as we know, no comprehensive study has been conducted on the robustnessof the well-trained dehazing models. Therefore, there is no evidence that thedehazing networks can resist malicious attacks. In this paper, we focus ondesigning a group of attack methods based on first order gradient to verify therobustness of the existing dehazing algorithms. By analyzing the general goalof image dehazing task, five attack methods are proposed, which are prediction,noise, mask, ground-truth and input attack. The corresponding experiments areconducted on six datasets with different scales. Further, the defense strategybased on adversarial training is adopted for reducing the negative effectscaused by malicious attacks. In summary, this paper defines a new challengingproblem for image dehazing area, which can be called as adversarial attack ondehazing networks (AADN). Code is available at", "output": "Adversarial Attack and Defense for Dehazing Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Temporal action detection aims to predict the time intervals and the classesof action instances in the video. Despite the promising performance, existingtwo-stream models exhibit slow inference speed due to their reliance oncomputationally expensive optical flow. In this paper, we introduce adecomposed cross-modal distillation framework to build a strong RGB-baseddetector by transferring knowledge of the motion modality. Specifically,instead of direct distillation, we propose to separately learn RGB and motionrepresentations, which are in turn combined to perform action localization. Thedual-branch design and the asymmetric training objectives enable effectivemotion knowledge transfer while preserving RGB information intact. In addition,we introduce a local attentive fusion to better exploit the multimodalcomplementarity. It is designed to preserve the local discriminability of thefeatures that is important for action localization. Extensive experiments onthe benchmarks verify the effectiveness of the proposed method in enhancingRGB-based action detectors. Notably, our framework is agnostic to backbones anddetection heads, bringing consistent gains across different model combinations.", "output": "Decomposed Cross-modal Distillation for RGB-based Temporal Action Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Weakly-supervised temporal action localization aims to localize actioninstances in untrimmed videos with only video-level supervision. We witnessthat different actions record common phases, e.g., the run-up in the HighJumpand LongJump. These different actions are defined as conjoint actions, whoserest parts are definite phases, e.g., leaping over the bar in a HighJump.Compared with the common phases, the definite phases are more easily localizedin existing researches. Most of them formulate this task as a Multiple InstanceLearning paradigm, in which the common phases are tended to be confused withthe background, and affect the localization completeness of the conjointactions. To tackle this challenge, we propose a Joint of Common and Definitephases Network (JCDNet) by improving feature discriminability of the conjointactions. Specifically, we design a Class-Aware Discriminative module to enhancethe contribution of the common phases in classification by the guidance of thecoarse definite-phase features. Besides, we introduce a temporal attentionmodule to learn robust action-ness scores via modeling temporal dependencies,distinguishing the common phases from the background. Extensive experiments onthree datasets (THUMOS14, ActivityNetv1.2, and a conjoint-action subset)demonstrate that JCDNet achieves competitive performance against thestate-of-the-art methods. Keywords: weakly-supervised learning, temporal actionlocalization, conjoint action", "output": "JCDNet: Joint of Common and Definite phases Network for Weakly Supervised Temporal Action Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "3D object detection is an essential perception task in autonomous driving tounderstand the environments. The Bird's-Eye-View (BEV) representations havesignificantly improved the performance of 3D detectors with camera inputs onpopular benchmarks. However, there still lacks a systematic understanding ofthe robustness of these vision-dependent BEV models, which is closely relatedto the safety of autonomous driving systems. In this paper, we evaluate thenatural and adversarial robustness of various representative models underextensive settings, to fully understand their behaviors influenced by explicitBEV features compared with those without BEV. In addition to the classicsettings, we propose a 3D consistent patch attack by applying adversarialpatches in the 3D space to guarantee the spatiotemporal consistency, which ismore realistic for the scenario of autonomous driving. With substantialexperiments, we draw several findings: 1) BEV models tend to be more stablethan previous methods under different natural conditions and common corruptionsdue to the expressive spatial representations; 2) BEV models are morevulnerable to adversarial noises, mainly caused by the redundant BEV features;3) Camera-LiDAR fusion models have superior performance under differentsettings with multi-modal inputs, but BEV fusion model is still vulnerable toadversarial noises of both point cloud and image. These findings alert thesafety issue in the applications of BEV detectors and could facilitate thedevelopment of more robust models.", "output": "Understanding the Robustness of 3D Object Detection with Bird's-Eye-View Representations in Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transformers have shown significant effectiveness for various vision tasksincluding both high-level vision and low-level vision. Recently, maskedautoencoders (MAE) for feature pre-training have further unleashed thepotential of Transformers, leading to state-of-the-art performances on varioushigh-level vision tasks. However, the significance of MAE pre-training onlow-level vision tasks has not been sufficiently explored. In this paper, weshow that masked autoencoders are also scalable self-supervised learners forimage processing tasks. We first present an efficient Transformer modelconsidering both channel attention and shifted-window-based self-attentiontermed CSformer. Then we develop an effective MAE architecture for imageprocessing (MAEIP) tasks. Extensive experimental results show that with thehelp of MAEIP pre-training, our proposed CSformer achieves state-of-the-artperformance on various image processing tasks, including Gaussian denoising,real image denoising, single-image motion deblurring, defocus deblurring, andimage deraining.", "output": "Masked Autoencoders as Image Processors."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Convolutional neural networks (CNNs) are increasingly being used to automatesegmentation of organs-at-risk in radiotherapy. Since large sets of highlycurated data are scarce, we investigated how much data is required to trainaccurate and robust head and neck auto-segmentation models. For this, anestablished 3D CNN was trained from scratch with different sized datasets(25-1000 scans) to segment the brainstem, parotid glands and spinal cord inCTs. Additionally, we evaluated multiple ensemble techniques to improve theperformance of these models. The segmentations improved with training set sizeup to 250 scans and the ensemble methods significantly improved performance forall organs. The impact of the ensemble methods was most notable in the smallestdatasets, demonstrating their potential for use in cases where large trainingdatasets are difficult to obtain.", "output": "The impact of training dataset size and ensemble inference strategies on head and neck auto-segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Data organization via forming local regions is an integral part of deeplearning networks that process 3D point clouds in a hierarchical manner. Ateach level, the point cloud is sampled to extract representative points andthese points are used to be centers of local regions. The organization of localregions is of considerable importance since it determines the location and sizeof the receptive field at a particular layer of feature aggregation. In thispaper, we present two local region-learning modules: Center Shift Module toinfer the appropriate shift for each center point, and Radius Update Module toalter the radius of each local region. The parameters of the modules arelearned through optimizing the loss associated with the particular task withinan end-to-end network. We present alternatives for these modules throughvarious ways of modeling the interactions of the features and locations of 3Dpoints in the point cloud. We integrated both modules independently andtogether to the PointNet++ object classification architecture, and demonstratedthat the modules contributed to a significant increase in classificationaccuracy for the ScanObjectNN data set.", "output": "Local region-learning modules for point cloud classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Dense geometric matching determines the dense pixel-wise correspondencebetween a source and support image corresponding to the same 3D structure.Prior works employ an encoder of transformer blocks to correlate the two-framefeatures. However, existing monocular pretraining tasks, e.g., imageclassification, and masked image modeling (MIM), can not pretrain thecross-frame module, yielding less optimal performance. To resolve this, wereformulate the MIM from reconstructing a single masked image to reconstructinga pair of masked images, enabling the pretraining of transformer module.Additionally, we incorporate a decoder into pretraining for improved upsamplingresults. Further, to be robust to the textureless area, we propose a novelcross-frame global matching module (CFGM). Since the most textureless area isplanar surfaces, we propose a homography loss to further regularize itslearning. Combined together, we achieve the State-of-The-Art (SoTA) performanceon geometric matching. Codes and models are available at", "output": "PMatch: Paired Masked Image Modeling for Dense Geometric Matching."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the machine learning domain, research on anomaly detection andlocalization within image data has garnered significant attention, particularlyin practical applications such as industrial defect detection. While existingapproaches predominantly rely on Convolutional Neural Networks (CNN) as theirbackbone network, we propose an innovative method based on the Transformerbackbone network. Our approach employs a two-stage incremental learningstrategy. In the first stage, we train a Masked Autoencoder (MAE) modelexclusively on normal images. Subsequently, in the second stage, we implementpixel-level data augmentation techniques to generate corrupted normal imagesand their corresponding pixel labels. This process enables the model to learnhow to repair corrupted regions and classify the state of each pixel.Ultimately, the model produces a pixel reconstruction error matrix and a pixelanomaly probability matrix, which are combined to create an anomaly scoringmatrix that effectively identifies abnormal regions. When compared to severalstate-of-the-art CNN-based techniques, our method demonstrates superiorperformance on the MVTec AD dataset, achieving an impressive 97.6% AUC.", "output": "Incremental Self-Supervised Learning Based on Transformer for Anomaly Detection and Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We show that symmetrically padded convolution can be analytically invertedvia DFT. We comprehensively analyze several different symmetric andanti-symmetric padding modes and show that multiple cases exist where theinversion can be achieved. The implementation is available aturl{", "output": "Invertible Convolution with Symmetric Paddings."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Synthetic data has emerged as a promising source for 3D human research as itoffers low-cost access to large-scale human datasets. To advance the diversityand annotation quality of human models, we introduce a new synthetic dataset,Synbody, with three appealing features: 1) a clothed parametric human modelthat can generate a diverse range of subjects; 2) the layered humanrepresentation that naturally offers high-quality 3D annotations to supportmultiple tasks; 3) a scalable system for producing realistic data to facilitatereal-world tasks. The dataset comprises 1.7M images with corresponding accurate3D annotations, covering 10,000 human body models, 1000 actions, and variousviewpoints. The dataset includes two subsets for human mesh recovery as well ashuman neural rendering. Extensive experiments on SynBody indicate that itsubstantially enhances both SMPL and SMPL-X estimation. Furthermore, theincorporation of layered annotations offers a valuable training resource forinvestigating the Human Neural Radiance Fields (NeRF).", "output": "SynBody: Synthetic Dataset with Layered Human Models for 3D Human Perception and Modeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "There has been a recent explosion of computer vision models which performmany tasks and are composed of an image encoder (usually a ViT) and anautoregressive decoder (usually a Transformer). However, most of this worksimply presents one system and its results, leaving many questions regardingdesign decisions and trade-offs of such systems unanswered. In this work, weaim to provide such answers. We take a close look at autoregressive decodersfor multi-task learning in multimodal computer vision, includingclassification, captioning, visual question answering, and optical characterrecognition. Through extensive systematic experiments, we study the effects oftask and data mixture, training and regularization hyperparameters,conditioning type and specificity, modality combination, and more. Importantly,we compare these to well-tuned single-task baselines to highlight the costincurred by multi-tasking. A key finding is that a small decoder learned on topof a frozen pretrained encoder works surprisingly well. We call this setuplocked-image tuning with decoder (LiT-decoder). It can be seen as teaching adecoder to interact with a pretrained vision model via natural language.", "output": "A Study of Autoregressive Decoders for Multi-Tasking in Computer Vision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "RGB-thermal semantic segmentation is one potential solution to achievereliable semantic scene understanding in adverse weather and lightingconditions. However, the previous studies mostly focus on designing amulti-modal fusion module without consideration of the nature of multi-modalityinputs. Therefore, the networks easily become over-reliant on a singlemodality, making it difficult to learn complementary and meaningfulrepresentations for each modality. This paper proposes 1) a complementaryrandom masking strategy of RGB-T images and 2) self-distillation loss betweenclean and masked input modalities. The proposed masking strategy preventsover-reliance on a single modality. It also improves the accuracy androbustness of the neural network by forcing the network to segment and classifyobjects even when one modality is partially available. Also, the proposedself-distillation loss encourages the network to extract complementary andmeaningful representations from a single modality or complementary maskedmodalities. Based on the proposed method, we achieve state-of-the-artperformance over three RGB-T semantic segmentation benchmarks. Our source codeis available at ", "output": "Complementary Random Masking for RGB-Thermal Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generalized category discovery (GCD) is a recently proposed open-worldproblem, which aims to automatically cluster partially labeled data. The mainchallenge is that the unlabeled data contain instances that are not only fromknown categories of the labeled data but also from novel categories. This leadstraditional novel category discovery (NCD) methods to be incapacitated for GCD,due to their assumption of unlabeled data are only from novel categories. Oneeffective way for GCD is applying self-supervised learning to learndiscriminate representation for unlabeled data. However, this manner largelyignores underlying relationships between instances of the same concepts (e.g.,class, super-class, and sub-class), which results in inferior representationlearning. In this paper, we propose a Dynamic Conceptional Contrastive Learning(DCCL) framework, which can effectively improve clustering accuracy byalternately estimating underlying visual conceptions and learning conceptionalrepresentation. In addition, we design a dynamic conception generation andupdate mechanism, which is able to ensure consistent conception learning andthus further facilitate the optimization of DCCL. Extensive experiments showthat DCCL achieves new state-of-the-art performances on six generic andfine-grained visual recognition datasets, especially on fine-grained ones. Forexample, our method significantly surpasses the best competitor by 16.2% on thenew classes for the CUB-200 dataset. Code is available at", "output": "Dynamic Conceptional Contrastive Learning for Generalized Category Discovery."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Removing supervision in semantic segmentation is still tricky. Currentapproaches can deal with common categorical patterns yet resort to multi-stagearchitectures. We design a novel end-to-end model leveraging local-global patchmatching to predict categories, good localization, area and shape of objectsfor semantic segmentation. The local-global matching is, in turn, compelled byoptimal transport plans fulfilling area constraints nearing a solution forexact shape prediction. Our model attains state-of-the-art in Weakly SupervisedSemantic Segmentation, only image-level labels, with 75% mIoU on PascalVOC2012val set and 46% on MS-COCO2014 val set. Dropping the image-level labels andclustering self-supervised learned features to yield pseudo-multi-level labels,we obtain an unsupervised model for semantic segmentation. We also attainstate-of-the-art on Unsupervised Semantic Segmentation with 43.6% mIoU onPascalVOC2012 val set and 19.4% on MS-COCO2014 val set. The code is availableat ", "output": "Removing supervision in semantic segmentation with local-global matching and area balancing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The accurate representation of 3D building models in urban environments issignificantly hindered by challenges such as texture occlusion, blurring, andmissing details, which are difficult to mitigate through standardphotogrammetric texture mapping pipelines. Current image completion methodsoften struggle to produce structured results and effectively handle theintricate nature of highly-structured fac{c}ade textures with diversearchitectural styles. Furthermore, existing image synthesis methods encounterdifficulties in preserving high-frequency details and artificial regularstructures, which are essential for achieving realistic fac{c}ade texturesynthesis. To address these challenges, we introduce a novel approach forsynthesizing fac{c}ade texture images that authentically reflect thearchitectural style from a structured label map, guided by a ground-truthfac{c}ade image. In order to preserve fine details and regular structures, wepropose a regularity-aware multi-domain method that capitalizes on frequencyinformation and corner maps. We also incorporate SEAN blocks into our generatorto enable versatile style transfer. To generate plausible structured imageswithout undesirable regions, we employ image completion techniques to removeocclusions according to semantics prior to image inference. Our proposed methodis also capable of synthesizing texture images with specific styles forfac{c}ades that lack pre-existing textures, using manually annotated labels.Experimental results on publicly available fac{c}ade image and 3D modeldatasets demonstrate that our method yields superior results and effectivelyaddresses issues associated with flawed textures. The code and datasets will bemade publicly available for further research and development.", "output": "Semantic Image Translation for Repairing the Texture Defects of Building Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Change detection (CD) in heterogeneous remote sensing images is a practicaland challenging issue for real-life emergencies. In the past decade, theheterogeneous CD problem has significantly benefited from the development ofdeep neural networks (DNN). However, the data-driven DNNs always perform like ablack box where the lack of interpretability limits the trustworthiness andcontrollability of DNNs in most practical CD applications. As a strongknowledge-driven tool to measure correlation between random variables, Copulatheory has been introduced into CD, yet it suffers from non-robust CDperformance without manual prior selection for Copula functions. To address theabove issues, we propose a knowledge-data-driven heterogeneous CD method(NN-Copula-CD) based on the Copula-guided interpretable neural network. In ourNN-Copula-CD, the mathematical characteristics of Copula are designed as thelosses to supervise a simple fully connected neural network to learn thecorrelation between bi-temporal image patches, and then the changed regions areidentified via binary classification for the correlation coefficients of allimage patch pairs of the bi-temporal images. We conduct in-depth experiments onthree datasets with multimodal images (e.g., Optical, SAR, and NIR), where thequantitative results and visualized analysis demonstrate both the effectivenessand interpretability of the proposed NN-Copula-CD.", "output": "NN-Copula-CD: A Copula-Guided Interpretable Neural Network for Change Detection in Heterogeneous Remote Sensing Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, transformer-based methods have gained significant success insequential 2D-to-3D lifting human pose estimation. As a pioneering work,PoseFormer captures spatial relations of human joints in each video frame andhuman dynamics across frames with cascaded transformer layers and has achievedimpressive performance. However, in real scenarios, the performance ofPoseFormer and its follow-ups is limited by two factors: (a) The length of theinput joint sequence; (b) The quality of 2D joint detection. Existing methodstypically apply self-attention to all frames of the input sequence, causing ahuge computational burden when the frame number is increased to obtain advancedestimation accuracy, and they are not robust to noise naturally brought by thelimited capability of 2D joint detectors. In this paper, we proposePoseFormerV2, which exploits a compact representation of lengthy skeletonsequences in the frequency domain to efficiently scale up the receptive fieldand boost robustness to noisy 2D joint detection. With minimum modifications toPoseFormer, the proposed method effectively fuses features both in the timedomain and frequency domain, enjoying a better speed-accuracy trade-off thanits precursor. Extensive experiments on two benchmark datasets (i.e., Human3.6Mand MPI-INF-3DHP) demonstrate that the proposed approach significantlyoutperforms the original PoseFormer and other transformer-based variants. Codeis released at url{", "output": "PoseFormerV2: Exploring Frequency Domain for Efficient and Robust 3D Human Pose Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Talking face generation, also known as speech-to-lip generation, reconstructsfacial motions concerning lips given coherent speech input. The previousstudies revealed the importance of lip-speech synchronization and visualquality. Despite much progress, they hardly focus on the content of lipmovements i.e., the visual intelligibility of the spoken words, which is animportant aspect of generation quality. To address the problem, we proposeusing a lip-reading expert to improve the intelligibility of the generated lipregions by penalizing the incorrect generation results. Moreover, to compensatefor data scarcity, we train the lip-reading expert in an audio-visualself-supervised manner. With a lip-reading expert, we propose a novelcontrastive learning to enhance lip-speech synchronization, and a transformerto encode audio synchronically with video, while considering global temporaldependency of audio. For evaluation, we propose a new strategy with twodifferent lip-reading experts to measure intelligibility of the generatedvideos. Rigorous experiments show that our proposal is superior to otherState-of-the-art (SOTA) methods, such as Wav2Lip, in reading intelligibilityi.e., over 38% Word Error Rate (WER) on LRS2 dataset and 27.8% accuracy on LRWdataset. We also achieve the SOTA performance in lip-speech synchronization andcomparable performances in visual quality.", "output": "Seeing What You Said: Talking Face Generation Guided by a Lip Reading Expert."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "How does audio describe the world around us? In this paper, we propose amethod for generating an image of a scene from sound. Our method addresses thechallenges of dealing with the large gaps that often exist between sight andsound. We design a model that works by scheduling the learning procedure ofeach model component to associate audio-visual modalities despite theirinformation gaps. The key idea is to enrich the audio features with visualinformation by learning to align audio to visual latent space. We translate theinput audio to visual features, then use a pre-trained generator to produce animage. To further improve the quality of our generated images, we use soundsource localization to select the audio-visual pairs that have strongcross-modal correlations. We obtain substantially better results on the VEGASand VGGSound datasets than prior approaches. We also show that we can controlour model's predictions by applying simple manipulations to the input waveform,or to the latent space.", "output": "Sound to Visual Scene Generation by Audio-to-Visual Latent Alignment."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In contrast to sparse keypoints, a handful of line segments can conciselyencode the high-level scene layout, as they often delineate the main structuralelements. In addition to offering strong geometric cues, they are alsoomnipresent in urban landscapes and indoor scenes. Despite their apparentadvantages, current line-based reconstruction methods are far behind theirpoint-based counterparts. In this paper we aim to close the gap by introducingLIMAP, a library for 3D line mapping that robustly and efficiently creates 3Dline maps from multi-view imagery. This is achieved through revisiting thedegeneracy problem of line triangulation, carefully crafted scoring and trackbuilding, and exploiting structural priors such as line coincidence,parallelism, and orthogonality. Our code integrates seamlessly with existingpoint-based Structure-from-Motion methods and can leverage their 3D points tofurther improve the line reconstruction. Furthermore, as a byproduct, themethod is able to recover 3D association graphs between lines and points /vanishing points (VPs). In thorough experiments, we show that LIMAPsignificantly outperforms existing approaches for 3D line mapping. Our robust3D line maps also open up new research directions. We show two exampleapplications: visual localization and bundle adjustment, where integratinglines alongside points yields the best results. Code is available at", "output": "3D Line Mapping Revisited."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Unsupervised anomaly detection (UAD) has been widely implemented inindustrial and medical applications, which reduces the cost of manualannotation and improves efficiency in disease diagnosis. Recently, deepauto-encoder with its variants has demonstrated its advantages in many UADscenarios. Training on the normal data, these models are expected to locateanomalies by producing higher reconstruction error for the abnormal areas thanthe normal ones. However, this assumption does not always hold because of theuncontrollable generalization capability. To solve this problem, we presentLSGS, a method that builds on Vector Quantised-Variational Autoencoder (VQVAE)with a novel aggregated codebook and transformers with global attention. Inthis work, the VQVAE focus on feature extraction and reconstruction of images,and the transformers fit the manifold and locate anomalies in the latent space.Then, leveraging the generated encoding sequences that conform to a normaldistribution, we can reconstruct a more accurate image for locating theanomalies. Experiments on various datasets demonstrate the effectiveness of theproposed method.", "output": "Unsupervised Anomaly Detection with Local-Sensitive VQVAE and Global-Sensitive Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Humans learn quickly even in tasks that contain complex visual information.This is due in part to the efficient formation of compressed representations ofvisual information, allowing for better generalization and robustness. However,compressed representations alone are insufficient for explaining the high speedof human learning. Reinforcement learning (RL) models that seek to replicatethis impressive efficiency may do so through the use of factoredrepresentations of tasks. These informationally simplistic representations oftasks are similarly motivated as the use of compressed representations ofvisual information. Recent studies have connected biological visual perceptionto disentangled and compressed representations. This raises the question of howhumans learn to efficiently represent visual information in a manner useful forlearning tasks. In this paper we present a model of human factoredrepresentation learning based on an altered form of a $beta$-VariationalAuto-encoder used in a visual learning task. Modelling results demonstrate atrade-off in the informational complexity of model latent dimension spaces,between the speed of learning and the accuracy of reconstructions.", "output": "Learning in Factored Domains with Information-Constrained Visual Representations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The objective of this work is to explore the learning of visually groundedspeech models (VGS) from multilingual perspective. Bilingual VGS models aregenerally trained with an equal number of spoken captions from both languages.However, in reality, there can be an imbalance among the languages for theavailable spoken captions. Our key contribution in this work is to leverage thepower of a high-resource language in a bilingual visually grounded speech modelto improve the performance of a low-resource language. We introduce two methodsto distill the knowledge of high-resource language into low-resource languages:(1) incorporating a strong pre-trained high-resource language encoder and (2)using semantically similar spoken captions. Our experiments show that combiningthese two approaches effectively enables the low-resource language to surpassthe performances of monolingual and bilingual counterparts for cross-modalretrieval tasks.", "output": "Hindi as a Second Language: Improving Visually Grounded Speech with Semantically Similar Samples."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Semi-supervised domain adaptation (SSDA) adapts a learner to a new domain byeffectively utilizing source domain data and a few labeled target samples. Itis a practical yet under-investigated research topic. In this paper, we analyzethe SSDA problem from two perspectives that have previously been overlooked,and correspondingly decompose it into two emph{key subproblems}: emph{robustdomain adaptation (DA) learning} and emph{maximal cross-domain datautilization}. textbf{(i)} From a causal theoretical view, a robust DA modelshould distinguish the invariant ``concept'' (key clue to image label) from thenuisance of confounding factors across domains. To achieve this goal, wepropose to generate emph{concept-invariant samples} to enable the model toclassify the samples through causal intervention, yielding improvedgeneralization guarantees; textbf{(ii)} Based on the robust DA theory, we aimto exploit the maximal utilization of rich source domain data and a few labeledtarget samples to boost SSDA further. Consequently, we propose acollaboratively debiasing learning framework that utilizes two complementarysemi-supervised learning (SSL) classifiers to mutually exchange their unbiasedknowledge, which helps unleash the potential of source and target domaintraining data, thereby producing more convincing pseudo-labels. Such obtainedlabels facilitate cross-domain feature alignment and duly improve the invariantconcept learning. In our experimental study, we show that the proposed modelsignificantly outperforms SOTA methods in terms of effectiveness andgeneralisability on SSDA datasets.", "output": "CAusal and collaborative proxy-tasKs lEarning for Semi-Supervised Domain Adaptation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The asymmetrical retrieval setting is a well suited solution for resourceconstrained face recognition. In this setting a large model is used forindexing the gallery while a lightweight model is used for querying. The keyprinciple in such systems is ensuring that both models share the same embeddingspace. Most methods in this domain are based on knowledge distillation. Whileuseful, they suffer from several drawbacks: they are upper-bounded by theperformance of the single best model found and cannot be extended to use anensemble of models in a straightforward manner. In this paper we present anapproach that does not rely on knowledge distillation, rather it utilizesembedding transformation models. This allows the use of N independently trainedand diverse gallery models (e.g., trained on different datasets or having adifferent architecture) and a single query model. As a result, we improve theoverall accuracy beyond that of any single model while maintaining a lowcomputational budget for querying. Additionally, we propose a gallery imagerejection method that utilizes the diversity between multiple transformedembeddings to estimate the uncertainty of gallery images.", "output": "Asymmetric Face Recognition with Cross Model Compatible Ensembles."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image editing using diffusion models has witnessed extremely fast-pacedgrowth recently. There are various ways in which previous works enablecontrolling and editing images. Some works use high-level conditioning such astext, while others use low-level conditioning. Nevertheless, most of them lackfine-grained control over the properties of the different objects present inthe image, i.e. object-level image editing. In this work, we consider an imageas a composition of multiple objects, each defined by various properties. Outof these properties, we identify structure and appearance as the most intuitiveto understand and useful for editing purposes. We proposeStructure-and-Appearance Paired Diffusion model (PAIR-Diffusion), which istrained using structure and appearance information explicitly extracted fromthe images. The proposed model enables users to inject a reference image'sappearance into the input image at both the object and global levels.Additionally, PAIR-Diffusion allows editing the structure while maintaining thestyle of individual components of the image unchanged. We extensively evaluateour method on LSUN datasets and the CelebA-HQ face dataset, and we demonstratefine-grained control over both structure and appearance at the object level. Wealso applied the method to Stable Diffusion to edit any real image at theobject level.", "output": "PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While recent research has made significant progress in speech-driven talkingface generation, the quality of the generated video still lags behind that ofreal recordings. One reason for this is the use of handcrafted intermediaterepresentations like facial landmarks and 3DMM coefficients, which are designedbased on human knowledge and are insufficient to precisely describe facialmovements. Additionally, these methods require an external pretrained model forextracting these representations, whose performance sets an upper bound ontalking face generation. To address these limitations, we propose a novelmethod called DAE-Talker that leverages data-driven latent representationsobtained from a diffusion autoencoder (DAE). DAE contains an image encoder thatencodes an image into a latent vector and a DDIM image decoder thatreconstructs the image from it. We train our DAE on talking face video framesand then extract their latent representations as the training target for aConformer-based speech2latent model. This allows DAE-Talker to synthesize fullvideo frames and produce natural head movements that align with the content ofspeech, rather than relying on a predetermined head pose from a template video.We also introduce pose modelling in speech2latent for pose controllability.Additionally, we propose a novel method for generating continuous video frameswith the DDIM image decoder trained on individual frames, eliminating the needfor modelling the joint distribution of consecutive frames directly. Ourexperiments show that DAE-Talker outperforms existing popular methods inlip-sync, video fidelity, and pose naturalness. We also conduct ablationstudies to analyze the effectiveness of the proposed techniques and demonstratethe pose controllability of DAE-Talker.", "output": "DAE-Talker: High Fidelity Speech-Driven Talking Face Generation with Diffusion Autoencoder."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a simple, efficient, yet powerful framework for dense visualpredictions based on the conditional diffusion pipeline. Our approach follows a\"noise-to-map\" generative paradigm for prediction by progressively removingnoise from a random Gaussian distribution, guided by the image. The method,called DDP, efficiently extends the denoising diffusion process into the modernperception pipeline. Without task-specific design and architecturecustomization, DDP is easy to generalize to most dense prediction tasks, e.g.,semantic segmentation and depth estimation. In addition, DDP shows attractiveproperties such as dynamic inference and uncertainty awareness, in contrast toprevious single-step discriminative methods. We show top results on threerepresentative tasks with six diverse benchmarks, without tricks, DDP achievesstate-of-the-art or competitive performance on each task compared to thespecialist counterparts. For example, semantic segmentation (83.9 mIoU onCityscapes), BEV map segmentation (70.6 mIoU on nuScenes), and depth estimation(0.05 REL on KITTI). We hope that our approach will serve as a solid baselineand facilitate future research", "output": "DDP: Diffusion Model for Dense Visual Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "During the preceding biennium, vision-language pre-training has achievednoteworthy success on several downstream tasks. Nevertheless, acquiringhigh-quality image-text pairs, where the pairs are entirely exclusive of eachother, remains a challenging task, and noise exists in the commonly useddatasets. To address this issue, we propose SoftCLIP, a novel approach thatrelaxes the strict one-to-one constraint and achieves a soft cross-modalalignment by introducing a softened target, which is generated from thefine-grained intra-modal self-similarity. The intra-modal guidance isindicative to enable two pairs have some local similarities and modelmany-to-many relationships between the two modalities. Besides, since thepositive still dominates in the softened target distribution, we disentanglethe negatives in the distribution to further boost the relation alignment withthe negatives in the cross-modal learning. Extensive experiments demonstratethe effectiveness of SoftCLIP. In particular, on ImageNet zero-shotclassification task, using CC3M/CC12M as pre-training dataset, SoftCLIP bringsa top-1 accuracy improvement of 6.8%/7.2% over the CLIP baseline.", "output": "SoftCLIP: Softer Cross-modal Alignment Makes CLIP Stronger."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a novel unsupervised backlit image enhancement method, abbreviatedas CLIP-LIT, by exploring the potential of Contrastive Language-ImagePre-Training (CLIP) for pixel-level image enhancement. We show that theopen-world CLIP prior not only aids in distinguishing between backlit andwell-lit images, but also in perceiving heterogeneous regions with differentluminance, facilitating the optimization of the enhancement network. Unlikehigh-level and image manipulation tasks, directly applying CLIP to enhancementtasks is non-trivial, owing to the difficulty in finding accurate prompts. Tosolve this issue, we devise a prompt learning framework that first learns aninitial prompt pair by constraining the text-image similarity between theprompt (negative/positive sample) and the corresponding image (backlitimage/well-lit image) in the CLIP latent space. Then, we train the enhancementnetwork based on the text-image similarity between the enhanced result and theinitial prompt pair. To further improve the accuracy of the initial promptpair, we iteratively fine-tune the prompt learning framework to reduce thedistribution gaps between the backlit images, enhanced results, and well-litimages via rank learning, boosting the enhancement performance. Our methodalternates between updating the prompt learning framework and enhancementnetwork until visually pleasing results are achieved. Extensive experimentsdemonstrate that our method outperforms state-of-the-art methods in terms ofvisual quality and generalization ability, without requiring any paired data.", "output": "Iterative Prompt Learning for Unsupervised Backlit Image Enhancement."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automated generation of clinically accurate radiology reports can improvepatient care. Previous report generation methods that rely on image captioningmodels often generate incoherent and incorrect text due to their lack ofrelevant domain knowledge, while retrieval-based attempts frequently retrievereports that are irrelevant to the input image. In this work, we proposeContrastive X-Ray REport Match (X-REM), a novel retrieval-based radiologyreport generation module that uses an image-text matching score to measure thesimilarity of a chest X-ray image and radiology report for report retrieval. Weobserve that computing the image-text matching score with a language-imagemodel can effectively capture the fine-grained interaction between image andtext that is often lost when using cosine similarity. X-REM outperformsmultiple prior radiology report generation modules in terms of both naturallanguage and clinical metrics. Human evaluation of the generated reportssuggests that X-REM increased the number of zero-error reports and decreasedthe average error severity compared to the baseline retrieval approach. Ourcode is available at: ", "output": "Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Solving complicated AI tasks with different domains and modalities is a keystep toward artificial general intelligence (AGI). While there are abundant AImodels available for different domains and modalities, they cannot handlecomplicated AI tasks. Considering large language models (LLMs) have exhibitedexceptional ability in language understanding, generation, interaction, andreasoning, we advocate that LLMs could act as a controller to manage existingAI models to solve complicated AI tasks and language could be a genericinterface to empower this. Based on this philosophy, we present HuggingGPT, asystem that leverages LLMs (e.g., ChatGPT) to connect various AI models inmachine learning communities (e.g., HuggingFace) to solve AI tasks.Specifically, we use ChatGPT to conduct task planning when receiving a userrequest, select models according to their function descriptions available inHuggingFace, execute each subtask with the selected AI model, and summarize theresponse according to the execution results. By leveraging the strong languagecapability of ChatGPT and abundant AI models in HuggingFace, HuggingGPT is ableto cover numerous sophisticated AI tasks in different modalities and domainsand achieve impressive results in language, vision, speech, and otherchallenging tasks, which paves a new way towards AGI.", "output": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Point-spread-function (PSF) engineering is a powerful computational imagingtechniques wherein a custom phase mask is integrated into an optical system toencode additional information into captured images. Used in combination withdeep learning, such systems now offer state-of-the-art performance at monoculardepth estimation, extended depth-of-field imaging, lensless imaging, and othertasks. Inspired by recent advances in spatial light modulator (SLM) technology,this paper answers a natural question: Can one encode additional informationand achieve superior performance by changing a phase mask dynamically overtime? We first prove that the set of PSFs described by static phase masks isnon-convex and that, as a result, time-averaged PSFs generated by dynamic phasemasks are fundamentally more expressive. We then demonstrate, in simulation,that time-averaged dynamic (TiDy) phase masks can offer substantially improvedmonocular depth estimation and extended depth-of-field imaging performance.", "output": "TiDy-PSFs: Computational Imaging with Time-Averaged Dynamic Point-Spread-Functions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Natural intelligences (NIs) thrive in a dynamic world - they learn quickly,sometimes with only a few samples. In contrast, Artificial intelligences (AIs)typically learn with prohibitive amount of training samples and computationalpower. What design principle difference between NI and AI could contribute tosuch a discrepancy? Here, we propose an angle from weight polarity: developmentprocesses initialize NIs with advantageous polarity configurations; as NIs growand learn, synapse magnitudes update yet polarities are largely kept unchanged.We demonstrate with simulation and image classification tasks that if weightpolarities are adequately set $textit{a priori}$, then networks learn withless time and data. We also explicitly illustrate situations in which$textit{a priori}$ setting the weight polarities is disadvantageous fornetworks. Our work illustrates the value of weight polarities from theperspective of statistical and computational efficiency during learning.", "output": "Polarity is all you need to learn and transfer faster."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large-scale pre-trained Vision &amp; Language (VL) models have shown remarkableperformance in many applications, enabling replacing a fixed set of supportedclasses with zero-shot open vocabulary reasoning over (almost arbitrary)natural language prompts. However, recent works have uncovered a fundamentalweakness of these models. For example, their difficulty to understand VisualLanguage Concepts (VLC) that go 'beyond nouns' such as the meaning ofnon-object words (e.g., attributes, actions, relations, states, etc.), ordifficulty in performing compositional reasoning such as understanding thesignificance of the order of the words in a sentence. In this work, weinvestigate to which extent purely synthetic data could be leveraged to teachthese models to overcome such shortcomings without compromising their zero-shotcapabilities. We contribute Synthetic Visual Concepts (SyViC) - a million-scalesynthetic dataset and data generation codebase allowing to generate additionalsuitable data to improve VLC understanding and compositional reasoning of VLmodels. Additionally, we propose a general VL finetuning strategy foreffectively leveraging SyViC towards achieving these improvements. Ourextensive experiments and ablations on VL-Checklist, Winoground, and ARObenchmarks demonstrate that it is possible to adapt strong pre-trained VLmodels with synthetic data significantly enhancing their VLC understanding(e.g. by 9.9% on ARO and 4.3% on VL-Checklist) with under 1% drop in theirzero-shot accuracy.", "output": "Going Beyond Nouns With Vision & Language Models Using Synthetic Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The unlearning problem of deep learning models, once primarily an academicconcern, has become a prevalent issue in the industry. The significant advancesin text-to-image generation techniques have prompted global discussions onprivacy, copyright, and safety, as numerous unauthorized personal IDs, content,artistic creations, and potentially harmful materials have been learned bythese models and later utilized to generate and distribute uncontrolledcontent. To address this challenge, we propose textbf{Forget-Me-Not}, anefficient and low-cost solution designed to safely remove specified IDs,objects, or styles from a well-configured text-to-image model in as little as30 seconds, without impairing its ability to generate other content. Alongsideour method, we introduce the textbf{Memorization Score (M-Score)} andtextbf{ConceptBench} to measure the models' capacity to generate generalconcepts, grouped into three primary categories: ID, object, and style. UsingM-Score and ConceptBench, we demonstrate that Forget-Me-Not can effectivelyeliminate targeted concepts while maintaining the model's performance on otherconcepts. Furthermore, Forget-Me-Not offers two practical extensions: a)removal of potentially harmful or NSFW content, and b) enhancement of modelaccuracy, inclusion and diversity through textbf{concept correction anddisentanglement}. It can also be adapted as a lightweight model patch forStable Diffusion, allowing for concept manipulation and convenientdistribution. To encourage future research in this critical area and promotethe development of safe and inclusive generative models, we will open-sourceour code and ConceptBench athref{", "output": "Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose the first framework to learn control policies for vision-basedhuman-to-robot handovers, a critical task for human-robot interaction. Whileresearch in Embodied AI has made significant progress in training robot agentsin simulated environments, interacting with humans remains challenging due tothe difficulties of simulating humans. Fortunately, recent research hasdeveloped realistic simulated environments for human-to-robot handovers.Leveraging this result, we introduce a method that is trained with ahuman-in-the-loop via a two-stage teacher-student framework that uses motionand grasp planning, reinforcement learning, and self-supervision. We showsignificant performance gains over baselines on a simulation benchmark,sim-to-sim transfer and sim-to-real transfer.", "output": "Learning Human-to-Robot Handovers from Point Clouds."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pulmonary Embolisms (PE) represent a leading cause of cardiovascular death.While medical imaging, through computed tomographic pulmonary angiography(CTPA), represents the gold standard for PE diagnosis, it is still susceptibleto misdiagnosis or significant diagnosis delays, which may be fatal forcritical cases. Despite the recently demonstrated power of deep learning tobring a significant boost in performance in a wide range of medical imagingtasks, there are still very few published researches on automatic pulmonaryembolism detection. Herein we introduce a deep learning based approach, whichefficiently combines computer vision and deep neural networks for pulmonaryembolism detection in CTPA. Our method features novel improvements along threeorthogonal axes: 1) automatic detection of anatomical structures; 2) anatomicalaware pretraining, and 3) a dual-hop deep neural net for PE detection. Weobtain state-of-the-art results on the publicly available multicenterlarge-scale RSNA dataset.", "output": "Anatomically aware dual-hop learning for pulmonary embolism detection in CT pulmonary angiograms."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although recent approaches aiming for video instance segmentation haveachieved promising results, it is still difficult to employ those approachesfor real-world applications on mobile devices, which mainly suffer from (1)heavy computation and memory cost and (2) complicated heuristics for trackingobjects. To address those issues, we present MobileInst, a lightweight andmobile-friendly framework for video instance segmentation on mobile devices.Firstly, MobileInst adopts a mobile vision transformer to extract multi-levelsemantic features and presents an efficient query-based dual-transformerinstance decoder for mask kernels and a semantic-enhanced mask decoder togenerate instance segmentation per frame. Secondly, MobileInst exploits simpleyet effective kernel reuse and kernel association to track objects for videoinstance segmentation. Further, we propose temporal query passing to enhancethe tracking ability for kernels. We conduct experiments on COCO andYouTube-VIS datasets to demonstrate the superiority of MobileInst and evaluatethe inference latency on a mobile CPU core of Qualcomm Snapdragon-778G, withoutother methods of acceleration. On the COCO dataset, MobileInst achieves 30.5mask AP and 176 ms on the mobile CPU, which reduces the latency by 50% comparedto the previous SOTA. For video instance segmentation, MobileInst achieves 35.0AP on YouTube-VIS 2019 and 30.1 AP on YouTube-VIS 2021. Code will be availableto facilitate real-world applications and future research.", "output": "MobileInst: Video Instance Segmentation on the Mobile."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Supervised learning of image classifiers distills human knowledge into aparametric model through pairs of images and corresponding labels (X,Y). Weargue that this simple and widely used representation of human knowledgeneglects rich auxiliary information from the annotation procedure, such as thetime-series of mouse traces and clicks left after image selection. Our insightis that such annotation byproducts Z provide approximate human attention thatweakly guides the model to focus on the foreground cues, reducing spuriouscorrelations and discouraging shortcut learning. To verify this, we createImageNet-AB and COCO-AB. They are ImageNet and COCO training sets enriched withsample-wise annotation byproducts, collected by replicating the respectiveoriginal annotation tasks. We refer to the new paradigm of training models withannotation byproducts as learning using annotation byproducts (LUAB). We showthat a simple multitask loss for regressing Z together with Y already improvesthe generalisability and robustness of the learned models. Compared to theoriginal supervised learning, LUAB does not require extra annotation costs.ImageNet-AB and COCO-AB are at ", "output": "Neglected Free Lunch -- Learning Image Classifiers Using Annotation Byproducts."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The robustness of 3D perception systems under natural corruptions fromenvironments and sensors is pivotal for safety-critical applications. Existinglarge-scale 3D perception datasets often contain data that are meticulouslycleaned. Such configurations, however, cannot reflect the reliability ofperception models during the deployment stage. In this work, we present Robo3D,the first comprehensive benchmark heading toward probing the robustness of 3Ddetectors and segmentors under out-of-distribution scenarios against naturalcorruptions that occur in real-world environments. Specifically, we considereight corruption types stemming from adversarial weather conditions, externaldisturbances, and internal sensor failure. We uncover that, although promisingresults have been progressively achieved on standard benchmarks,state-of-the-art 3D perception models are at risk of being vulnerable tocorruptions. We draw key observations on the use of data representations,augmentation schemes, and training strategies, that could severely affect themodel's performance. To pursue better robustness, we propose adensity-insensitive training framework along with a simple flexiblevoxelization strategy to enhance the model resiliency. We hope our benchmarkand approach could inspire future research in designing more robust andreliable 3D perception models. Our robustness benchmark suite is publiclyavailable.", "output": "Robo3D: Towards Robust and Reliable 3D Perception against Corruptions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Novel view synthesis from a single image has been a cornerstone problem formany Virtual Reality applications that provide immersive experiences. However,most existing techniques can only synthesize novel views within a limited rangeof camera motion or fail to generate consistent and high-quality novel viewsunder significant camera movement. In this work, we propose a pose-guideddiffusion model to generate a consistent long-term video of novel views from asingle image. We design an attention layer that uses epipolar lines asconstraints to facilitate the association between different viewpoints.Experimental results on synthetic and real-world datasets demonstrate theeffectiveness of the proposed diffusion model against state-of-the-arttransformer-based and GAN-based approaches.", "output": "Consistent View Synthesis with Pose-Guided Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large-scale text-to-image diffusion models achieve unprecedented success inimage generation and editing. However, how to extend such success to videoediting is unclear. Recent initial attempts at video editing requiresignificant text-to-video data and computation resources for training, which isoften not accessible. In this work, we propose vid2vid-zero, a simple yeteffective method for zero-shot video editing. Our vid2vid-zero leveragesoff-the-shelf image diffusion models, and doesn't require training on anyvideo. At the core of our method is a null-text inversion module fortext-to-video alignment, a cross-frame modeling module for temporalconsistency, and a spatial regularization module for fidelity to the originalvideo. Without any training, we leverage the dynamic nature of the attentionmechanism to enable bi-directional temporal modeling at test time. Experimentsand analyses show promising results in editing attributes, subjects, places,etc., in real-world videos. Code will be made available aturl{", "output": "Zero-Shot Video Editing Using Off-The-Shelf Image Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Episodic training, where an agent's environment is reset after every successor failure, is the de facto standard when training embodied reinforcementlearning (RL) agents. The underlying assumption that the environment can beeasily reset is limiting both practically, as resets generally require humaneffort in the real world and can be computationally expensive in simulation,and philosophically, as we'd expect intelligent agents to be able tocontinuously learn without intervention. Work in learning without any resets,i.e{.} Reset-Free RL (RF-RL), is promising but is plagued by the problem ofirreversible transitions (e.g{.} an object breaking) which halt learning.Moreover, the limited state diversity and instrument setup encountered duringRF-RL means that works studying RF-RL largely do not require their models togeneralize to new environments. In this work, we instead look to minimize,rather than completely eliminate, resets while building visual agents that canmeaningfully generalize. As studying generalization has previously not been afocus of benchmarks designed for RF-RL, we propose a new Stretch Pick-and-Placebenchmark designed for evaluating generalizations across goals, cosmeticvariations, and structural changes. Moreover, towards building performantreset-minimizing RL agents, we propose unsupervised metrics to detectirreversible transitions and a single-policy training mechanism to enablegeneralization. Our proposed approach significantly outperforms prior episodic,reset-free, and reset-minimizing approaches achieving higher success rates withfewer resets in Stretch-P&amp;P and another popular RF-RL benchmark. Finally, wefind that our proposed approach can dramatically reduce the number of resetsrequired for training other embodied tasks, in particular for RoboTHORObjectNav we obtain higher success rates than episodic approaches using 99.97%fewer resets.", "output": "When Learning Is Out of Reach, Reset: Generalization in Autonomous Visuomotor Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Human-centric visual tasks have attracted increasing research attention dueto their widespread applications. In this paper, we aim to learn a generalhuman representation from massive unlabeled human images which can benefitdownstream human-centric tasks to the maximum extent. We call this methodSOLIDER, a Semantic cOntrollable seLf-supervIseD lEaRning framework. Unlike theexisting self-supervised learning methods, prior knowledge from human images isutilized in SOLIDER to build pseudo semantic labels and import more semanticinformation into the learned representation. Meanwhile, we note that differentdownstream tasks always require different ratios of semantic information andappearance information. For example, human parsing requires more semanticinformation, while person re-identification needs more appearance informationfor identification purpose. So a single learned representation cannot fit forall requirements. To solve this problem, SOLIDER introduces a conditionalnetwork with a semantic controller. After the model is trained, users can sendvalues to the controller to produce representations with different ratios ofsemantic information, which can fit different needs of downstream tasks.Finally, SOLIDER is verified on six downstream human-centric visual tasks. Itoutperforms state of the arts and builds new baselines for these tasks. Thecode is released in ", "output": "Beyond Appearance: a Semantic Controllable Self-Supervised Learning Framework for Human-Centric Visual Tasks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce a novel framework for training deep stereo networks effortlesslyand without any ground-truth. By leveraging state-of-the-art neural renderingsolutions, we generate stereo training data from image sequences collected witha single handheld camera. On top of them, a NeRF-supervised training procedureis carried out, from which we exploit rendered stereo triplets to compensatefor occlusions and depth maps as proxy labels. This results in stereo networkscapable of predicting sharp and detailed disparity maps. Experimental resultsshow that models trained under this regime yield a 30-40% improvement overexisting self-supervised methods on the challenging Middlebury dataset, fillingthe gap to supervised models and, most times, outperforming them at zero-shotgeneralization.", "output": "NeRF-Supervised Deep Stereo."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The landscape of image generation has been forever changed by open vocabularydiffusion models. However, at their core these models use transformers, whichmakes generation slow. Better implementations to increase the throughput ofthese transformers have emerged, but they still evaluate the entire model. Inthis paper, we instead speed up diffusion models by exploiting naturalredundancy in generated images by merging redundant tokens. After making somediffusion-specific improvements to Token Merging (ToMe), our ToMe for StableDiffusion can reduce the number of tokens in an existing Stable Diffusion modelby up to 60% while still producing high quality images without any extratraining. In the process, we speed up image generation by up to 2x and reducememory consumption by up to 5.6x. Furthermore, this speed-up stacks withefficient implementations such as xFormers, minimally impacting quality whilebeing up to 5.4x faster for large images. Code is available at", "output": "Token Merging for Fast Stable Diffusion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "High-resolution images enable neural networks to learn richer visualrepresentations. However, this improved performance comes at the cost ofgrowing computational complexity, hindering their usage in latency-sensitiveapplications. As not all pixels are equal, skipping computations forless-important regions offers a simple and effective measure to reduce thecomputation. This, however, is hard to be translated into actual speedup forCNNs since it breaks the regularity of the dense convolution workload. In thispaper, we introduce SparseViT that revisits activation sparsity for recentwindow-based vision transformers (ViTs). As window attentions are naturallybatched over blocks, actual speedup with window activation pruning becomespossible: i.e., ~50% latency reduction with 60% sparsity. Different layersshould be assigned with different pruning ratios due to their diversesensitivities and computational costs. We introduce sparsity-aware adaptationand apply the evolutionary search to efficiently find the optimal layerwisesparsity configuration within the vast search space. SparseViT achievesspeedups of 1.5x, 1.4x, and 1.3x compared to its dense counterpart in monocular3D object detection, 2D instance segmentation, and 2D semantic segmentation,respectively, with negligible to no loss of accuracy.", "output": "SparseViT: Revisiting Activation Sparsity for Efficient High-Resolution Vision Transformer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural implicit fields are powerful for representing 3D scenes and generatinghigh-quality novel views, but it remains challenging to use such implicitrepresentations for creating a 3D human avatar with a specific identity andartistic style that can be easily animated. Our proposed method, AvatarCraft,addresses this challenge by using diffusion models to guide the learning ofgeometry and texture for a neural avatar based on a single text prompt. Wecarefully design the optimization framework of neural implicit fields,including a coarse-to-fine multi-bounding box training strategy, shaperegularization, and diffusion-based constraints, to produce high-qualitygeometry and texture. Additionally, we make the human avatar animatable bydeforming the neural implicit field with an explicit warping field that mapsthe target human mesh to a template human mesh, both represented usingparametric human models. This simplifies animation and reshaping of thegenerated avatar by controlling pose and shape parameters. Extensiveexperiments on various text descriptions show that AvatarCraft is effective androbust in creating human avatars and rendering novel views, poses, and shapes.Our project page is: url{", "output": "AvatarCraft: Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we develop methods for few-shot image classification from a newperspective of optimal matching between image regions. We employ the EarthMover's Distance (EMD) as a metric to compute a structural distance betweendense image representations to determine image relevance. The EMD generates theoptimal matching flows between structural elements that have the minimummatching cost, which is used to calculate the image distance forclassification. To generate the important weights of elements in the EMDformulation, we design a cross-reference mechanism, which can effectivelyalleviate the adverse impact caused by the cluttered background and largeintra-class appearance variations. To implement k-shot classification, wepropose to learn a structured fully connected layer that can directly classifydense image representations with the EMD. Based on the implicit functiontheorem, the EMD can be inserted as a layer into the network for end-to-endtraining. Our extensive experiments validate the effectiveness of our algorithmwhich outperforms state-of-the-art methods by a significant margin on fivewidely used few-shot classification benchmarks, namely, miniImageNet,tieredImageNet, Fewshot-CIFAR100 (FC100), Caltech-UCSD Birds-200-2011 (CUB),and CIFAR-FewShot (CIFAR-FS). We also demonstrate the effectiveness of ourmethod on the image retrieval task in our experiments.", "output": "DeepEMD: Differentiable Earth Mover's Distance for Few-Shot Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transformers yield state-of-the-art results across many tasks. However, theirheuristically designed architecture impose huge computational costs duringinference. This work aims on challenging the common design philosophy of theVision Transformer (ViT) model with uniform dimension across all the stackedblocks in a model stage, where we redistribute the parameters both acrosstransformer blocks and between different structures within the block via thefirst systematic attempt on global structural pruning. Dealing with diverse ViTstructural components, we derive a novel Hessian-based structural pruningcriteria comparable across all layers and structures, with latency-awareregularization for direct latency reduction. Performing iterative pruning onthe DeiT-Base model leads to a new architecture family called NViT (Novel ViT),with a novel parameter redistribution that utilizes parameters moreefficiently. On ImageNet-1K, NViT-Base achieves a 2.6x FLOPs reduction, 5.1xparameter reduction, and 1.9x run-time speedup over the DeiT-Base model in anear lossless manner. Smaller NViT variants achieve more than 1% accuracy gainat the same throughput of the DeiT Small/Tiny variants, as well as a lossless3.3x parameter reduction over the SWIN-Small model. These results outperformprior art by a large margin. Further analysis is provided on the parameterredistribution insight of NViT, where we show the high prunability of ViTmodels, distinct sensitivity within ViT block, and unique parameterdistribution trend across stacked ViT blocks. Our insights provide viabilityfor a simple yet effective parameter redistribution rule towards more efficientViTs for off-the-shelf performance boost.", "output": "Global Vision Transformer Pruning with Hessian-Aware Saliency."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep convolutional neural networks are shown to be overkill with highparametric and computational redundancy in many application scenarios, and anincreasing number of works have explored model pruning to obtain lightweightand efficient networks. However, most existing pruning approaches are driven byempirical heuristic and rarely consider the joint impact of channels, leadingto unguaranteed and suboptimal performance. In this paper, we propose a novelchannel pruning method via Class-Aware Trace Ratio Optimization (CATRO) toreduce the computational burden and accelerate the model inference. Utilizingclass information from a few samples, CATRO measures the joint impact ofmultiple channels by feature space discriminations and consolidates thelayer-wise impact of preserved channels. By formulating channel pruning as asubmodular set function maximization problem, CATRO solves it efficiently via atwo-stage greedy iterative optimization procedure. More importantly, we presenttheoretical justifications on convergence of CATRO and performance of prunednetworks. Experimental results demonstrate that CATRO achieves higher accuracywith similar computation cost or lower computation cost with similar accuracythan other state-of-the-art channel pruning algorithms. In addition, because ofits class-aware property, CATRO is suitable to prune efficient networksadaptively for various classification subtasks, enhancing handy deployment andusage of deep networks in real-world applications.", "output": "CATRO: Channel Pruning via Class-Aware Trace Ratio Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Observability is a fundamental structural property of any dynamic system anddescribes the possibility of reconstructing the state that characterizes thesystem from observing its inputs and outputs. Despite the huge effort made tostudy this property and to introduce analytical criteria able to check whethera dynamic system satisfies this property or not, there is no general analyticalcriterion to automatically check the state observability when the dynamics arealso driven by unknown inputs. Here, we introduce the general analyticalsolution of this fundamental problem, often called the unknown inputobservability problem. This paper provides the general analytical solution ofthis problem, namely, it provides the systematic procedure, based on automaticcomputation (differentiation and matrix rank determination), that allows us toautomatically check the state observability even in the presence of unknowninputs (Algorithm 6.1). A first solution of this problem was presented in thesecond part of the book: \"Observability: A New Theory Based on the Group ofInvariance\" [45]. The solution presented by this paper completes the previoussolution in [45]. In particular, the new solution exhaustively accounts for thesystems that do not belong to the category of the systems that are \"canonicwith respect to their unknown inputs\". The analytical derivations largelyexploit several new concepts and analytical results introduced in [45].Finally, as a simple consequence of the results here obtained, we also providethe answer to the problem of unknown input reconstruction which is intimatelyrelated to the problem of state observability. We illustrate the implementationof the new algorithm by studying the observability properties of a nonlinearsystem in the framework of visual-inertial sensor fusion, whose dynamics aredriven by two unknown inputs and one known input.", "output": "Nonlinear Unknown Input Observability and Unknown Input Reconstruction: The General Analytical Solution."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Understanding scenes in movies is crucial for a variety of applications suchas video moderation, search, and recommendation. However, labeling individualscenes is a time-consuming process. In contrast, movie level metadata (e.g.,genre, synopsis, etc.) regularly gets produced as part of the film productionprocess, and is therefore significantly more commonly available. In this work,we propose a novel contrastive learning approach that uses movie metadata tolearn a general-purpose scene representation. Specifically, we use moviemetadata to define a measure of movie similarity, and use it during contrastivelearning to limit our search for positive scene-pairs to only the movies thatare considered similar to each other. Our learned scene representationconsistently outperforms existing state-of-the-art methods on a diverse set oftasks evaluated using multiple benchmark datasets. Notably, our learnedrepresentation offers an average improvement of 7.9% on the sevenclassification tasks and 9.7% improvement on the two regression tasks in LVUdataset. Furthermore, using a newly collected movie dataset, we presentcomparative results of our scene representation on a set of video moderationtasks to demonstrate its generalizability on previously less explored tasks.", "output": "Movies2Scenes: Using Movie Metadata to Learn Scene Representation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While ischemic stroke is a leading cause of death worldwide, there has beenlittle success translating putative cerebroprotectants from rodent preclinicaltrials to human patients. We investigated computational image-based assessmenttools for practical improvement of the quality, scalability, and outlook forlarge scale preclinical screening for potential therapeutic interventions inrodent models. We developed, evaluated, and deployed a pipeline for image-basedstroke outcome quantification for the Stroke Preclinical Assessment Network(SPAN), a multi-site, multi-arm, multi-stage study evaluating a suite ofcerebroprotectant interventions. Our fully automated pipeline combinesstate-of-the-art algorithmic and data analytic approaches to assess strokeoutcomes from multi-parameter MRI data collected longitudinally from a rodentmodel of middle cerebral artery occlusion (MCAO), including measures of infarctvolume, brain atrophy, midline shift, and data quality. We applied our approachto 1,368 scans and report population level results of lesion extent andlongitudinal changes from injury. We validated our system by comparison withboth manual annotations of coronal MRI slices and tissue sections from the samebrain, using crowdsourcing from blinded stroke experts from the network. Ourresults demonstrate the efficacy and robustness of our image-based strokeassessments. The pipeline may provide a promising resource for ongoing rodentpreclinical studies conducted by SPAN and other networks in the future.", "output": "Computational Image-based Stroke Assessment for Evaluation of Cerebroprotectants with Longitudinal and Multi-site Preclinical MRI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Powerful priors allow us to perform inference with insufficient information.In this paper, we propose an autoregressive prior for 3D shapes to solvemultimodal 3D tasks such as shape completion, reconstruction, and generation.We model the distribution over 3D shapes as a non-sequential autoregressivedistribution over a discretized, low-dimensional, symbolic grid-like latentrepresentation of 3D shapes. This enables us to represent distributions over 3Dshapes conditioned on information from an arbitrary set of spatially anchoredquery locations and thus perform shape completion in such arbitrary settings(e.g., generating a complete chair given only a view of the back leg). We alsoshow that the learned autoregressive prior can be leveraged for conditionaltasks such as single-view reconstruction and language-based generation. This isachieved by learning task-specific naive conditionals which can be approximatedby light-weight models trained on minimal paired data. We validate theeffectiveness of the proposed method using both quantitative and qualitativeevaluation and show that the proposed method outperforms the specializedstate-of-the-art methods trained for individual tasks. The project page withcode and video visualizations can be found at", "output": "AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-contrast magnetic resonance imaging (MRI) is widely used in clinicalpractice as each contrast provides complementary information. However, theavailability of each imaging contrast may vary amongst patients, which poseschallenges to radiologists and automated image analysis algorithms. A generalapproach for tackling this problem is missing data imputation, which aims tosynthesize the missing contrasts from existing ones. While severalconvolutional neural networks (CNN) based algorithms have been proposed, theysuffer from the fundamental limitations of CNN models, such as the requirementfor fixed numbers of input and output channels, the inability to capturelong-range dependencies, and the lack of interpretability. In this work, weformulate missing data imputation as a sequence-to-sequence learning problemand propose a multi-contrast multi-scale Transformer (MMT), which can take anysubset of input contrasts and synthesize those that are missing. MMT consistsof a multi-scale Transformer encoder that builds hierarchical representationsof inputs combined with a multi-scale Transformer decoder that generates theoutputs in a coarse-to-fine fashion. The proposed multi-contrast SwinTransformer blocks can efficiently capture intra- and inter-contrastdependencies for accurate image synthesis. Moreover, MMT is inherentlyinterpretable as it allows us to understand the importance of each inputcontrast in different regions by analyzing the in-built attention maps ofTransformer blocks in the decoder. Extensive experiments on two large-scalemulti-contrast MRI datasets demonstrate that MMT outperforms thestate-of-the-art methods quantitatively and qualitatively.", "output": "One Model to Synthesize Them All: Multi-contrast Multi-scale Transformer for Missing Data Imputation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Humans naturally change their environment through interactions, e.g., byopening doors or moving furniture. To reproduce such interactions in virtualspaces (e.g., metaverse), we need to capture and model them, including changesin the scene geometry, ideally from egocentric input alone (head camera andbody-worn inertial sensors). While the head camera can be used to localize theperson in the scene, estimating dynamic object pose is much more challenging.As the object is often not visible from the head camera (e.g., a human notlooking at a chair while sitting down), we can not rely on visual object poseestimation. Instead, our key observation is that human motion tells us a lotabout scene changes. Motivated by this, we present iReplica, the firsthuman-object interaction reasoning method which can track objects and scenechanges based solely on human motion. iReplica is an essential first steptowards advanced AR/VR applications in immersive virtual universes and canprovide human-centric training data to teach machines to interact with theirsurroundings. Our code, data and model will be available on our project page at<a href=\" http URL</a>", "output": "Interaction Replica: Tracking human-object interaction and scene changes from human motion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a new imaging technique, swept-angle synthetic wavelengthinterferometry, for full-field micron-scale 3D sensing. As in conventionalsynthetic wavelength interferometry, our technique uses light consisting of twonarrowly-separated optical wavelengths, resulting in per-pixel interferometricmeasurements whose phase encodes scene depth. Our technique additionally uses anew type of light source that, by emulating spatially-incoherent illumination,makes interferometric measurements insensitive to aberrations and (sub)surfacescattering, effects that corrupt phase measurements. The resulting techniquecombines the robustness to such corruptions of scanning interferometric setups,with the speed of full-field interferometric setups. Overall, our technique canrecover full-frame depth at a lateral and axial resolution of 5 microns, atframe rates of 5 Hz, even under strong ambient light. We build an experimentalprototype, and use it to demonstrate these capabilities by scanning a varietyof objects, including objects representative of applications in inspection andfabrication, and objects that contain challenging light scattering effects.", "output": "Swept-Angle Synthetic Wavelength Interferometry."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Modern image captioning models are usually trained with text similarityobjectives. However, since reference captions in public datasets often describethe most salient common objects, models trained with text similarity objectivestend to ignore specific and detailed aspects of an image that distinguish itfrom others. Toward more descriptive and distinctive caption generation, wepropose using CLIP, a multimodal encoder trained on huge image-text pairs fromweb, to calculate multimodal similarity and use it as a reward function. Wealso propose a simple finetuning strategy of the CLIP text encoder to improvegrammar that does not require extra text annotation. This completely eliminatesthe need for reference captions during the reward computation. Tocomprehensively evaluate descriptive captions, we introduce FineCapEval, a newdataset for caption evaluation with fine-grained criteria: overall, background,object, relations. In our experiments on text-to-image retrieval andFineCapEval, the proposed CLIP-guided model generates more distinctive captionsthan the CIDEr-optimized model. We also show that our unsupervised grammarfinetuning of the CLIP text encoder alleviates the degeneration problem of thenaive CLIP reward. Lastly, we show human analysis where the annotators stronglyprefer the CLIP reward to the CIDEr and MLE objectives according to variouscriteria. Code and Data: ", "output": "Fine-grained Image Captioning with CLIP Reward."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Combining multiple datasets enables performance boost on many computer visiontasks. But similar trend has not been witnessed in object detection whencombining multiple datasets due to two inconsistencies among detectiondatasets: taxonomy difference and domain gap. In this paper, we address thesechallenges by a new design (named Detection Hub) that is dataset-aware andcategory-aligned. It not only mitigates the dataset inconsistency but alsoprovides coherent guidance for the detector to learn across multiple datasets.In particular, the dataset-aware design is achieved by learning a datasetembedding that is used to adapt object queries as well as convolutional kernelsin detection heads. The categories across datasets are semantically alignedinto a unified space by replacing one-hot category representations with wordembedding and leveraging the semantic coherence of language embedding.Detection Hub fulfills the benefits of large data on object detection.Experiments demonstrate that joint training on multiple datasets achievessignificant performance gains over training on each dataset alone. DetectionHub further achieves SoTA performance on UODB benchmark with wide variety ofdatasets.", "output": "Detection Hub: Unifying Object Detection Datasets via Query Adaptation on Language Embedding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automated and semi-automated techniques in biomedical electron microscopy(EM) enable the acquisition of large datasets at a high rate. Segmentationmethods are therefore essential to analyze and interpret these large volumes ofdata, which can no longer completely be labeled manually. In recent years, deeplearning algorithms achieved impressive results in both pixel-level labeling(semantic segmentation) and the labeling of separate instances of the sameclass (instance segmentation). In this review, we examine how these algorithmswere adapted to the task of segmenting cellular and sub-cellular structures inEM images. The special challenges posed by such images and the networkarchitectures that overcame some of them are described. Moreover, a thoroughoverview is also provided on the notable datasets that contributed to theproliferation of deep learning in EM. Finally, an outlook of current trends andfuture prospects of EM segmentation is given, especially in the area oflabel-free learning.", "output": "Segmentation in large-scale cellular electron microscopy with deep learning: A literature survey."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-scale architectures and attention modules have shown effectiveness inmany deep learning-based image de-raining methods. However, manually designingand integrating these two components into a neural network requires a bulk oflabor and extensive expertise. In this article, a high-performance multi-scaleattentive neural architecture search (MANAS) framework is technically developedfor image deraining. The proposed method formulates a new multi-scale attentionsearch space with multiple flexible modules that are favorite to the imagede-raining task. Under the search space, multi-scale attentive cells are built,which are further used to construct a powerful image de-raining network. Theinternal multiscale attentive architecture of the de-raining network issearched automatically through a gradient-based search algorithm, which avoidsthe daunting procedure of the manual design to some extent. Moreover, in orderto obtain a robust image de-raining model, a practical and effectivemulti-to-one training strategy is also presented to allow the de-rainingnetwork to get sufficient background information from multiple rainy imageswith the same background scene, and meanwhile, multiple loss functionsincluding external loss, internal loss, architecture regularization loss, andmodel complexity loss are jointly optimized to achieve robust de-rainingperformance and controllable model complexity. Extensive experimental resultson both synthetic and realistic rainy images, as well as the down-stream visionapplications (i.e., objection detection and segmentation) consistentlydemonstrate the superiority of our proposed method. The code is publiclyavailable at ", "output": "Multi-scale Attentive Image De-raining Networks via Neural Architecture Search."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Universal domain adaptation (UniDA) aims to transfer the knowledge from alabeled source domain to an unlabeled target domain without any assumptions ofthe label sets, which requires distinguishing the unknown samples from theknown ones in the target domain. A main challenge of UniDA is that thenonidentical label sets cause the misalignment between the two domains.Moreover, the domain discrepancy and the supervised objectives in the sourcedomain easily lead the whole model to be biased towards the common classes andproduce overconfident predictions for unknown samples. To address the abovechallenging problems, we propose a new uncertainty-guided UniDA framework.Firstly, we introduce an empirical estimation of the probability of a targetsample belonging to the unknown class which fully exploits the distribution ofthe target samples in the latent space. Then, based on the estimation, wepropose a novel neighbors searching scheme in a linear subspace with a$delta$-filter to estimate the uncertainty score of a target sample anddiscover unknown samples. It fully utilizes the relationship between a targetsample and its neighbors in the source domain to avoid the influence of domainmisalignment. Secondly, this paper well balances the confidences of predictionsfor both known and unknown samples through an uncertainty-guided margin lossbased on the confidences of discovered unknown samples, which can reduce thegap between the intra-class variances of known classes with respect to theunknown class. Finally, experiments on three public datasets demonstrate thatour method significantly outperforms existing state-of-the-art methods.", "output": "Provably Uncertainty-Guided Universal Domain Adaptation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks (DNNs) have demonstrated their superiority in practice.Arguably, the rapid development of DNNs is largely benefited from high-quality(open-sourced) datasets, based on which researchers and developers can easilyevaluate and improve their learning methods. Since the data collection isusually time-consuming or even expensive, how to protect their copyrights is ofgreat significance and worth further exploration. In this paper, we revisitdataset ownership verification. We find that existing verification methodsintroduced new security risks in DNNs trained on the protected dataset, due tothe targeted nature of poison-only backdoor watermarks. To alleviate thisproblem, in this work, we explore the untargeted backdoor watermarking scheme,where the abnormal model behaviors are not deterministic. Specifically, weintroduce two dispersibilities and prove their correlation, based on which wedesign the untargeted backdoor watermark under both poisoned-label andclean-label settings. We also discuss how to use the proposed untargetedbackdoor watermark for dataset ownership verification. Experiments on benchmarkdatasets verify the effectiveness of our methods and their resistance toexisting backdoor defenses. Our codes are available aturl{", "output": "Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, self-supervised large-scale visual pre-training models have showngreat promise in representing pixel-level semantic relationships, significantlypromoting the development of unsupervised dense prediction tasks, e.g.,unsupervised semantic segmentation (USS). The extracted relationship amongpixel-level representations typically contains rich class-aware informationthat semantically identical pixel embeddings in the representation space gathertogether to form sophisticated concepts. However, leveraging the learned modelsto ascertain semantically consistent pixel groups or regions in the image isnon-trivial since over/ under-clustering overwhelms the conceptualizationprocedure under various semantic distributions of different images. In thiswork, we investigate the pixel-level semantic aggregation in self-supervisedViT pre-trained models as image Segmentation and propose the AdaptiveConceptualization approach for USS, termed ACSeg. Concretely, we explicitlyencode concepts into learnable prototypes and design the Adaptive ConceptGenerator (ACG), which adaptively maps these prototypes to informative conceptsfor each image. Meanwhile, considering the scene complexity of differentimages, we propose the modularity loss to optimize ACG independent of theconcept number based on estimating the intensity of pixel pairs belonging tothe same concept. Finally, we turn the USS task into classifying the discoveredconcepts in an unsupervised manner. Extensive experiments with state-of-the-artresults demonstrate the effectiveness of the proposed ACSeg.", "output": "ACSeg: Adaptive Conceptualization for Unsupervised Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Decoding human visual neural representations is a challenging task with greatscientific significance in revealing vision-processing mechanisms anddeveloping brain-like intelligent machines. Most existing methods are difficultto generalize to novel categories that have no corresponding neural data fortraining. The two main reasons are 1) the under-exploitation of the multimodalsemantic knowledge underlying the neural data and 2) the small number of paired(stimuli-responses) training data. To overcome these limitations, this paperpresents a generic neural decoding method called BraVL that uses multimodallearning of brain-visual-linguistic features. We focus on modeling therelationships between brain, visual and linguistic features via multimodal deepgenerative models. Specifically, we leverage the mixture-of-product-of-expertsformulation to infer a latent code that enables a coherent joint generation ofall three modalities. To learn a more consistent joint representation andimprove the data efficiency in the case of limited brain activity data, weexploit both intra- and inter-modality mutual information maximizationregularization terms. In particular, our BraVL model can be trained undervarious semi-supervised scenarios to incorporate the visual and textualfeatures obtained from the extra categories. Finally, we construct threetrimodal matching datasets, and the extensive experiments lead to someinteresting conclusions and cognitive insights: 1) decoding novel visualcategories from human brain activity is practically possible with goodaccuracy; 2) decoding models using the combination of visual and linguisticfeatures perform much better than those using either of them alone; 3) visualperception may be accompanied by linguistic influences to represent thesemantics of visual stimuli. Code and data: ", "output": "Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Domain adaptation framework of GANs has achieved great progress in recentyears as a main successful approach of training contemporary GANs in the caseof very limited training data. In this work, we significantly improve thisframework by proposing an extremely compact parameter space for fine-tuning thegenerator. We introduce a novel domain-modulation technique that allows tooptimize only 6 thousand-dimensional vector instead of 30 million weights ofStyleGAN2 to adapt to a target domain. We apply this parameterization to thestate-of-art domain adaptation methods and show that it has almost the sameexpressiveness as the full parameter space. Additionally, we propose a newregularization loss that considerably enhances the diversity of the fine-tunedgenerator. Inspired by the reduction in the size of the optimizing parameterspace we consider the problem of multi-domain adaptation of GANs, i.e. settingwhen the same model can adapt to several domains depending on the input query.We propose the HyperDomainNet that is a hypernetwork that predicts ourparameterization given the target domain. We empirically confirm that it cansuccessfully learn a number of domains at once and may even generalize tounseen domains. Source code can be found at", "output": "HyperDomainNet: Universal Domain Adaptation for Generative Adversarial Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing Visual Object Tracking (VOT) only takes the target area in the firstframe as a template. This causes tracking to inevitably fail in fast-changingand crowded scenes, as it cannot account for changes in object appearancebetween frames. To this end, we revamped the tracking framework withProgressive Context Encoding Transformer Tracker (ProContEXT), which coherentlyexploits spatial and temporal contexts to predict object motion trajectories.Specifically, ProContEXT leverages a context-aware self-attention module toencode the spatial and temporal context, refining and updating the multi-scalestatic and dynamic templates to progressively perform accurately tracking. Itexplores the complementary between spatial and temporal context, raising a newpathway to multi-context modeling for transformer-based trackers. In addition,ProContEXT revised the token pruning technique to reduce computationalcomplexity. Extensive experiments on popular benchmark datasets such as GOT-10kand TrackingNet demonstrate that the proposed ProContEXT achievesstate-of-the-art performance.", "output": "ProContEXT: Exploring Progressive Context Transformer for Tracking."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Streaming perception is a critical task in autonomous driving that requiresbalancing the latency and accuracy of the autopilot system. However, currentmethods for streaming perception are limited as they only rely on the currentand adjacent two frames to learn movement patterns. This restricts theirability to model complex scenes, often resulting in poor detection results. Toaddress this limitation, we propose LongShortNet, a novel dual-path networkthat captures long-term temporal motion and integrates it with short-termspatial semantics for real-time perception. LongShortNet is notable as it isthe first work to extend long-term temporal modeling to streaming perception,enabling spatiotemporal feature fusion. We evaluate LongShortNet on thechallenging Argoverse-HD dataset and demonstrate that it outperforms existingstate-of-the-art methods with almost no additional computational cost.", "output": "LongShortNet: Exploring Temporal and Semantic Features Fusion in Streaming Perception."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The prediction of pancreatic ductal adenocarcinoma therapy response is aclinically challenging and important task in this high-mortality tumour entity.The training of neural networks able to tackle this challenge is impeded by alack of large datasets and the difficult anatomical localisation of thepancreas. Here, we propose a hybrid deep neural network pipeline to predicttumour response to initial chemotherapy which is based on the ResponseEvaluation Criteria in Solid Tumors (RECIST) score, a standardised method forcancer response evaluation by clinicians as well as tumour markers, andclinical evaluation of the patients. We leverage a combination ofrepresentation transfer from segmentation to classification, as well aslocalisation and representation learning. Our approach yields a remarkablydata-efficient method able to predict treatment response with a ROC-AUC of63.7% using only 477 datasets in total.", "output": "Exploiting segmentation labels and representation learning to forecast therapy response of PDAC patients."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Archaeology is an intriguing domain for computer vision. It suffers not onlyfrom shortage in (labeled) data, but also from highly-challenging data, whichis often extremely abraded and damaged. This paper proposes a novelsemi-supervised model for classification and retrieval of images ofarchaeological artifacts. This model utilizes unique data that exists in thedomain -- manual drawings made by special artists. These are used duringtraining to implicitly transfer the domain knowledge from the drawings to theircorresponding images, improving their classification results. We show thatwhile learning how to classify, our model also learns how to generate drawingsof the artifacts, an important documentation task, which is currently performedmanually. Last but not least, we collected a new dataset of stamp-seals of theSouthern Levant. The dataset and the code will be released upon acceptance.", "output": "ArcAid: Analysis of Archaeological Artifacts using Drawings."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, large-scale pre-trained Vision-and-Language (VL) foundation modelshave demonstrated remarkable capabilities in many zero-shot downstream tasks,achieving competitive results for recognizing objects defined by as little asshort text prompts. However, it has also been shown that VL models are stillbrittle in Structured VL Concept (SVLC) reasoning, such as the ability torecognize object attributes, states, and inter-object relations. This leads toreasoning mistakes, which need to be corrected as they occur by teaching VLmodels the missing SVLC skills; often this must be done using private datawhere the issue was found, which naturally leads to a data-free continual (notask-id) VL learning setting. In this work, we introduce the first ContinualData-Free Structured VL Concepts Learning (ConStruct-VL) benchmark and show itis challenging for many existing data-free CL strategies. We, therefore,propose a data-free method comprised of a new approach of AdversarialPseudo-Replay (APR) which generates adversarial reminders of past tasks frompast task models. To use this method efficiently, we also propose a continualparameter-efficient Layered-LoRA (LaLo) neural architecture allowingno-memory-cost access to all past models at train time. We show this approachoutperforms all data-free methods by as much as ~7% while even matching somelevels of experience-replay (prohibitive for applications where data-privacymust be preserved). Our code is publicly available at", "output": "ConStruct-VL: Data-Free Continual Structured VL Concepts Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Video-based gait recognition has achieved impressive results in constrainedscenarios. However, visual cameras neglect human 3D structure information,which limits the feasibility of gait recognition in the 3D wild world. Insteadof extracting gait features from images, this work explores precise 3D gaitfeatures from point clouds and proposes a simple yet efficient 3D gaitrecognition framework, termed LidarGait. Our proposed approach projects sparsepoint clouds into depth maps to learn the representations with 3D geometryinformation, which outperforms existing point-wise and camera-based methods bya significant margin. Due to the lack of point cloud datasets, we built thefirst large-scale LiDAR-based gait recognition dataset, SUSTech1K, collected bya LiDAR sensor and an RGB camera. The dataset contains 25,239 sequences from1,050 subjects and covers many variations, including visibility, views,occlusions, clothing, carrying, and scenes. Extensive experiments show that (1)3D structure information serves as a significant feature for gait recognition.(2) LidarGait outperforms existing point-based and silhouette-based methods bya significant margin, while it also offers stable cross-view results. (3) TheLiDAR sensor is superior to the RGB camera for gait recognition in the outdoorenvironment. The source code and dataset have been made available at", "output": "LidarGait: Benchmarking 3D Gait Recognition with Point Clouds."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Because anomalous samples cannot be used for training, many anomaly detectionand localization methods use pre-trained networks and non-parametric modelingto estimate encoded feature distribution. However, these methods neglect theimpact of position and neighborhood information on the distribution of normalfeatures. To overcome this, we propose a new algorithm, textbf{PNI}, whichestimates the normal distribution using conditional probability givenneighborhood features, modeled with a multi-layer perceptron network. Moreover,position information is utilized by creating a histogram of representativefeatures at each position. Instead of simply resizing the anomaly map, theproposed method employs an additional refine network trained on syntheticanomaly images to better interpolate and account for the shape and edge of theinput image. We conducted experiments on the MVTec AD benchmark dataset andachieved state-of-the-art performance, with textbf{99.56%} andtextbf{98.98%} AUROC scores in anomaly detection and localization,respectively.", "output": "PNI : Industrial Anomaly Detection using Position and Neighborhood Information."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Computer vision models suffer from a phenomenon known as catastrophicforgetting when learning novel concepts from continuously shifting trainingdata. Typical solutions for this continual learning problem require extensiverehearsal of previously seen data, which increases memory costs and may violatedata privacy. Recently, the emergence of large-scale pre-trained visiontransformer models has enabled prompting approaches as an alternative todata-rehearsal. These approaches rely on a key-query mechanism to generateprompts and have been found to be highly resistant to catastrophic forgettingin the well-established rehearsal-free continual learning setting. However, thekey mechanism of these methods is not trained end-to-end with the tasksequence. Our experiments show that this leads to a reduction in theirplasticity, hence sacrificing new task accuracy, and inability to benefit fromexpanded parameter capacity. We instead propose to learn a set of promptcomponents which are assembled with input-conditioned weights to produceinput-conditioned prompts, resulting in a novel attention-based end-to-endkey-query scheme. Our experiments show that we outperform the current SOTAmethod DualPrompt on established benchmarks by as much as 4.5% in average finalaccuracy. We also outperform the state of art by as much as 4.4% accuracy on acontinual learning benchmark which contains both class-incremental anddomain-incremental task shifts, corresponding to many practical settings. Ourcode is available at ", "output": "CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Standard multi-modal models assume the use of the same modalities in trainingand inference stages. However, in practice, the environment in whichmulti-modal models operate may not satisfy such assumption. As such, theirperformances degrade drastically if any modality is missing in the inferencestage. We ask: how can we train a model that is robust to missing modalities?This paper seeks a set of good practices for multi-modal action recognition,with a particular interest in circumstances where some modalities are notavailable at an inference time. First, we study how to effectively regularizethe model during training (e.g., data augmentation). Second, we investigate onfusion methods for robustness to missing modalities: we find thattransformer-based fusion shows better robustness for missing modality thansummation or concatenation. Third, we propose a simple modular network,ActionMAE, which learns missing modality predictive coding by randomly droppingmodality features and tries to reconstruct them with the remaining modalityfeatures. Coupling these good practices, we build a model that is not onlyeffective in multi-modal action recognition but also robust to modalitymissing. Our model achieves the state-of-the-arts on multiple benchmarks andmaintains competitive performances even in missing modality scenarios. Codesare available at ", "output": "Towards Good Practices for Missing Modality Robust Action Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present Fast Language-Image Pre-training (FLIP), a simple and moreefficient method for training CLIP. Our method randomly masks out and removes alarge portion of image patches during training. Masking allows us to learn frommore image-text pairs given the same wall-clock time and contrast more samplesper iteration with similar memory footprint. It leads to a favorable trade-offbetween accuracy and training time. In our experiments on 400 millionimage-text pairs, FLIP improves both accuracy and speed over the no-maskingbaseline. On a large diversity of downstream tasks, FLIP dominantly outperformsthe CLIP counterparts trained on the same data. Facilitated by the speedup, weexplore the scaling behavior of increasing the model size, data size, ortraining length, and report encouraging results and comparisons. We hope thatour work will foster future research on scaling vision-language learning.", "output": "Scaling Language-Image Pre-training via Masking."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Tracking objects over long videos effectively means solving a spectrum ofproblems, from short-term association for un-occluded objects to long-termassociation for objects that are occluded and then reappear in the scene.Methods tackling these two tasks are often disjoint and crafted for specificscenarios, and top-performing approaches are often a mix of techniques, whichyields engineering-heavy solutions that lack generality. In this work, wequestion the need for hybrid approaches and introduce SUSHI, a unified andscalable multi-object tracker. Our approach processes long clips by splittingthem into a hierarchy of subclips, which enables high scalability. We leveragegraph neural networks to process all levels of the hierarchy, which makes ourmodel unified across temporal scales and highly general. As a result, we obtainsignificant improvements over state-of-the-art on four diverse datasets. Ourcode and models are available at bit.ly/sushi-mot.", "output": "Unifying Short and Long-Term Tracking with Graph Hierarchies."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study focuses on using large language models (LLMs) as a planner forembodied agents that can follow natural language instructions to completecomplex tasks in a visually-perceived environment. The high data cost and poorsample efficiency of existing methods hinders the development of versatileagents that are capable of many tasks and can learn new tasks quickly. In thiswork, we propose a novel method, LLM-Planner, that harnesses the power of largelanguage models to do few-shot planning for embodied agents. We further proposea simple but effective way to enhance LLMs with physical grounding to generateand update plans that are grounded in the current environment. Experiments onthe ALFRED dataset show that our method can achieve very competitive few-shotperformance: Despite using less than 0.5% of paired training data, LLM-Plannerachieves competitive performance with recent baselines that are trained usingthe full training data. Existing methods can barely complete any tasksuccessfully under the same few-shot setting. Our work opens the door fordeveloping versatile and sample-efficient embodied agents that can quicklylearn many tasks. Website: ", "output": "LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "FSS(Few-shot segmentation) aims to segment a target class using a smallnumber of labeled images (support set). To extract the information relevant totarget class, a dominant approach in best performing FSS methods removesbackground features using a support mask. We observe that this feature excisionthrough a limiting support mask introduces an information bottleneck in severalchallenging FSS cases, e.g., for small targets and/or inaccurate targetboundaries. To this end, we present a novel method (MSI), which maximizes thesupport-set information by exploiting two complementary sources of features togenerate super correlation maps. We validate the effectiveness of our approachby instantiating it into three recent and strong FSS methods. Experimentalresults on several publicly available FSS benchmarks show that our proposedmethod consistently improves the performance by visible margins and leads tofaster convergence. Our code and models will be publicly released.", "output": "MSI: Maximize Support-Set Information for Few-Shot Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The recognition capabilities of current state-of-the-art 3D models arelimited by datasets with a small number of annotated data and a pre-defined setof categories. In its 2D counterpart, recent advances have shown that similarproblems can be significantly alleviated by employing knowledge from othermodalities, such as language. Inspired by this, leveraging multimodalinformation for 3D modality could be promising to improve 3D understandingunder the restricted data regime, but this line of research is not wellstudied. Therefore, we introduce ULIP to learn a unified representation ofimage, text, and 3D point cloud by pre-training with object triplets from thethree modalities. To overcome the shortage of training triplets, ULIP leveragesa pre-trained vision-language model that has already learned a common visualand textual space by training with massive image-text pairs. Then, ULIP learnsa 3D representation space aligned with the common image-text space, using asmall number of automatically synthesized triplets. ULIP is agnostic to 3Dbackbone networks and can easily be integrated into any 3D architecture.Experiments show that ULIP effectively improves the performance of multiplerecent 3D backbones by simply pre-training them on ShapeNet55 using ourframework, achieving state-of-the-art performance in both standard 3Dclassification and zero-shot 3D classification on ModelNet40 and ScanObjectNN.ULIP also improves the performance of PointMLP by around 3% in 3Dclassification on ScanObjectNN, and outperforms PointCLIP by 28.8% on top-1accuracy for zero-shot 3D classification on ModelNet40. Our code andpre-trained models are released at ", "output": "ULIP: Learning a Unified Representation of Language, Images, and Point Clouds for 3D Understanding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image-based head swapping task aims to stitch a source head to another sourcebody flawlessly. This seldom-studied task faces two major challenges: 1)Preserving the head and body from various sources while generating a seamlesstransition region. 2) No paired head swapping dataset and benchmark so far. Inthis paper, we propose a semantic-mixing diffusion model for head swapping(HS-Diffusion) which consists of a latent diffusion model (LDM) and a semanticlayout generator. We blend the semantic layouts of source head and source body,and then inpaint the transition region by the semantic layout generator,achieving a coarse-grained head swapping. Semantic-mixing LDM can furtherimplement a fine-grained head swapping with the inpainted layout as conditionby a progressive fusion process, while preserving head and body withhigh-quality reconstruction. To this end, we propose a semantic calibrationstrategy for natural inpainting and a neck alignment for geometric realism.Importantly, we construct a new image-based head swapping benchmark and designtwo tailor-designed metrics (Mask-FID and Focal-FID). Extensive experimentsdemonstrate the superiority of our framework. The code will be available:", "output": "HS-Diffusion: Learning a Semantic-Mixing Diffusion Model for Head Swapping."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Problem: Detecting COVID-19 from chest X-Ray (CXR) images has become one ofthe fastest and easiest methods for detecting COVID-19. However, the existingmethods usually use supervised transfer learning from natural images as apretraining process. These methods do not consider the unique features ofCOVID-19 and the similar features between COVID-19 and other pneumonia. Aim: Inthis paper, we want to design a novel high-accuracy COVID-19 detection methodthat uses CXR images, which can consider the unique features of COVID-19 andthe similar features between COVID-19 and other pneumonia. Methods: Our methodconsists of two phases. One is self-supervised learning-based pertaining; theother is batch knowledge ensembling-based fine-tuning. Self-supervisedlearning-based pretraining can learn distinguished representations from CXRimages without manually annotated labels. On the other hand, batch knowledgeensembling-based fine-tuning can utilize category knowledge of images in abatch according to their visual feature similarities to improve detectionperformance. Unlike our previous implementation, we introduce batch knowledgeensembling into the fine-tuning phase, reducing the memory used inself-supervised learning and improving COVID-19 detection accuracy. Results: Ontwo public COVID-19 CXR datasets, namely, a large dataset and an unbalanceddataset, our method exhibited promising COVID-19 detection performance. Ourmethod maintains high detection accuracy even when annotated CXR trainingimages are reduced significantly (e.g., using only 10% of the originaldataset). In addition, our method is insensitive to changes in hyperparameters.", "output": "Boosting Automatic COVID-19 Detection Performance with Self-Supervised Learning and Batch Knowledge Ensembling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Lane detection is a long-standing task and a basic module in autonomousdriving. The task is to detect the lane of the current driving road, andprovide relevant information such as the ID, direction, curvature, width,length, with visualization. Our work is based on CNN backbone DLA-34, alongwith Affinity Fields, aims to achieve robust detection of various lanes withoutassuming the number of lanes. Besides, we investigate novel decoding methods toachieve more efficient lane detection algorithm.", "output": "Multi Lane Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Video representation learning has been successful in video-text pre-trainingfor zero-shot transfer, where each sentence is trained to be close to thepaired video clips in a common feature space. For long videos, given aparagraph of description where the sentences describe different segments of thevideo, by matching all sentence-clip pairs, the paragraph and the full videoare aligned implicitly. However, such unit-level comparison may ignore globaltemporal context, which inevitably limits the generalization ability. In thispaper, we propose a contrastive learning framework TempCLR to compare the fullvideo and the paragraph explicitly. As the video/paragraph is formulated as asequence of clips/sentences, under the constraint of their temporal order, weuse dynamic time warping to compute the minimum cumulative cost oversentence-clip pairs as the sequence-level distance. To explore the temporaldynamics, we break the consistency of temporal succession by shuffling videoclips w.r.t. temporal granularity. Then, we obtain the representations forclips/sentences, which perceive the temporal information and thus facilitatethe sequence alignment. In addition to pre-training on the video and paragraph,our approach can also generalize on the matching between video instances. Weevaluate our approach on video retrieval, action step localization, andfew-shot action recognition, and achieve consistent performance gain over allthree tasks. Detailed ablation studies are provided to justify the approachdesign.", "output": "TempCLR: Temporal Alignment Representation with Contrastive Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "By optimizing the rate-distortion-realism trade-off, generative compressionapproaches produce detailed, realistic images, even at low bit rates, insteadof the blurry reconstructions produced by rate-distortion optimized models.However, previous methods do not explicitly control how much detail issynthesized, which results in a common criticism of these methods: users mightbe worried that a misleading reconstruction far from the input image isgenerated. In this work, we alleviate these concerns by training a decoder thatcan bridge the two regimes and navigate the distortion-realism trade-off. Froma single compressed representation, the receiver can decide to eitherreconstruct a low mean squared error reconstruction that is close to the input,a realistic reconstruction with high perceptual quality, or anything inbetween. With our method, we set a new state-of-the-art in distortion-realism,pushing the frontier of achievable distortion-realism pairs, i.e., our methodachieves better distortions at high realism and better realism at lowdistortion than ever before.", "output": "Multi-Realism Image Compression with a Conditional Generator."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision-language models trained with contrastive learning on large-scale noisydata are becoming increasingly popular for zero-shot recognition problems. Inthis paper we improve the following three aspects of the contrastivepre-training pipeline: dataset noise, model initialization and the trainingobjective. First, we propose a straightforward filtering strategy titledComplexity, Action, and Text-spotting (CAT) that significantly reduces datasetsize, while achieving improved performance across zero-shot vision-languagetasks. Next, we propose an approach titled Concept Distillation to leveragestrong unimodal representations for contrastive training that does not increasetraining complexity while outperforming prior work. Finally, we modify thetraditional contrastive alignment objective, and propose an importance-samplingapproach to up-sample the importance of hard-negatives without addingadditional complexity. On an extensive zero-shot benchmark of 29 tasks, ourDistilled and Hard-negative Training (DiHT) approach improves on 20 taskscompared to the baseline. Furthermore, for few-shot linear probing, we proposea novel approach that bridges the gap between zero-shot and few-shotperformance, substantially improving over prior work. Models are available at", "output": "Filtering, Distillation, and Hard Negatives for Vision-Language Pre-Training."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Human-robot co-manipulation of soft materials, such as fabrics, composites,and sheets of paper/cardboard, is a challenging operation that presents severalrelevant industrial applications. Estimating the deformation state of theco-manipulated material is one of the main challenges. Viable methods providethe indirect measure by calculating the human-robot relative distance. In thispaper, we develop a data-driven model to estimate the deformation state of thematerial from a depth image through a Convolutional Neural Network (CNN).First, we define the deformation state of the material as the relativeroto-translation from the current robot pose and a human grasping position. Themodel estimates the current deformation state through a Convolutional NeuralNetwork, specifically a DenseNet-121 pretrained on ImageNet.The delta betweenthe current and the desired deformation state is fed to the robot controllerthat outputs twist commands. The paper describes the developed approach toacquire, preprocess the dataset and train the model. The model is compared withthe current state-of-the-art method based on a skeletal tracker from cameras.Results show that our approach achieves better performances and avoids thevarious drawbacks caused by using a skeletal tracker.Finally, we also studiedthe model performance according to different architectures and datasetdimensions to minimize the time required for dataset acquisition", "output": "Co-manipulation of soft-materials estimating deformation from depth images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transformer, as an alternative to CNN, has been proven effective in manymodalities (e.g., texts and images). For 3D point cloud transformers, existingefforts focus primarily on pushing their accuracy to the state-of-the-artlevel. However, their latency lags behind sparse convolution-based models (3xslower), hindering their usage in resource-constrained, latency-sensitiveapplications (such as autonomous driving). This inefficiency comes from pointclouds' sparse and irregular nature, whereas transformers are designed fordense, regular workloads. This paper presents FlatFormer to close this latencygap by trading spatial proximity for better computational regularity. We firstflatten the point cloud with window-based sorting and partition points intogroups of equal sizes rather than windows of equal shapes. This effectivelyavoids expensive structuring and padding overheads. We then applyself-attention within groups to extract local features, alternate sorting axisto gather features from different directions, and shift windows to exchangefeatures across groups. FlatFormer delivers state-of-the-art accuracy on WaymoOpen Dataset with 4.6x speedup over (transformer-based) SST and 1.4x speedupover (sparse convolutional) CenterPoint. This is the first point cloudtransformer that achieves real-time performance on edge GPUs and is faster thansparse convolutional methods while achieving on-par or even superior accuracyon large-scale benchmarks.", "output": "FlatFormer: Flattened Window Attention for Efficient Point Cloud Transformer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The interpretation of facial emotions plays a crucial role in humancommunication, allowing people to recognize emotions such as happiness,sadness, and anger through facial expressions and vocal tones. Facial EmotionRecognition (FER) is an area of great interest in computer vision and AI, withextensive academic and commercial potential, including security, advertising,and entertainment. We present a FER framework based on Swin vision Transformers(SwinT) and squeeze and excitation block (SE), which utilizes a transformermodel with an attention mechanism to address vision tasks. Our approach uses avision transformer with SE and a sharpness-aware minimizer (SAM), astransformers typically require substantial data to be as efficient as othercompetitive models. Our challenge was to create a good FER model based on theSwinT configuration with the ability to detect facial emotions using a smallamount of data. We used a hybrid dataset to train our model and evaluated itsperformance on the AffectNet dataset, achieving an F1-score of 0.5420. Ourmodel outperformed the winner of the (ABAW) Competition, which was held inconjunction with the European Conference on Computer Vision (ECCV) 2022", "output": "Facial Expression Recognition using Squeeze and Excitation-powered Swin Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite the remarkable progress in deep generative models, synthesizinghigh-resolution and temporally coherent videos still remains a challenge due totheir high-dimensionality and complex temporal dynamics along with largespatial variations. Recent works on diffusion models have shown their potentialto solve this challenge, yet they suffer from severe computation- andmemory-inefficiency that limit the scalability. To handle this issue, wepropose a novel generative model for videos, coined projected latent videodiffusion models (PVDM), a probabilistic diffusion model which learns a videodistribution in a low-dimensional latent space and thus can be efficientlytrained with high-resolution videos under limited resources. Specifically, PVDMis composed of two components: (a) an autoencoder that projects a given videoas 2D-shaped latent vectors that factorize the complex cubic structure of videopixels and (b) a diffusion model architecture specialized for our newfactorized latent space and the training/sampling procedure to synthesizevideos of arbitrary length with a single model. Experiments on popular videogeneration datasets demonstrate the superiority of PVDM compared with previousvideo synthesis methods; e.g., PVDM obtains the FVD score of 639.7 on theUCF-101 long video (128 frames) generation benchmark, which improves 1773.4 ofthe prior state-of-the-art.", "output": "Video Probabilistic Diffusion Models in Projected Latent Space."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Object detection with on-board sensors (e.g., lidar, radar, and camera) playa crucial role in autonomous driving (AD), and these sensors complement eachother in modalities. While crowdsensing may potentially exploit these sensors(of huge quantity) to derive more comprehensive knowledge, textit{federatedlearning} (FL) appears to be the necessary tool to reach this potential: itenables autonomous vehicles (AVs) to train machine learning models withoutexplicitly sharing raw sensory data. However, the multimodal sensors introducevarious data heterogeneity across distributed AVs (e.g., label quantity skewsand varied modalities), posing critical challenges to effective FL. To thisend, we present AutoFed as a heterogeneity-aware FL framework to fully exploitmultimodal sensory data on AVs and thus enable robust AD. Specifically, wefirst propose a novel model leveraging pseudo-labeling to avoid mistakenlytreating unlabeled objects as the background. We also propose anautoencoder-based data imputation method to fill missing data modality (ofcertain AVs) with the available ones. To further reconcile the heterogeneity,we finally present a client selection mechanism exploiting the similaritiesamong client models to improve both training stability and convergence rate.Our experiments on benchmark dataset confirm that AutoFed substantiallyimproves over status quo approaches in both precision and recall, whiledemonstrating strong robustness to adverse weather conditions.", "output": "AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Whole slide image (WSI) has been widely used to assist automated diagnosisunder the deep learning fields. However, most previous works only discuss theSINGLE task setting which is not aligned with real clinical setting, wherepathologists often conduct multiple diagnosis tasks simultaneously. Also, it iscommonly recognized that the multi-task learning paradigm can improve learningefficiency by exploiting commonalities and differences across multiple tasks.To this end, we present a novel multi-task framework (i.e., MulGT) for WSIanalysis by the specially designed Graph-Transformer equipped with Task-awareKnowledge Injection and Domain Knowledge-driven Graph Pooling modules.Basically, with the Graph Neural Network and Transformer as the buildingcommons, our framework is able to learn task-agnostic low-level localinformation as well as task-specific high-level global representation.Considering that different tasks in WSI analysis depend on different featuresand properties, we also design a novel Task-aware Knowledge Injection module totransfer the task-shared graph embedding into task-specific feature spaces tolearn more accurate representation for different tasks. Further, we elaboratelydesign a novel Domain Knowledge-driven Graph Pooling module for each task toimprove both the accuracy and robustness of different tasks by leveragingdifferent diagnosis patterns of multiple tasks. We evaluated our method on twopublic WSI datasets from TCGA projects, i.e., esophageal carcinoma and kidneycarcinoma. Experimental results show that our method outperforms single-taskcounterparts and the state-of-theart methods on both tumor typing and stagingtasks.", "output": "MulGT: Multi-task Graph-Transformer with Task-aware Knowledge Injection and Domain Knowledge-driven Pooling for Whole Slide Image Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent years have shown an increased development of methods for justifyingthe predictions of neural networks through visual explanations. Theseexplanations usually take the form of heatmaps which assign a saliency (orrelevance) value to each pixel of the input image that expresses how relevantthe pixel is for the prediction of a label.Complementing this development, evaluation methods have been proposed toassess the \"goodness\" of such explanations. On the one hand, some of thesemethods rely on synthetic datasets. However, this introduces the weakness ofhaving limited guarantees regarding their applicability on more realisticsettings. On the other hand, some methods rely on metrics for objectiveevaluation. However the level to which some of these evaluation methods performwith respect to each other is uncertain.Taking this into account, we conduct a comprehensive study on a subset of theImageNet-1k validation set where we evaluate a number of differentcommonly-used explanation methods following a set of evaluation methods. Wecomplement our study with sanity checks on the studied evaluation methods as ameans to investigate their reliability and the impact of characteristics of theexplanations on the evaluation methods.Results of our study suggest that there is a lack of coherency on the gradingprovided by some of the considered evaluation methods. Moreover, we haveidentified some characteristics of the explanations, e.g. sparsity, which canhave a significant effect on the performance.", "output": "On The Coherence of Quantitative Evaluation of Visual Explanations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Selective experience replay is a popular strategy for integrating lifelonglearning with deep reinforcement learning. Selective experience replay aims torecount selected experiences from previous tasks to avoid catastrophicforgetting. Furthermore, selective experience replay based techniques are modelagnostic and allow experiences to be shared across different models. However,storing experiences from all previous tasks make lifelong learning usingselective experience replay computationally very expensive and impractical asthe number of tasks increase. To that end, we propose a rewarddistribution-preserving coreset compression technique for compressingexperience replay buffers stored for selective experience replay.We evaluated the coreset compression technique on the brain tumorsegmentation (BRATS) dataset for the task of ventricle localization and on thewhole-body MRI for localization of left knee cap, left kidney, righttrochanter, left lung, and spleen. The coreset lifelong learning models trainedon a sequence of 10 different brain MR imaging environments demonstratedexcellent performance localizing the ventricle with a mean pixel error distanceof 12.93 for the compression ratio of 10x. In comparison, the conventionallifelong learning model localized the ventricle with a mean pixel distance of10.87. Similarly, the coreset lifelong learning models trained on whole-bodyMRI demonstrated no significant difference (p=0.28) between the 10x compressedcoreset lifelong learning models and conventional lifelong learning models forall the landmarks. The mean pixel distance for the 10x compressed models acrossall the landmarks was 25.30, compared to 19.24 for the conventional lifelonglearning models. Our results demonstrate that the potential of thecoreset-based ERB compression method for compressing experiences without asignificant drop in performance.", "output": "Selective experience replay compression using coresets for lifelong deep reinforcement learning in medical imaging."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Masked Autoencoders (MAE) have shown promising performance in self-supervisedlearning for both 2D and 3D computer vision. However, existing MAE-stylemethods can only learn from the data of a single modality, i.e., either imagesor point clouds, which neglect the implicit semantic and geometric correlationbetween 2D and 3D. In this paper, we explore how the 2D modality can benefit 3Dmasked autoencoding, and propose Joint-MAE, a 2D-3D joint MAE framework forself-supervised 3D point cloud pre-training. Joint-MAE randomly masks an input3D point cloud and its projected 2D images, and then reconstructs the maskedinformation of the two modalities. For better cross-modal interaction, weconstruct our JointMAE by two hierarchical 2D-3D embedding modules, a jointencoder, and a joint decoder with modal-shared and model-specific decoders. Ontop of this, we further introduce two cross-modal strategies to boost the 3Drepresentation learning, which are local-aligned attention mechanisms for 2D-3Dsemantic cues, and a cross-reconstruction loss for 2D-3D geometric constraints.By our pre-training paradigm, Joint-MAE achieves superior performance onmultiple downstream tasks, e.g., 92.4% accuracy for linear SVM on ModelNet40and 86.07% accuracy on the hardest split of ScanObjectNN.", "output": "Joint-MAE: 2D-3D Joint Masked Autoencoders for 3D Point Cloud Pre-training."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present DejaVu, a novel framework which leverages conditional imageregeneration as additional supervision during training to improve deep networksfor dense prediction tasks such as segmentation, depth estimation, and surfacenormal prediction. First, we apply redaction to the input image, which removescertain structural information by sparse sampling or selective frequencyremoval. Next, we use a conditional regenerator, which takes the redacted imageand the dense predictions as inputs, and reconstructs the original image byfilling in the missing structural information. In the redacted image,structural attributes like boundaries are broken while semantic context islargely preserved. In order to make the regeneration feasible, the conditionalgenerator will then require the structure information from the other inputsource, i.e., the dense predictions. As such, by including this conditionalregeneration objective during training, DejaVu encourages the base network tolearn to embed accurate scene structure in its dense prediction. This leads tomore accurate predictions with clearer boundaries and better spatialconsistency. When it is feasible to leverage additional computation, DejaVu canbe extended to incorporate an attention-based regeneration module within thedense prediction network, which further improves accuracy. Through extensiveexperiments on multiple dense prediction benchmarks such as Cityscapes, COCO,ADE20K, NYUD-v2, and KITTI, we demonstrate the efficacy of employing DejaVuduring training, as it outperforms SOTA methods at no added computation cost.", "output": "DejaVu: Conditional Regenerative Learning to Enhance Dense Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Artificial intelligence-based methods have generated substantial interest innuclear medicine. An area of significant interest has been using deep-learning(DL)-based approaches for denoising images acquired with lower doses, shorteracquisition times, or both. Objective evaluation of these approaches isessential for clinical application. DL-based approaches for denoisingnuclear-medicine images have typically been evaluated using fidelity-basedfigures of merit (FoMs) such as RMSE and SSIM. However, these images areacquired for clinical tasks and thus should be evaluated based on theirperformance in these tasks. Our objectives were to (1) investigate whetherevaluation with these FoMs is consistent with objective clinical-task-basedevaluation; (2) provide a theoretical analysis for determining the impact ofdenoising on signal-detection tasks; (3) demonstrate the utility of virtualclinical trials (VCTs) to evaluate DL-based methods. A VCT to evaluate aDL-based method for denoising myocardial perfusion SPECT (MPS) images wasconducted. The impact of DL-based denoising was evaluated using fidelity-basedFoMs and AUC, which quantified performance on detecting perfusion defects inMPS images as obtained using a model observer with anthropomorphic channels.Based on fidelity-based FoMs, denoising using the considered DL-based methodled to significantly superior performance. However, based on ROC analysis,denoising did not improve, and in fact, often degraded detection-taskperformance. The results motivate the need for objective task-based evaluationof DL-based denoising approaches. Further, this study shows how VCTs provide amechanism to conduct such evaluations using VCTs. Finally, our theoreticaltreatment reveals insights into the reasons for the limited performance of thedenoising approach.", "output": "Need for Objective Task-based Evaluation of Deep Learning-Based Denoising Methods: A Study in the Context of Myocardial Perfusion SPECT."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Human pose and shape (HPS) estimation methods achieve remarkable results.However, current HPS benchmarks are mostly designed to test models in scenariosthat are similar to the training data. This can lead to critical situations inreal-world applications when the observed data differs significantly from thetraining data and hence is out-of-distribution (OOD). It is therefore importantto test and improve the OOD robustness of HPS methods. To address thisfundamental problem, we develop a simulator that can be controlled in afine-grained manner using interpretable parameters to explore the manifold ofimages of human pose, e.g. by varying poses, shapes, and clothes. We introducea learning-based testing method, termed PoseExaminer, that automaticallydiagnoses HPS algorithms by searching over the parameter space of human poseimages to find the failure modes. Our strategy for exploring thishigh-dimensional parameter space is a multi-agent reinforcement learningsystem, in which the agents collaborate to explore different parts of theparameter space. We show that our PoseExaminer discovers a variety oflimitations in current state-of-the-art models that are relevant in real-worldscenarios but are missed by current benchmarks. For example, it finds largeregions of realistic human poses that are not predicted correctly, as well asreduced performance for humans with skinny and corpulent body shapes. Inaddition, we show that fine-tuning HPS methods by exploiting the failure modesfound by PoseExaminer improve their robustness and even their performance onstandard benchmarks by a significant margin. The code are available forresearch purposes.", "output": "PoseExaminer: Automated Testing of Out-of-Distribution Robustness in Human Pose and Shape Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "No-reference video quality assessment (NR-VQA) for user generated content(UGC) is crucial for understanding and improving visual experience. Unlikevideo recognition tasks, VQA tasks are sensitive to changes in inputresolution. Since large amounts of UGC videos nowadays are 720p or above, thefixed and relatively small input used in conventional NR-VQA methods results inmissing high-frequency details for many videos. In this paper, we propose anovel Transformer-based NR-VQA framework that preserves the high-resolutionquality information. With the multi-resolution input representation and a novelmulti-resolution patch sampling mechanism, our method enables a comprehensiveview of both the global video composition and local high-resolution details.The proposed approach can effectively aggregate quality information acrossdifferent granularities in spatial and temporal dimensions, making the modelrobust to input resolution variations. Our method achieves state-of-the-artperformance on large-scale UGC VQA datasets LSVQ and LSVQ-1080p, and onKoNViD-1k and LIVE-VQC without fine-tuning.", "output": "MRET: Multi-resolution Transformer for Video Quality Assessment."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep Learning (DL) is one of the most popular research topics in machinelearning and DL-driven image recognition systems have developed rapidly. Recentresearch has employed metamorphic testing (MT) to detect misclassified images.Most of them discuss metamorphic relations (MR), with limited attention givento which regions should be transformed. We focus on the fact that there aresensitive regions where even small transformations can easily change theprediction results and propose an MT framework that efficiently tests forregions prone to misclassification by transforming these sensitive regions. Ourevaluation demonstrated that the sensitive regions can be specified byExplainable AI (XAI) and our framework effectively detects faults.", "output": "Sensitive Region-based Metamorphic Testing Framework using Explainable AI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite significant efforts, cutting-edge video segmentation methods stillremain sensitive to occlusion and rapid movement, due to their reliance on theappearance of objects in the form of object embeddings, which are vulnerable tothese disturbances. A common solution is to use optical flow to provide motioninformation, but essentially it only considers pixel-level motion, which stillrelies on appearance similarity and hence is often inaccurate under occlusionand fast movement. In this work, we study the instance-level motion and presentInstMove, which stands for Instance Motion for Object-centric VideoSegmentation. In comparison to pixel-wise motion, InstMove mainly relies oninstance-level motion information that is free from image feature embeddings,and features physical interpretations, making it more accurate and robusttoward occlusion and fast-moving objects. To better fit in with the videosegmentation tasks, InstMove uses instance masks to model the physical presenceof an object and learns the dynamic model through a memory network to predictits position and shape in the next frame. With only a few lines of code,InstMove can be integrated into current SOTA methods for three different videosegmentation tasks and boost their performance. Specifically, we improve theprevious arts by 1.5 AP on OVIS dataset, which features heavy occlusions, and4.9 AP on YouTubeVIS-Long dataset, which mainly contains fast-moving objects.These results suggest that instance-level motion is robust and accurate, andhence serving as a powerful solution in complex scenarios for object-centricvideo segmentation.", "output": "InstMove: Instance Motion for Object-centric Video Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we present a novel algorithm to extract a quaternion from atwo dimensional camera frame for estimating a contained human skeletal pose.The problem of pose estimation is usually tackled through the usage of stereocameras and intertial measurement units for obtaining depth and euclideandistance for measurement of points in 3D space. However, the usage of thesedevices comes with a high signal processing latency as well as a significantmonetary cost. By making use of MediaPipe, a framework for building perceptionpipelines for human pose estimation, the proposed algorithm extracts aquaternion from a 2-D frame capturing an image of a human object at a sub-fiftymillisecond latency while also being capable of deployment at edges with asingle camera frame and a generally low computational resource availability,especially for use cases involving last-minute detection and reaction byautonomous robots. The algorithm seeks to bypass the funding barrier andimprove accessibility for robotics researchers involved in designing controlsystems.", "output": "Economical Quaternion Extraction from a Human Skeletal Pose Estimate using 2-D Cameras."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The quadratic computational complexity to the number of tokens limits thepractical applications of Vision Transformers (ViTs). Several works propose toprune redundant tokens to achieve efficient ViTs. However, these methodsgenerally suffer from (i) dramatic accuracy drops, (ii) application difficultyin the local vision transformer, and (iii) non-general-purpose networks fordownstream tasks. In this work, we propose a novel Semantic Token ViT (STViT),for efficient global and local vision transformers, which can also be revisedto serve as backbone for downstream tasks. The semantic tokens representcluster centers, and they are initialized by pooling image tokens in space andrecovered by attention, which can adaptively represent global or local semanticinformation. Due to the cluster properties, a few semantic tokens can attainthe same effect as vast image tokens, for both global and local visiontransformers. For instance, only 16 semantic tokens on DeiT-(Tiny,Small,Base)can achieve the same accuracy with more than 100% inference speed improvementand nearly 60% FLOPs reduction; on Swin-(Tiny,Small,Base), we can employ 16semantic tokens in each window to further speed it up by around 20% with slightaccuracy increase. Besides great success in image classification, we alsoextend our method to video recognition. In addition, we design aSTViT-R(ecover) network to restore the detailed spatial information based onthe STViT, making it work for downstream tasks, which is powerless for previoustoken sparsification methods. Experiments demonstrate that our method canachieve competitive results compared to the original networks in objectdetection and instance segmentation, with over 30% FLOPs reduction forbackbone. Code is available at <a href=\" http URL</a>", "output": "Making Vision Transformers Efficient from A Token Sparsification View."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Camera motion introduces spatially varying blur due to the depth changes inthe 3D world. This work investigates scene configurations where such blur isproduced under parallax camera motion. We present a simple, yet accurate, ImageCompositing Blur (ICB) model for depth-dependent spatially varying blur. The(forward) model produces realistic motion blur from a single image, depth map,and camera trajectory. Furthermore, we utilize the ICB model, combined with acoordinate-based MLP, to learn a sharp neural representation from the blurredinput. Experimental results are reported for synthetic and real examples. Theresults verify that the ICB forward model is computationally efficient andproduces realistic blur, despite the lack of occlusion information.Additionally, our method for restoring a sharp representation proves to be acompetitive approach for the deblurring task.", "output": "Depth-Aware Image Compositing Model for Parallax Camera Motion Blur."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In contrast to the natural capabilities of humans to learn new tasks in asequential fashion, neural networks are known to suffer from catastrophicforgetting, where the model's performances on old tasks drop dramatically afterbeing optimized for a new task. Since then, the continual learning (CL)community has proposed several solutions aiming to equip the neural networkwith the ability to learn the current task (plasticity) while still achievinghigh accuracy on the previous tasks (stability). Despite remarkableimprovements, the plasticity-stability trade-off is still far from being solvedand its underlying mechanism is poorly understood. In this work, we proposeAuxiliary Network Continual Learning (ANCL), a novel method that applies anadditional auxiliary network which promotes plasticity to the continuallylearned model which mainly focuses on stability. More concretely, the proposedframework materializes in a regularizer that naturally interpolates betweenplasticity and stability, surpassing strong baselines on task incremental andclass incremental scenarios. Through extensive analyses on ANCL solutions, weidentify some essential principles beneath the stability-plasticity trade-off.", "output": "Achieving a Better Stability-Plasticity Trade-off via Auxiliary Networks in Continual Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Classification and segmentation are crucial in medical image analysis as theyenable accurate diagnosis and disease monitoring. However, current methodsoften prioritize the mutual learning features and shared model parameters,while neglecting the reliability of features and performances. In this paper,we propose a novel Uncertainty-informed Mutual Learning (UML) framework forreliable and interpretable medical image analysis. Our UML introducesreliability to joint classification and segmentation tasks, leveraging mutuallearning with uncertainty to improve performance. To achieve this, we first useevidential deep learning to provide image-level and pixel-wise confidences.Then, an Uncertainty Navigator Decoder is constructed for better using mutualfeatures and generating segmentation results. Besides, an UncertaintyInstructor is proposed to screen reliable masks for classification. Overall,UML could produce confidence estimation in features and performance for eachlink (classification and segmentation). The experiments on the public datasetsdemonstrate that our UML outperforms existing methods in terms of both accuracyand robustness. Our UML has the potential to explore the development of morereliable and explainable medical image analysis models. We will release thecodes for reproduction after acceptance.", "output": "Uncertainty-informed Mutual Learning for Joint Medical Image Classification and Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although many recent works have investigated generalizable NeRF-based novelview synthesis for unseen scenes, they seldom consider the synthetic-to-realgeneralization, which is desired in many practical applications. In this work,we first investigate the effects of synthetic data in synthetic-to-real novelview synthesis and surprisingly observe that models trained with synthetic datatend to produce sharper but less accurate volume densities. For pixels wherethe volume densities are correct, fine-grained details will be obtained.Otherwise, severe artifacts will be produced. To maintain the advantages ofusing synthetic data while avoiding its negative effects, we propose tointroduce geometry-aware contrastive learning to learn multi-view consistentfeatures with geometric constraints. Meanwhile, we adopt cross-view attentionto further enhance the geometry perception of features by querying featuresacross input views. Experiments demonstrate that under the synthetic-to-realsetting, our method can render images with higher quality and betterfine-grained details, outperforming existing generalizable novel view synthesismethods in terms of PSNR, SSIM, and LPIPS. When trained on real data, ourmethod also achieves state-of-the-art results.", "output": "ContraNeRF: Generalizable Neural Radiance Fields for Synthetic-to-real Novel View Synthesis via Contrastive Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Given an abstract, deformed, ordinary sketch from untrained amateurs like youand me, this paper turns it into a photorealistic image - just like those shownin Fig. 1(a), all non-cherry-picked. We differ significantly from prior art inthat we do not dictate an edgemap-like sketch to start with, but aim to workwith abstract free-hand human sketches. In doing so, we essentially democratisethe sketch-to-photo pipeline, \"picturing\" a sketch regardless of how good yousketch. Our contribution at the outset is a decoupled encoder-decoder trainingparadigm, where the decoder is a StyleGAN trained on photos only. Thisimportantly ensures that generated results are always photorealistic. The restis then all centred around how best to deal with the abstraction gap betweensketch and photo. For that, we propose an autoregressive sketch mapper trainedon sketch-photo pairs that maps a sketch to the StyleGAN latent space. Wefurther introduce specific designs to tackle the abstract nature of humansketches, including a fine-grained discriminative loss on the back of a trainedsketch-photo retrieval model, and a partial-aware sketch augmentation strategy.Finally, we showcase a few downstream tasks our generation model enables,amongst them is showing how fine-grained sketch-based image retrieval, awell-studied problem in the sketch community, can be reduced to an image(generated) to image retrieval task, surpassing state-of-the-arts. We putforward generated results in the supplementary for everyone to scrutinise.", "output": "Picture that Sketch: Photorealistic Image Generation from Abstract Sketches."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Human sketch has already proved its worth in various visual understandingtasks (e.g., retrieval, segmentation, image-captioning, etc). In this paper, wereveal a new trait of sketches - that they are also salient. This is intuitiveas sketching is a natural attentive process at its core. More specifically, weaim to study how sketches can be used as a weak label to detect salient objectspresent in an image. To this end, we propose a novel method that emphasises onhow \"salient object\" could be explained by hand-drawn sketches. To accomplishthis, we introduce a photo-to-sketch generation model that aims to generatesequential sketch coordinates corresponding to a given visual photo through a2D attention mechanism. Attention maps accumulated across the time steps giverise to salient regions in the process. Extensive quantitative and qualitativeexperiments prove our hypothesis and delineate how our sketch-based saliencydetection model gives a competitive performance compared to thestate-of-the-art.", "output": "Sketch2Saliency: Learning to Detect Salient Objects from Human Drawings."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce Correlational Image Modeling (CIM), a novel and surprisinglyeffective approach to self-supervised visual pre-training. Our CIM performs asimple pretext task: we randomly crop image regions (exemplars) from an inputimage (context) and predict correlation maps between the exemplars and thecontext. Three key designs enable correlational image modeling as a nontrivialand meaningful self-supervisory task. First, to generate usefulexemplar-context pairs, we consider cropping image regions with various scales,shapes, rotations, and transformations. Second, we employ a bootstrap learningframework that involves online and target encoders. During pre-training, theformer takes exemplars as inputs while the latter converts the context. Third,we model the output correlation maps via a simple cross-attention block, withinwhich the context serves as queries and the exemplars offer values and keys. Weshow that CIM performs on par or better than the current state of the art onself-supervised and transfer benchmarks.", "output": "Correlational Image Modeling for Self-Supervised Visual Pre-Training."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "3D semantic scene completion (SSC) is an ill-posed task that requiresinferring a dense 3D scene from incomplete observations. Previous methodseither explicitly incorporate 3D geometric input or rely on learnt 3D priorbehind monocular RGB images. However, 3D sensors such as LiDAR are expensiveand intrusive while monocular cameras face challenges in modeling precisegeometry due to the inherent ambiguity. In this work, we propose StereoScenefor 3D Semantic Scene Completion (SSC), which explores taking full advantage oflight-weight camera inputs without resorting to any external 3D sensors. Ourkey insight is to leverage stereo matching to resolve geometric ambiguity. Toimprove its robustness in unmatched areas, we introduce bird's-eye-view (BEV)representation to inspire hallucination ability with rich context information.On top of the stereo and BEV representations, a mutual interactive aggregation(MIA) module is carefully devised to fully unleash their power. Specifically, aBi-directional Interaction Transformer (BIT) augmented with confidencere-weighting is used to encourage reliable prediction through mutual guidancewhile a Dual Volume Aggregation (DVA) module is designed to facilitatecomplementary aggregation. Experimental results on SemanticKITTI demonstratethat the proposed StereoScene outperforms the state-of-the-art camera-basedmethods by a large margin with a relative improvement of 26.9% in geometry and38.6% in semantic.", "output": "StereoScene: BEV-Assisted Stereo Matching Empowers 3D Semantic Scene Completion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Medical datasets and especially biobanks, often contain extensive tabulardata with rich clinical information in addition to images. In practice,clinicians typically have less data, both in terms of diversity and scale, butstill wish to deploy deep learning solutions. Combined with increasing medicaldataset sizes and expensive annotation costs, the necessity for unsupervisedmethods that can pretrain multimodally and predict unimodally has risen.To address these needs, we propose the first self-supervised contrastivelearning framework that takes advantage of images and tabular data to trainunimodal encoders. Our solution combines SimCLR and SCARF, two leadingcontrastive learning strategies, and is simple and effective. In ourexperiments, we demonstrate the strength of our framework by predicting risksof myocardial infarction and coronary artery disease (CAD) using cardiac MRimages and 120 clinical features from 40,000 UK Biobank subjects. Furthermore,we show the generalizability of our approach to natural images using the DVMcar advertisement dataset.We take advantage of the high interpretability of tabular data and throughattribution and ablation experiments find that morphometric tabular features,describing size and shape, have outsized importance during the contrastivelearning process and improve the quality of the learned embeddings. Finally, weintroduce a novel form of supervised contrastive learning, label as a feature(LaaF), by appending the ground truth label as a tabular feature duringmultimodal pretraining, outperforming all supervised contrastive baselines.", "output": "Best of Both Worlds: Multimodal Contrastive Learning with Tabular and Imaging Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a simple pairwise sigmoid loss for image-text pre-training. Unlikestandard contrastive learning with softmax normalization, the sigmoid lossoperates solely on image-text pairs and does not require a global view of thepairwise similarities for normalization. The sigmoid loss simultaneously allowsfurther scaling up the batch size, while also performing better at smallerbatch sizes. With only four TPUv4 chips, we can train a Base CLIP model at 4kbatch size and a Large LiT model at 20k batch size, the latter achieves 84.5%ImageNet zero-shot accuracy in two days. This disentanglement of the batch sizefrom the loss further allows us to study the impact of examples vs pairs andnegative to positive ratio. Finally, we push the batch size to the extreme, upto one million, and find that the benefits of growing batch size quicklydiminish, with a more reasonable batch size of 32k being sufficient. We hopeour research motivates further explorations in improving the quality andefficiency of language-image pre-training.", "output": "Sigmoid Loss for Language Image Pre-Training."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision Transformers (ViTs) emerge to achieve impressive performance on manydata-abundant computer vision tasks by capturing long-range dependencies amonglocal features. However, under few-shot learning (FSL) settings on smalldatasets with only a few labeled data, ViT tends to overfit and suffers fromsevere performance degradation due to its absence of CNN-alike inductive bias.Previous works in FSL avoid such problem either through the help ofself-supervised auxiliary losses, or through the dextile uses of labelinformation under supervised settings. But the gap between self-supervised andsupervised few-shot Transformers is still unfilled. Inspired by recent advancesin self-supervised knowledge distillation and masked image modeling (MIM), wepropose a novel Supervised Masked Knowledge Distillation model (SMKD) forfew-shot Transformers which incorporates label information intoself-distillation frameworks. Compared with previous self-supervised methods,we allow intra-class knowledge distillation on both class and patch tokens, andintroduce the challenging task of masked patch tokens reconstruction acrossintra-class images. Experimental results on four few-shot classificationbenchmark datasets show that our method with simple design outperforms previousmethods by a large margin and achieves a new start-of-the-art. Detailedablation studies confirm the effectiveness of each component of our model. Codefor this paper is available here: ", "output": "Supervised Masked Knowledge Distillation for Few-Shot Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The success of existing multi-view clustering relies on the assumption ofsample integrity across multiple views. However, in real-world scenarios,samples of multi-view are partially available due to data corruption or sensorfailure, which leads to incomplete multi-view clustering study (IMVC). Althoughseveral attempts have been proposed to address IMVC, they suffer from thefollowing drawbacks: i) Existing methods mainly adopt cross-view contrastivelearning forcing the representations of each sample across views to be exactlythe same, which might ignore view discrepancy and flexibility inrepresentations; ii) Due to the absence of non-observed samples across multipleviews, the obtained prototypes of clusters might be unaligned and biased,leading to incorrect fusion. To address the above issues, we propose aCross-view Partial Sample and Prototype Alignment Network (CPSPAN) for DeepIncomplete Multi-view Clustering. Firstly, unlike existing contrastive-basedmethods, we adopt pair-observed data alignment as 'proxy supervised signals' toguide instance-to-instance correspondence construction among views. Then,regarding of the shifted prototypes in IMVC, we further propose a prototypealignment module to achieve incomplete distribution calibration across views.Extensive experimental results showcase the effectiveness of our proposedmodules, attaining noteworthy performance improvements when compared toexisting IMVC competitors on benchmark datasets.", "output": "Deep Incomplete Multi-view Clustering with Cross-view Partial Sample and Prototype Alignment."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, the authors develop regression approaches based on deeplearning to perform thread density estimation for plain weave canvas analysis.Previous approaches were based on Fourier analysis, which is quite robust forsome scenarios but fails in some others, in machine learning tools, thatinvolve pre-labeling of the painting at hand, or the segmentation of threadcrossing points, that provides good estimations in all scenarios with no needof pre-labeling. The segmentation approach is time-consuming as the estimationof the densities is performed after locating the crossing points. In this novelproposal, we avoid this step by computing the density of threads directly fromthe image with a regression deep learning model. We also incorporate someimprovements in the initial preprocessing of the input image with an impact onthe final error. Several models are proposed and analyzed to retain the bestone. Furthermore, we further reduce the density estimation error by introducinga semi-supervised approach. The performance of our novel algorithm is analyzedwith works by Ribera, Vel'azquez, and Poussin where we compare our results tothe ones of previous approaches. Finally, the method is put into practice tosupport the change of authorship or a masterpiece at the Museo del Prado.", "output": "Thread Counting in Plain Weave for Old Paintings Using Semi-Supervised Regression Deep Learning Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural Radiance Fields (NeRFs) learn to represent a 3D scene from just a setof registered images. Increasing sizes of a scene demands more complexfunctions, typically represented by neural networks, to capture all details.Training and inference then involves querying the neural network millions oftimes per image, which becomes impractically slow. Since such complex functionscan be replaced by multiple simpler functions to improve speed, we show that ahierarchy of Voronoi diagrams is a suitable choice to partition the scene. Byequipping each Voronoi cell with its own NeRF, our approach is able to quicklylearn a scene representation. We propose an intuitive partitioning of the spacethat increases quality gains during training by distributing information evenlyamong the networks and avoids artifacts through a top-down adaptive refinement.Our framework is agnostic to the underlying NeRF method and easy to implement,which allows it to be applied to various NeRF variants for improved learningand rendering speeds.", "output": "Adaptive Voronoi NeRFs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated Magnetic Resonance Imaging (MRI) reconstruction enables multiplehospitals to collaborate distributedly without aggregating local data, therebyprotecting patient privacy. However, the data heterogeneity caused by differentMRI protocols, insufficient local training data, and limited communicationbandwidth inevitably impair global model convergence and updating. In thispaper, we propose a new algorithm, FedPR, to learn federated visual prompts inthe null space of global prompt for MRI reconstruction. FedPR is a newfederated paradigm that adopts a powerful pre-trained model while only learningand communicating the prompts with few learnable parameters, therebysignificantly reducing communication costs and achieving competitiveperformance on limited local data. Moreover, to deal with catastrophicforgetting caused by data heterogeneity, FedPR also updates efficient federatedvisual prompts that project the local prompts into an approximate null space ofthe global prompt, thereby suppressing the interference of gradients on theserver performance. Extensive experiments on federated MRI show that FedPRsignificantly outperforms state-of-the-art FL algorithms with &lt;6% ofcommunication costs when given the limited amount of local training data.", "output": "Learning Federated Visual Prompt in Null Space for MRI Reconstruction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study presents a novel approach to bone age assessment (BAA) using amulti-view, multi-task classification model based on the Sauvegrain method. Astraightforward solution to automating the Sauvegrain method, which assesses amaturity score for each landmark in the elbow and predicts the bone age, is totrain classifiers independently to score each region of interest (RoI), butthis approach limits the accessible information to local morphologies andincreases computational costs. As a result, this work proposes aself-accumulative vision transformer (SAT) that mitigates anisotropic behavior,which usually occurs in multi-view, multi-task problems and limits theeffectiveness of a vision transformer, by applying token replay and regionalattention bias. A number of experiments show that SAT successfully exploits therelationships between landmarks and learns global morphological features,resulting in a mean absolute error of BAA that is 0.11 lower than that of theprevious work. Additionally, the proposed SAT has four times reduced parametersthan an ensemble of individual classifiers of the previous work. Lastly, thiswork also provides informative implications for clinical practice, improvingthe accuracy and efficiency of BAA in diagnosing abnormal growth inadolescents.", "output": "Self-accumulative Vision Transformer for Bone Age Assessment Using the Sauvegrain Method."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The fairness of a deep neural network is strongly affected by dataset biasand spurious correlations, both of which are usually present in modernfeature-rich and complex visual datasets. Due to the difficulty and variabilityof the task, no single de-biasing method has been universally successful. Inparticular, implicit methods not requiring explicit knowledge of bias variablesare especially relevant for real-world applications. We propose a novelimplicit mitigation method using a Bayesian neural network, allowing us toleverage the relationship between epistemic uncertainties and the presence ofbias or spurious correlations in a sample. Our proposed posterior estimatesharpening procedure encourages the network to focus on core features that donot contribute to high uncertainties. Experimental results on three benchmarkdatasets demonstrate that Bayesian networks with sharpened posterior estimatesperform comparably to prior existing methods and show potential worthy offurther exploration.", "output": "Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a Bayesian Neural Network."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image generation using diffusion can be controlled in multiple ways. In thispaper, we systematically analyze the equations of modern generative diffusionnetworks to propose a framework, called MDP, that explains the design space ofsuitable manipulations. We identify 5 different manipulations, includingintermediate latent, conditional embedding, cross attention maps, guidance, andpredicted noise. We analyze the corresponding parameters of these manipulationsand the manipulation schedule. We show that some previous editing methods fitnicely into our framework. Particularly, we identified one specificconfiguration as a new type of control by manipulating the predicted noise,which can perform higher-quality edits than previous work for a variety oflocal and global edits.", "output": "MDP: A Generalized Framework for Text-Guided Image Editing by Manipulating the Diffusion Path."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-view camera-based 3D object detection has gained popularity due to itslow cost. But accurately inferring 3D geometry solely from camera data remainschallenging, which impacts model performance. One promising approach to addressthis issue is to distill precise 3D geometry knowledge from LiDAR data.However, transferring knowledge between different sensor modalities is hinderedby the significant modality gap. In this paper, we approach this challenge fromthe perspective of both architecture design and knowledge distillation andpresent a new simulated multi-modal 3D object detection method named BEVSimDet.We first introduce a novel framework that includes a LiDAR and camerafusion-based teacher and a simulated multi-modal student, where the studentsimulates multi-modal features with image-only input. To facilitate effectivedistillation, we propose a simulated multi-modal distillation scheme thatsupports intra-modal, cross-modal, and multi-modal distillation simultaneously.By combining them together, BEVSimDet can learn better feature representationsfor 3D object detection while enjoying cost-effective camera-only deployment.Experimental results on the challenging nuScenes benchmark demonstrate theeffectiveness and superiority of BEVSimDet over recent representative methods.The source code will be released athref{", "output": "BEVSimDet: Simulated Multi-modal Distillation in Bird's-Eye View for Multi-view 3D Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The development of language models have moved from encoder-decoder todecoder-only designs. In addition, the common knowledge has it that the twomost popular multimodal tasks, the generative and contrastive tasks, tend toconflict with one another, are hard to accommodate in one architecture, andfurther need complex adaptations for downstream tasks. We propose a novelparadigm of training with a decoder-only model for multimodal tasks, which issurprisingly effective in jointly learning of these disparate vision-languagetasks. This is done with a simple model, called MaMMUT. It consists of a singlevision encoder and a text decoder, and is able to accommodate contrastive andgenerative learning by a novel two-pass approach on the text decoder. Wedemonstrate that joint learning of these diverse objectives is simple,effective, and maximizes the weight-sharing of the model across these tasks.Furthermore, the same architecture enables straightforward extensions toopen-vocabulary object detection and video-language tasks. The model tackles adiverse range of tasks, while being modest in capacity. Our model achieves thestate of the art on image-text and text-image retrieval, video questionanswering and open-vocabulary detection tasks, outperforming much larger andmore extensively trained foundational models. It shows very competitive resultson VQA and Video Captioning, especially considering its capacity. Ablationsconfirm the flexibility and advantages of our approach.", "output": "MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ground-glass opacity is a hallmark of numerous lung diseases, includingpatients with COVID19 and pneumonia. This brief note presents experimentalresults of a proof-of-concept framework that got implemented and tested overthree days as driven by the third challenge entitled \"COVID-19 Competition\",hosted at the AI-Enabled Medical Image Analysis Workshop of the 2023 IEEEInternational Conference on Acoustics, Speech and Signal Processing (ICASSP2023). Using a newly built virtual environment (created on March 17, 2023), weinvestigated various pre-trained two-dimensional convolutional neural networks(CNN) such as Dense Neural Network, Residual Neural Networks (ResNet), andVision Transformers, as well as the extent of fine-tuning. Based on empiricalexperiments, we opted to fine-tune them using ADAM's optimization algorithmwith a standard learning rate of 0.001 for all CNN architectures and applyearly-stopping whenever the validation loss reached a plateau. For each trainedCNN, the model state with the best validation accuracy achieved during trainingwas stored and later reloaded for new classifications of unseen samples drawnfrom the validation set provided by the challenge organizers. According to theorganizers, few of these 2D CNNs yielded performance comparable to anarchitecture that combined ResNet and Recurrent Neural Network (Gated RecurrentUnits). As part of the challenge requirement, the source code produced duringthe course of this exercise is posted at  Wealso hope that other researchers may find this light prototype consisting offew Python files based on PyTorch 1.13.1 and TorchVision 0.14.1 approachable.", "output": "Severity classification of ground-glass opacity via 2-D convolutional neural network and lung CT scans: a 3-day exploration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "One of the most important magnetic spin structure is the topologicallystabilised skyrmion quasi-particle. Its interesting physical properties makethem candidates for memory and efficient neuromorphic computation schemes. Forthe device operation, detection of the position, shape, and size of skyrmionsis required and magnetic imaging is typically employed. A frequently usedtechnique is magneto-optical Kerr microscopy where depending on the samplesmaterial composition, temperature, material growing procedures, etc., themeasurements suffer from noise, low-contrast, intensity gradients, or otheroptical artifacts. Conventional image analysis packages require manualtreatment, and a more automatic solution is required. We report a convolutionalneural network specifically designed for segmentation problems to detect theposition and shape of skyrmions in our measurements. The network is tuned usingselected techniques to optimize predictions and in particular the number ofdetected classes is found to govern the performance. The results of this studyshows that a well-trained network is a viable method of automating datapre-processing in magnetic microscopy. The approach is easily extendable toother spin structures and other magnetic imaging methods.", "output": "Machine learning-based spin structure detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Concept drift detection has attracted considerable attention due to itsimportance in many real-world applications such as health monitoring and faultdiagnosis. Conventionally, most advanced approaches will be of poor performancewhen the evaluation criteria of the environment has changed (i.e. conceptdrift), either can only detect and adapt to virtual drift. In this paper, wepropose a new approach to detect real-drift in the chunk data stream withlimited annotations based on concept confusion. When a new data chunk arrives,we use both real labels and pseudo labels to update the model after predictionand drift detection. In this context, the model will be confused and yieldsprediction difference once drift occurs. We then adopt cosine similarity tomeasure the difference. And an adaptive threshold method is proposed to findthe abnormal value. Experiments show that our method has a low false alarm rateand false negative rate with the utilization of different classifiers.", "output": "CADM: Confusion Model-based Detection Method for Real-drift in Chunk Data Stream."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The process of training feedforward neural networks (FFNNs) can benefit froman automated process where the best heuristic to train the network is soughtout automatically by means of a high-level probabilistic-based heuristic. Thisresearch introduces a novel population-based Bayesian hyper-heuristic (BHH)that is used to train feedforward neural networks (FFNNs). The performance ofthe BHH is compared to that of ten popular low-level heuristics, each withdifferent search behaviours. The chosen heuristic pool consists of classicgradient-based heuristics as well as meta-heuristics (MHs). The empiricalprocess is executed on fourteen datasets consisting of classification andregression problems with varying characteristics. The BHH is shown to be ableto train FFNNs well and provide an automated method for finding the bestheuristic to train the FFNNs at various stages of the training process.", "output": "Training Feedforward Neural Networks with Bayesian Hyper-Heuristics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the field of functional genomics, the analysis of gene expression profilesthrough Machine and Deep Learning is increasingly providing meaningful insightinto a number of diseases. The paper proposes a novel algorithm to performFeature Selection on genomic-scale data, which exploits the reconstructioncapabilities of autoencoders and an ad-hoc defined Explainable ArtificialIntelligence-based score in order to select the most informative genes fordiagnosis, prognosis, and precision medicine. Results of the application on aChronic Lymphocytic Leukemia dataset evidence the effectiveness of thealgorithm, by identifying and suggesting a set of meaningful genes for furthermedical investigation.", "output": "A New Deep Learning and XAI-Based Algorithm for Features Selection in Genomics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural Architecture Search (NAS) benchmarks significantly improved thecapability of developing and comparing NAS methods while at the same timedrastically reduced the computational overhead by providing meta-informationabout thousands of trained neural networks. However, tabular benchmarks haveseveral drawbacks that can hinder fair comparisons and provide unreliableresults. These usually focus on providing a small pool of operations in heavilyconstrained search spaces -- usually cell-based neural networks withpre-defined outer-skeletons. In this work, we conducted an empirical analysisof the widely used NAS-Bench-101, NAS-Bench-201 and TransNAS-Bench-101benchmarks in terms of their generability and how different operationsinfluence the performance of the generated architectures. We found that only asubset of the operation pool is required to generate architectures close to theupper-bound of the performance range. Also, the performance distribution isnegatively skewed, having a higher density of architectures in the upper-boundrange. We consistently found convolution layers to have the highest impact onthe architecture's performance, and that specific combination of operationsfavors top-scoring architectures. These findings shed insights on the correctevaluation and comparison of NAS methods using NAS benchmarks, showing thatdirectly searching on NAS-Bench-201, ImageNet16-120 and TransNAS-Bench-101produces more reliable results than searching only on CIFAR-10. Furthermore,with this work we provide suggestions for future benchmark evaluations anddesign. The code used to conduct the evaluations is available at", "output": "Are Neural Architecture Search Benchmarks Well Designed? A Deeper Look Into Operation Importance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Dense Self-Supervised Learning (SSL) methods address the limitations of usingimage-level feature representations when handling images with multiple objects.Although the dense features extracted by employing segmentation maps andbounding boxes allow networks to perform SSL for each object, we show that theysuffer from coupling and positional bias, which arise from the receptive fieldincreasing with layer depth and zero-padding. We address this by introducingthree data augmentation strategies, and leveraging them in (i) a decouplingmodule that aims to robustify the network to variations in the object'ssurroundings, and (ii) a de-positioning module that encourages the network todiscard positional object information. We demonstrate the benefits of ourmethod on COCO and on a new challenging benchmark, OpenImage-MINI, for objectclassification, semantic segmentation, and object detection. Our extensiveexperiments evidence the better generalization of our method compared to theSOTA dense SSL methods", "output": "De-coupling and De-positioning Dense Self-supervised Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Conventional optimization methods in machine learning and controls relyheavily on first-order update rules. Selecting the right method andhyperparameters for a particular task often involves trial-and-error orpractitioner intuition, motivating the field of meta-learning. We generalize abroad family of preexisting update rules by proposing a meta-learning frameworkin which the inner loop optimization step involves solving a differentiableconvex optimization (DCO). We illustrate the theoretical appeal of thisapproach by showing that it enables one-step optimization of a family of linearleast squares problems, given that the meta-learner has sufficient exposure tosimilar tasks. Various instantiations of the DCO update rule are compared toconventional optimizers on a range of illustrative experimental settings.", "output": "Meta-Learning Parameterized First-Order Optimizers using Differentiable Convex Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a hierarchical Bayesian learning approach to infer jointly sparseparameter vectors from multiple measurement vectors. Our model uses separateconditionally Gaussian priors for each parameter vector and commongamma-distributed hyper-parameters to enforce joint sparsity. The resultingjoint-sparsity-promoting priors are combined with existing Bayesian inferencemethods to generate a new family of algorithms. Our numerical experiments,which include a multi-coil magnetic resonance imaging application, demonstratethat our new approach consistently outperforms commonly used hierarchicalBayesian methods.", "output": "Leveraging joint sparsity in hierarchical Bayesian learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, quantum computing has emerged as a promising technology forsolving complex computational problems. Generative modeling is a technique thatallows us to learn and generate new data samples similar to the originaldataset. In this paper, we propose a generative modeling approach using quantumgates to generate new samples from a given dataset. We start with a briefintroduction to quantum computing and generative modeling. Then, we describeour proposed approach, which involves encoding the dataset into quantum statesand using quantum gates to manipulate these states to generate new samples. Wealso provide mathematical details of our approach and demonstrate itseffectiveness through experimental results on various datasets.", "output": "A Generative Modeling Approach Using Quantum Gates."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With growing security and privacy concerns in the Smart Grid domain,intrusion detection on critical energy infrastructure has become a highpriority in recent years. To remedy the challenges of privacy preservation anddecentralized power zones with strategic data owners, Federated Learning (FL)has contemporarily surfaced as a viable privacy-preserving alternative whichenables collaborative training of attack detection models without requiring thesharing of raw data. To address some of the technical challenges associatedwith conventional synchronous FL, this paper proposes FeDiSa, a novelSemi-asynchronous Federated learning framework for power system faults andcyberattack Discrimination which takes into account communication latency andstragglers. Specifically, we propose a collaborative training of deepauto-encoder by Supervisory Control and Data Acquisition sub-systems whichupload their local model updates to a control centre, which then perform asemi-asynchronous model aggregation for a new global model parameters based ona buffer system and a preset cut-off time. Experiments on the proposedframework using publicly available industrial control systems datasets revealsuperior attack detection accuracy whilst preserving data confidentiality andminimizing the adverse effects of communication latency and stragglers.Furthermore, we see a 35% improvement in training time, thus validating therobustness of our proposed method.", "output": "FeDiSa: A Semi-asynchronous Federated Learning Framework for Power System Fault and Cyberattack Discrimination."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Data valuation is a ML field that studies the value of training instancestowards a given predictive task. Although data bias is one of the main sourcesof downstream model unfairness, previous work in data valuation does notconsider how training instances may influence both performance and fairness ofML models. Thus, we propose Fairness-Aware Data vauatiOn (FADO), a datavaluation framework that can be used to incorporate fairness concerns into aseries of ML-related tasks (e.g., data pre-processing, exploratory dataanalysis, active learning). We propose an entropy-based data valuation metricsuited to address our two-pronged goal of maximizing both performance andfairness, which is more computationally efficient than existing metrics. Wethen show how FADO can be applied as the basis for unfairness mitigationpre-processing techniques. Our methods achieve promising results -- up to a 40p.p. improvement in fairness at a less than 1 p.p. loss in performance comparedto a baseline -- and promote fairness in a data-centric way, where a deeperunderstanding of data quality takes center stage.", "output": "Fairness-Aware Data Valuation for Supervised Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Sparse joint shift (SJS) was recently proposed as a tractable model forgeneral dataset shift which may cause changes to the marginal distributions offeatures and labels as well as the posterior probabilities and theclass-conditional feature distributions. Fitting SJS for a target datasetwithout label observations may produce valid predictions of labels andestimates of class prior probabilities. We present new results on thetransmission of SJS from sets of features to larger sets of features, aconditional correction formula for the class posterior probabilities under thetarget distribution, identifiability of SJS, and the relationship between SJSand covariate shift. In addition, we point out inconsistencies in thealgorithms which were proposed for estimating the characteristics of SJS, asthey could hamper the search for optimal solutions.", "output": "Sparse joint shift in multinomial classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent developments in deep learning have made remarkable progress inspeeding up the prediction of quantum chemical (QC) properties by removing theneed for expensive electronic structure calculations like density functionaltheory. However, previous methods that relied on 1D SMILES sequences or 2Dmolecular graphs failed to achieve high accuracy as QC properties are primarilydependent on the 3D equilibrium conformations optimized by electronic structuremethods. In this paper, we propose a novel approach called Uni-Mol+ to tacklethis challenge. Firstly, given a 2D molecular graph, Uni-Mol+ generates aninitial 3D conformation from inexpensive methods such as RDKit. Then, theinitial conformation is iteratively optimized to its equilibrium conformation,and the optimized conformation is further used to predict the QC properties.All these steps are automatically learned using Transformer models. We observedthe quality of the optimized conformation is crucial for QC property predictionperformance. To effectively optimize conformation, we introduce a two-trackTransformer model backbone in Uni-Mol+ and train it together with the QCproperty prediction task. We also design a novel training approach calledlinear trajectory injection to ensure proper supervision for the Uni-Mol+learning process. Our extensive benchmarking results demonstrate that theproposed Uni-Mol+ significantly improves the accuracy of QC propertyprediction. We have made the code and model publicly available aturl{", "output": "Highly Accurate Quantum Chemical Property Prediction with Uni-Mol+."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, the study of linear misspecified bandits has generated intriguingimplications of the hardness of learning in bandits and reinforcement learning(RL). In particular, Du et al. (2020) show that even if a learner is givenlinear features in $mathbb{R}^d$ that approximate the rewards in a bandit orRL with a uniform error of $varepsilon$, searching for an$O(varepsilon)$-optimal action requires pulling at least $Omega(exp(d))$queries. Furthermore, Lattimore et al. (2020) show that a degraded$O(varepsilonsqrt{d})$-optimal solution can be learned within$operatorname{poly}(d/varepsilon)$ queries. Yet it is unknown whether astructural assumption on the ground-truth parameter, such as sparsity, couldbreak the $varepsilonsqrt{d}$ barrier. In this paper, we address thisquestion by showing that algorithms can obtain $O(varepsilon)$-optimal actionsby querying $O(varepsilon^{-s}d^s)$ actions, where $s$ is the sparsityparameter, removing the $exp(d)$-dependence. We then establishinformation-theoretical lower bounds, i.e., $Omega(exp(s))$, to show that ourupper bound on sample complexity is nearly tight if one demands an error $O(s^{delta}varepsilon)$ for $0&lt;delta&lt;1$. For $deltageq 1$, we further showthat $operatorname{poly}(s/varepsilon)$ queries are possible when the linearfeatures are \"good\" and even in general settings. These results provide anearly complete picture of how sparsity can help in misspecified banditlearning and provide a deeper understanding of when linear features are\"useful\" for bandit and reinforcement learning with misspecification.", "output": "Does Sparsity Help in Learning Misspecified Linear Bandits?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reducing the computational cost of running large scale neural networks usingsparsity has attracted great attention in the deep learning community. Whilemuch success has been achieved in reducing FLOP and parameter counts whilemaintaining acceptable task performance, achieving actual speed improvementshas typically been much more difficult, particularly on general purposeaccelerators (GPAs) such as NVIDIA GPUs using low precision number formats. Inthis work we introduce PopSparse, a library that enables fast sparse operationson Graphcore IPUs by leveraging both the unique hardware characteristics ofIPUs as well as any block structure defined in the data. We target twodifferent types of sparsity: static, where the sparsity pattern is fixed atcompile-time; and dynamic, where it can change each time the model is run. Wepresent benchmark results for matrix multiplication for both of these modes onIPU with a range of block sizes, matrix sizes and densities. Results indicatethat the PopSparse implementations are faster than dense matrix multiplicationson IPU at a range of sparsity levels with large matrix size and block size.Furthermore, static sparsity in general outperforms dynamic sparsity. Whileprevious work on GPAs has shown speedups only for very high sparsity (typically99% and above), the present work demonstrates that our static sparseimplementation outperforms equivalent dense calculations in FP16 at lowersparsity (around 90%).", "output": "PopSparse: Accelerated block sparse matrix multiplication on IPU."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Graph Laplacian based algorithms for data lying on a manifold have beenproven effective for tasks such as dimensionality reduction, clustering, anddenoising. In this work, we consider data sets whose data point not only lie ona manifold, but are also closed under the action of a continuous group. Anexample of such data set is volumes that line on a low dimensional manifold,where each volume may be rotated in three-dimensional space. We introduce theG-invariant graph Laplacian that generalizes the graph Laplacian by accountingfor the action of the group on the data set. We show that like the standardgraph Laplacian, the G-invariant graph Laplacian converges to theLaplace-Beltrami operator on the data manifold, but with a significantlyimproved convergence rate. Furthermore, we show that the eigenfunctions of theG-invariant graph Laplacian admit the form of tensor products between the groupelements and eigenvectors of certain matrices, which can be computedefficiently using FFT-type algorithms. We demonstrate our construction and itsadvantages on the problem of filtering data on a noisy manifold closed underthe action of the special unitary group SU(2).", "output": "The G-invariant graph Laplacian."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The present study aims to explore the capabilities of Language Models (LMs)in tackling high-stakes multiple-choice tests, represented here by the ExameNacional do Ensino M'edio (ENEM), a multidisciplinary entrance examinationwidely adopted by Brazilian universities. This exam poses challenging tasks forLMs, since its questions may span into multiple fields of knowledge, requiringunderstanding of information from diverse domains. For instance, a question mayrequire comprehension of both statistics and biology to be solved. This workanalyzed responses generated by GPT-3.5 and GPT-4 models for questionspresented in the 2009-2017 exams, as well as for questions of the 2022 exam,which were made public after the training of the models was completed.Furthermore, different prompt strategies were tested, including the use ofChain-of-Thought (CoT) prompts to generate explanations for answers. On the2022 edition, the best-performing model, GPT-4 with CoT, achieved an accuracyof 87%, largely surpassing GPT-3.5 by 11 points. The code and data used onexperiments are available at ", "output": "Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image-to-image translation (I2I) methods allow the generation of artificialimages that share the content of the original image but have a different style.With the advances in Generative Adversarial Networks (GANs)-based methods, I2Imethods enabled the generation of artificial images that are indistinguishablefrom natural images. Recently, I2I methods were also employed in histopathologyfor generating artificial images of in silico stained tissues from a differenttype of staining. We refer to this process as stain transfer. The number of I2Ivariants is constantly increasing, which makes a well justified choice of themost suitable I2I methods for stain transfer challenging. In our work, wecompare twelve stain transfer approaches, three of which are based ontraditional and nine on GAN-based image processing methods. The analysis relieson complementary quantitative measures for the quality of image translation,the assessment of the suitability for deep learning-based tissue grading, andthe visual evaluation by pathologists. Our study highlights the strengths andweaknesses of the stain transfer approaches, thereby allowing a rational choiceof the underlying I2I algorithms. Code, data, and trained models for staintransfer between H&amp;E and Masson's Trichrome staining will be made availableonline.", "output": "A comparative evaluation of image-to-image translation methods for stain transfer in histopathology."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Advancements in simulation and formal methods-guided environment samplinghave enabled the rigorous evaluation of machine learning models in a number ofsafety-critical scenarios, such as autonomous driving. Application of theseenvironment sampling techniques towards improving the learned models themselveshas yet to be fully exploited. In this work, we introduce a novel method forimproving imitation-learned models in a semantically aware fashion byleveraging specification-guided sampling techniques as a means of aggregatingexpert data in new environments. Specifically, we create a set of formalspecifications as a means of partitioning the space of possible environmentsinto semantically similar regions, and identify elements of this partitionwhere our learned imitation behaves most differently from the expert. We thenaggregate expert data on environments in these identified regions, leading tomore accurate imitation of the expert's behavior semantics. We instantiate ourapproach in a series of experiments in the CARLA driving simulator, anddemonstrate that our approach leads to models that are more accurate than thoselearned with other environment sampling methods.", "output": "Specification-Guided Data Aggregation for Semantically Aware Imitation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Implicit neural fields, typically encoded by a multilayer perceptron (MLP)that maps from coordinates (e.g., xyz) to signals (e.g., signed distances),have shown remarkable promise as a high-fidelity and compact representation.However, the lack of a regular and explicit grid structure also makes itchallenging to apply generative modeling directly on implicit neural fields inorder to synthesize new data. To this end, we propose HyperDiffusion, a novelapproach for unconditional generative modeling of implicit neural fields.HyperDiffusion operates directly on MLP weights and generates new neuralimplicit fields encoded by synthesized MLP parameters. Specifically, acollection of MLPs is first optimized to faithfully represent individual datasamples. Subsequently, a diffusion process is trained in this MLP weight spaceto model the underlying distribution of neural implicit fields. HyperDiffusionenables diffusion modeling over a implicit, compact, and yet high-fidelityrepresentation of complex signals across 3D shapes and 4D mesh animationswithin one single unified framework.", "output": "HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "To drive safely in complex traffic environments, autonomous vehicles need tomake an accurate prediction of the future trajectories of nearby heterogeneoustraffic agents (i.e., vehicles, pedestrians, bicyclists, etc). Due to theinteractive nature, human drivers are accustomed to infer what the futuresituations will become if they are going to execute different maneuvers. Tofully exploit the impacts of interactions, this paper proposes a ego-planningguided multi-graph convolutional network (EPG-MGCN) to predict the trajectoriesof heterogeneous agents using both historical trajectory information and egovehicle's future planning information. The EPG-MGCN first models the socialinteractions by employing four graph topologies, i.e., distance graphs,visibility graphs, planning graphs and category graphs. Then, the planninginformation of the ego vehicle is encoded by both the planning graph and thesubsequent planning-guided prediction module to reduce uncertainty in thetrajectory prediction. Finally, a category-specific gated recurrent unit(CS-GRU) encoder-decoder is designed to generate future trajectories for eachspecific type of agents. Our network is evaluated on two real-world trajectorydatasets: ApolloScape and NGSIM. The experimental results show that theproposed EPG-MGCN achieves state-of-the-art performance compared to existingmethods.", "output": "EPG-MGCN: Ego-Planning Guided Multi-Graph Convolutional Network for Heterogeneous Agent Trajectory Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Immersion plays a vital role when designing cinematic creations, yet thedifficulty in immersive shooting prevents designers to create satisfactoryoutputs. In this work, we analyze the specific components that contribute tocinematographic immersion considering spatial, emotional, and aesthetic level,while these components are then combined into a high-level evaluationmechanism. Guided by such a immersion mechanism, we propose a GAN-based cameracontrol system that is able to generate actor-driven camera movements in the 3Dvirtual environment to obtain immersive film sequences. The proposedencoder-decoder architecture in the generation flow transfers character motioninto camera trajectory conditioned on an emotion factor. This ensures spatialand emotional immersion by performing actor-camera synchronization physicallyand psychologically. The emotional immersion is further strengthened byincorporating regularization that controls camera shakiness for expressingdifferent mental statuses. To achieve aesthetic immersion, we make effort toimprove aesthetic frame compositions by modifying the synthesized cameratrajectory. Based on a self-supervised adjustor, the adjusted camera placementscan project the character to the appropriate on-frame locations followingaesthetic rules. The experimental results indicate that our proposed cameracontrol system can efficiently offer immersive cinematic videos, bothquantitatively and qualitatively, based on a fine-grained immersive shooting.Live examples are shown in the supplementary video.", "output": "The secret of immersion: actor driven camera movement generation for auto-cinematography."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study the problem of federated stochastic multi-arm contextual banditswith unknown contexts, in which M agents are faced with different bandits andcollaborate to learn. The communication model consists of a central server andthe agents share their estimates with the central server periodically to learnto choose optimal actions in order to minimize the total regret. We assume thatthe exact contexts are not observable and the agents observe only adistribution of the contexts. Such a situation arises, for instance, when thecontext itself is a noisy measurement or based on a prediction mechanism. Ourgoal is to develop a distributed and federated algorithm that facilitatescollaborative learning among the agents to select a sequence of optimal actionsso as to maximize the cumulative reward. By performing a feature vectortransformation, we propose an elimination-based algorithm and prove the regretbound for linearly parametrized reward functions. Finally, we validated theperformance of our algorithm and compared it with another baseline approachusing numerical simulations on synthetic data and on the real-world movielensdataset.", "output": "Federated Stochastic Bandit Learning with Unobserved Context."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study the parameterized complexity of training two-layer neural networkswith respect to the dimension of the input data and the number of hiddenneurons, considering ReLU and linear threshold activation functions. Albeit thecomputational complexity of these problems has been studied numerous times inrecent years, several questions are still open. We answer questions by Arora etal. [ICLR '18] and Khalife and Basu [IPCO '22] showing that both problems areNP-hard for two dimensions, which excludes any polynomial-time algorithm forconstant dimension. We also answer a question by Froese et al. [JAIR '22]proving W[1]-hardness for four ReLUs (or two linear threshold neurons) withzero training error. Finally, in the ReLU case, we show fixed-parametertractability for the combined parameter number of dimensions and number ofReLUs if the network is assumed to compute a convex map. Our results settle thecomplexity status regarding these parameters almost completely.", "output": "Training Neural Networks is NP-Hard in Fixed Dimension."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "When training a machine learning model with differential privacy, one sets aprivacy budget. This budget represents a maximal privacy violation that anyuser is willing to face by contributing their data to the training set. Weargue that this approach is limited because different users may have differentprivacy expectations. Thus, setting a uniform privacy budget across all pointsmay be overly conservative for some users or, conversely, not sufficientlyprotective for others. In this paper, we capture these preferences throughindividualized privacy budgets. To demonstrate their practicality, we introducea variant of Differentially Private Stochastic Gradient Descent (DP-SGD) whichsupports such individualized budgets. DP-SGD is the canonical approach totraining models with differential privacy. We modify its data sampling andgradient noising mechanisms to arrive at our approach, which we callIndividualized DP-SGD (IDP-SGD). Because IDP-SGD provides privacy guaranteestailored to the preferences of individual users and their data points, we findit empirically improves privacy-utility trade-offs.", "output": "Have it your way: Individualized Privacy Assignment for DP-SGD."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Sound source localization is a typical and challenging task that predicts thelocation of sound sources in a video. Previous single-source methods mainlyused the audio-visual association as clues to localize sounding objects in eachimage. Due to the mixed property of multiple sound sources in the originalspace, there exist rare multi-source approaches to localizing multiple sourcessimultaneously, except for one recent work using a contrastive random walk inthe graph with images and separated sound as nodes. Despite their promisingperformance, they can only handle a fixed number of sources, and they cannotlearn compact class-aware representations for individual sources. To alleviatethis shortcoming, in this paper, we propose a novel audio-visual groupingnetwork, namely AVGN, that can directly learn category-wise semantic featuresfor each source from the input audio mixture and image to localize multiplesources simultaneously. Specifically, our AVGN leverages learnable audio-visualclass tokens to aggregate class-aware source features. Then, the aggregatedsemantic features for each source can be used as guidance to localize thecorresponding visual regions. Compared to existing multi-source methods, ournew framework can localize a flexible number of sources and disentanglecategory-aware audio-visual representations for individual sound sources. Weconduct extensive experiments on MUSIC, VGGSound-Instruments, and VGG-SoundSources benchmarks. The results demonstrate that the proposed AVGN can achievestate-of-the-art sounding object localization performance on both single-sourceand multi-source scenarios. Code is available aturl{", "output": "Audio-Visual Grouping Network for Sound Localization from Mixtures."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a methodology for formulating simplifying abstractions in machinelearning systems by identifying and harnessing the utility structure ofdecisions. Machine learning tasks commonly involve high-dimensional outputspaces (e.g., predictions for every pixel in an image or node in a graph), eventhough a coarser output would often suffice for downstream decision-making(e.g., regions of an image instead of pixels). Developers often hand-engineerabstractions of the output space, but numerous abstractions are possible and itis unclear how the choice of output space for a model impacts its usefulness indownstream decision-making. We propose a method that configures the outputspace automatically in order to minimize the loss of decision-relevantinformation. Taking a geometric perspective, we formulate a step of thealgorithm as a projection of the probability simplex, termed fold, thatminimizes the total loss of decision-related information in the H-entropysense. Crucially, learning in the abstracted outcome space requires less data,leading to a net improvement in decision quality. We demonstrate the method intwo domains: data acquisition for deep neural network training and aclosed-loop wildfire management task.", "output": "Ideal Abstractions for Decision-Focused Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large language models (LLMs) have emerged as valuable tools for many naturallanguage understanding tasks. In safety-critical applications such ashealthcare, the utility of these models is governed by their ability togenerate outputs that are factually accurate and complete. In this work, wepresent dialog-enabled resolving agents (DERA). DERA is a paradigm madepossible by the increased conversational abilities of LLMs, namely GPT-4. Itprovides a simple, interpretable forum for models to communicate feedback anditeratively improve output. We frame our dialog as a discussion between twoagent types - a Researcher, who processes information and identifies crucialproblem components, and a Decider, who has the autonomy to integrate theResearcher's information and makes judgments on the final output.We test DERA against three clinically-focused tasks. For medical conversationsummarization and care plan generation, DERA shows significant improvement overthe base GPT-4 performance in both human expert preference evaluations andquantitative metrics. In a new finding, we also show that GPT-4's performance(70%) on an open-ended version of the MedQA question-answering (QA) dataset(Jin et al. 2021, USMLE) is well above the passing level (60%), with DERAshowing similar performance. We release the open-ended MEDQA dataset at", "output": "DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present DiffCollage, a compositional diffusion model that can generatelarge content by leveraging diffusion models trained on generating pieces ofthe large content. Our approach is based on a factor graph representation whereeach factor node represents a portion of the content and a variable noderepresents their overlap. This representation allows us to aggregateintermediate outputs from diffusion models defined on individual nodes togenerate content of arbitrary size and shape in parallel without resorting toan autoregressive generation procedure. We apply DiffCollage to various tasks,including infinite image generation, panorama image generation, andlong-duration text-guided motion generation. Extensive experimental resultswith a comparison to strong autoregressive baselines verify the effectivenessof our approach.", "output": "DiffCollage: Parallel Generation of Large Content with Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Partial differential equations (PDEs) are among the most universal andparsimonious descriptions of natural physical laws, capturing a rich variety ofphenomenology and multi-scale physics in a compact and symbolic representation.This review will examine several promising avenues of PDE research that arebeing advanced by machine learning, including: 1) the discovery of newgoverning PDEs and coarse-grained approximations for complex natural andengineered systems, 2) learning effective coordinate systems and reduced-ordermodels to make PDEs more amenable to analysis, and 3) representing solutionoperators and improving traditional numerical algorithms. In each of thesefields, we summarize key advances, ongoing challenges, and opportunities forfurther development.", "output": "Machine Learning for Partial Differential Equations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we present a data poisoning attack that confounds machinelearning models without any manipulation of the image or label. This isachieved by simply leveraging the most confounding natural samples found withinthe training data itself, in a new form of a targeted attack coined \"MoleRecruitment.\" We define moles as the training samples of a class that appearmost similar to samples of another class, and show that simply restructuringtraining batches with an optimal number of moles can lead to significantdegradation in the performance of the targeted class. We show the efficacy ofthis novel attack in an offline setting across several standard imageclassification datasets, and demonstrate the real-world viability of thisattack in a continual learning (CL) setting. Our analysis reveals thatstate-of-the-art models are susceptible to Mole Recruitment, thereby exposing apreviously undetected vulnerability of image classifiers.", "output": "Mole Recruitment: Poisoning of Image Classifiers via Selective Batch Sampling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reliable confidence estimation for deep neural classifiers is a challengingyet fundamental requirement in high-stakes applications. Unfortunately, moderndeep neural networks are often overconfident for their erroneous predictions.In this work, we exploit the easily available outlier samples, i.e., unlabeledsamples coming from non-target classes, for helping detect misclassificationerrors. Particularly, we find that the well-known Outlier Exposure, which ispowerful in detecting out-of-distribution (OOD) samples from unknown classes,does not provide any gain in identifying misclassification errors. Based onthese observations, we propose a novel method called OpenMix, whichincorporates open-world knowledge by learning to reject uncertainpseudo-samples generated via outlier transformation. OpenMix significantlyimproves confidence reliability under various scenarios, establishing a strongand unified framework for detecting both misclassified samples from knownclasses and OOD samples from unknown classes. The code is publicly available at", "output": "OpenMix: Exploring Outlier Samples for Misclassification Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper deals with the problem of efficient sampling from a stochasticdifferential equation, given the drift function and the diffusion matrix. Theproposed approach leverages a recent model for probabilitiescitep{rudi2021psd} (the positive semi-definite -- PSD model) from which it ispossible to obtain independent and identically distributed (i.i.d.) samples atprecision $varepsilon$ with a cost that is $m^2 d log(1/varepsilon)$ where$m$ is the dimension of the model, $d$ the dimension of the space. The proposedapproach consists in: first, computing the PSD model that satisfies theFokker-Planck equation (or its fractional variant) associated with the SDE, upto error $varepsilon$, and then sampling from the resulting PSD model.Assuming some regularity of the Fokker-Planck solution (i.e. $beta$-timesdifferentiability plus some geometric condition on its zeros) We obtain analgorithm that: (a) in the preparatory phase obtains a PSD model with L2distance $varepsilon$ from the solution of the equation, with a model ofdimension $m = varepsilon^{-(d+1)/(beta-2s)} (log(1/varepsilon))^{d+1}$where $0&lt;sleq1$ is the fractional power to the Laplacian, and totalcomputational complexity of $O(m^{3.5} log(1/varepsilon))$ and then (b) forFokker-Planck equation, it is able to produce i.i.d. samples with error$varepsilon$ in Wasserstein-1 distance, with a cost that is $O(dvarepsilon^{-2(d+1)/beta-2} log(1/varepsilon)^{2d+3})$ per sample. Thismeans that, if the probability associated with the SDE is somewhat regular,i.e. $beta geq 4d+2$, then the algorithm requires $O(varepsilon^{-0.88}log(1/varepsilon)^{4.5d})$ in the preparatory phase, and$O(varepsilon^{-1/2}log(1/varepsilon)^{2d+2})$ for each sample. Our resultssuggest that as the true solution gets smoother, we can circumvent the curse ofdimensionality without requiring any sort of convexity.", "output": "Efficient Sampling of Stochastic Differential Equations with Positive Semi-Definite Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study contextual combinatorial bandits with probabilistically triggeredarms (C$^2$MAB-T) under a variety of smoothness conditions that capture a widerange of applications, such as contextual cascading bandits and contextualinfluence maximization bandits. Under the triggering probability modulated(TPM) condition, we devise the C$^2$-UCB-T algorithm and propose a novelanalysis that achieves an $tilde{O}(dsqrt{KT})$ regret bound, removing apotentially exponentially large factor $O(1/p_{min})$, where $d$ is thedimension of contexts, $p_{min}$ is the minimum positive probability that anyarm can be triggered, and batch-size $K$ is the maximum number of arms that canbe triggered per round. Under the variance modulated (VM) or triggeringprobability and variance modulated (TPVM) conditions, we propose a newvariance-adaptive algorithm VAC$^2$-UCB and derive a regret bound$tilde{O}(dsqrt{T})$, which is independent of the batch-size $K$. As avaluable by-product, we find our analysis technique and variance-adaptivealgorithm can be applied to the CMAB-T and C$^2$MAB~setting, improving existingresults there as well. We also include experiments that demonstrate theimproved performance of our algorithms compared with benchmark algorithms onsynthetic and real-world datasets.", "output": "Contextual Combinatorial Bandits with Probabilistically Triggered Arms."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the phenomenal success of diffusion models and ChatGPT, deep generationmodels (DGMs) have been experiencing explosive growth from 2022. Not limited tocontent generation, DGMs are also widely adopted in Internet of Things,Metaverse, and digital twin, due to their outstanding ability to representcomplex patterns and generate plausible samples. In this article, we explorethe applications of DGMs in a crucial task, i.e., improving the efficiency ofwireless network management. Specifically, we firstly overview the generativeAI, as well as three representative DGMs. Then, a DGM-empowered framework forwireless network management is proposed, in which we elaborate the issues ofthe conventional network management approaches, why DGMs can address themefficiently, and the step-by-step workflow for applying DGMs in managingwireless networks. Moreover, we conduct a case study on network economics,using the state-of-the-art DGM model, i.e., diffusion model, to generateeffective contracts for incentivizing the mobile AI-Generated Content (AIGC)services. Last but not least, we discuss important open directions for thefurther research.", "output": "Deep Generative Model and Its Applications in Efficient Wireless Network Management: A Tutorial and Case Study."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Masked Autoencoder (MAE) has demonstrated superior performance on variousvision tasks via randomly masking image patches and reconstruction. However,effective data augmentation strategies for MAE still remain open questions,different from those in contrastive learning that serve as the most importantpart. This paper studies the prevailing mixing augmentation for MAE. We firstdemonstrate that naive mixing will in contrast degenerate model performance dueto the increase of mutual information (MI). To address, we propose homologousrecognition, an auxiliary pretext task, not only to alleviate the MIincreasement by explicitly requiring each patch to recognize homologouspatches, but also to perform object-aware self-supervised pre-training forbetter downstream dense perception performance. With extensive experiments, wedemonstrate that our proposed Mixed Autoencoder (MixedAE) achieves thestate-of-the-art transfer results among masked image modeling (MIM)augmentations on different downstream tasks with significant efficiency.Specifically, our MixedAE outperforms MAE by +0.3% accuracy, +1.7 mIoU and +0.9AP on ImageNet-1K, ADE20K and COCO respectively with a standard ViT-Base.Moreover, MixedAE surpasses iBOT, a strong MIM method combined with instancediscrimination, while accelerating training by 2x. To our best knowledge, thisis the very first work to consider mixing for MIM from the perspective ofpretext task design. Code will be made available.", "output": "Mixed Autoencoder for Self-supervised Visual Representation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study a new paradigm for sequential decision making, called offline PolicyLearning from Observation (PLfO). Offline PLfO aims to learn policies usingdatasets with substandard qualities: 1) only a subset of trajectories islabeled with rewards, 2) labeled trajectories may not contain actions, 3)labeled trajectories may not be of high quality, and 4) the overall data maynot have full coverage. Such imperfection is common in real-world learningscenarios, so offline PLfO encompasses many existing offline learning setups,including offline imitation learning (IL), ILfO, and reinforcement learning(RL). In this work, we present a generic approach, called Modality-agnosticAdversarial Hypothesis Adaptation for Learning from Observations (MAHALO), foroffline PLfO. Built upon the pessimism concept in offline RL, MAHALO optimizesthe policy using a performance lower bound that accounts for uncertainty due tothe dataset's insufficient converge. We implement this idea by adversariallytraining data-consistent critic and reward functions in policy optimization,which forces the learned policy to be robust to the data deficiency. We showthat MAHALO consistently outperforms or matches specialized algorithms across avariety of offline PLfO tasks in theory and experiments.", "output": "MAHALO: Unifying Offline Reinforcement Learning and Imitation Learning from Observations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "For Human Action Recognition tasks (HAR), 3D Convolutional Neural Networkshave proven to be highly effective, achieving state-of-the-art results. Thisstudy introduces a novel streaming architecture based toolflow for mapping suchmodels onto FPGAs considering the model's inherent characteristics and thefeatures of the targeted FPGA device. The HARFLOW3D toolflow takes as input a3D CNN in ONNX format and a description of the FPGA characteristics, generatinga design that minimizes the latency of the computation. The toolflow iscomprised of a number of parts, including i) a 3D CNN parser, ii) a performanceand resource model, iii) a scheduling algorithm for executing 3D models on thegenerated hardware, iv) a resource-aware optimization engine tailored for 3Dmodels, v) an automated mapping to synthesizable code for FPGAs. The ability ofthe toolflow to support a broad range of models and devices is shown through anumber of experiments on various 3D CNN and FPGA system pairs. Furthermore, thetoolflow has produced high-performing results for 3D CNN models that have notbeen mapped to FPGAs before, demonstrating the potential of FPGA-based systemsin this space. Overall, HARFLOW3D has demonstrated its ability to delivercompetitive latency compared to a range of state-of-the-art hand-tunedapproaches being able to achieve up to 5$times$ better performance compared tosome of the existing works.", "output": "HARFLOW3D: A Latency-Oriented 3D-CNN Accelerator Toolflow for HAR on FPGA Devices."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Given a graph with a subset of labeled nodes, we are interested in thequality of the averaging estimator which for an unlabeled node predicts theaverage of the observations of its labeled neighbours. We rigorously studyconcentration properties, variance bounds and risk bounds in this context.While the estimator itself is very simple and the data generating process istoo idealistic for practical applications, we believe that our small steps willcontribute towards the theoretical understanding of more sophisticated methodssuch as Graph Neural Networks.", "output": "The Graphical Nadaraya-Watson Estimator on Latent Position Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Self-supervised learning (SSL) has shown remarkable performance in computervision tasks when trained offline. However, in a Continual Learning (CL)scenario where new data is introduced progressively, models still suffer fromcatastrophic forgetting. Retraining a model from scratch to adapt to newlygenerated data is time-consuming and inefficient. Previous approaches suggestedre-purposing self-supervised objectives with knowledge distillation to mitigateforgetting across tasks, assuming that labels from all tasks are availableduring fine-tuning. In this paper, we generalize self-supervised continuallearning in a practical setting where available labels can be leveraged in anystep of the SSL process. With an increasing number of continual tasks, thisoffers more flexibility in the pre-training and fine-tuning phases. WithKaizen, we introduce a training architecture that is able to mitigatecatastrophic forgetting for both the feature extractor and classifier with acarefully designed loss function. By using a set of comprehensive evaluationmetrics reflecting different aspects of continual learning, we demonstratedthat Kaizen significantly outperforms previous SSL models in competitive visionbenchmarks, with up to 16.5% accuracy improvement on split CIFAR-100. Kaizen isable to balance the trade-off between knowledge retention and learning from newdata with an end-to-end model, paving the way for practical deployment ofcontinual learning systems.", "output": "Practical self-supervised continual learning with continual fine-tuning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In spite of increased attention on explainable machine learning models,explaining multi-output predictions has not yet been extensively addressed.Methods that use Shapley values to attribute feature contributions to thedecision making are one of the most popular approaches to explain localindividual and global predictions. By considering each output separately inmulti-output tasks, these methods fail to provide complete featureexplanations. We propose Shapley Chains to overcome this issue by includinglabel interdependencies in the explanation design process. Shapley Chainsassign Shapley values as feature importance scores in multi-outputclassification using classifier chains, by separating the direct and indirectinfluence of these feature scores. Compared to existing methods, this approachallows to attribute a more complete feature contribution to the predictions ofmulti-output classification tasks. We provide a mechanism to distribute thehidden contributions of the outputs with respect to a given chaining order ofthese outputs. Moreover, we show how our approach can reveal indirect featurecontributions missed by existing approaches. Shapley Chains help to emphasizethe real learning factors in multi-output applications and allows a betterunderstanding of the flow of information through output interdependencies insynthetic and real-world datasets.", "output": "Shapley Chains: Extending Shapley Values to Classifier Chains."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-view clustering (MvC) aims at exploring the category structure amongmulti-view data without label supervision. Multiple views provide moreinformation than single views and thus existing MvC methods can achievesatisfactory performance. However, their performance might seriously degeneratewhen the views are noisy in practical scenarios. In this paper, we firstformally investigate the drawback of noisy views and then propose atheoretically grounded deep MvC method (namely MvCAN) to address this issue.Specifically, we propose a novel MvC objective that enables un-sharedparameters and inconsistent clustering predictions across multiple views toreduce the side effects of noisy views. Furthermore, a non-parametric iterativeprocess is designed to generate a robust learning target for mining multipleviews' useful information. Theoretical analysis reveals that MvCAN works byachieving the multi-view consistency, complementarity, and noise robustness.Finally, experiments on public datasets demonstrate that MvCAN outperformsstate-of-the-art methods and is robust against the existence of noisy views.", "output": "Investigating and Mitigating the Side Effects of Noisy Views in Multi-view Clustering in Practical Scenarios."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The science of social bots seeks knowledge and solutions to one of the mostdebated forms of online misinformation. Yet, social bots research is plagued bywidespread biases, hyped results, and misconceptions that set the stage forambiguities, unrealistic expectations, and seemingly irreconcilable findings.Overcoming such issues is instrumental towards ensuring reliable solutions andreaffirming the validity of the scientific method. In this contribution werevise some recent results in social bots research, highlighting and correctingfactual errors as well as methodological and conceptual issues. Moreimportantly, we demystify common misconceptions, addressing fundamental pointson how social bots research is discussed. Our analysis surfaces the need todiscuss misinformation research in a rigorous, unbiased, and responsible way.This article bolsters such effort by identifying and refuting common fallaciousarguments used by both proponents and opponents of social bots research as wellas providing indications on the correct methodologies and sound directions forfuture research in the field.", "output": "Demystifying Misconceptions in Social Bots Research."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Disentangling complex data to its latent factors of variation is afundamental task in representation learning. Existing work on sequentialdisentanglement mostly provides two factor representations, i.e., it separatesthe data to time-varying and time-invariant factors. In contrast, we considermultifactor disentanglement in which multiple (more than two) semanticdisentangled components are generated. Key to our approach is a stronginductive bias where we assume that the underlying dynamics can be representedlinearly in the latent space. Under this assumption, it becomes natural toexploit the recently introduced Koopman autoencoder models. However,disentangled representations are not guaranteed in Koopman approaches, and thuswe propose a novel spectral loss term which leads to structured Koopmanmatrices and disentanglement. Overall, we propose a simple and easy to code newdeep model that is fully unsupervised and it supports multifactordisentanglement. We showcase new disentangling abilities such as swapping ofindividual static factors between characters, and an incremental swap ofdisentangled factors from the source to the target. Moreover, we evaluate ourmethod extensively on two factor standard benchmark tasks where wesignificantly improve over competing unsupervised approaches, and we performcompetitively in comparison to weakly- and self-supervised state-of-the-artapproaches. The code is available at ", "output": "Multifactor Sequential Disentanglement via Structured Koopman Autoencoders."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Increase in computational scale and fine-tuning has seen a dramaticimprovement in the quality of outputs of large language models (LLMs) like GPT.Given that both GPT-3 and GPT-4 were trained on large quantities ofhuman-generated text, we might ask to what extent their outputs reflectpatterns of human thinking, both for correct and incorrect cases. The EroteticTheory of Reason (ETR) provides a symbolic generative model of both humansuccess and failure in thinking, across propositional, quantified, andprobabilistic reasoning, as well as decision-making. We presented GPT-3,GPT-3.5, and GPT-4 with 61 central inference and judgment problems from arecent book-length presentation of ETR, consisting of experimentally verifieddata-points on human judgment and extrapolated data-points predicted by ETR,with correct inference patterns as well as fallacies and framing effects (theETR61 benchmark). ETR61 includes classics like Wason's card task, illusoryinferences, the decoy effect, and opportunity-cost neglect, among others. GPT-3showed evidence of ETR-predicted outputs for 59% of these examples, rising to77% in GPT-3.5 and 75% in GPT-4. Remarkably, the production of human-likefallacious judgments increased from 18% in GPT-3 to 33% in GPT-3.5 and 34% inGPT-4. This suggests that larger and more advanced LLMs may develop a tendencytoward more human-like mistakes, as relevant thought patterns are inherent inhuman-produced training data. According to ETR, the same fundamental patternsare involved both in successful and unsuccessful ordinary reasoning, so thatthe \"bad\" cases could paradoxically be learned from the \"good\" cases. Wefurther present preliminary evidence that ETR-inspired prompt engineering couldreduce instances of these mistakes.", "output": "Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a generic spatiotemporal framework to analyze manifold-valuedmeasurements, which allows for employing an intrinsic and computationallyefficient Riemannian hierarchical model. Particularly, utilizing regression, werepresent discrete trajectories in a Riemannian manifold by composite B' eziersplines, propose a natural metric induced by the Sasaki metric to compare thetrajectories, and estimate average trajectories as group-wise trends. Weevaluate our framework in comparison to state-of-the-art methods withinqualitative and quantitative experiments on hurricane tracks. Notably, ourresults demonstrate the superiority of spline-based approaches for an intensityclassification of the tracks.", "output": "Sasaki Metric for Spline Models of Manifold-Valued Trajectories."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Along with the rapid evolution of mobile communication technologies, such as5G, there has been a drastically increase in telecom fraud, which significantlydissipates individual fortune and social wealth. In recent years, graph miningtechniques are gradually becoming a mainstream solution for detecting telecomfraud. However, the graph imbalance problem, caused by the Pareto principle,brings severe challenges to graph data mining. This is a new and challengingproblem, but little previous work has been noticed. In this paper, we propose aGraph ATtention network with COst-sensitive BOosting (GAT-COBO) for the graphimbalance problem. First, we design a GAT-based base classifier to learn theembeddings of all nodes in the graph. Then, we feed the embeddings into awell-designed cost-sensitive learner for imbalanced learning. Next, we updatethe weights according to the misclassification cost to make the model focusmore on the minority class. Finally, we sum the node embeddings obtained bymultiple cost-sensitive learners to obtain a comprehensive node representation,which is used for the downstream anomaly detection task. Extensive experimentson two real-world telecom fraud detection datasets demonstrate that ourproposed method is effective for the graph imbalance problem, outperforming thestate-of-the-art GNNs and GNN-based fraud detectors. In addition, our model isalso helpful for solving the widespread over-smoothing problem in GNNs. TheGAT-COBO code and datasets are available at ", "output": "GAT-COBO: Cost-Sensitive Graph Neural Network for Telecom Fraud Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the machine learning domain, research on anomaly detection andlocalization within image data has garnered significant attention, particularlyin practical applications such as industrial defect detection. While existingapproaches predominantly rely on Convolutional Neural Networks (CNN) as theirbackbone network, we propose an innovative method based on the Transformerbackbone network. Our approach employs a two-stage incremental learningstrategy. In the first stage, we train a Masked Autoencoder (MAE) modelexclusively on normal images. Subsequently, in the second stage, we implementpixel-level data augmentation techniques to generate corrupted normal imagesand their corresponding pixel labels. This process enables the model to learnhow to repair corrupted regions and classify the state of each pixel.Ultimately, the model produces a pixel reconstruction error matrix and a pixelanomaly probability matrix, which are combined to create an anomaly scoringmatrix that effectively identifies abnormal regions. When compared to severalstate-of-the-art CNN-based techniques, our method demonstrates superiorperformance on the MVTec AD dataset, achieving an impressive 97.6% AUC.", "output": "Incremental Self-Supervised Learning Based on Transformer for Anomaly Detection and Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes a client selection (CS) method to tackle thecommunication bottleneck of federated learning (FL) while concurrently copingwith FL's data heterogeneity issue. Specifically, we first analyze the effectof CS in FL and show that FL training can be accelerated by adequately choosingparticipants to diversify the training dataset in each round of training. Basedon this, we leverage data profiling and determinantal point process (DPP)sampling techniques to develop an algorithm termed Federated Learning withDPP-based Participant Selection (FL-DP$^3$S). This algorithm effectivelydiversifies the participants' datasets in each round of training whilepreserving their data privacy. We conduct extensive experiments to examine theefficacy of our proposed method. The results show that our scheme attains afaster convergence rate, as well as a smaller communication overhead thanseveral baselines.", "output": "DPP-based Client Selection for Federated Learning with Non-IID Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We show that symmetrically padded convolution can be analytically invertedvia DFT. We comprehensively analyze several different symmetric andanti-symmetric padding modes and show that multiple cases exist where theinversion can be achieved. The implementation is available aturl{", "output": "Invertible Convolution with Symmetric Paddings."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "There has been a recent explosion of computer vision models which performmany tasks and are composed of an image encoder (usually a ViT) and anautoregressive decoder (usually a Transformer). However, most of this worksimply presents one system and its results, leaving many questions regardingdesign decisions and trade-offs of such systems unanswered. In this work, weaim to provide such answers. We take a close look at autoregressive decodersfor multi-task learning in multimodal computer vision, includingclassification, captioning, visual question answering, and optical characterrecognition. Through extensive systematic experiments, we study the effects oftask and data mixture, training and regularization hyperparameters,conditioning type and specificity, modality combination, and more. Importantly,we compare these to well-tuned single-task baselines to highlight the costincurred by multi-tasking. A key finding is that a small decoder learned on topof a frozen pretrained encoder works surprisingly well. We call this setuplocked-image tuning with decoder (LiT-decoder). It can be seen as teaching adecoder to interact with a pretrained vision model via natural language.", "output": "A Study of Autoregressive Decoders for Multi-Tasking in Computer Vision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The current state of the art systems in Artificial Intelligence (AI) enabledintrusion detection use a variety of black box methods. These black box methodsare generally trained using Error Based Learning (EBL) techniques with a focuson creating accurate models. These models have high performative costs and arenot easily explainable. A white box Competitive Learning (CL) based eXplainableIntrusion Detection System (X-IDS) offers a potential solution to theseproblem. CL models utilize an entirely different learning paradigm than EBLapproaches. This different learning process makes the CL family of algorithmsinnately explainable and less resource intensive. In this paper, we create anX-IDS architecture that is based on DARPA's recommendation for explainablesystems. In our architecture we leverage CL algorithms like, Self OrganizingMaps (SOM), Growing Self Organizing Maps (GSOM), and Growing Hierarchical SelfOrganizing Map (GHSOM). The resulting models can be data-mined to createstatistical and visual explanations. Our architecture is tested using NSL-KDDand CIC-IDS-2017 benchmark datasets, and produces accuracies that are 1% - 3%less than EBL models. However, CL models are much more explainable than EBLmodels. Additionally, we use a pruning process that is able to significantlyreduce the size of these CL based models. By pruning our models, we are able toincrease prediction speeds. Lastly, we analyze the statistical and visualexplanations generated by our architecture, and we give a strategy that userscould use to help navigate the set of explanations. These explanations willhelp users build trust with an Intrusion Detection System (IDS), and allowusers to discover ways to increase the IDS's potency.", "output": "Explainable Intrusion Detection Systems Using Competitive Learning Techniques."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Offline reinforcement learning (RL) allows for the training of competentagents from offline datasets without any interaction with the environment.Online finetuning of such offline models can further improve performance. Buthow should we ideally finetune agents obtained from offline RL training? Whileoffline RL algorithms can in principle be used for finetuning, in practice,their online performance improves slowly. In contrast, we show that it ispossible to use standard online off-policy algorithms for faster improvement.However, we find this approach may suffer from policy collapse, where thepolicy undergoes severe performance deterioration during initial onlinelearning. We investigate the issue of policy collapse and how it relates todata diversity, algorithm choices and online replay distribution. Based onthese insights, we propose a conservative policy optimization procedure thatcan achieve stable and sample-efficient online learning from offlinepretraining.", "output": "Finetuning from Offline Reinforcement Learning: Challenges, Trade-offs and Practical Solutions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Removing supervision in semantic segmentation is still tricky. Currentapproaches can deal with common categorical patterns yet resort to multi-stagearchitectures. We design a novel end-to-end model leveraging local-global patchmatching to predict categories, good localization, area and shape of objectsfor semantic segmentation. The local-global matching is, in turn, compelled byoptimal transport plans fulfilling area constraints nearing a solution forexact shape prediction. Our model attains state-of-the-art in Weakly SupervisedSemantic Segmentation, only image-level labels, with 75% mIoU on PascalVOC2012val set and 46% on MS-COCO2014 val set. Dropping the image-level labels andclustering self-supervised learned features to yield pseudo-multi-level labels,we obtain an unsupervised model for semantic segmentation. We also attainstate-of-the-art on Unsupervised Semantic Segmentation with 43.6% mIoU onPascalVOC2012 val set and 19.4% on MS-COCO2014 val set. The code is availableat ", "output": "Removing supervision in semantic segmentation with local-global matching and area balancing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Change detection (CD) in heterogeneous remote sensing images is a practicaland challenging issue for real-life emergencies. In the past decade, theheterogeneous CD problem has significantly benefited from the development ofdeep neural networks (DNN). However, the data-driven DNNs always perform like ablack box where the lack of interpretability limits the trustworthiness andcontrollability of DNNs in most practical CD applications. As a strongknowledge-driven tool to measure correlation between random variables, Copulatheory has been introduced into CD, yet it suffers from non-robust CDperformance without manual prior selection for Copula functions. To address theabove issues, we propose a knowledge-data-driven heterogeneous CD method(NN-Copula-CD) based on the Copula-guided interpretable neural network. In ourNN-Copula-CD, the mathematical characteristics of Copula are designed as thelosses to supervise a simple fully connected neural network to learn thecorrelation between bi-temporal image patches, and then the changed regions areidentified via binary classification for the correlation coefficients of allimage patch pairs of the bi-temporal images. We conduct in-depth experiments onthree datasets with multimodal images (e.g., Optical, SAR, and NIR), where thequantitative results and visualized analysis demonstrate both the effectivenessand interpretability of the proposed NN-Copula-CD.", "output": "NN-Copula-CD: A Copula-Guided Interpretable Neural Network for Change Detection in Heterogeneous Remote Sensing Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Relational events are a type of social interactions, that sometimes arereferred to as dynamic networks. Its dynamics typically depends on emergingpatterns, so-called endogenous variables, or external forces, referred to asexogenous variables. Comprehensive information on the actors in the network,especially for huge networks, is rare, however. A latent space approach innetwork analysis has been a popular way to account for unmeasured covariatesthat are driving network configurations. Bayesian and EM-type algorithms havebeen proposed for inferring the latent space, but both the sheer size manysocial network applications as well as the dynamic nature of the process, andtherefore the latent space, make computations prohibitively expensive. In thiswork we propose a likelihood-based algorithm that can deal with huge relationalevent networks. We propose a hierarchical strategy for inferring networkcommunity dynamics embedded into an interpretable latent space. Node dynamicsare described by smooth spline processes. To make the framework feasible forlarge networks we borrow from machine learning optimization methodology.Model-based clustering is carried out via a convex clustering penalization,encouraging shared trajectories for ease of interpretation. We propose amodel-based approach for separating macro-microstructures and perform ahierarchical analysis within successive hierarchies. The method can fitmillions of nodes on a public Colab GPU in a few minutes. The code and atutorial are available in a Github repository.", "output": "Fast inference of latent space dynamics in huge relational event networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Business Process Simulation (BPS) is an approach to analyze the performanceof business processes under different scenarios. For example, BPS allows us toestimate what would be the cycle time of a process if one or more resourcesbecame unavailable. The starting point of BPS is a process model annotated withsimulation parameters (a BPS model). BPS models may be manually designed, basedon information collected from stakeholders and empirical observations, orautomatically discovered from execution data. Regardless of its origin, a keyquestion when using a BPS model is how to assess its quality. In this paper, wepropose a collection of measures to evaluate the quality of a BPS model w.r.t.its ability to replicate the observed behavior of the process. We advocate anapproach whereby different measures tackle different process perspectives. Weevaluate the ability of the proposed measures to discern the impact ofmodifications to a BPS model, and their ability to uncover the relativestrengths and weaknesses of two approaches for automated discovery of BPSmodels. The evaluation shows that the measures not only capture how close a BPSmodel is to the observed behavior, but they also help us to identify sources ofdiscrepancies.", "output": "Can I Trust My Simulation Model? Measuring the Quality of Business Process Simulation Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents a novel methodology that uses surrogate models in theform of neural networks to reduce the computation time of simulation-basedoptimization of a reference trajectory. Simulation-based optimization isnecessary when there is no analytical form of the system accessible, onlyinput-output data that can be used to create a surrogate model of thesimulation. Like many high-fidelity simulations, this trajectory planningsimulation is very nonlinear and computationally expensive, making itchallenging to optimize iteratively. Through gradient descent optimization, ourapproach finds the optimal reference trajectory for landing a hypersonicvehicle. In contrast to the large datasets used to create the surrogate modelsin prior literature, our methodology is specifically designed to minimize thenumber of simulation executions required by the gradient descent optimizer. Wedemonstrated this methodology to be more efficient than the standard practiceof hand-tuning the inputs through trial-and-error or randomly sampling theinput parameter space. Due to the intelligently selected input values to thesimulation, our approach yields better simulation outcomes that are achievedmore rapidly and to a higher degree of accuracy. Optimizing the hypersonicvehicle's reference trajectory is very challenging due to the simulation'sextreme nonlinearity, but even so, this novel approach found a 74%better-performing reference trajectory compared to nominal, and the numericalresults clearly show a substantial reduction in computation time for designingfuture trajectories.", "output": "Surrogate Neural Networks for Efficient Simulation-based Trajectory Planning Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This article describes an efficient method to learn distributedrepresentations, also known as embeddings. This is accomplished minimizing anobjective function similar to the one introduced in the Word2Vec algorithm andlater adopted in several works. The optimization computational bottleneck isthe calculation of the softmax normalization constants for which a number ofoperations scaling quadratically with the sample size is required. Thiscomplexity is unsuited for large datasets and negative sampling is a popularworkaround, allowing one to obtain distributed representations in linear timewith respect to the sample size. Negative sampling consists, however, in achange of the loss function and hence solves a different optimization problemfrom the one originally proposed. Our contribution is to show that the sotfmaxnormalization constants can be estimated in linear time, allowing us to designan efficient optimization strategy to learn distributed representations. Wetest our approximation on two popular applications related to word and nodeembeddings. The results evidence competing performance in terms of accuracywith respect to negative sampling with a remarkably lower computational time.", "output": "Efficient distributed representations beyond negative sampling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Several research works have applied Reinforcement Learning (RL) algorithms tosolve the Rate Adaptation (RA) problem in Wi-Fi networks. The dynamic nature ofthe radio link requires the algorithms to be responsive to changes in linkquality. Delays in the execution of the algorithm may be detrimental to itsperformance, which in turn may decrease network performance. This aspect hasbeen overlooked in the state of the art. In this paper, we present an analysisof common computational delays in RL-based RA algorithms, and propose amethodology that may be applied to reduce these computational delays andincrease the efficiency of this type of algorithms. We apply the proposedmethodology to an existing RL-based RA algorithm. The obtained experimentalresults indicate a reduction of one order of magnitude in the execution time ofthe algorithm, improving its responsiveness to link quality changes.", "output": "On the Analysis of Computational Delays in Reinforcement Learning-based Rate Adaptation Algorithms."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As an emerging concept cognitive learning model, partial order formalstructure analysis (POFSA) has been widely used in the field of knowledgeprocessing. In this paper, we propose the method named three-way causalattribute partial order structure (3WCAPOS) to evolve the POFSA from setcoverage to causal coverage in order to increase the interpretability andclassification performance of the model. First, the concept of causal factor(CF) is proposed to evaluate the causal correlation between attributes anddecision attributes in the formal decision context. Then, combining CF withattribute partial order structure, the concept of causal attribute partialorder structure is defined and makes set coverage evolve into causal coverage.Finally, combined with the idea of three-way decision, 3WCAPOS is formed, whichmakes the purity of nodes in the structure clearer and the changes betweenlevels more obviously. In addition, the experiments are carried out from theclassification ability and the interpretability of the structure through thesix datasets. Through these experiments, it is concluded the accuracy of3WCAPOS is improved by 1% - 9% compared with classification and regressiontree, and more interpretable and the processing of knowledge is more reasonablecompared with attribute partial order structure.", "output": "Three-way causal attribute partial order structure analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the rapid development of mobile networks, the people's social contactshave been considerably facilitated. However, the rise of mobile social networkfraud upon those networks, has caused a great deal of distress, in case ofdepleting personal and social wealth, then potentially doing significanteconomic harm. To detect fraudulent users, call detail record (CDR) data, whichportrays the social behavior of users in mobile networks, has been widelyutilized. But the imbalance problem in the aforementioned data, which couldseverely hinder the effectiveness of fraud detectors based on graph neuralnetworks(GNN), has hardly been addressed in previous work. In this paper, weare going to present a novel Cost-Sensitive Graph Neural Network (CSGNN) bycreatively combining cost-sensitive learning and graph neural networks. Weconduct extensive experiments on two open-source realworld mobile network frauddatasets. The results show that CSGNN can effectively solve the graph imbalanceproblem and then achieve better detection performance than the state-of-the-artalgorithms. We believe that our research can be applied to solve the graphimbalance problems in other fields. The CSGNN code and datasets are publiclyavailable at ", "output": "Cost Sensitive GNN-based Imbalanced Learning for Mobile Social Network Fraud Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Agents capable of carrying out general tasks on a computer can improveefficiency and productivity by automating repetitive tasks and assisting incomplex problem-solving. Ideally, such agents should be able to solve newcomputer tasks presented to them through natural language commands. However,previous approaches to this problem require large amounts of expertdemonstrations and task-specific reward functions, both of which areimpractical for new tasks. In this work, we show that a pre-trained largelanguage model (LLM) agent can execute computer tasks guided by naturallanguage using a simple prompting scheme where the agent recursively criticizesand improves its output (RCI). The RCI approach significantly outperformsexisting LLM methods for automating computer tasks and surpasses supervisedlearning (SL) and reinforcement learning (RL) approaches on the MiniWoB++benchmark. RCI is competitive with the state-of-the-art SL+RL method, usingonly a handful of demonstrations per task rather than tens of thousands, andwithout a task-specific reward function. Furthermore, we demonstrate RCIprompting's effectiveness in enhancing LLMs' reasoning abilities on a suite ofnatural language reasoning tasks, outperforming chain of thought (CoT)prompting. We find that RCI combined with CoT performs better than eitherseparately.", "output": "Language Models can Solve Computer Tasks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Subgrid parameterizations, which represent physical processes occurring belowthe resolution of current climate models, are an important component inproducing accurate, long-term predictions for the climate. A variety ofapproaches have been tested to design these components, including deep learningmethods. In this work, we evaluate a proof of concept illustrating a multiscaleapproach to this prediction problem. We train neural networks to predictsubgrid forcing values on a testbed model and examine improvements inprediction accuracy that can be obtained by using additional information inboth fine-to-coarse and coarse-to-fine directions.", "output": "Data-driven multiscale modeling of subgrid parameterizations in climate models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose Pgx, a collection of board game simulators written in JAX. Thanksto auto-vectorization and Just-In-Time compilation of JAX, Pgx scales easily tothousands of parallel execution on GPU/TPU accelerators. We found that thesimulation of Pgx on a single A100 GPU is 10x faster than that of existingreinforcement learning libraries. Pgx implements games considered vitalbenchmarks in artificial intelligence research, such as Backgammon, Shogi, andGo. Pgx is available at ", "output": "Pgx: Hardware-accelerated parallel game simulation for reinforcement learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Quantum computing has entered the Noisy Intermediate-Scale Quantum (NISQ)era. Currently, the quantum processors we have are sensitive to environmentalvariables like radiation and temperature, thus producing noisy outputs.Although many proposed algorithms and applications exist for NISQ processors,we still face uncertainties when interpreting their noisy results.Specifically, how much confidence do we have in the quantum states we arepicking as the output? This confidence is important since a NISQ computer willoutput a probability distribution of its qubit measurements, and it issometimes hard to distinguish whether the distribution represents meaningfulcomputation or just random noise. This paper presents a novel approach toattack this problem by framing quantum circuit fidelity prediction as a TimeSeries Forecasting problem, therefore making it possible to utilize the powerof Long Short-Term Memory (LSTM) neural networks. A complete workflow to buildthe training circuit dataset and LSTM architecture is introduced, including anintuitive method of calculating the quantum circuit fidelity. The trained LSTMsystem, Q-fid, can predict the output fidelity of a quantum circuit running ona specific processor, without the need for any separate input of hardwarecalibration data or gate error rates. Evaluated on the QASMbench NISQ benchmarksuite, Q-fid's prediction achieves an average RMSE of 0.0515, up to 24.7x moreaccurate than the default Qiskit transpile tool mapomatic. When used to findthe high-fidelity circuit layouts from the available circuit transpilations,Q-fid predicts the fidelity for the top 10% layouts with an average RMSE of0.0252, up to 32.8x more accurate than mapomatic.", "output": "Quantum Circuit Fidelity Improvement with Long Short-Term Memory Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image editing using diffusion models has witnessed extremely fast-pacedgrowth recently. There are various ways in which previous works enablecontrolling and editing images. Some works use high-level conditioning such astext, while others use low-level conditioning. Nevertheless, most of them lackfine-grained control over the properties of the different objects present inthe image, i.e. object-level image editing. In this work, we consider an imageas a composition of multiple objects, each defined by various properties. Outof these properties, we identify structure and appearance as the most intuitiveto understand and useful for editing purposes. We proposeStructure-and-Appearance Paired Diffusion model (PAIR-Diffusion), which istrained using structure and appearance information explicitly extracted fromthe images. The proposed model enables users to inject a reference image'sappearance into the input image at both the object and global levels.Additionally, PAIR-Diffusion allows editing the structure while maintaining thestyle of individual components of the image unchanged. We extensively evaluateour method on LSUN datasets and the CelebA-HQ face dataset, and we demonstratefine-grained control over both structure and appearance at the object level. Wealso applied the method to Stable Diffusion to edit any real image at theobject level.", "output": "PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Language models (LMs) are increasingly being used in open-ended contexts,where the opinions reflected by LMs in response to subjective queries can havea profound impact, both on user satisfaction, as well as shaping the views ofsociety at large. In this work, we put forth a quantitative framework toinvestigate the opinions reflected by LMs -- by leveraging high-quality publicopinion polls and their associated human responses. Using this framework, wecreate OpinionsQA, a new dataset for evaluating the alignment of LM opinionswith those of 60 US demographic groups over topics ranging from abortion toautomation. Across topics, we find substantial misalignment between the viewsreflected by current LMs and those of US demographic groups: on par with theDemocrat-Republican divide on climate change. Notably, this misalignmentpersists even after explicitly steering the LMs towards particular demographicgroups. Our analysis not only confirms prior observations about theleft-leaning tendencies of some human feedback-tuned LMs, but also surfacesgroups whose opinions are poorly reflected by current LMs (e.g., 65+ andwidowed individuals). Our code and data are available at", "output": "Whose Opinions Do Language Models Reflect?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Intersectionality is a critical framework that, through inquiry and praxis,allows us to examine how social inequalities persist through domains ofstructure and discipline. Given AI fairness' raison d'^etre of ``fairness,''we argue that adopting intersectionality as an analytical framework is pivotalto effectively operationalizing fairness. Through a critical review of howintersectionality is discussed in 30 papers from the AI fairness literature, wedeductively and inductively: 1) map how intersectionality tenets operate withinthe AI fairness paradigm and 2) uncover gaps between the conceptualization andoperationalization of intersectionality. We find that researchersoverwhelmingly reduce intersectionality to optimizing for fairness metrics overdemographic subgroups. They also fail to discuss their social context and whenmentioning power, they mostly situate it only within the AI pipeline. We: 3)outline and assess the implications of these gaps for critical inquiry andpraxis, and 4) provide actionable recommendations for AI fairness researchersto engage with intersectionality in their work by grounding it in AIepistemology.", "output": "Factoring the Matrix of Domination: A Critical Review and Reimagination of Intersectionality in AI Fairness."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The training of modern large language models (LLMs) takes place in a regimewhere most training examples are seen only a few times by the model during thecourse of training. What does a model remember about such examples seen only afew times during training and how long does that memory persist in the face ofcontinuous training with new examples? Here, we investigate these questionsthrough simple recognition, recall, and retention experiments with LLMs. Inrecognition experiments, we ask if the model can distinguish the seen examplefrom a novel example; in recall experiments, we ask if the model can correctlyrecall the seen example when cued by a part of it; and in retentionexperiments, we periodically probe the model's memory for the original examplesas the model is trained continuously with new examples. We find that a singleexposure is generally sufficient for a model to achieve near perfect accuracyeven in very challenging recognition experiments. We estimate that therecognition performance of even small language models easily exceeds humanrecognition performance reported in similar experiments with humans (Shepard,1967). Achieving near perfect recall takes more exposures, but most models cando it in just 3 exposures. The flip side of this remarkable capacity for fastlearning is that precise memories are quickly overwritten: recall performancefor the original examples drops steeply over the first 10 training updates withnew examples, followed by a more gradual decline. Even after 100K updates,however, some of the original examples are still recalled near perfectly. Aqualitatively similar retention pattern has been observed in human long-termmemory retention studies before (Bahrick, 1984). Finally, recognition is muchmore robust to interference than recall and memory for natural languagesentences is generally superior to memory for stimuli without structure.", "output": "Recognition, recall, and retention of few-shot memories in large language models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The debate about the concept of the so called right to explanation in AI isthe subject of a wealth of literature. It has focused, in the legalscholarship, on art. 22 GDPR and, in the technical scholarship, on techniquesthat help explain the output of a certain model (XAI). The purpose of this workis to investigate if the new provisions introduced by the proposal for aRegulation laying down harmonised rules on artificial intelligence (AI Act), incombination with Convention 108 plus and GDPR, are enough to indicate theexistence of a right to technical explainability in the EU legal framework and,if not, whether the EU should include it in its current legislation. This is apreliminary work submitted to the online event organised by the InformationSociety Law Center and it will be later developed into a full paper.", "output": "The AI Act proposal: a new right to technical interpretability?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The use of NLP in the realm of financial technology is broad and complex,with applications ranging from sentiment analysis and named entity recognitionto question answering. Large Language Models (LLMs) have been shown to beeffective on a variety of tasks; however, no LLM specialized for the financialdomain has been reported in literature. In this work, we present BloombergGPT,a 50 billion parameter language model that is trained on a wide range offinancial data. We construct a 363 billion token dataset based on Bloomberg'sextensive data sources, perhaps the largest domain-specific dataset yet,augmented with 345 billion tokens from general purpose datasets. We validateBloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suiteof internal benchmarks that most accurately reflect our intended usage. Ourmixed dataset training leads to a model that outperforms existing models onfinancial tasks by significant margins without sacrificing performance ongeneral LLM benchmarks. Additionally, we explain our modeling choices, trainingprocess, and evaluation methodology. As a next step, we plan to releasetraining logs (Chronicles) detailing our experience in training BloombergGPT.", "output": "BloombergGPT: A Large Language Model for Finance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine Learning (ML) models are widely employed to drive many modern datasystems. While they are undeniably powerful tools, ML models often demonstrateimbalanced performance and unfair behaviors. The root of this problem oftenlies in the fact that different subpopulations commonly display divergenttrends: as a learning algorithm tries to identify trends in the data, itnaturally favors the trends of the majority groups, leading to a model thatperforms poorly and unfairly for minority populations. Our goal is to improvethe fairness and trustworthiness of ML models by applying only non-invasiveinterventions, i.e., without altering the data or the learning algorithm. Weuse a simple but key insight: the divergence of trends between differentpopulations, and, consecutively, between a learned model and minoritypopulations, is analogous to data drift, which indicates the poor conformancebetween parts of the data and the trained model. We explore two strategies(model-splitting and reweighing) to resolve this drift, aiming to improve theoverall conformance of models to the underlying data. Both our methodsintroduce novel ways to employ the recently-proposed data profiling primitiveof Conformance Constraints. Our experimental evaluation over 7 real-worlddatasets shows that both DifFair and ConFair improve the fairness of ML models.", "output": "Non-Invasive Fairness in Learning through the Lens of Data Drift."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large pre-trained code generation models, such as OpenAI Codex, can generatesyntax- and function-correct code, making the coding of programmers moreproductive and our pursuit of artificial general intelligence closer. In thispaper, we introduce CodeGeeX, a multilingual model with 13 billion parametersfor code generation. CodeGeeX is pre-trained on 850 billion tokens of 23programming languages as of June 2022. Our extensive experiments suggest thatCodeGeeX outperforms multilingual code models of similar scale for both thetasks of code generation and translation on HumanEval-X. Building uponHumanEval (Python only), we develop the HumanEval-X benchmark for evaluatingmultilingual models by hand-writing the solutions in C++, Java, JavaScript, andGo. In addition, we build CodeGeeX-based extensions on Visual Studio Code,JetBrains, and Cloud Studio, generating 4.7 billion tokens for tens ofthousands of active users per week. Our user study demonstrates that CodeGeeXcan help to increase coding efficiency for 83.4% of its users. Finally,CodeGeeX is publicly accessible and in Sep. 2022, we open-sourced its code,model weights (the version of 850B tokens), API, extensions, and HumanEval-X at", "output": "CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present an artificial intelligence system to remotely assess the motorperformance of individuals with Parkinson's disease (PD). Participantsperformed a motor task (i.e., tapping fingers) in front of a webcam, and datafrom 250 global participants were rated by three expert neurologists followingthe Movement Disorder Society Unified Parkinson's Disease Rating Scale(MDS-UPDRS). The neurologists' ratings were highly reliable, with anintra-class correlation coefficient (ICC) of 0.88. We developed computeralgorithms to obtain objective measurements that align with the MDS-UPDRSguideline and are strongly correlated with the neurologists' ratings. Ourmachine learning model trained on these measures outperformed an MDS-UPDRScertified rater, with a mean absolute error (MAE) of 0.59 compared to therater's MAE of 0.79. However, the model performed slightly worse than theexpert neurologists (0.53 MAE). The methodology can be replicated for similarmotor tasks, providing the possibility of evaluating individuals with PD andother movement disorders remotely, objectively, and in areas with limitedaccess to neurological care.", "output": "Using AI to Measure Parkinson's Disease Severity at Home."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ideally, dialogue systems should generate responses that are faithful to theknowledge contained in relevant documents. However, many models generatehallucinated responses instead that contradict it or contain unverifiableinformation. To mitigate such undesirable behaviour, it has been proposed tofine-tune a `negative expert' on negative examples and subtract its parametersfrom those of a pre-trained model. However, intuitively, this does not takeinto account that some parameters are more responsible than others in causinghallucinations. Thus, we propose to weigh their individual importance via (anapproximation of) the Fisher Information matrix, which measures the uncertaintyof their estimate. We call this method Elastic Weight Removal (EWR). Weevaluate our method -- using different variants of Flan-T5 as a backbonelanguage model -- on multiple datasets for information-seeking dialoguegeneration and compare our method with state-of-the-art techniques forfaithfulness, such as CTRL, Quark, DExperts, and Noisy Channel reranking.Extensive automatic and human evaluation shows that EWR systematicallyincreases faithfulness at minor costs in terms of other metrics. However, wenotice that only discouraging hallucinations may increase extractiveness, i.e.shallow copy-pasting of document spans, which can be undesirable. Hence, as asecond main contribution, we show that our method can be extended tosimultaneously discourage hallucinations and extractive responses. We publiclyrelease the code for reproducing EWR and all baselines.", "output": "Elastic Weight Removal for Faithful and Abstractive Dialogue Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In a recent article, Alon, Hanneke, Holzman, and Moran (FOCS '21) introduceda unifying framework to study the learnability of classes of partial concepts.One of the central questions studied in their work is whether the learnabilityof a partial concept class is always inherited from the learnability of some``extension'' of it to a total concept class.They showed this is not the case for PAC learning but left the problem openfor the stronger notion of online learnability.We resolve this problem by constructing a class of partial concepts that isonline learnable, but no extension of it to a class of total concepts is onlinelearnable (or even PAC learnable).", "output": "Online Learning and Disambiguations of Partial Concept Classes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Solving complicated AI tasks with different domains and modalities is a keystep toward artificial general intelligence (AGI). While there are abundant AImodels available for different domains and modalities, they cannot handlecomplicated AI tasks. Considering large language models (LLMs) have exhibitedexceptional ability in language understanding, generation, interaction, andreasoning, we advocate that LLMs could act as a controller to manage existingAI models to solve complicated AI tasks and language could be a genericinterface to empower this. Based on this philosophy, we present HuggingGPT, asystem that leverages LLMs (e.g., ChatGPT) to connect various AI models inmachine learning communities (e.g., HuggingFace) to solve AI tasks.Specifically, we use ChatGPT to conduct task planning when receiving a userrequest, select models according to their function descriptions available inHuggingFace, execute each subtask with the selected AI model, and summarize theresponse according to the execution results. By leveraging the strong languagecapability of ChatGPT and abundant AI models in HuggingFace, HuggingGPT is ableto cover numerous sophisticated AI tasks in different modalities and domainsand achieve impressive results in language, vision, speech, and otherchallenging tasks, which paves a new way towards AGI.", "output": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Natural intelligences (NIs) thrive in a dynamic world - they learn quickly,sometimes with only a few samples. In contrast, Artificial intelligences (AIs)typically learn with prohibitive amount of training samples and computationalpower. What design principle difference between NI and AI could contribute tosuch a discrepancy? Here, we propose an angle from weight polarity: developmentprocesses initialize NIs with advantageous polarity configurations; as NIs growand learn, synapse magnitudes update yet polarities are largely kept unchanged.We demonstrate with simulation and image classification tasks that if weightpolarities are adequately set $textit{a priori}$, then networks learn withless time and data. We also explicitly illustrate situations in which$textit{a priori}$ setting the weight polarities is disadvantageous fornetworks. Our work illustrates the value of weight polarities from theperspective of statistical and computational efficiency during learning.", "output": "Polarity is all you need to learn and transfer faster."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The unlearning problem of deep learning models, once primarily an academicconcern, has become a prevalent issue in the industry. The significant advancesin text-to-image generation techniques have prompted global discussions onprivacy, copyright, and safety, as numerous unauthorized personal IDs, content,artistic creations, and potentially harmful materials have been learned bythese models and later utilized to generate and distribute uncontrolledcontent. To address this challenge, we propose textbf{Forget-Me-Not}, anefficient and low-cost solution designed to safely remove specified IDs,objects, or styles from a well-configured text-to-image model in as little as30 seconds, without impairing its ability to generate other content. Alongsideour method, we introduce the textbf{Memorization Score (M-Score)} andtextbf{ConceptBench} to measure the models' capacity to generate generalconcepts, grouped into three primary categories: ID, object, and style. UsingM-Score and ConceptBench, we demonstrate that Forget-Me-Not can effectivelyeliminate targeted concepts while maintaining the model's performance on otherconcepts. Furthermore, Forget-Me-Not offers two practical extensions: a)removal of potentially harmful or NSFW content, and b) enhancement of modelaccuracy, inclusion and diversity through textbf{concept correction anddisentanglement}. It can also be adapted as a lightweight model patch forStable Diffusion, allowing for concept manipulation and convenientdistribution. To encourage future research in this critical area and promotethe development of safe and inclusive generative models, we will open-sourceour code and ConceptBench athref{", "output": "Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose the first framework to learn control policies for vision-basedhuman-to-robot handovers, a critical task for human-robot interaction. Whileresearch in Embodied AI has made significant progress in training robot agentsin simulated environments, interacting with humans remains challenging due tothe difficulties of simulating humans. Fortunately, recent research hasdeveloped realistic simulated environments for human-to-robot handovers.Leveraging this result, we introduce a method that is trained with ahuman-in-the-loop via a two-stage teacher-student framework that uses motionand grasp planning, reinforcement learning, and self-supervision. We showsignificant performance gains over baselines on a simulation benchmark,sim-to-sim transfer and sim-to-real transfer.", "output": "Learning Human-to-Robot Handovers from Point Clouds."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Supervised learning of image classifiers distills human knowledge into aparametric model through pairs of images and corresponding labels (X,Y). Weargue that this simple and widely used representation of human knowledgeneglects rich auxiliary information from the annotation procedure, such as thetime-series of mouse traces and clicks left after image selection. Our insightis that such annotation byproducts Z provide approximate human attention thatweakly guides the model to focus on the foreground cues, reducing spuriouscorrelations and discouraging shortcut learning. To verify this, we createImageNet-AB and COCO-AB. They are ImageNet and COCO training sets enriched withsample-wise annotation byproducts, collected by replicating the respectiveoriginal annotation tasks. We refer to the new paradigm of training models withannotation byproducts as learning using annotation byproducts (LUAB). We showthat a simple multitask loss for regressing Z together with Y already improvesthe generalisability and robustness of the learned models. Compared to theoriginal supervised learning, LUAB does not require extra annotation costs.ImageNet-AB and COCO-AB are at ", "output": "Neglected Free Lunch -- Learning Image Classifiers Using Annotation Byproducts."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents the Relaxed Continuous-Time Actor-critic (RCTAC)algorithm, a method for finding the nearly optimal policy for nonlinearcontinuous-time (CT) systems with known dynamics and infinite horizon, such asthe path-tracking control of vehicles. RCTAC has several advantages overexisting adaptive dynamic programming algorithms for CT systems. It does notrequire the ``admissibility\" of the initialized policy or the input-affinenature of controlled systems for convergence. Instead, given any initialpolicy, RCTAC can converge to an admissible, and subsequently nearly optimalpolicy for a general nonlinear system with a saturated controller. RCTACconsists of two phases: a warm-up phase and a generalized policy iterationphase. The warm-up phase minimizes the square of the Hamiltonian to achieveadmissibility, while the generalized policy iteration phase relaxes the updatetermination conditions for faster convergence. The convergence and optimalityof the algorithm are proven through Lyapunov analysis, and its effectiveness isdemonstrated through simulations and real-world path-tracking tasks.", "output": "Relaxed Actor-Critic with Convergence Guarantees for Continuous-Time Optimal Control of Nonlinear Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose to compute Wasserstein barycenters (WBs) by solving for Monge mapswith variational principle. We discuss the metric properties of WBs and exploretheir connections, especially the connections of Monge WBs, to K-meansclustering and co-clustering. We also discuss the feasibility of Monge WBs onunbalanced measures and spherical domains. We propose two new problems --regularized K-means and Wasserstein barycenter compression. We demonstrate theuse of VWBs in solving these clustering-related problems.", "output": "Variational Wasserstein Barycenters for Geometric Clustering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we develop methods for few-shot image classification from a newperspective of optimal matching between image regions. We employ the EarthMover's Distance (EMD) as a metric to compute a structural distance betweendense image representations to determine image relevance. The EMD generates theoptimal matching flows between structural elements that have the minimummatching cost, which is used to calculate the image distance forclassification. To generate the important weights of elements in the EMDformulation, we design a cross-reference mechanism, which can effectivelyalleviate the adverse impact caused by the cluttered background and largeintra-class appearance variations. To implement k-shot classification, wepropose to learn a structured fully connected layer that can directly classifydense image representations with the EMD. Based on the implicit functiontheorem, the EMD can be inserted as a layer into the network for end-to-endtraining. Our extensive experiments validate the effectiveness of our algorithmwhich outperforms state-of-the-art methods by a significant margin on fivewidely used few-shot classification benchmarks, namely, miniImageNet,tieredImageNet, Fewshot-CIFAR100 (FC100), Caltech-UCSD Birds-200-2011 (CUB),and CIFAR-FewShot (CIFAR-FS). We also demonstrate the effectiveness of ourmethod on the image retrieval task in our experiments.", "output": "DeepEMD: Differentiable Earth Mover's Distance for Few-Shot Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Describing systems in terms of choices and their resulting costs and rewardsoffers the promise of freeing algorithm designers and programmers fromspecifying how those choices should be made; in implementations, the choicescan be realized by optimization techniques and, increasingly, bymachine-learning methods. We study this approach from a programming-languageperspective. We define two small languages that support decision-makingabstractions: one with choices and rewards, and the other additionally withprobabilities. We give both operational and denotational semantics.In the case of the second language we consider three denotational semantics,with varying degrees of correlation between possible program values andexpected rewards. The operational semantics combine the usual semantics ofstandard constructs with optimization over spaces of possible executionstrategies. The denotational semantics, which are compositional, rely on theselection monad, to handle choice, augmented with an auxiliary monad to handleother effects, such as rewards or probability.We establish adequacy theorems that the two semantics coincide in all cases.We also prove full abstraction at base types, with varying notions ofobservation in the probabilistic case corresponding to the various degrees ofcorrelation. We present axioms for choice combined with rewards andprobability, establishing completeness at base types for the case of rewardswithout probability.", "output": "Smart Choices and the Selection Monad."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Solving high dimensional optimal control problems and correspondingHamilton-Jacobi PDEs are important but challenging problems in controlengineering. In this paper, we propose two abstract neural networkarchitectures which are respectively used to compute the value function and theoptimal control for certain class of high dimensional optimal control problems.We provide the mathematical analysis for the two abstract architectures. Wealso show several numerical results computed using the deep neural networkimplementations of these abstract architectures. A preliminary implementationof our proposed neural network architecture on FPGAs shows promising speed upcompared to CPUs. This work paves the way to leverage efficient dedicatedhardware designed for neural networks to solve high dimensional optimal controlproblems and Hamilton-Jacobi PDEs.", "output": "Neural network architectures using min-plus algebra for solving certain high dimensional optimal control problems and Hamilton-Jacobi PDEs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A common lens to theoretically study neural net architectures is to analyzethe functions they can approximate. However, constructions from approximationtheory may be unrealistic and therefore less meaningful. For example, a commonunrealistic trick is to encode target function values using infinite precision.To address these issues, this work proposes a formal definition ofstatistically meaningful (SM) approximation which requires the approximatingnetwork to exhibit good statistical learnability. We study SM approximation fortwo function classes: boolean circuits and Turing machines. We show thatoverparameterized feedforward neural nets can SM approximate boolean circuitswith sample complexity depending only polynomially on the circuit size, not thesize of the network. In addition, we show that transformers can SM approximateTuring machines with computation time bounded by $T$ with sample complexitypolynomial in the alphabet size, state space size, and $log (T)$. We alsointroduce new tools for analyzing generalization which provide much tightersample complexities than the typical VC-dimension or norm-based bounds, whichmay be of independent interest.", "output": "Statistically Meaningful Approximation: a Case Study on Approximating Turing Machines with Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep convolutional neural networks are shown to be overkill with highparametric and computational redundancy in many application scenarios, and anincreasing number of works have explored model pruning to obtain lightweightand efficient networks. However, most existing pruning approaches are driven byempirical heuristic and rarely consider the joint impact of channels, leadingto unguaranteed and suboptimal performance. In this paper, we propose a novelchannel pruning method via Class-Aware Trace Ratio Optimization (CATRO) toreduce the computational burden and accelerate the model inference. Utilizingclass information from a few samples, CATRO measures the joint impact ofmultiple channels by feature space discriminations and consolidates thelayer-wise impact of preserved channels. By formulating channel pruning as asubmodular set function maximization problem, CATRO solves it efficiently via atwo-stage greedy iterative optimization procedure. More importantly, we presenttheoretical justifications on convergence of CATRO and performance of prunednetworks. Experimental results demonstrate that CATRO achieves higher accuracywith similar computation cost or lower computation cost with similar accuracythan other state-of-the-art channel pruning algorithms. In addition, because ofits class-aware property, CATRO is suitable to prune efficient networksadaptively for various classification subtasks, enhancing handy deployment andusage of deep networks in real-world applications.", "output": "CATRO: Channel Pruning via Class-Aware Trace Ratio Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Promotions are becoming more important and prevalent in e-commerce to attractcustomers and boost sales, leading to frequent changes of occasions, whichdrives users to behave differently. In such situations, most existingClick-Through Rate (CTR) models can't generalize well to online serving due todistribution uncertainty of the upcoming occasion. In this paper, we propose anovel CTR model named MOEF for recommendations under frequent changes ofoccasions. Firstly, we design a time series that consists of occasion signalsgenerated from the online business scenario. Since occasion signals are morediscriminative in the frequency domain, we apply Fourier Transformation tosliding time windows upon the time series, obtaining a sequence of frequencyspectrum which is then processed by Occasion Evolution Layer (OEL). In thisway, a high-order occasion representation can be learned to handle the onlinedistribution uncertainty. Moreover, we adopt multiple experts to learn featurerepresentations from multiple aspects, which are guided by the occasionrepresentation via an attention mechanism. Accordingly, a mixture of featurerepresentations is obtained adaptively for different occasions to predict thefinal CTR. Experimental results on real-world datasets validate the superiorityof MOEF and online A/B tests also show MOEF outperforms representative CTRmodels significantly.", "output": "MOEF: Modeling Occasion Evolution in Frequency Domain for Promotion-Aware Click-Through Rate Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper studies the approximation capacity of ReLU neural networks withnorm constraint on the weights. We prove upper and lower bounds on theapproximation error of these networks for smooth function classes. The lowerbound is derived through the Rademacher complexity of neural networks, whichmay be of independent interest. We apply these approximation bounds to analyzethe convergences of regression using norm constrained neural networks anddistribution estimation by GANs. In particular, we obtain convergence rates forover-parameterized neural networks. It is also shown that GANs can achieveoptimal rate of learning probability distributions, when the discriminator is aproperly chosen norm constrained neural network.", "output": "Approximation bounds for norm constrained neural networks with applications to regression and GANs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the sequential decision making setting, an agent aims to achievesystematic generalization over a large, possibly infinite, set of environments.Such environments are modeled as discrete Markov decision processes with bothstates and actions represented through a feature vector. The underlyingstructure of the environments allows the transition dynamics to be factoredinto two components: one that is environment-specific and another that isshared. Consider a set of environments that share the laws of motion as anexample. In this setting, the agent can take a finite amount of reward-freeinteractions from a subset of these environments. The agent then must be ableto approximately solve any planning task defined over any environment in theoriginal set, relying on the above interactions only. Can we design a provablyefficient algorithm that achieves this ambitious goal of systematicgeneralization? In this paper, we give a partially positive answer to thisquestion. First, we provide a tractable formulation of systematicgeneralization by employing a causal viewpoint. Then, under specific structuralassumptions, we provide a simple learning algorithm that guarantees any desiredplanning error up to an unavoidable sub-optimality term, while showcasing apolynomial sample complexity.", "output": "Provably Efficient Causal Model-Based Reinforcement Learning for Systematic Generalization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study the problem of post-processing a supervised machine-learnedregressor to maximize fair binary classification at all decision thresholds.Specifically, we show that by decreasing the statistical distance between eachgroup's score distributions, we can increase fair performance across allthresholds at once, and that we can do so without a significant decrease inaccuracy. To this end, we introduce a formal measure of distributional parity,which captures the degree of similarity in the distributions of classificationsfor different protected groups. In contrast to prior work, which has beenlimited to studies of demographic parity across all thresholds, our measureapplies to a large class of fairness metrics. Our main result is to put forwarda novel post-processing algorithm based on optimal transport, which provablymaximizes distributional parity. We support this result with experiments onseveral fairness benchmarks.", "output": "Geometric Repair for Fair Classification at Any Decision Threshold."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Powerful priors allow us to perform inference with insufficient information.In this paper, we propose an autoregressive prior for 3D shapes to solvemultimodal 3D tasks such as shape completion, reconstruction, and generation.We model the distribution over 3D shapes as a non-sequential autoregressivedistribution over a discretized, low-dimensional, symbolic grid-like latentrepresentation of 3D shapes. This enables us to represent distributions over 3Dshapes conditioned on information from an arbitrary set of spatially anchoredquery locations and thus perform shape completion in such arbitrary settings(e.g., generating a complete chair given only a view of the back leg). We alsoshow that the learned autoregressive prior can be leveraged for conditionaltasks such as single-view reconstruction and language-based generation. This isachieved by learning task-specific naive conditionals which can be approximatedby light-weight models trained on minimal paired data. We validate theeffectiveness of the proposed method using both quantitative and qualitativeevaluation and show that the proposed method outperforms the specializedstate-of-the-art methods trained for individual tasks. The project page withcode and video visualizations can be found at", "output": "AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-label learning is usually used to mine the correlation between featuresand labels, and feature selection can retain as much information as possiblethrough a small number of features. $ell_{2,1}$ regularization method can getsparse coefficient matrix, but it can not solve multicollinearity problemeffectively. The model proposed in this paper can obtain the most relevant fewfeatures by solving the joint constrained optimization problems of $ell_{2,1}$and $ell_{F}$ regularization.In manifold regularization, we implement randomwalk strategy based on joint information matrix, and get a highly robustneighborhood graph.In addition, we given the algorithm for solving the modeland proved its convergence.Comparative experiments on real-world data sets showthat the proposed method outperforms other methods.", "output": "Random Manifold Sampling and Joint Sparse Regularization for Multi-label Feature Selection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper studies third-degree price discrimination (3PD) based on a randomsample of valuation and covariate data, where the covariate is continuous, andthe distribution of the data is unknown to the seller. The main results of thispaper are twofold. The first set of results is pricing strategy independent andreveals the fundamental information-theoretic limitation of any data-basedpricing strategy in revenue generation for two cases: 3PD and uniform pricing.The second set of results proposes the $K$-markets empirical revenuemaximization (ERM) strategy and shows that the $K$-markets ERM and the uniformERM strategies achieve the optimal rate of convergence in revenue to thatgenerated by their respective true-distribution 3PD and uniform pricing optima.Our theoretical and numerical results suggest that the uniform (i.e.,$1$-market) ERM strategy generates a larger revenue than the $K$-markets ERMstrategy when the sample size is small enough, and vice versa.", "output": "Information-theoretic limitations of data-based price discrimination."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Spiking Neural Network (SNN) is a promising energy-efficient AI model whenimplemented on neuromorphic hardware. However, it is a challenge to efficientlytrain SNNs due to their non-differentiability. Most existing methods eithersuffer from high latency (i.e., long simulation time steps), or cannot achieveas high performance as Artificial Neural Networks (ANNs). In this paper, wepropose the Differentiation on Spike Representation (DSR) method, which couldachieve high performance that is competitive to ANNs yet with low latency.First, we encode the spike trains into spike representation using (weighted)firing rate coding. Based on the spike representation, we systematically derivethat the spiking dynamics with common neural models can be represented as somesub-differentiable mapping. With this viewpoint, our proposed DSR method trainsSNNs through gradients of the mapping and avoids the commonnon-differentiability problem in SNN training. Then we analyze the error whenrepresenting the specific mapping with the forward computation of the SNN. Toreduce such error, we propose to train the spike threshold in each layer, andto introduce a new hyperparameter for the neural models. With these components,the DSR method can achieve state-of-the-art SNN performance with low latency onboth static and neuromorphic datasets, including CIFAR-10, CIFAR-100, ImageNet,and DVS-CIFAR10.", "output": "Training High-Performance Low-Latency Spiking Neural Networks by Differentiation on Spike Representation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Given a collection of vertex-aligned networks and an additionallabel-shuffled network, we propose procedures for leveraging the signal in thevertex-aligned collection to recover the labels of the shuffled network. Weconsider matching the shuffled network to averages of the networks in thevertex-aligned collection at different levels of granularity. We demonstrateboth in theory and practice that if the graphs come from different networkclasses, then clustering the networks into classes followed by matching the newgraph to cluster-averages can yield higher fidelity matching performance thanmatching to the global average graph. Moreover, by minimizing the graphmatching objective function with respect to each cluster average, this approachsimultaneously classifies and recovers the vertex labels for the shuffledgraph. These theoretical developments are further reinforced via anilluminating real data experiment matching human connectomes.", "output": "Clustered Graph Matching for Label Recovery and Graph Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce semi-parametric inducing point networks (SPIN), ageneral-purpose architecture that can query the training set at inference timein a compute-efficient manner. Semi-parametric architectures are typically morecompact than parametric models, but their computational complexity is oftenquadratic. In contrast, SPIN attains linear complexity via a cross-attentionmechanism between datapoints inspired by inducing point methods. Querying largetraining sets can be particularly useful in meta-learning, as it unlocksadditional training signal, but often exceeds the scaling limits of existingmodels. We use SPIN as the basis of the Inducing Point Neural Process, aprobabilistic model which supports large contexts in meta-learning and achieveshigh accuracy where existing models fail. In our experiments, SPIN reducesmemory requirements, improves accuracy across a range of meta-learning tasks,and improves state-of-the-art performance on an important practical problem,genotype imputation.", "output": "Semi-Parametric Inducing Point Networks and Neural Processes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Continual learning (CL) aims to learn a sequence of tasks over time, withdata distributions shifting from one task to another. When training on new taskdata, data representations from old tasks may drift. Some negativerepresentation drift can result in catastrophic forgetting, by causing thelocally learned class prototypes and data representations to correlate poorlyacross tasks. To mitigate such representation drift, we propose a method thatfinds global prototypes to guide the learning, and learns data representationswith the regularization of the self-supervised information. Specifically, forNLP tasks, we formulate each task in a masked language modeling style, andlearn the task via a neighbor attention mechanism over a pre-trained languagemodel. Experimental results show that our proposed method can learn fairlyconsistent representations with less representation drift, and significantlyreduce catastrophic forgetting in CL without resampling data from past tasks.", "output": "Enhancing Continual Learning with Global Prototypes: Counteracting Negative Representation Drift."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study stochastic zeroth order gradient and Hessian estimators forreal-valued functions in $mathbb{R}^n$. We show that, via taking finitedifference along random orthogonal directions, the variance of the stochasticfinite difference estimators can be significantly reduced. In particular, wedesign estimators for smooth functions such that, if one uses $ Theta left( kright) $ random directions sampled from the Stiefel's manifold $ text{St}(n,k) $ and finite-difference granularity $delta$, the variance of thegradient estimator is bounded by $ mathcal{O} left( left( frac{n}{k} - 1right) + left( frac{n^2}{k} - n right) delta^2 + frac{ n^2 delta^4 }{ k} right) $, and the variance of the Hessian estimator is bounded by$mathcal{O} left( left( frac{n^2}{k^2} - 1 right) + left( frac{n^4}{k^2}- n^2 right) delta^2 + frac{n^4 delta^4 }{k^2} right) $. When $k = n$, thevariances become negligibly small. In addition, we provide improved bias boundsfor the estimators. The bias of both gradient and Hessian estimators for smoothfunction $f$ is of order $mathcal{O} left( delta^2 Gamma right)$, where$delta$ is the finite-difference granularity, and $ Gamma $ depends on highorder derivatives of $f$. Our results are evidenced by empirical observations.", "output": "Stochastic Zeroth Order Gradient and Hessian Estimators: Variance Reduction and Refined Bias Bounds."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The complexity of modern software has led to a drastic increase in the timeand cost associated with detecting and rectifying software bugs. In response,researchers have explored various methods to automatically generate fixes forbuggy code. However, due to the large combinatorial space of possible fixes forany given bug, few tools and datasets are available to evaluate model-generatedfixes effectively. To address this issue, we introduce FixEval, a benchmarkcomprising of buggy code submissions to competitive programming problems andtheir corresponding fixes. FixEval offers an extensive collection of unit teststo evaluate the correctness of model-generated program fixes and assess furtherinformation regarding time, memory constraints, and acceptance based on averdict. We consider two Transformer language models pretrained on programminglanguages as our baseline and compare them using match-based andexecution-based evaluation metrics. Our experiments show that match-basedmetrics do not reflect model-generated program fixes accurately. At the sametime, execution-based methods evaluate programs through all cases and scenariosdesigned explicitly for that solution. Therefore, we believe FixEval provides astep towards real-world automatic bug fixing and model-generated codeevaluation. The dataset and models are open-sourced at", "output": "FixEval: Execution-based Evaluation of Program Fixes for Programming Problems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Antibody design is valuable for therapeutic usage and biological research.Existing deep-learning-based methods encounter several key issues: 1)incomplete context for Complementarity-Determining Regions (CDRs) generation;2) incapability of capturing the entire 3D geometry of the input structure; 3)inefficient prediction of the CDR sequences in an autoregressive manner. Inthis paper, we propose Multi-channel Equivariant Attention Network (MEAN) toco-design 1D sequences and 3D structures of CDRs. To be specific, MEANformulates antibody design as a conditional graph translation problem byimporting extra components including the target antigen and the light chain ofthe antibody. Then, MEAN resorts to E(3)-equivariant message passing along witha proposed attention mechanism to better capture the geometrical correlationbetween different components. Finally, it outputs both the 1D sequences and 3Dstructure via a multi-round progressive full-shot scheme, which enjoys moreefficiency and precision against previous autoregressive approaches. Our methodsignificantly surpasses state-of-the-art models in sequence and structuremodeling, antigen-binding CDR design, and binding affinity optimization.Specifically, the relative improvement to baselines is about 23% inantigen-binding CDR design and 34% for affinity optimization.", "output": "Conditional Antibody Design as 3D Equivariant Graph Translation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We address the task of controlled generation of small molecules, whichentails finding novel molecules with desired properties under certainconstraints (e.g., similarity to a reference molecule). Here we introduceMolMIM, a probabilistic auto-encoder for small molecule drug discovery thatlearns an informative and clustered latent space. MolMIM is trained with MutualInformation Machine (MIM) learning, and provides a fixed length representationof variable length SMILES strings. Since encoder-decoder models can learnrepresentations with ``holes'' of invalid samples, here we propose a novelextension to the training procedure which promotes a dense latent space, andallows the model to sample valid molecules from random perturbations of latentcodes. We provide a thorough comparison of MolMIM to several variable-size andfixed-size encoder-decoder models, demonstrating MolMIM's superior generationas measured in terms of validity, uniqueness, and novelty. We then utilizeCMA-ES, a naive black-box and gradient free search algorithm, over MolMIM'slatent space for the task of property guided molecule optimization. We achievestate-of-the-art results in several constrained single property optimizationtasks as well as in the challenging task of multi-objective optimization,improving over previous success rate SOTA by more than 5% . We attribute thestrong results to MolMIM's latent representation which clusters similarmolecules in the latent space, whereas CMA-ES is often used as a baselineoptimization method. We also demonstrate MolMIM to be favourable in a computelimited regime, making it an attractive model for such cases.", "output": "Improving Small Molecule Generation using Mutual Information Machine."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks have shown excellent prospects in speech separationtasks. However, obtaining good results while keeping a low model complexityremains challenging in real-world applications. In this paper, we provide abio-inspired efficient encoder-decoder architecture by mimicking the brain'stop-down attention, called TDANet, with decreased model complexity withoutsacrificing performance. The top-down attention in TDANet is extracted by theglobal attention (GA) module and the cascaded local attention (LA) layers. TheGA module takes multi-scale acoustic features as input to extract globalattention signal, which then modulates features of different scales by directtop-down connections. The LA layers use features of adjacent layers as input toextract the local attention signal, which is used to modulate the lateral inputin a top-down manner. On three benchmark datasets, TDANet consistently achievedcompetitive separation performance to previous state-of-the-art (SOTA) methodswith higher efficiency. Specifically, TDANet's multiply-accumulate operations(MACs) are only 5% of Sepformer, one of the previous SOTA models, and CPUinference time is only 10% of Sepformer. In addition, a large-size version ofTDANet obtained SOTA results on three datasets, with MACs still only 10% ofSepformer and the CPU inference time only 24% of Sepformer.", "output": "An efficient encoder-decoder architecture with top-down attention for speech separation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks (DNNs) have demonstrated their superiority in practice.Arguably, the rapid development of DNNs is largely benefited from high-quality(open-sourced) datasets, based on which researchers and developers can easilyevaluate and improve their learning methods. Since the data collection isusually time-consuming or even expensive, how to protect their copyrights is ofgreat significance and worth further exploration. In this paper, we revisitdataset ownership verification. We find that existing verification methodsintroduced new security risks in DNNs trained on the protected dataset, due tothe targeted nature of poison-only backdoor watermarks. To alleviate thisproblem, in this work, we explore the untargeted backdoor watermarking scheme,where the abnormal model behaviors are not deterministic. Specifically, weintroduce two dispersibilities and prove their correlation, based on which wedesign the untargeted backdoor watermark under both poisoned-label andclean-label settings. We also discuss how to use the proposed untargetedbackdoor watermark for dataset ownership verification. Experiments on benchmarkdatasets verify the effectiveness of our methods and their resistance toexisting backdoor defenses. Our codes are available aturl{", "output": "Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep Ensembles (DE) are a prominent approach for achieving excellentperformance on key metrics such as accuracy, calibration, uncertaintyestimation, and out-of-distribution detection. However, hardware limitations ofreal-world systems constrain to smaller ensembles and lower-capacity networks,significantly deteriorating their performance and properties. We introducePacked-Ensembles (PE), a strategy to design and train lightweight structuredensembles by carefully modulating the dimension of their encoding space. Weleverage grouped convolutions to parallelize the ensemble into a single sharedbackbone and forward pass to improve training and inference speeds. PE isdesigned to operate within the memory limits of a standard neural network. Ourextensive research indicates that PE accurately preserves the properties of DE,such as diversity, and performs equally well in terms of accuracy, calibration,out-of-distribution detection, and robustness to distribution shift. We makeour code available at ", "output": "Packed-Ensembles for Efficient Uncertainty Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Computing observables from conditioned dynamics is typically computationallyhard, because, although obtaining independent samples efficiently from theunconditioned dynamics is usually feasible, generally most of the samples mustbe discarded (in a form of importance sampling) because they do not satisfy theimposed conditions. Sampling directly from the conditioned distribution isnon-trivial, as conditioning breaks the causal properties of the dynamics whichultimately renders the sampling procedure efficient. One standard way ofachieving it is through a Metropolis Monte-Carlo procedure, but this procedureis normally slow and a very large number of Monte-Carlo steps is needed toobtain a small number of statistically independent samples. In this work, wepropose an alternative method to produce independent samples from a conditioneddistribution. The method learns the parameters of a generalized dynamical modelthat optimally describe the conditioned distribution in a variational sense.The outcome is an effective, unconditioned, dynamical model, from which one cantrivially obtain independent samples, effectively restoring causality of theconditioned distribution. The consequences are twofold: on the one hand, itallows us to efficiently compute observables from the conditioned dynamics bysimply averaging over independent samples. On the other hand, the method givesan effective unconditioned distribution which is easier to interpret. Themethod is flexible and can be applied virtually to any dynamics. We discuss animportant application of the method, namely the problem of epidemic riskassessment from (imperfect) clinical tests, for a large family oftime-continuous epidemic models endowed with a Gillespie-like sampler. We showthat the method compares favorably against the state of the art, including thesoft-margin approach and mean-field methods.", "output": "Inference in conditioned dynamics through causality restoration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this study we focus on the diagnosis of Parkinson's Disease (PD) based onelectroencephalogram (EEG) signals. We propose a new approach inspired by thefunctioning of the brain that uses the dynamics, frequency and temporal contentof EEGs to extract new demarcating features of the disease. The method wasevaluated on a publicly available dataset containing EEG signals recordedduring a 3-oddball auditory task involving N = 50 subjects, of whom 25 sufferfrom PD. By extracting two features, and separating them with a straight lineusing a Linear Discriminant Analysis (LDA) classifier, we can separate thehealthy from the unhealthy subjects with an accuracy of 90 % $(p &lt; 0.03)$ usinga single channel. By aggregating the information from three channels and makingthem vote, we obtain an accuracy of 94 %, a sensitivity of 96 % and aspecificity of 92 %. The evaluation was carried out using a nestedLeave-One-Out cross-validation procedure, thus preventing data leakage problemsand giving a less biased evaluation. Several tests were carried out to assessthe validity and robustness of our approach, including the test where we useonly half the available data for training. Under this constraint, the modelachieves an accuracy of 83.8 %.", "output": "Sparse Dynamical Features generation, application to Parkinson's Disease diagnosis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, there is a lot of interest in modeling students' digitaltraces in Learning Management System (LMS) to understand students' learningbehavior patterns including aspects of meta-cognition and self-regulation, withthe ultimate goal to turn those insights into actionable information to supportstudents to improve their learning outcomes. In achieving this goal, however,there are two main issues that need to be addressed given the existingliterature. Firstly, most of the current work is course-centered (i.e. modelsare built from data for a specific course) rather than student-centered;secondly, a vast majority of the models are correlational rather than causal.Those issues make it challenging to identify the most promising actionablefactors for intervention at the student level where most of the campus-wideacademic support is designed for. In this paper, we explored a student-centricanalytical framework for LMS activity data that can provide not onlycorrelational but causal insights mined from observational data. Wedemonstrated this approach using a dataset of 1651 computing major students ata public university in the US during one semester in the Fall of 2019. Thisdataset includes students' fine-grained LMS interaction logs and administrativedata, e.g. demographics and academic performance. In addition, we expand therepository of LMS behavior indicators to include those that can characterizethe time-of-the-day of login (e.g. chronotype). Our analysis showed thatstudent login volume, compared with other login behavior indicators, is bothstrongly correlated and causally linked to student academic performance,especially among students with low academic performance. We envision that thoseinsights will provide convincing evidence for college student support groups tolaunch student-centered and targeted interventions that are effective andscalable.", "output": "Student-centric Model of Learning Management System Activity and Academic Performance: from Correlation to Causation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In many cutting-edge applications, high-fidelity computational models provetoo slow to be practical and are thus replaced by much faster surrogate models.Recently, deep learning techniques have become increasingly important inaccelerating such predictions. However, they tend to falter when faced withlarger and more complex problems. Therefore, this work introduces MAgNET:Multi-channel Aggregation Network, a novel geometric deep learning frameworkdesigned to operate on large-dimensional data of arbitrary structure (graphdata). MAgNET is built upon the MAg (Multichannel Aggregation) operation, whichgeneralizes the concept of multi-channel local operations in convolutionalneural networks to arbitrary non-grid inputs. The MAg layers are interleavedwith the proposed novel graph pooling/unpooling operations to form a graphU-Net architecture that is robust and can handle arbitrary complex meshes,efficiently performing supervised learning on large-dimensionalgraph-structured data. We demonstrate the predictive capabilities of MAgNET forseveral non-linear finite element simulations and provide open-source datasetsand codes to facilitate future research.", "output": "MAgNET: A Graph U-Net Architecture for Mesh-Based Simulations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated Learning is a popular distributed learning paradigm in machinelearning. Meanwhile, composition optimization is an effective hierarchicallearning model, which appears in many machine learning applications such asmeta learning and robust learning. More recently, although a few federatedcomposition optimization algorithms have been proposed, they still suffer fromhigh sample and communication complexities. In the paper, thus, we propose aclass of faster federated compositional optimization algorithms (i.e., MFCGDand AdaMFCGD) to solve the nonconvex distributed composition problems, whichbuilds on the momentum-based variance reduced and local-SGD techniques. Inparticular, our adaptive algorithm (i.e., AdaMFCGD) uses a unified adaptivematrix to flexibly incorporate various adaptive learning rates. Moreover, weprovide a solid theoretical analysis for our algorithms under non-i.i.d.setting, and prove our algorithms obtain a lower sample and communicationcomplexities simultaneously than the existing federated compositionalalgorithms. Specifically, our algorithms obtain lower sample complexity of$tilde{O}(epsilon^{-3})$ with lower communication complexity of$tilde{O}(epsilon^{-2})$ in finding an $epsilon$-stationary solution. Weconduct the numerical experiments on robust federated learning and distributedmeta learning tasks to demonstrate the efficiency of our algorithms.", "output": "Faster Adaptive Momentum-Based Federated Methods for Distributed Composition Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine learning algorithms designed to learn dynamical systems from data canbe used to forecast, control and interpret the observed dynamics. In this workwe exemplify the use of one of such algorithms, namely Koopman operatorlearning, in the context of open quantum system dynamics. We will study thedynamics of a small spin chain coupled with dephasing gates and show howKoopman operator learning is an approach to efficiently learn not only theevolution of the density matrix, but also of every physical observableassociated to the system. Finally, leveraging the spectral decomposition of thelearned Koopman operator, we show how symmetries obeyed by the underlyingdynamics can be inferred directly from data.", "output": "Learning dynamical systems: an example from open quantum system dynamics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We describe the development of a model to detect user-level clinicaldepression based on a user's temporal social media posts. Our model uses aDepression Symptoms Detection (DSD) classifier, which is trained on the largestexisting samples of clinician annotated tweets for clinical depressionsymptoms. We subsequently use our DSD model to extract clinically relevantfeatures, e.g., depression scores and their consequent temporal patterns, aswell as user posting activity patterns, e.g., quantifying their ``no activity''or ``silence.'' Furthermore, to evaluate the efficacy of these extractedfeatures, we create three kinds of datasets including a test dataset, from twoexisting well-known benchmark datasets for user-level depression detection. Wethen provide accuracy measures based on single features, baseline features andfeature ablation tests, at several different levels of temporal granularity.The relevant data distributions and clinical depression detection relatedsettings can be exploited to draw a complete picture of the impact of differentfeatures across our created datasets. Finally, we show that, in general, onlysemantic oriented representation models perform well. However, clinicalfeatures may enhance overall performance provided that the training and testingdistribution is similar, and there is more data in a user's timeline. Theconsequence is that the predictive capability of depression scores increasesignificantly while used in a more sensitive clinical depression detectionsettings.", "output": "Deep Temporal Modelling of Clinical Depression through Social Media Text."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, large-scale pre-trained Vision-and-Language (VL) foundation modelshave demonstrated remarkable capabilities in many zero-shot downstream tasks,achieving competitive results for recognizing objects defined by as little asshort text prompts. However, it has also been shown that VL models are stillbrittle in Structured VL Concept (SVLC) reasoning, such as the ability torecognize object attributes, states, and inter-object relations. This leads toreasoning mistakes, which need to be corrected as they occur by teaching VLmodels the missing SVLC skills; often this must be done using private datawhere the issue was found, which naturally leads to a data-free continual (notask-id) VL learning setting. In this work, we introduce the first ContinualData-Free Structured VL Concepts Learning (ConStruct-VL) benchmark and show itis challenging for many existing data-free CL strategies. We, therefore,propose a data-free method comprised of a new approach of AdversarialPseudo-Replay (APR) which generates adversarial reminders of past tasks frompast task models. To use this method efficiently, we also propose a continualparameter-efficient Layered-LoRA (LaLo) neural architecture allowingno-memory-cost access to all past models at train time. We show this approachoutperforms all data-free methods by as much as ~7% while even matching somelevels of experience-replay (prohibitive for applications where data-privacymust be preserved). Our code is publicly available at", "output": "ConStruct-VL: Data-Free Continual Structured VL Concepts Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Computer vision models suffer from a phenomenon known as catastrophicforgetting when learning novel concepts from continuously shifting trainingdata. Typical solutions for this continual learning problem require extensiverehearsal of previously seen data, which increases memory costs and may violatedata privacy. Recently, the emergence of large-scale pre-trained visiontransformer models has enabled prompting approaches as an alternative todata-rehearsal. These approaches rely on a key-query mechanism to generateprompts and have been found to be highly resistant to catastrophic forgettingin the well-established rehearsal-free continual learning setting. However, thekey mechanism of these methods is not trained end-to-end with the tasksequence. Our experiments show that this leads to a reduction in theirplasticity, hence sacrificing new task accuracy, and inability to benefit fromexpanded parameter capacity. We instead propose to learn a set of promptcomponents which are assembled with input-conditioned weights to produceinput-conditioned prompts, resulting in a novel attention-based end-to-endkey-query scheme. Our experiments show that we outperform the current SOTAmethod DualPrompt on established benchmarks by as much as 4.5% in average finalaccuracy. We also outperform the state of art by as much as 4.4% accuracy on acontinual learning benchmark which contains both class-incremental anddomain-incremental task shifts, corresponding to many practical settings. Ourcode is available at ", "output": "CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Standard multi-modal models assume the use of the same modalities in trainingand inference stages. However, in practice, the environment in whichmulti-modal models operate may not satisfy such assumption. As such, theirperformances degrade drastically if any modality is missing in the inferencestage. We ask: how can we train a model that is robust to missing modalities?This paper seeks a set of good practices for multi-modal action recognition,with a particular interest in circumstances where some modalities are notavailable at an inference time. First, we study how to effectively regularizethe model during training (e.g., data augmentation). Second, we investigate onfusion methods for robustness to missing modalities: we find thattransformer-based fusion shows better robustness for missing modality thansummation or concatenation. Third, we propose a simple modular network,ActionMAE, which learns missing modality predictive coding by randomly droppingmodality features and tries to reconstruct them with the remaining modalityfeatures. Coupling these good practices, we build a model that is not onlyeffective in multi-modal action recognition but also robust to modalitymissing. Our model achieves the state-of-the-arts on multiple benchmarks andmaintains competitive performances even in missing modality scenarios. Codesare available at ", "output": "Towards Good Practices for Missing Modality Robust Action Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pareto Front Learning (PFL) was recently introduced as an effective approachto obtain a mapping function from a given trade-off vector to a solution on thePareto front, which solves the multi-objective optimization (MOO) problem. Dueto the inherent trade-off between conflicting objectives, PFL offers a flexibleapproach in many scenarios in which the decision makers can not specify thepreference of one Pareto solution over another, and must switch between themdepending on the situation. However, existing PFL methods ignore therelationship between the solutions during the optimization process, whichhinders the quality of the obtained front. To overcome this issue, we propose anovel PFL framework namely PHN-HVI, which employs a hypernetwork to generatemultiple solutions from a set of diverse trade-off preferences and enhance thequality of the Pareto front by maximizing the Hypervolume indicator defined bythese solutions. The experimental results on several MOO machine learning tasksshow that the proposed framework significantly outperforms the baselines inproducing the trade-off Pareto front.", "output": "Improving Pareto Front Learning via Multi-Sample Hypernetworks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Learning semantic-rich representations from raw unlabeled time series data iscritical for downstream tasks such as classification and forecasting.Contrastive learning has recently shown its promising representation learningcapability in the absence of expert annotations. However, existing contrastiveapproaches generally treat each instance independently, which leads to falsenegative pairs that share the same semantics. To tackle this problem, wepropose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model,which exploits semantic information obtained from the hierarchical structureconsisting of multiple latent partitions for multivariate time series.Motivated by the observation that fine-grained clustering preserves higherpurity while coarse-grained one reflects higher-level semantics, we propose anovel downward masking strategy to filter out fake negatives and supplementpositives by incorporating the multi-granularity information from theclustering hierarchy. In addition, a novel upward masking strategy is designedin MHCCL to remove outliers of clusters at each partition to refine prototypes,which helps speed up the hierarchical clustering process and improves theclustering quality. We conduct experimental evaluations on seven widely-usedmultivariate time series datasets. The results demonstrate the superiority ofMHCCL over the state-of-the-art approaches for unsupervised time seriesrepresentation learning.", "output": "MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study focuses on using large language models (LLMs) as a planner forembodied agents that can follow natural language instructions to completecomplex tasks in a visually-perceived environment. The high data cost and poorsample efficiency of existing methods hinders the development of versatileagents that are capable of many tasks and can learn new tasks quickly. In thiswork, we propose a novel method, LLM-Planner, that harnesses the power of largelanguage models to do few-shot planning for embodied agents. We further proposea simple but effective way to enhance LLMs with physical grounding to generateand update plans that are grounded in the current environment. Experiments onthe ALFRED dataset show that our method can achieve very competitive few-shotperformance: Despite using less than 0.5% of paired training data, LLM-Plannerachieves competitive performance with recent baselines that are trained usingthe full training data. Existing methods can barely complete any tasksuccessfully under the same few-shot setting. Our work opens the door fordeveloping versatile and sample-efficient embodied agents that can quicklylearn many tasks. Website: ", "output": "LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Optimal transport (OT) has become exceedingly popular in machine learning,data science, and computer vision. The core assumption in the OT problem is theequal total amount of mass in source and target measures, which limits itsapplication. Optimal Partial Transport (OPT) is a recently proposed solution tothis limitation. Similar to the OT problem, the computation of OPT relies onsolving a linear programming problem (often in high dimensions), which canbecome computationally prohibitive. In this paper, we propose an efficientalgorithm for calculating the OPT problem between two non-negative measures inone dimension. Next, following the idea of sliced OT distances, we utilizeslicing to define the sliced OPT distance. Finally, we demonstrate thecomputational and accuracy benefits of the sliced OPT-based method in variousnumerical experiments. In particular, we show an application of our proposedSliced-OPT in noisy point cloud registration.", "output": "Sliced Optimal Partial Transport."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "By optimizing the rate-distortion-realism trade-off, generative compressionapproaches produce detailed, realistic images, even at low bit rates, insteadof the blurry reconstructions produced by rate-distortion optimized models.However, previous methods do not explicitly control how much detail issynthesized, which results in a common criticism of these methods: users mightbe worried that a misleading reconstruction far from the input image isgenerated. In this work, we alleviate these concerns by training a decoder thatcan bridge the two regimes and navigate the distortion-realism trade-off. Froma single compressed representation, the receiver can decide to eitherreconstruct a low mean squared error reconstruction that is close to the input,a realistic reconstruction with high perceptual quality, or anything inbetween. With our method, we set a new state-of-the-art in distortion-realism,pushing the frontier of achievable distortion-realism pairs, i.e., our methodachieves better distortions at high realism and better realism at lowdistortion than ever before.", "output": "Multi-Realism Image Compression with a Conditional Generator."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Projection operations are a typical computation bottleneck in onlinelearning. In this paper, we enable projection-free online learning within theframework of Online Convex Optimization with Memory (OCO-M) -- OCO-M captureshow the history of decisions affects the current outcome by allowing the onlinelearning loss functions to depend on both current and past decisions.Particularly, we introduce the first projection-free meta-base learningalgorithm with memory that minimizes dynamic regret, i.e., that minimizes thesuboptimality against any sequence of time-varying decisions. We are motivatedby artificial intelligence applications where autonomous agents need to adaptto time-varying environments in real-time, accounting for how past decisionsaffect the present. Examples of such applications are: online control ofdynamical systems; statistical arbitrage; and time series prediction. Thealgorithm builds on the Online Frank-Wolfe (OFW) and Hedge algorithms. Wedemonstrate how our algorithm can be applied to the online control of lineartime-varying systems in the presence of unpredictable process noise. To thisend, we develop the first controller with memory and bounded dynamic regretagainst any optimal time-varying linear feedback control policy. We validateour algorithm in simulated scenarios of online control of linear time-invariantsystems.", "output": "Efficient Online Learning with Memory via Frank-Wolfe Optimization: Algorithms with Bounded Dynamic Regret and Applications to Control."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Human-robot co-manipulation of soft materials, such as fabrics, composites,and sheets of paper/cardboard, is a challenging operation that presents severalrelevant industrial applications. Estimating the deformation state of theco-manipulated material is one of the main challenges. Viable methods providethe indirect measure by calculating the human-robot relative distance. In thispaper, we develop a data-driven model to estimate the deformation state of thematerial from a depth image through a Convolutional Neural Network (CNN).First, we define the deformation state of the material as the relativeroto-translation from the current robot pose and a human grasping position. Themodel estimates the current deformation state through a Convolutional NeuralNetwork, specifically a DenseNet-121 pretrained on ImageNet.The delta betweenthe current and the desired deformation state is fed to the robot controllerthat outputs twist commands. The paper describes the developed approach toacquire, preprocess the dataset and train the model. The model is compared withthe current state-of-the-art method based on a skeletal tracker from cameras.Results show that our approach achieves better performances and avoids thevarious drawbacks caused by using a skeletal tracker.Finally, we also studiedthe model performance according to different architectures and datasetdimensions to minimize the time required for dataset acquisition", "output": "Co-manipulation of soft-materials estimating deformation from depth images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Data-driven approaches coupled with physical knowledge are powerfultechniques to model systems. The goal of such models is to efficiently solvefor the underlying field by combining measurements with known physical laws. Asmany systems contain unknown elements, such as missing parameters, noisy data,or incomplete physical laws, this is widely approached as an uncertaintyquantification problem. The common techniques to handle all the variablestypically depend on the numerical scheme used to approximate the posterior, andit is desirable to have a method which is independent of any suchdiscretization. Information field theory (IFT) provides the tools necessary toperform statistics over fields that are not necessarily Gaussian. We extend IFTto physics-informed IFT (PIFT) by encoding the functional priors withinformation about the physical laws which describe the field. The posteriorsderived from this PIFT remain independent of any numerical scheme and cancapture multiple modes, allowing for the solution of problems which areill-posed. We demonstrate our approach through an analytical example involvingthe Klein-Gordon equation. We then develop a variant of stochastic gradientLangevin dynamics to draw samples from the joint posterior over the field andmodel parameters. We apply our method to numerical examples with variousdegrees of model-form error and to inverse problems involving nonlineardifferential equations. As an addendum, the method is equipped with a metricwhich allows the posterior to automatically quantify model-form uncertainty.Because of this, our numerical experiments show that the method remains robustto even an incorrect representation of the physics given sufficient data. Wenumerically demonstrate that the method correctly identifies when the physicscannot be trusted, in which case it automatically treats learning the field asa regression problem.", "output": "Physics-informed Information Field Theory for Modeling Physical Systems with Uncertainty Quantification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Short-term forecasting of solar photovoltaic energy (PV) production isimportant for powerplant management. Ideally these forecasts are equipped witherror bars, so that downstream decisions can account for uncertainty. Toproduce predictions with error bars in this setting, we consider Gaussianprocesses (GPs) for modelling and predicting solar photovoltaic energyproduction in the UK. A standard application of GP regression on the PVtimeseries data is infeasible due to the large data size and non-Gaussianity ofPV readings. However, this is made possible by leveraging recent advances inscalable GP inference, in particular, by using the state-space form of GPs,combined with modern variational inference techniques. The resulting model isnot only scalable to large datasets but can also handle continuous data streamsvia Kalman filtering.", "output": "Short-term Prediction and Filtering of Solar Power Using State-Space Gaussian Processes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Despite the remarkable progress in deep generative models, synthesizinghigh-resolution and temporally coherent videos still remains a challenge due totheir high-dimensionality and complex temporal dynamics along with largespatial variations. Recent works on diffusion models have shown their potentialto solve this challenge, yet they suffer from severe computation- andmemory-inefficiency that limit the scalability. To handle this issue, wepropose a novel generative model for videos, coined projected latent videodiffusion models (PVDM), a probabilistic diffusion model which learns a videodistribution in a low-dimensional latent space and thus can be efficientlytrained with high-resolution videos under limited resources. Specifically, PVDMis composed of two components: (a) an autoencoder that projects a given videoas 2D-shaped latent vectors that factorize the complex cubic structure of videopixels and (b) a diffusion model architecture specialized for our newfactorized latent space and the training/sampling procedure to synthesizevideos of arbitrary length with a single model. Experiments on popular videogeneration datasets demonstrate the superiority of PVDM compared with previousvideo synthesis methods; e.g., PVDM obtains the FVD score of 639.7 on theUCF-101 long video (128 frames) generation benchmark, which improves 1773.4 ofthe prior state-of-the-art.", "output": "Video Probabilistic Diffusion Models in Projected Latent Space."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Object detection with on-board sensors (e.g., lidar, radar, and camera) playa crucial role in autonomous driving (AD), and these sensors complement eachother in modalities. While crowdsensing may potentially exploit these sensors(of huge quantity) to derive more comprehensive knowledge, textit{federatedlearning} (FL) appears to be the necessary tool to reach this potential: itenables autonomous vehicles (AVs) to train machine learning models withoutexplicitly sharing raw sensory data. However, the multimodal sensors introducevarious data heterogeneity across distributed AVs (e.g., label quantity skewsand varied modalities), posing critical challenges to effective FL. To thisend, we present AutoFed as a heterogeneity-aware FL framework to fully exploitmultimodal sensory data on AVs and thus enable robust AD. Specifically, wefirst propose a novel model leveraging pseudo-labeling to avoid mistakenlytreating unlabeled objects as the background. We also propose anautoencoder-based data imputation method to fill missing data modality (ofcertain AVs) with the available ones. To further reconcile the heterogeneity,we finally present a client selection mechanism exploiting the similaritiesamong client models to improve both training stability and convergence rate.Our experiments on benchmark dataset confirm that AutoFed substantiallyimproves over status quo approaches in both precision and recall, whiledemonstrating strong robustness to adverse weather conditions.", "output": "AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pretrained Foundation Models (PFMs) are regarded as the foundation forvarious downstream tasks with different data modalities. A PFM (e.g., BERT,ChatGPT, and GPT-4) is trained on large-scale data which provides a reasonableparameter initialization for a wide range of downstream applications. BERTlearns bidirectional encoder representations from Transformers, which aretrained on large datasets as contextual language models. Similarly, thegenerative pretrained transformer (GPT) method employs Transformers as thefeature extractor and is trained using an autoregressive paradigm on largedatasets. Recently, ChatGPT shows promising success on large language models,which applies an autoregressive language model with zero shot or few shotprompting. The remarkable achievements of PFM have brought significantbreakthroughs to various fields of AI. Numerous studies have proposed differentmethods, raising the demand for an updated survey. This study provides acomprehensive review of recent research advancements, challenges, andopportunities for PFMs in text, image, graph, as well as other data modalities.The review covers the basic components and existing pretraining methods used innatural language processing, computer vision, and graph learning. Additionally,it explores advanced PFMs used for different data modalities and unified PFMsthat consider data quality and quantity. The review also discusses researchrelated to the fundamentals of PFMs, such as model efficiency and compression,security, and privacy. Finally, the study provides key implications, futureresearch directions, challenges, and open problems in the field of PFMs.Overall, this survey aims to shed light on the research of the PFMs onscalability, security, logical reasoning ability, cross-domain learningability, and the user-friendly interactive ability for artificial generalintelligence.", "output": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Selective experience replay is a popular strategy for integrating lifelonglearning with deep reinforcement learning. Selective experience replay aims torecount selected experiences from previous tasks to avoid catastrophicforgetting. Furthermore, selective experience replay based techniques are modelagnostic and allow experiences to be shared across different models. However,storing experiences from all previous tasks make lifelong learning usingselective experience replay computationally very expensive and impractical asthe number of tasks increase. To that end, we propose a rewarddistribution-preserving coreset compression technique for compressingexperience replay buffers stored for selective experience replay.We evaluated the coreset compression technique on the brain tumorsegmentation (BRATS) dataset for the task of ventricle localization and on thewhole-body MRI for localization of left knee cap, left kidney, righttrochanter, left lung, and spleen. The coreset lifelong learning models trainedon a sequence of 10 different brain MR imaging environments demonstratedexcellent performance localizing the ventricle with a mean pixel error distanceof 12.93 for the compression ratio of 10x. In comparison, the conventionallifelong learning model localized the ventricle with a mean pixel distance of10.87. Similarly, the coreset lifelong learning models trained on whole-bodyMRI demonstrated no significant difference (p=0.28) between the 10x compressedcoreset lifelong learning models and conventional lifelong learning models forall the landmarks. The mean pixel distance for the 10x compressed models acrossall the landmarks was 25.30, compared to 19.24 for the conventional lifelonglearning models. Our results demonstrate that the potential of thecoreset-based ERB compression method for compressing experiences without asignificant drop in performance.", "output": "Selective experience replay compression using coresets for lifelong deep reinforcement learning in medical imaging."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "textit{Objective:} In this paper, we introduce Physics-Informed FourierNetworks for Electrical Properties Tomography (PIFON-EPT), a novel deeplearning-based method that solves an inverse scattering problem based on noisyand/or incomplete magnetic resonance (MR) measurements. textit{Methods:} Weused two separate fully-connected neural networks, namely $B_1^{+}$ Net and EPNet, to solve the Helmholtz equation in order to learn a de-noised version ofthe input $B_1^{+}$ maps and estimate the object's EP. A random Fourierfeatures mapping was embedded into $B_1^{+}$ Net, to learn the high-frequencydetails of $B_1^{+}$ more efficiently. The two neural networks were trainedjointly by minimizing the combination of a physics-informed loss and a datamismatch loss via gradient descent. textit{Results:} We performed severalnumerical experiments, showing that PIFON-EPT could provide physicallyconsistent reconstructions of the EP and transmit field. Even when only $50%$of the noisy MR measurements were used as inputs, our method could stillreconstruct the EP and transmit field with average error $2.49%$, $4.09%$ and$0.32%$ for the relative permittivity, conductivity and $B_{1}^{+}$,respectively, over the entire volume of the phantom. The generalized version ofPIFON-EPT that accounts for gradients of EP yielded accurate results at theinterface between regions of different EP values without requiring any boundaryconditions. textit{Conclusion:} This work demonstrated the feasibility ofPIFON-EPT, suggesting it could be an accurate and effective method for EPestimation. textit{Significance:} PIFON-EPT can efficiently de-noise $B_1^{+}$maps, which has the potential to improve other MR-based EPT techniques.Furthermore, PIFON-EPT is the first technique that can reconstruct EP and$B_{1}^{+}$ simultaneously from incomplete noisy MR measurements.", "output": "PIFON-EPT: MR-Based Electrical Property Tomography Using Physics-Informed Fourier Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Forecasting the water level of the Han river is important to control trafficand avoid natural disasters. There are many variables related to the Han riverand they are intricately connected. In this work, we propose a noveltransformer that exploits the causal relationship based on the prior knowledgeamong the variables and forecasts the water level at the Jamsu bridge in theHan river. Our proposed model considers both spatial and temporal causation byformalizing the causal structure as a multilayer network and using maskingmethods. Due to this approach, we can have interpretability that consistentwith prior knowledge. In real data analysis, we use the Han river dataset from2016 to 2021 and compare the proposed model with deep learning models.", "output": "Interpretable Water Level Forecaster with Spatiotemporal Causal Attention Mechanisms."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Artificial intelligence-based methods have generated substantial interest innuclear medicine. An area of significant interest has been using deep-learning(DL)-based approaches for denoising images acquired with lower doses, shorteracquisition times, or both. Objective evaluation of these approaches isessential for clinical application. DL-based approaches for denoisingnuclear-medicine images have typically been evaluated using fidelity-basedfigures of merit (FoMs) such as RMSE and SSIM. However, these images areacquired for clinical tasks and thus should be evaluated based on theirperformance in these tasks. Our objectives were to (1) investigate whetherevaluation with these FoMs is consistent with objective clinical-task-basedevaluation; (2) provide a theoretical analysis for determining the impact ofdenoising on signal-detection tasks; (3) demonstrate the utility of virtualclinical trials (VCTs) to evaluate DL-based methods. A VCT to evaluate aDL-based method for denoising myocardial perfusion SPECT (MPS) images wasconducted. The impact of DL-based denoising was evaluated using fidelity-basedFoMs and AUC, which quantified performance on detecting perfusion defects inMPS images as obtained using a model observer with anthropomorphic channels.Based on fidelity-based FoMs, denoising using the considered DL-based methodled to significantly superior performance. However, based on ROC analysis,denoising did not improve, and in fact, often degraded detection-taskperformance. The results motivate the need for objective task-based evaluationof DL-based denoising approaches. Further, this study shows how VCTs provide amechanism to conduct such evaluations using VCTs. Finally, our theoreticaltreatment reveals insights into the reasons for the limited performance of thedenoising approach.", "output": "Need for Objective Task-based Evaluation of Deep Learning-Based Denoising Methods: A Study in the Context of Myocardial Perfusion SPECT."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep Learning (DL) is one of the most popular research topics in machinelearning and DL-driven image recognition systems have developed rapidly. Recentresearch has employed metamorphic testing (MT) to detect misclassified images.Most of them discuss metamorphic relations (MR), with limited attention givento which regions should be transformed. We focus on the fact that there aresensitive regions where even small transformations can easily change theprediction results and propose an MT framework that efficiently tests forregions prone to misclassification by transforming these sensitive regions. Ourevaluation demonstrated that the sensitive regions can be specified byExplainable AI (XAI) and our framework effectively detects faults.", "output": "Sensitive Region-based Metamorphic Testing Framework using Explainable AI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The quadratic computational complexity to the number of tokens limits thepractical applications of Vision Transformers (ViTs). Several works propose toprune redundant tokens to achieve efficient ViTs. However, these methodsgenerally suffer from (i) dramatic accuracy drops, (ii) application difficultyin the local vision transformer, and (iii) non-general-purpose networks fordownstream tasks. In this work, we propose a novel Semantic Token ViT (STViT),for efficient global and local vision transformers, which can also be revisedto serve as backbone for downstream tasks. The semantic tokens representcluster centers, and they are initialized by pooling image tokens in space andrecovered by attention, which can adaptively represent global or local semanticinformation. Due to the cluster properties, a few semantic tokens can attainthe same effect as vast image tokens, for both global and local visiontransformers. For instance, only 16 semantic tokens on DeiT-(Tiny,Small,Base)can achieve the same accuracy with more than 100% inference speed improvementand nearly 60% FLOPs reduction; on Swin-(Tiny,Small,Base), we can employ 16semantic tokens in each window to further speed it up by around 20% with slightaccuracy increase. Besides great success in image classification, we alsoextend our method to video recognition. In addition, we design aSTViT-R(ecover) network to restore the detailed spatial information based onthe STViT, making it work for downstream tasks, which is powerless for previoustoken sparsification methods. Experiments demonstrate that our method canachieve competitive results compared to the original networks in objectdetection and instance segmentation, with over 30% FLOPs reduction forbackbone. Code is available at <a href=\" http URL</a>", "output": "Making Vision Transformers Efficient from A Token Sparsification View."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In contrast to the natural capabilities of humans to learn new tasks in asequential fashion, neural networks are known to suffer from catastrophicforgetting, where the model's performances on old tasks drop dramatically afterbeing optimized for a new task. Since then, the continual learning (CL)community has proposed several solutions aiming to equip the neural networkwith the ability to learn the current task (plasticity) while still achievinghigh accuracy on the previous tasks (stability). Despite remarkableimprovements, the plasticity-stability trade-off is still far from being solvedand its underlying mechanism is poorly understood. In this work, we proposeAuxiliary Network Continual Learning (ANCL), a novel method that applies anadditional auxiliary network which promotes plasticity to the continuallylearned model which mainly focuses on stability. More concretely, the proposedframework materializes in a regularizer that naturally interpolates betweenplasticity and stability, surpassing strong baselines on task incremental andclass incremental scenarios. Through extensive analyses on ANCL solutions, weidentify some essential principles beneath the stability-plasticity trade-off.", "output": "Achieving a Better Stability-Plasticity Trade-off via Auxiliary Networks in Continual Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Determining clinically relevant physiological states from multivariate timeseries data with missing values is essential for providing appropriatetreatment for acute conditions such as Traumatic Brain Injury (TBI),respiratory failure, and heart failure. Utilizing non-temporal clustering ordata imputation and aggregation techniques may lead to loss of valuableinformation and biased analyses. In our study, we apply the SLAC-Timealgorithm, an innovative self-supervision-based approach that maintains dataintegrity by avoiding imputation or aggregation, offering a more usefulrepresentation of acute patient states. By using SLAC-Time to cluster data in alarge research dataset, we identified three distinct TBI physiological statesand their specific feature profiles. We employed various clustering evaluationmetrics and incorporated input from a clinical domain expert to validate andinterpret the identified physiological states. Further, we discovered howspecific clinical events and interventions can influence patient states andstate transitions.", "output": "Identifying TBI Physiological States by Clustering of Multivariate Clinical Time-Series."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, a plethora of spectral graph neural networks (GNN) methodshave utilized polynomial basis with learnable coefficients to achieve top-tierperformances on many node-level tasks. Although various kinds of polynomialbases have been explored, each such method adopts a fixed polynomial basiswhich might not be the optimal choice for the given graph. Besides, we identifythe so-called over-passing issue of these methods and show that it is somewhatrooted in their less-principled regularization strategy and unnormalized basis.In this paper, we make the first attempts to address these two issues.Leveraging Jacobi polynomials, we design a novel spectral GNN, LON-GNN, withLearnable OrthoNormal bases and prove that regularizing coefficients becomesequivalent to regularizing the norm of learned filter function now. We conductextensive experiments on diverse graph datasets to evaluate the fitting andgeneralization capability of LON-GNN, where the results imply its superiority.", "output": "LON-GNN: Spectral GNNs with Learnable Orthonormal Basis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Major depressive disorder (MDD) is a heterogeneous condition; multipleunderlying neurobiological substrates could be associated with treatmentresponse variability. Understanding the sources of this variability andpredicting outcomes has been elusive. Machine learning has shown promise inpredicting treatment response in MDD, but one limitation has been the lack ofclinical interpretability of machine learning models. We analyzed data from sixclinical trials of pharmacological treatment for depression (total n = 5438)using the Differential Prototypes Neural Network (DPNN), a neural network modelthat derives patient prototypes which can be used to derive treatment-relevantpatient clusters while learning to generate probabilities for differentialtreatment response. A model classifying remission and outputting individualremission probabilities for five first-line monotherapies and three combinationtreatments was trained using clinical and demographic data. Model validity andclinical utility were measured based on area under the curve (AUC) and expectedimprovement in sample remission rate with model-guided treatment, respectively.Post-hoc analyses yielded clusters (subgroups) based on patient prototypeslearned during training. Prototypes were evaluated for interpretability byassessing differences in feature distributions and treatment-specific outcomes.A 3-prototype model achieved an AUC of 0.66 and an expected absoluteimprovement in population remission rate compared to the sample remission rate.We identified three treatment-relevant patient clusters which were clinicallyinterpretable. It is possible to produce novel treatment-relevant patientprofiles using machine learning models; doing so may improve precision medicinefor depression. Note: This model is not currently the subject of any activeclinical trials and is not intended for clinical use.", "output": "Towards Outcome-Driven Patient Subgroups: A Machine Learning Analysis Across Six Depression Treatment Studies."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The success of existing multi-view clustering relies on the assumption ofsample integrity across multiple views. However, in real-world scenarios,samples of multi-view are partially available due to data corruption or sensorfailure, which leads to incomplete multi-view clustering study (IMVC). Althoughseveral attempts have been proposed to address IMVC, they suffer from thefollowing drawbacks: i) Existing methods mainly adopt cross-view contrastivelearning forcing the representations of each sample across views to be exactlythe same, which might ignore view discrepancy and flexibility inrepresentations; ii) Due to the absence of non-observed samples across multipleviews, the obtained prototypes of clusters might be unaligned and biased,leading to incorrect fusion. To address the above issues, we propose aCross-view Partial Sample and Prototype Alignment Network (CPSPAN) for DeepIncomplete Multi-view Clustering. Firstly, unlike existing contrastive-basedmethods, we adopt pair-observed data alignment as 'proxy supervised signals' toguide instance-to-instance correspondence construction among views. Then,regarding of the shifted prototypes in IMVC, we further propose a prototypealignment module to achieve incomplete distribution calibration across views.Extensive experimental results showcase the effectiveness of our proposedmodules, attaining noteworthy performance improvements when compared toexisting IMVC competitors on benchmark datasets.", "output": "Deep Incomplete Multi-view Clustering with Cross-view Partial Sample and Prototype Alignment."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Road network digital twins (RNDTs) play a critical role in the development ofnext-generation intelligent transportation systems, enabling more precisetraffic planning and control. To support just-in-time (JIT) decision making,RNDTs require a model that dynamically learns the traffic patterns from onlinesensor data and generates high-fidelity simulation results. Although currenttraffic prediction techniques based on graph neural networks have achievedstate-of-the-art performance, these techniques only predict future traffic bymining correlations in historical traffic data, disregarding the causes oftraffic generation, such as traffic demands and route selection. Therefore,their performance is unreliable for JIT decision making. To fill this gap, weintroduce a novel deep learning framework called TraffNet that learns thecausality of traffic volume from vehicle trajectory data. First, we use aheterogeneous graph to represent the road network, allowing the model toincorporate causal features of traffic volumes. Next, motivated by the trafficdomain knowledge, we propose a traffic causality learning method to learn anembedding vector that encodes travel demands and path-level dependencies foreach road segment. Then, we model temporal dependencies to match the underlyingprocess of traffic generation. Finally, the experiments verify the utility ofTraffNet. The code of TraffNet is available at", "output": "TraffNet: Learning Causality of Traffic Generation for Road Network Digital Twins."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The increasingly deeper neural networks hinder the democratization ofprivacy-enhancing distributed learning, such as federated learning (FL), toresource-constrained devices. To overcome this challenge, in this paper, weadvocate the integration of edge computing paradigm and parallel split learning(PSL), allowing multiple client devices to offload substantial trainingworkloads to an edge server via layer-wise model split. By observing thatexisting PSL schemes incur excessive training latency and large volume of datatransmissions, we propose an innovative PSL framework, namely, efficientparallel split learning (EPSL), to accelerate model training. To be specific,EPSL parallelizes client-side model training and reduces the dimension of localgradients for back propagation (BP) via last-layer gradient aggregation,leading to a significant reduction in server-side training and communicationlatency. Moreover, by considering the heterogeneous channel conditions andcomputing capabilities at client devices, we jointly optimize subchannelallocation, power control, and cut layer selection to minimize the per-roundlatency. Simulation results show that the proposed EPSL framework significantlydecreases the training latency needed to achieve a target accuracy comparedwith the state-of-the-art benchmarks, and the tailored resource management andlayer split strategy can considerably reduce latency than the counterpartwithout optimization.", "output": "Efficient Parallel Split Learning over Resource-constrained Wireless Edge Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, the authors develop regression approaches based on deeplearning to perform thread density estimation for plain weave canvas analysis.Previous approaches were based on Fourier analysis, which is quite robust forsome scenarios but fails in some others, in machine learning tools, thatinvolve pre-labeling of the painting at hand, or the segmentation of threadcrossing points, that provides good estimations in all scenarios with no needof pre-labeling. The segmentation approach is time-consuming as the estimationof the densities is performed after locating the crossing points. In this novelproposal, we avoid this step by computing the density of threads directly fromthe image with a regression deep learning model. We also incorporate someimprovements in the initial preprocessing of the input image with an impact onthe final error. Several models are proposed and analyzed to retain the bestone. Furthermore, we further reduce the density estimation error by introducinga semi-supervised approach. The performance of our novel algorithm is analyzedwith works by Ribera, Vel'azquez, and Poussin where we compare our results tothe ones of previous approaches. Finally, the method is put into practice tosupport the change of authorship or a masterpiece at the Museo del Prado.", "output": "Thread Counting in Plain Weave for Old Paintings Using Semi-Supervised Regression Deep Learning Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural Radiance Fields (NeRFs) learn to represent a 3D scene from just a setof registered images. Increasing sizes of a scene demands more complexfunctions, typically represented by neural networks, to capture all details.Training and inference then involves querying the neural network millions oftimes per image, which becomes impractically slow. Since such complex functionscan be replaced by multiple simpler functions to improve speed, we show that ahierarchy of Voronoi diagrams is a suitable choice to partition the scene. Byequipping each Voronoi cell with its own NeRF, our approach is able to quicklylearn a scene representation. We propose an intuitive partitioning of the spacethat increases quality gains during training by distributing information evenlyamong the networks and avoids artifacts through a top-down adaptive refinement.Our framework is agnostic to the underlying NeRF method and easy to implement,which allows it to be applied to various NeRF variants for improved learningand rendering speeds.", "output": "Adaptive Voronoi NeRFs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We show how any PAC learning algorithm that works under the uniformdistribution can be transformed, in a blackbox fashion, into one that worksunder an arbitrary and unknown distribution $mathcal{D}$. The efficiency ofour transformation scales with the inherent complexity of $mathcal{D}$,running in $mathrm{poly}(n, (md)^d)$ time for distributions over ${pm 1}^n$whose pmfs are computed by depth-$d$ decision trees, where $m$ is the samplecomplexity of the original algorithm. For monotone distributions ourtransformation uses only samples from $mathcal{D}$, and for general ones ituses subcube conditioning samples.A key technical ingredient is an algorithm which, given the aforementionedaccess to $mathcal{D}$, produces an optimal decision tree decomposition of$mathcal{D}$: an approximation of $mathcal{D}$ as a mixture of uniformdistributions over disjoint subcubes. With this decomposition in hand, we runthe uniform-distribution learner on each subcube and combine the hypothesesusing the decision tree. This algorithmic decomposition lemma also yields newalgorithms for learning decision tree distributions with runtimes thatexponentially improve on the prior state of the art -- results of independentinterest in distribution learning.", "output": "Lifting uniform learners via distributional decomposition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated learning is a popular collaborative learning approach that enablesclients to train a global model without sharing their local data. Verticalfederated learning (VFL) deals with scenarios in which the data on clients havedifferent feature spaces but share some overlapping samples. Existing VFLapproaches suffer from high communication costs and cannot deal efficientlywith limited overlapping samples commonly seen in the real world. We propose apractical vertical federated learning (VFL) framework called textbf{one-shotVFL} that can solve the communication bottleneck and the problem of limitedoverlapping samples simultaneously based on semi-supervised learning. We alsopropose textbf{few-shot VFL} to improve the accuracy further with just onemore communication round between the server and the clients. In our proposedframework, the clients only need to communicate with the server once or only afew times. We evaluate the proposed VFL framework on both image and tabulardatasets. Our methods can improve the accuracy by more than 46.5% and reducethe communication cost by more than 330$times$ compared with state-of-the-artVFL methods when evaluated on CIFAR-10. Our code will be made publiclyavailable at url{", "output": "Communication-Efficient Vertical Federated Learning with Limited Overlapping Samples."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "PCA-Net is a recently proposed neural operator architecture which combinesprincipal component analysis (PCA) with neural networks to approximateoperators between infinite-dimensional function spaces. The present workdevelops approximation theory for this approach, improving and significantlyextending previous work in this direction: First, a novel universalapproximation result is derived, under minimal assumptions on the underlyingoperator and the data-generating distribution. Then, two potential obstacles toefficient operator learning with PCA-Net are identified, and made precisethrough lower complexity bounds; the first relates to the complexity of theoutput distribution, measured by a slow decay of the PCA eigenvalues. The otherobstacle relates to the inherent complexity of the space of operators betweeninfinite-dimensional input and output spaces, resulting in a rigorous andquantifiable statement of the curse of dimensionality. In addition to theselower bounds, upper complexity bounds are derived. A suitable smoothnesscriterion is shown to ensure an algebraic decay of the PCA eigenvalues.Furthermore, it is shown that PCA-Net can overcome the general curse ofdimensionality for specific operators of interest, arising from the Darcy flowand the Navier-Stokes equations.", "output": "Operator learning with PCA-Net: upper and lower complexity bounds."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We investigate semantic guarantees of private learning algorithms for theirresilience to training Data Reconstruction Attacks (DRAs) by informedadversaries. To this end, we derive non-asymptotic minimax lower bounds on theadversary's reconstruction error against learners that satisfy differentialprivacy (DP) and metric differential privacy (mDP). Furthermore, we demonstratethat our lower bound analysis for the latter also covers the high dimensionalregime, wherein, the input data dimensionality may be larger than theadversary's query budget. Motivated by the theoretical improvements conferredby metric DP, we extend the privacy analysis of popular deep learningalgorithms such as DP-SGD and Projected Noisy SGD to cover the broader notionof metric differential privacy.", "output": "Non-Asymptotic Lower Bounds For Training Data Reconstruction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The development of language models have moved from encoder-decoder todecoder-only designs. In addition, the common knowledge has it that the twomost popular multimodal tasks, the generative and contrastive tasks, tend toconflict with one another, are hard to accommodate in one architecture, andfurther need complex adaptations for downstream tasks. We propose a novelparadigm of training with a decoder-only model for multimodal tasks, which issurprisingly effective in jointly learning of these disparate vision-languagetasks. This is done with a simple model, called MaMMUT. It consists of a singlevision encoder and a text decoder, and is able to accommodate contrastive andgenerative learning by a novel two-pass approach on the text decoder. Wedemonstrate that joint learning of these diverse objectives is simple,effective, and maximizes the weight-sharing of the model across these tasks.Furthermore, the same architecture enables straightforward extensions toopen-vocabulary object detection and video-language tasks. The model tackles adiverse range of tasks, while being modest in capacity. Our model achieves thestate of the art on image-text and text-image retrieval, video questionanswering and open-vocabulary detection tasks, outperforming much larger andmore extensively trained foundational models. It shows very competitive resultson VQA and Video Captioning, especially considering its capacity. Ablationsconfirm the flexibility and advantages of our approach.", "output": "MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks."}]